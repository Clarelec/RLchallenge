28-Feb-25 11:06:48 - agent.DQN.DQN - INFO - device is cpu
28-Feb-25 11:06:49 - numexpr.utils - INFO - Note: NumExpr detected 22 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
28-Feb-25 11:06:49 - numexpr.utils - INFO - NumExpr defaulting to 8 threads.
28-Feb-25 11:06:50 - __main__ - INFO - Libraries imported
28-Feb-25 11:06:50 - __main__ - INFO - Device: cpu
28-Feb-25 11:06:50 - __main__ - INFO - Starting training of DQN2 agent
28-Feb-25 11:06:51 - __main__ - INFO - Environment initialized
28-Feb-25 11:06:51 - agent.DQN.DQN - INFO - QNetwork initialized with 10 observations and 9 actions
28-Feb-25 11:06:51 - agent.DQN.DQN - INFO - QNetwork initialized with 10 observations and 9 actions
28-Feb-25 11:06:51 - __main__ - INFO - Q-Networks initialized and synchronized
28-Feb-25 11:06:52 - __main__ - INFO - Optimizer, LR scheduler, and loss function initialized
28-Feb-25 11:06:52 - __main__ - INFO - Epsilon-greedy strategy initialized
28-Feb-25 11:06:52 - __main__ - INFO - Replay buffer initialized
28-Feb-25 11:06:52 - __main__ - INFO - Training DQN2 agent
28-Feb-25 11:06:52 - agent.DQN.DQN - INFO - episode 1 step 128 reward tensor([-7.3094]) loss 283.1352844238281 epsilon 0.82
28-Feb-25 11:06:52 - agent.DQN.DQN - INFO - episode 1 step 129 reward tensor([-7.3009]) loss 254.67042541503906 epsilon 0.82
28-Feb-25 11:06:52 - agent.DQN.DQN - INFO - episode 1 step 130 reward tensor([-7.2943]) loss 173.04620361328125 epsilon 0.82
28-Feb-25 11:06:52 - agent.DQN.DQN - INFO - episode 1 step 131 reward tensor([-7.2886]) loss 152.1841583251953 epsilon 0.82
28-Feb-25 11:06:52 - agent.DQN.DQN - INFO - episode 1 step 132 reward tensor([-7.2832]) loss 57.84374237060547 epsilon 0.82
28-Feb-25 11:06:52 - agent.DQN.DQN - INFO - episode 1 step 133 reward tensor([-7.2782]) loss 16.16672706604004 epsilon 0.82
28-Feb-25 11:06:52 - agent.DQN.DQN - INFO - episode 1 step 134 reward tensor([-7.2726]) loss 37.365379333496094 epsilon 0.82
28-Feb-25 11:06:52 - agent.DQN.DQN - INFO - episode 1 step 135 reward tensor([-7.2672]) loss 60.99375915527344 epsilon 0.82
28-Feb-25 11:06:52 - agent.DQN.DQN - INFO - episode 1 step 136 reward tensor([-7.2639]) loss 55.279693603515625 epsilon 0.82
28-Feb-25 11:06:52 - agent.DQN.DQN - INFO - episode 1 step 137 reward tensor([-7.2637]) loss 40.839717864990234 epsilon 0.82
28-Feb-25 11:06:52 - agent.DQN.DQN - INFO - episode 1 step 138 reward tensor([-7.2682]) loss 24.578231811523438 epsilon 0.82
28-Feb-25 11:06:52 - agent.DQN.DQN - INFO - episode 1 step 139 reward tensor([-7.2782]) loss 14.102188110351562 epsilon 0.82
28-Feb-25 11:06:52 - agent.DQN.DQN - INFO - episode 1 step 140 reward tensor([-7.2940]) loss 10.304736137390137 epsilon 0.82
28-Feb-25 11:06:52 - agent.DQN.DQN - INFO - episode 1 step 141 reward tensor([-7.3171]) loss 10.178464889526367 epsilon 0.82
28-Feb-25 11:06:52 - agent.DQN.DQN - INFO - episode 1 step 142 reward tensor([-7.3489]) loss 8.493805885314941 epsilon 0.82
28-Feb-25 11:06:52 - agent.DQN.DQN - INFO - episode 1 step 143 reward tensor([-7.3898]) loss 8.709443092346191 epsilon 0.82
28-Feb-25 11:06:52 - agent.DQN.DQN - INFO - episode 1 step 144 reward tensor([-7.4405]) loss 9.050422668457031 epsilon 0.82
28-Feb-25 11:06:52 - agent.DQN.DQN - INFO - episode 1 step 145 reward tensor([-7.5013]) loss 10.673576354980469 epsilon 0.82
28-Feb-25 11:06:52 - agent.DQN.DQN - INFO - episode 1 step 146 reward tensor([-7.5723]) loss 10.056797981262207 epsilon 0.82
28-Feb-25 11:06:52 - agent.DQN.DQN - INFO - episode 1 step 147 reward tensor([-7.6524]) loss 10.2388277053833 epsilon 0.82
28-Feb-25 11:06:52 - agent.DQN.DQN - INFO - episode 1 step 148 reward tensor([-7.7413]) loss 7.841621398925781 epsilon 0.82
28-Feb-25 11:06:52 - agent.DQN.DQN - INFO - episode 1 step 149 reward tensor([-7.8355]) loss 5.832371234893799 epsilon 0.82
28-Feb-25 11:06:52 - agent.DQN.DQN - INFO - episode 1 step 150 reward tensor([-7.9376]) loss 4.145933151245117 epsilon 0.82
28-Feb-25 11:06:52 - agent.DQN.DQN - INFO - episode 1 step 151 reward tensor([-8.0474]) loss 15.566131591796875 epsilon 0.82
28-Feb-25 11:06:52 - agent.DQN.DQN - INFO - episode 1 step 152 reward tensor([-8.1642]) loss 12.729419708251953 epsilon 0.82
28-Feb-25 11:06:52 - agent.DQN.DQN - INFO - episode 1 step 153 reward tensor([-8.2879]) loss 7.604048252105713 epsilon 0.82
28-Feb-25 11:06:53 - agent.DQN.DQN - INFO - episode 1 step 154 reward tensor([-8.4175]) loss 5.2380571365356445 epsilon 0.82
28-Feb-25 11:06:53 - agent.DQN.DQN - INFO - episode 1 step 155 reward tensor([-8.5527]) loss 3.2069969177246094 epsilon 0.82
28-Feb-25 11:06:53 - agent.DQN.DQN - INFO - episode 1 step 156 reward tensor([-8.6925]) loss 2.7535557746887207 epsilon 0.82
28-Feb-25 11:06:53 - agent.DQN.DQN - INFO - episode 1 step 157 reward tensor([-8.8358]) loss 4.034678936004639 epsilon 0.82
28-Feb-25 11:06:53 - agent.DQN.DQN - INFO - episode 1 step 158 reward tensor([-8.9828]) loss 5.053277015686035 epsilon 0.82
28-Feb-25 11:06:53 - agent.DQN.DQN - INFO - episode 1 step 159 reward tensor([-9.1317]) loss 5.954695701599121 epsilon 0.82
28-Feb-25 11:06:53 - agent.DQN.DQN - INFO - episode 1 step 160 reward tensor([-9.2830]) loss 6.529600143432617 epsilon 0.82
28-Feb-25 11:06:53 - agent.DQN.DQN - INFO - episode 1 step 161 reward tensor([-9.4352]) loss 4.977855682373047 epsilon 0.82
28-Feb-25 11:06:53 - agent.DQN.DQN - INFO - episode 1 step 162 reward tensor([-9.5884]) loss 3.846248149871826 epsilon 0.82
28-Feb-25 11:06:53 - agent.DQN.DQN - INFO - episode 1 step 163 reward tensor([-9.7418]) loss 3.041459798812866 epsilon 0.82
28-Feb-25 11:06:53 - agent.DQN.DQN - INFO - episode 1 step 164 reward tensor([-9.8948]) loss 2.4390499591827393 epsilon 0.82
28-Feb-25 11:06:53 - agent.DQN.DQN - INFO - episode 1 step 165 reward tensor([-10.0469]) loss 1.9358179569244385 epsilon 0.82
28-Feb-25 11:06:53 - agent.DQN.DQN - INFO - episode 1 step 166 reward tensor([-10.1973]) loss 1.691290020942688 epsilon 0.82
28-Feb-25 11:06:53 - agent.DQN.DQN - INFO - episode 1 step 167 reward tensor([-10.3460]) loss 1.6352899074554443 epsilon 0.82
28-Feb-25 11:06:53 - agent.DQN.DQN - INFO - episode 1 step 168 reward tensor([-10.4907]) loss 1.497950553894043 epsilon 0.82
28-Feb-25 11:06:53 - agent.DQN.DQN - INFO - episode 1 step 169 reward tensor([-10.6292]) loss 1.5484083890914917 epsilon 0.82
28-Feb-25 11:06:53 - agent.DQN.DQN - INFO - episode 1 step 170 reward tensor([-10.7596]) loss 1.417041301727295 epsilon 0.82
28-Feb-25 11:06:53 - agent.DQN.DQN - INFO - episode 1 step 171 reward tensor([-10.8845]) loss 1.623832106590271 epsilon 0.82
28-Feb-25 11:06:53 - agent.DQN.DQN - INFO - episode 1 step 172 reward tensor([-11.0080]) loss 1.7592989206314087 epsilon 0.82
28-Feb-25 11:06:53 - agent.DQN.DQN - INFO - episode 1 step 173 reward tensor([-11.1318]) loss 2.1025593280792236 epsilon 0.82
28-Feb-25 11:06:53 - agent.DQN.DQN - INFO - episode 1 step 174 reward tensor([-11.2554]) loss 1.7781226634979248 epsilon 0.82
28-Feb-25 11:06:53 - agent.DQN.DQN - INFO - episode 1 step 175 reward tensor([-11.3800]) loss 1.5729031562805176 epsilon 0.82
28-Feb-25 11:06:53 - agent.DQN.DQN - INFO - episode 1 step 176 reward tensor([-11.5057]) loss 1.2598719596862793 epsilon 0.82
28-Feb-25 11:06:53 - agent.DQN.DQN - INFO - episode 1 step 177 reward tensor([-11.6320]) loss 1.00417160987854 epsilon 0.82
28-Feb-25 11:06:53 - agent.DQN.DQN - INFO - episode 1 step 178 reward tensor([-11.7587]) loss 0.8947960138320923 epsilon 0.82
28-Feb-25 11:06:53 - agent.DQN.DQN - INFO - episode 1 step 179 reward tensor([-11.8862]) loss 0.8454562425613403 epsilon 0.82
28-Feb-25 11:06:53 - agent.DQN.DQN - INFO - episode 1 step 180 reward tensor([-12.0149]) loss 1.078763723373413 epsilon 0.82
28-Feb-25 11:06:53 - agent.DQN.DQN - INFO - episode 1 step 181 reward tensor([-12.1414]) loss 30.167613983154297 epsilon 0.82
28-Feb-25 11:06:53 - agent.DQN.DQN - INFO - episode 1 step 182 reward tensor([-12.2693]) loss 24.849885940551758 epsilon 0.82
28-Feb-25 11:06:53 - agent.DQN.DQN - INFO - episode 1 step 183 reward tensor([-12.3947]) loss 20.880760192871094 epsilon 0.82
28-Feb-25 11:06:53 - agent.DQN.DQN - INFO - episode 1 step 184 reward tensor([-12.5213]) loss 12.60181713104248 epsilon 0.82
28-Feb-25 11:06:53 - agent.DQN.DQN - INFO - episode 1 step 185 reward tensor([-12.6495]) loss 9.650511741638184 epsilon 0.82
28-Feb-25 11:06:53 - agent.DQN.DQN - INFO - episode 1 step 186 reward tensor([-12.7797]) loss 4.70549201965332 epsilon 0.82
28-Feb-25 11:06:53 - agent.DQN.DQN - INFO - episode 1 step 187 reward tensor([-12.9113]) loss 3.670330762863159 epsilon 0.82
28-Feb-25 11:06:53 - agent.DQN.DQN - INFO - episode 1 step 188 reward tensor([-13.0452]) loss 3.003488779067993 epsilon 0.82
28-Feb-25 11:06:53 - agent.DQN.DQN - INFO - episode 1 step 189 reward tensor([-13.1808]) loss 3.272423505783081 epsilon 0.82
28-Feb-25 11:06:53 - agent.DQN.DQN - INFO - episode 1 step 190 reward tensor([-13.3175]) loss 3.489243745803833 epsilon 0.82
28-Feb-25 11:06:53 - agent.DQN.DQN - INFO - episode 1 step 191 reward tensor([-13.4545]) loss 4.564062118530273 epsilon 0.82
28-Feb-25 11:06:53 - agent.DQN.DQN - INFO - episode 1 step 192 reward tensor([-13.5915]) loss 5.638676643371582 epsilon 0.82
28-Feb-25 11:06:53 - agent.DQN.DQN - INFO - episode 1 step 193 reward tensor([-13.7289]) loss 4.181431293487549 epsilon 0.82
28-Feb-25 11:06:53 - agent.DQN.DQN - INFO - episode 1 step 194 reward tensor([-13.8664]) loss 4.602838516235352 epsilon 0.82
28-Feb-25 11:06:53 - agent.DQN.DQN - INFO - episode 1 step 195 reward tensor([-14.0036]) loss 3.8718745708465576 epsilon 0.82
28-Feb-25 11:06:53 - agent.DQN.DQN - INFO - episode 1 step 196 reward tensor([-14.1400]) loss 4.628209114074707 epsilon 0.82
28-Feb-25 11:06:53 - agent.DQN.DQN - INFO - episode 1 step 197 reward tensor([-14.2756]) loss 3.541839599609375 epsilon 0.82
28-Feb-25 11:06:53 - agent.DQN.DQN - INFO - episode 1 step 198 reward tensor([-14.4101]) loss 2.8494997024536133 epsilon 0.82
28-Feb-25 11:06:53 - agent.DQN.DQN - INFO - episode 1 step 199 reward tensor([-14.5395]) loss 2.617788314819336 epsilon 0.82
28-Feb-25 11:06:53 - agent.DQN.DQN - INFO - episode 1 step 200 reward tensor([-14.6680]) loss 2.769521713256836 epsilon 0.82
28-Feb-25 11:06:53 - agent.DQN.DQN - INFO - episode 1 step 201 reward tensor([-14.7955]) loss 3.1292150020599365 epsilon 0.82
28-Feb-25 11:06:53 - agent.DQN.DQN - INFO - episode 1 step 202 reward tensor([-14.9231]) loss 1.8738222122192383 epsilon 0.82
28-Feb-25 11:06:53 - agent.DQN.DQN - INFO - episode 1 step 203 reward tensor([-15.0462]) loss 1.2691038846969604 epsilon 0.82
28-Feb-25 11:06:53 - agent.DQN.DQN - INFO - episode 1 step 204 reward tensor([-15.1691]) loss 1.1676907539367676 epsilon 0.82
28-Feb-25 11:06:53 - agent.DQN.DQN - INFO - episode 1 step 205 reward tensor([-15.2910]) loss 1.3686186075210571 epsilon 0.82
28-Feb-25 11:06:53 - agent.DQN.DQN - INFO - episode 1 step 206 reward tensor([-15.4076]) loss 1.0125741958618164 epsilon 0.82
28-Feb-25 11:06:53 - agent.DQN.DQN - INFO - episode 1 step 207 reward tensor([-15.5230]) loss 1.1729062795639038 epsilon 0.82
28-Feb-25 11:06:53 - agent.DQN.DQN - INFO - episode 1 step 208 reward tensor([-15.6330]) loss 1.3380775451660156 epsilon 0.82
28-Feb-25 11:06:53 - agent.DQN.DQN - INFO - episode 1 step 209 reward tensor([-15.7384]) loss 1.4867537021636963 epsilon 0.82
28-Feb-25 11:06:53 - agent.DQN.DQN - INFO - episode 1 step 210 reward tensor([-15.8400]) loss 1.2551823854446411 epsilon 0.82
28-Feb-25 11:06:53 - agent.DQN.DQN - INFO - episode 1 step 211 reward tensor([-15.9408]) loss 42.21726608276367 epsilon 0.82
28-Feb-25 11:06:53 - agent.DQN.DQN - INFO - episode 1 step 212 reward tensor([-16.0399]) loss 43.84861755371094 epsilon 0.82
28-Feb-25 11:06:53 - agent.DQN.DQN - INFO - episode 1 step 213 reward tensor([-16.1350]) loss 36.95903778076172 epsilon 0.82
28-Feb-25 11:06:53 - agent.DQN.DQN - INFO - episode 1 step 214 reward tensor([-16.2211]) loss 35.44991683959961 epsilon 0.82
28-Feb-25 11:06:53 - agent.DQN.DQN - INFO - episode 1 step 215 reward tensor([-16.2921]) loss 29.534168243408203 epsilon 0.82
28-Feb-25 11:06:53 - agent.DQN.DQN - INFO - episode 1 step 216 reward tensor([-16.3437]) loss 22.401466369628906 epsilon 0.82
28-Feb-25 11:06:53 - agent.DQN.DQN - INFO - episode 1 step 217 reward tensor([-16.3761]) loss 17.203916549682617 epsilon 0.82
28-Feb-25 11:06:53 - agent.DQN.DQN - INFO - episode 1 step 218 reward tensor([-16.3971]) loss 12.01369857788086 epsilon 0.82
28-Feb-25 11:06:53 - agent.DQN.DQN - INFO - episode 1 step 219 reward tensor([-16.4146]) loss 8.7791748046875 epsilon 0.82
28-Feb-25 11:06:53 - agent.DQN.DQN - INFO - episode 1 step 220 reward tensor([-16.4313]) loss 6.077600479125977 epsilon 0.82
28-Feb-25 11:06:53 - agent.DQN.DQN - INFO - episode 1 step 221 reward tensor([-16.4464]) loss 4.518434047698975 epsilon 0.82
28-Feb-25 11:06:53 - agent.DQN.DQN - INFO - episode 1 step 222 reward tensor([-16.4593]) loss 3.5685160160064697 epsilon 0.82
28-Feb-25 11:06:53 - agent.DQN.DQN - INFO - episode 1 step 223 reward tensor([-16.4680]) loss 2.8380517959594727 epsilon 0.82
28-Feb-25 11:06:53 - agent.DQN.DQN - INFO - episode 1 step 224 reward tensor([-16.4750]) loss 4.417344093322754 epsilon 0.82
28-Feb-25 11:06:53 - agent.DQN.DQN - INFO - episode 1 step 225 reward tensor([-16.4801]) loss 3.396613121032715 epsilon 0.82
28-Feb-25 11:06:53 - agent.DQN.DQN - INFO - episode 1 step 226 reward tensor([-16.4827]) loss 3.7838423252105713 epsilon 0.82
28-Feb-25 11:06:53 - agent.DQN.DQN - INFO - episode 1 step 227 reward tensor([-16.4838]) loss 3.883650541305542 epsilon 0.82
28-Feb-25 11:06:53 - agent.DQN.DQN - INFO - episode 1 step 228 reward tensor([-16.4837]) loss 3.9782073497772217 epsilon 0.82
28-Feb-25 11:06:53 - agent.DQN.DQN - INFO - episode 1 step 229 reward tensor([-16.4832]) loss 4.212620258331299 epsilon 0.82
28-Feb-25 11:06:53 - agent.DQN.DQN - INFO - episode 1 step 230 reward tensor([-16.4824]) loss 4.999981880187988 epsilon 0.82
28-Feb-25 11:06:53 - agent.DQN.DQN - INFO - episode 1 step 231 reward tensor([-16.4817]) loss 4.3665995597839355 epsilon 0.82
28-Feb-25 11:06:53 - agent.DQN.DQN - INFO - episode 1 step 232 reward tensor([-16.4803]) loss 5.497279167175293 epsilon 0.82
28-Feb-25 11:06:53 - agent.DQN.DQN - INFO - episode 1 step 233 reward tensor([-16.4794]) loss 3.2721645832061768 epsilon 0.82
28-Feb-25 11:06:53 - agent.DQN.DQN - INFO - episode 1 step 234 reward tensor([-16.4792]) loss 2.693399667739868 epsilon 0.82
28-Feb-25 11:06:53 - agent.DQN.DQN - INFO - episode 1 step 235 reward tensor([-16.4795]) loss 4.044388294219971 epsilon 0.82
28-Feb-25 11:06:53 - agent.DQN.DQN - INFO - episode 1 step 236 reward tensor([-16.4805]) loss 3.7600009441375732 epsilon 0.82
28-Feb-25 11:06:53 - agent.DQN.DQN - INFO - episode 1 step 237 reward tensor([-16.4819]) loss 2.1021265983581543 epsilon 0.82
28-Feb-25 11:06:53 - agent.DQN.DQN - INFO - episode 1 step 238 reward tensor([-16.4840]) loss 2.5413153171539307 epsilon 0.82
28-Feb-25 11:06:53 - agent.DQN.DQN - INFO - episode 1 step 239 reward tensor([-16.4868]) loss 2.162240743637085 epsilon 0.82
28-Feb-25 11:06:53 - agent.DQN.DQN - INFO - episode 1 step 240 reward tensor([-16.4901]) loss 1.5941497087478638 epsilon 0.82
28-Feb-25 11:06:53 - agent.DQN.DQN - INFO - episode 1 step 241 reward tensor([-16.4942]) loss 54.261390686035156 epsilon 0.82
28-Feb-25 11:06:53 - agent.DQN.DQN - INFO - episode 1 step 242 reward tensor([-16.4990]) loss 49.833274841308594 epsilon 0.82
28-Feb-25 11:06:53 - agent.DQN.DQN - INFO - episode 1 step 243 reward tensor([-16.5046]) loss 59.67188262939453 epsilon 0.82
28-Feb-25 11:06:53 - agent.DQN.DQN - INFO - episode 1 step 244 reward tensor([-16.5111]) loss 53.04606246948242 epsilon 0.82
28-Feb-25 11:06:53 - agent.DQN.DQN - INFO - episode 1 step 245 reward tensor([-16.5184]) loss 47.416934967041016 epsilon 0.82
28-Feb-25 11:06:53 - agent.DQN.DQN - INFO - episode 1 step 246 reward tensor([-16.5267]) loss 42.52705383300781 epsilon 0.82
28-Feb-25 11:06:54 - agent.DQN.DQN - INFO - episode 1 step 247 reward tensor([-16.5360]) loss 40.42354202270508 epsilon 0.82
28-Feb-25 11:06:54 - agent.DQN.DQN - INFO - episode 1 step 248 reward tensor([-16.5463]) loss 33.13713073730469 epsilon 0.82
28-Feb-25 11:06:54 - agent.DQN.DQN - INFO - episode 1 step 249 reward tensor([-16.5577]) loss 27.959033966064453 epsilon 0.82
28-Feb-25 11:06:54 - agent.DQN.DQN - INFO - episode 1 step 250 reward tensor([-16.5703]) loss 26.788660049438477 epsilon 0.82
28-Feb-25 11:06:54 - agent.DQN.DQN - INFO - episode 1 step 251 reward tensor([-16.5840]) loss 21.2380428314209 epsilon 0.82
28-Feb-25 11:06:54 - agent.DQN.DQN - INFO - episode 1 step 252 reward tensor([-16.5990]) loss 16.267826080322266 epsilon 0.82
28-Feb-25 11:06:54 - agent.DQN.DQN - INFO - episode 1 step 253 reward tensor([-16.6152]) loss 10.780416488647461 epsilon 0.82
28-Feb-25 11:06:54 - agent.DQN.DQN - INFO - episode 1 step 254 reward tensor([-16.6328]) loss 9.810510635375977 epsilon 0.82
28-Feb-25 11:06:54 - agent.DQN.DQN - INFO - episode 1 step 255 reward tensor([-16.6517]) loss 8.726739883422852 epsilon 0.82
28-Feb-25 11:06:54 - agent.DQN.DQN - INFO - episode 1 step 256 reward tensor([-16.6721]) loss 6.337661266326904 epsilon 0.82
28-Feb-25 11:06:54 - agent.DQN.DQN - INFO - episode 1 step 257 reward tensor([-16.6938]) loss 5.422558307647705 epsilon 0.82
28-Feb-25 11:06:54 - agent.DQN.DQN - INFO - episode 1 step 258 reward tensor([-16.7171]) loss 3.3658530712127686 epsilon 0.82
28-Feb-25 11:06:54 - agent.DQN.DQN - INFO - episode 1 step 259 reward tensor([-16.7420]) loss 3.160764455795288 epsilon 0.82
28-Feb-25 11:06:54 - agent.DQN.DQN - INFO - episode 1 step 260 reward tensor([-16.7683]) loss 2.670182466506958 epsilon 0.82
28-Feb-25 11:06:54 - agent.DQN.DQN - INFO - episode 1 step 261 reward tensor([-16.7963]) loss 2.209434986114502 epsilon 0.82
28-Feb-25 11:06:54 - agent.DQN.DQN - INFO - episode 1 step 262 reward tensor([-16.8260]) loss 2.716966152191162 epsilon 0.82
28-Feb-25 11:06:54 - agent.DQN.DQN - INFO - episode 1 step 263 reward tensor([-16.8572]) loss 2.40837025642395 epsilon 0.82
28-Feb-25 11:06:54 - agent.DQN.DQN - INFO - episode 1 step 264 reward tensor([-16.8902]) loss 2.0572195053100586 epsilon 0.82
28-Feb-25 11:06:54 - agent.DQN.DQN - INFO - episode 1 step 265 reward tensor([-16.9249]) loss 2.6207897663116455 epsilon 0.82
28-Feb-25 11:06:54 - agent.DQN.DQN - INFO - episode 1 step 266 reward tensor([-16.9614]) loss 3.380676746368408 epsilon 0.82
28-Feb-25 11:06:54 - agent.DQN.DQN - INFO - episode 1 step 267 reward tensor([-16.9996]) loss 3.8484888076782227 epsilon 0.82
28-Feb-25 11:06:54 - agent.DQN.DQN - INFO - episode 1 step 268 reward tensor([-17.0396]) loss 3.8151345252990723 epsilon 0.82
28-Feb-25 11:06:54 - agent.DQN.DQN - INFO - episode 1 step 269 reward tensor([-17.0815]) loss 4.8770527839660645 epsilon 0.82
28-Feb-25 11:06:54 - agent.DQN.DQN - INFO - episode 1 step 270 reward tensor([-17.1251]) loss 3.2808244228363037 epsilon 0.82
28-Feb-25 11:06:54 - agent.DQN.DQN - INFO - episode 1 step 271 reward tensor([-17.1706]) loss 55.6727180480957 epsilon 0.82
28-Feb-25 11:06:54 - agent.DQN.DQN - INFO - episode 1 step 272 reward tensor([-17.2180]) loss 47.398406982421875 epsilon 0.82
28-Feb-25 11:06:54 - agent.DQN.DQN - INFO - episode 1 step 273 reward tensor([-17.2672]) loss 51.33659362792969 epsilon 0.82
28-Feb-25 11:06:54 - agent.DQN.DQN - INFO - episode 1 step 274 reward tensor([-17.3183]) loss 43.46458053588867 epsilon 0.82
28-Feb-25 11:06:54 - agent.DQN.DQN - INFO - episode 1 step 275 reward tensor([-17.3713]) loss 46.9248046875 epsilon 0.82
28-Feb-25 11:06:54 - agent.DQN.DQN - INFO - episode 1 step 276 reward tensor([-17.4261]) loss 33.473628997802734 epsilon 0.82
28-Feb-25 11:06:54 - agent.DQN.DQN - INFO - episode 1 step 277 reward tensor([-17.4829]) loss 32.51323318481445 epsilon 0.82
28-Feb-25 11:06:54 - agent.DQN.DQN - INFO - episode 1 step 278 reward tensor([-17.5415]) loss 26.469566345214844 epsilon 0.82
28-Feb-25 11:06:54 - agent.DQN.DQN - INFO - episode 1 step 279 reward tensor([-17.6020]) loss 22.465986251831055 epsilon 0.82
28-Feb-25 11:06:54 - agent.DQN.DQN - INFO - episode 1 step 280 reward tensor([-17.6644]) loss 16.472028732299805 epsilon 0.82
28-Feb-25 11:06:54 - agent.DQN.DQN - INFO - episode 1 step 281 reward tensor([-17.7287]) loss 14.381855010986328 epsilon 0.82
28-Feb-25 11:06:54 - agent.DQN.DQN - INFO - episode 1 step 282 reward tensor([-17.7948]) loss 10.560722351074219 epsilon 0.82
28-Feb-25 11:06:54 - agent.DQN.DQN - INFO - episode 1 step 283 reward tensor([-17.8627]) loss 7.39757776260376 epsilon 0.82
28-Feb-25 11:06:54 - agent.DQN.DQN - INFO - episode 1 step 284 reward tensor([-17.9325]) loss 4.6524858474731445 epsilon 0.82
28-Feb-25 11:06:54 - agent.DQN.DQN - INFO - episode 1 step 285 reward tensor([-18.0041]) loss 3.724730968475342 epsilon 0.82
28-Feb-25 11:06:54 - agent.DQN.DQN - INFO - episode 1 step 286 reward tensor([-18.0776]) loss 3.6151583194732666 epsilon 0.82
28-Feb-25 11:06:54 - agent.DQN.DQN - INFO - episode 1 step 287 reward tensor([-18.1528]) loss 2.111363410949707 epsilon 0.82
28-Feb-25 11:06:54 - agent.DQN.DQN - INFO - episode 1 step 288 reward tensor([-18.2297]) loss 2.110332489013672 epsilon 0.82
28-Feb-25 11:06:54 - agent.DQN.DQN - INFO - episode 1 step 289 reward tensor([-18.3084]) loss 2.8569538593292236 epsilon 0.82
28-Feb-25 11:06:54 - agent.DQN.DQN - INFO - episode 1 step 290 reward tensor([-18.3888]) loss 2.9890596866607666 epsilon 0.82
28-Feb-25 11:06:54 - agent.DQN.DQN - INFO - episode 1 step 291 reward tensor([-18.4708]) loss 2.5729525089263916 epsilon 0.82
28-Feb-25 11:06:54 - agent.DQN.DQN - INFO - episode 1 step 292 reward tensor([-18.5545]) loss 4.05622673034668 epsilon 0.82
28-Feb-25 11:06:54 - agent.DQN.DQN - INFO - episode 1 step 293 reward tensor([-18.6399]) loss 4.243267059326172 epsilon 0.82
28-Feb-25 11:06:54 - agent.DQN.DQN - INFO - episode 1 step 294 reward tensor([-18.7268]) loss 4.9595112800598145 epsilon 0.82
28-Feb-25 11:06:54 - agent.DQN.DQN - INFO - episode 1 step 295 reward tensor([-18.8153]) loss 4.40925931930542 epsilon 0.82
28-Feb-25 11:06:54 - agent.DQN.DQN - INFO - episode 1 step 296 reward tensor([-18.9049]) loss 4.069756031036377 epsilon 0.82
28-Feb-25 11:06:54 - agent.DQN.DQN - INFO - episode 1 step 297 reward tensor([-18.9952]) loss 4.254878044128418 epsilon 0.82
28-Feb-25 11:06:54 - agent.DQN.DQN - INFO - episode 1 step 298 reward tensor([-19.0856]) loss 4.045725345611572 epsilon 0.82
28-Feb-25 11:06:54 - agent.DQN.DQN - INFO - episode 1 step 299 reward tensor([-19.1760]) loss 3.77469539642334 epsilon 0.82
28-Feb-25 11:06:54 - agent.DQN.DQN - INFO - episode 1 step 300 reward tensor([-19.2661]) loss 3.5365164279937744 epsilon 0.82
28-Feb-25 11:06:54 - agent.DQN.DQN - INFO - episode 1 step 301 reward tensor([-19.3558]) loss 49.34677505493164 epsilon 0.82
28-Feb-25 11:06:54 - agent.DQN.DQN - INFO - episode 2 step 0 reward tensor([-1.9839]) loss 48.608970642089844 epsilon 0.79335
28-Feb-25 11:06:54 - agent.DQN.DQN - INFO - episode 2 step 1 reward tensor([-1.9836]) loss 50.76837158203125 epsilon 0.79335
28-Feb-25 11:06:54 - agent.DQN.DQN - INFO - episode 2 step 2 reward tensor([-1.9836]) loss 47.365264892578125 epsilon 0.79335
28-Feb-25 11:06:54 - agent.DQN.DQN - INFO - episode 2 step 3 reward tensor([-1.9852]) loss 37.63419723510742 epsilon 0.79335
28-Feb-25 11:06:54 - agent.DQN.DQN - INFO - episode 2 step 4 reward tensor([-1.9903]) loss 34.951637268066406 epsilon 0.79335
28-Feb-25 11:06:54 - agent.DQN.DQN - INFO - episode 2 step 5 reward tensor([-2.0015]) loss 33.74146270751953 epsilon 0.79335
28-Feb-25 11:06:54 - agent.DQN.DQN - INFO - episode 2 step 6 reward tensor([-2.0204]) loss 30.233476638793945 epsilon 0.79335
28-Feb-25 11:06:54 - agent.DQN.DQN - INFO - episode 2 step 7 reward tensor([-2.0495]) loss 14.23110580444336 epsilon 0.79335
28-Feb-25 11:06:54 - agent.DQN.DQN - INFO - episode 2 step 8 reward tensor([-2.0888]) loss 21.77733612060547 epsilon 0.79335
28-Feb-25 11:06:54 - agent.DQN.DQN - INFO - episode 2 step 9 reward tensor([-2.1398]) loss 20.307220458984375 epsilon 0.79335
28-Feb-25 11:06:54 - agent.DQN.DQN - INFO - episode 2 step 10 reward tensor([-2.2015]) loss 16.567150115966797 epsilon 0.79335
28-Feb-25 11:06:54 - agent.DQN.DQN - INFO - episode 2 step 11 reward tensor([-2.2724]) loss 15.549429893493652 epsilon 0.79335
28-Feb-25 11:06:54 - agent.DQN.DQN - INFO - episode 2 step 12 reward tensor([-2.3520]) loss 14.673687934875488 epsilon 0.79335
28-Feb-25 11:06:54 - agent.DQN.DQN - INFO - episode 2 step 13 reward tensor([-2.4434]) loss 2.7627739906311035 epsilon 0.79335
28-Feb-25 11:06:54 - agent.DQN.DQN - INFO - episode 2 step 14 reward tensor([-2.5406]) loss 3.046809673309326 epsilon 0.79335
28-Feb-25 11:06:54 - agent.DQN.DQN - INFO - episode 2 step 15 reward tensor([-2.6467]) loss 3.1309566497802734 epsilon 0.79335
28-Feb-25 11:06:54 - agent.DQN.DQN - INFO - episode 2 step 16 reward tensor([-2.7616]) loss 13.682329177856445 epsilon 0.79335
28-Feb-25 11:06:54 - agent.DQN.DQN - INFO - episode 2 step 17 reward tensor([-2.8844]) loss 13.705347061157227 epsilon 0.79335
28-Feb-25 11:06:54 - agent.DQN.DQN - INFO - episode 2 step 18 reward tensor([-3.0141]) loss 14.104312896728516 epsilon 0.79335
28-Feb-25 11:06:54 - agent.DQN.DQN - INFO - episode 2 step 19 reward tensor([-3.1508]) loss 4.754698753356934 epsilon 0.79335
28-Feb-25 11:06:54 - agent.DQN.DQN - INFO - episode 2 step 20 reward tensor([-3.2927]) loss 6.3729963302612305 epsilon 0.79335
28-Feb-25 11:06:54 - agent.DQN.DQN - INFO - episode 2 step 21 reward tensor([-3.4409]) loss 4.771329879760742 epsilon 0.79335
28-Feb-25 11:06:54 - agent.DQN.DQN - INFO - episode 2 step 22 reward tensor([-3.5894]) loss 5.787641525268555 epsilon 0.79335
28-Feb-25 11:06:54 - agent.DQN.DQN - INFO - episode 2 step 23 reward tensor([-3.7436]) loss 5.643639087677002 epsilon 0.79335
28-Feb-25 11:06:54 - agent.DQN.DQN - INFO - episode 2 step 24 reward tensor([-3.8975]) loss 15.182008743286133 epsilon 0.79335
28-Feb-25 11:06:54 - agent.DQN.DQN - INFO - episode 2 step 25 reward tensor([-4.0564]) loss 5.444741249084473 epsilon 0.79335
28-Feb-25 11:06:54 - agent.DQN.DQN - INFO - episode 2 step 26 reward tensor([-4.2163]) loss 5.122407913208008 epsilon 0.79335
28-Feb-25 11:06:54 - agent.DQN.DQN - INFO - episode 2 step 27 reward tensor([-4.3652]) loss 4.396085262298584 epsilon 0.79335
28-Feb-25 11:06:54 - agent.DQN.DQN - INFO - episode 2 step 28 reward tensor([-4.5144]) loss 13.479509353637695 epsilon 0.79335
28-Feb-25 11:06:54 - agent.DQN.DQN - INFO - episode 2 step 29 reward tensor([-4.6667]) loss 43.610652923583984 epsilon 0.79335
28-Feb-25 11:06:54 - agent.DQN.DQN - INFO - episode 2 step 30 reward tensor([-4.8173]) loss 44.11336898803711 epsilon 0.79335
28-Feb-25 11:06:54 - agent.DQN.DQN - INFO - episode 2 step 31 reward tensor([-4.9700]) loss 28.86281394958496 epsilon 0.79335
28-Feb-25 11:06:54 - agent.DQN.DQN - INFO - episode 2 step 32 reward tensor([-5.1244]) loss 26.54407501220703 epsilon 0.79335
28-Feb-25 11:06:54 - agent.DQN.DQN - INFO - episode 2 step 33 reward tensor([-5.2765]) loss 34.41246795654297 epsilon 0.79335
28-Feb-25 11:06:54 - agent.DQN.DQN - INFO - episode 2 step 34 reward tensor([-5.4293]) loss 22.773889541625977 epsilon 0.79335
28-Feb-25 11:06:54 - agent.DQN.DQN - INFO - episode 2 step 35 reward tensor([-5.5796]) loss 28.693735122680664 epsilon 0.79335
28-Feb-25 11:06:54 - agent.DQN.DQN - INFO - episode 2 step 36 reward tensor([-5.7272]) loss 16.371585845947266 epsilon 0.79335
28-Feb-25 11:06:54 - agent.DQN.DQN - INFO - episode 2 step 37 reward tensor([-5.8743]) loss 13.030746459960938 epsilon 0.79335
28-Feb-25 11:06:54 - agent.DQN.DQN - INFO - episode 2 step 38 reward tensor([-6.0186]) loss 8.350696563720703 epsilon 0.79335
28-Feb-25 11:06:54 - agent.DQN.DQN - INFO - episode 2 step 39 reward tensor([-6.1616]) loss 8.109710693359375 epsilon 0.79335
28-Feb-25 11:06:54 - agent.DQN.DQN - INFO - episode 2 step 40 reward tensor([-6.3016]) loss 20.499902725219727 epsilon 0.79335
28-Feb-25 11:06:54 - agent.DQN.DQN - INFO - episode 2 step 41 reward tensor([-6.4395]) loss 20.298982620239258 epsilon 0.79335
28-Feb-25 11:06:54 - agent.DQN.DQN - INFO - episode 2 step 42 reward tensor([-6.5743]) loss 4.052111625671387 epsilon 0.79335
28-Feb-25 11:06:54 - agent.DQN.DQN - INFO - episode 2 step 43 reward tensor([-6.7064]) loss 3.9402236938476562 epsilon 0.79335
28-Feb-25 11:06:54 - agent.DQN.DQN - INFO - episode 2 step 44 reward tensor([-6.8353]) loss 19.887554168701172 epsilon 0.79335
28-Feb-25 11:06:55 - agent.DQN.DQN - INFO - episode 2 step 45 reward tensor([-6.9607]) loss 20.058658599853516 epsilon 0.79335
28-Feb-25 11:06:55 - agent.DQN.DQN - INFO - episode 2 step 46 reward tensor([-7.0825]) loss 20.440237045288086 epsilon 0.79335
28-Feb-25 11:06:55 - agent.DQN.DQN - INFO - episode 2 step 47 reward tensor([-7.1921]) loss 3.3678107261657715 epsilon 0.79335
28-Feb-25 11:06:55 - agent.DQN.DQN - INFO - episode 2 step 48 reward tensor([-7.2900]) loss 3.7525835037231445 epsilon 0.79335
28-Feb-25 11:06:55 - agent.DQN.DQN - INFO - episode 2 step 49 reward tensor([-7.3770]) loss 4.511558532714844 epsilon 0.79335
28-Feb-25 11:06:55 - agent.DQN.DQN - INFO - episode 2 step 50 reward tensor([-7.4538]) loss 21.15338897705078 epsilon 0.79335
28-Feb-25 11:06:55 - agent.DQN.DQN - INFO - episode 2 step 51 reward tensor([-7.5095]) loss 4.582971572875977 epsilon 0.79335
28-Feb-25 11:06:55 - agent.DQN.DQN - INFO - episode 2 step 52 reward tensor([-7.5350]) loss 20.031484603881836 epsilon 0.79335
28-Feb-25 11:06:55 - agent.DQN.DQN - INFO - episode 2 step 53 reward tensor([-7.5384]) loss 19.939556121826172 epsilon 0.79335
28-Feb-25 11:06:55 - agent.DQN.DQN - INFO - episode 2 step 54 reward tensor([-7.5254]) loss 4.019625663757324 epsilon 0.79335
28-Feb-25 11:06:55 - agent.DQN.DQN - INFO - episode 2 step 55 reward tensor([-7.5005]) loss 3.2666354179382324 epsilon 0.79335
28-Feb-25 11:06:55 - agent.DQN.DQN - INFO - episode 2 step 56 reward tensor([-7.4670]) loss 3.7625370025634766 epsilon 0.79335
28-Feb-25 11:06:55 - agent.DQN.DQN - INFO - episode 2 step 57 reward tensor([-7.4275]) loss 18.37491226196289 epsilon 0.79335
28-Feb-25 11:06:55 - agent.DQN.DQN - INFO - episode 2 step 58 reward tensor([-7.3839]) loss 18.3331356048584 epsilon 0.79335
28-Feb-25 11:06:55 - agent.DQN.DQN - INFO - episode 2 step 59 reward tensor([-7.3378]) loss 20.330402374267578 epsilon 0.79335
28-Feb-25 11:06:55 - agent.DQN.DQN - INFO - episode 2 step 60 reward tensor([-7.2904]) loss 15.043746948242188 epsilon 0.79335
28-Feb-25 11:06:55 - agent.DQN.DQN - INFO - episode 2 step 61 reward tensor([-7.2435]) loss 33.726497650146484 epsilon 0.79335
28-Feb-25 11:06:55 - agent.DQN.DQN - INFO - episode 2 step 62 reward tensor([-7.1982]) loss 15.720611572265625 epsilon 0.79335
28-Feb-25 11:06:55 - agent.DQN.DQN - INFO - episode 2 step 63 reward tensor([-7.1555]) loss 31.353389739990234 epsilon 0.79335
28-Feb-25 11:06:55 - agent.DQN.DQN - INFO - episode 2 step 64 reward tensor([-7.1159]) loss 19.103282928466797 epsilon 0.79335
28-Feb-25 11:06:55 - agent.DQN.DQN - INFO - episode 2 step 65 reward tensor([-7.0798]) loss 13.426451683044434 epsilon 0.79335
28-Feb-25 11:06:55 - agent.DQN.DQN - INFO - episode 2 step 66 reward tensor([-7.0473]) loss 26.437593460083008 epsilon 0.79335
28-Feb-25 11:06:55 - agent.DQN.DQN - INFO - episode 2 step 67 reward tensor([-7.0187]) loss 9.764148712158203 epsilon 0.79335
28-Feb-25 11:06:55 - agent.DQN.DQN - INFO - episode 2 step 68 reward tensor([-6.9938]) loss 5.607312202453613 epsilon 0.79335
28-Feb-25 11:06:55 - agent.DQN.DQN - INFO - episode 2 step 69 reward tensor([-6.9727]) loss 6.128115177154541 epsilon 0.79335
28-Feb-25 11:06:55 - agent.DQN.DQN - INFO - episode 2 step 70 reward tensor([-6.9551]) loss 4.218011379241943 epsilon 0.79335
28-Feb-25 11:06:55 - agent.DQN.DQN - INFO - episode 2 step 71 reward tensor([-6.9410]) loss 4.131696701049805 epsilon 0.79335
28-Feb-25 11:06:55 - agent.DQN.DQN - INFO - episode 2 step 72 reward tensor([-6.9300]) loss 3.527432680130005 epsilon 0.79335
28-Feb-25 11:06:55 - agent.DQN.DQN - INFO - episode 2 step 73 reward tensor([-6.9220]) loss 25.043659210205078 epsilon 0.79335
28-Feb-25 11:06:55 - agent.DQN.DQN - INFO - episode 2 step 74 reward tensor([-6.9168]) loss 2.2091526985168457 epsilon 0.79335
28-Feb-25 11:06:55 - agent.DQN.DQN - INFO - episode 2 step 75 reward tensor([-6.9140]) loss 3.3995885848999023 epsilon 0.79335
28-Feb-25 11:06:55 - agent.DQN.DQN - INFO - episode 2 step 76 reward tensor([-6.9134]) loss 25.763931274414062 epsilon 0.79335
28-Feb-25 11:06:55 - agent.DQN.DQN - INFO - episode 2 step 77 reward tensor([-6.9148]) loss 3.8718652725219727 epsilon 0.79335
28-Feb-25 11:06:55 - agent.DQN.DQN - INFO - episode 2 step 78 reward tensor([-6.9177]) loss 26.373708724975586 epsilon 0.79335
28-Feb-25 11:06:55 - agent.DQN.DQN - INFO - episode 2 step 79 reward tensor([-6.9220]) loss 3.0422348976135254 epsilon 0.79335
28-Feb-25 11:06:55 - agent.DQN.DQN - INFO - episode 2 step 80 reward tensor([-6.9274]) loss 26.767017364501953 epsilon 0.79335
28-Feb-25 11:06:55 - agent.DQN.DQN - INFO - episode 2 step 81 reward tensor([-6.9336]) loss 3.0432827472686768 epsilon 0.79335
28-Feb-25 11:06:55 - agent.DQN.DQN - INFO - episode 2 step 82 reward tensor([-6.9403]) loss 3.197596549987793 epsilon 0.79335
28-Feb-25 11:06:55 - agent.DQN.DQN - INFO - episode 2 step 83 reward tensor([-6.9472]) loss 2.6813817024230957 epsilon 0.79335
28-Feb-25 11:06:55 - agent.DQN.DQN - INFO - episode 2 step 84 reward tensor([-6.9541]) loss 24.903106689453125 epsilon 0.79335
28-Feb-25 11:06:55 - agent.DQN.DQN - INFO - episode 2 step 85 reward tensor([-6.9607]) loss 2.8346338272094727 epsilon 0.79335
28-Feb-25 11:06:55 - agent.DQN.DQN - INFO - episode 2 step 86 reward tensor([-6.9667]) loss 3.07919979095459 epsilon 0.79335
28-Feb-25 11:06:55 - agent.DQN.DQN - INFO - episode 2 step 87 reward tensor([-6.9720]) loss 2.9737138748168945 epsilon 0.79335
28-Feb-25 11:06:55 - agent.DQN.DQN - INFO - episode 2 step 88 reward tensor([-6.9763]) loss 2.773733615875244 epsilon 0.79335
28-Feb-25 11:06:55 - agent.DQN.DQN - INFO - episode 2 step 89 reward tensor([-6.9794]) loss 17.388324737548828 epsilon 0.79335
28-Feb-25 11:06:55 - agent.DQN.DQN - INFO - episode 2 step 90 reward tensor([-6.9810]) loss 42.15116500854492 epsilon 0.79335
28-Feb-25 11:06:55 - agent.DQN.DQN - INFO - episode 2 step 91 reward tensor([-6.9810]) loss 20.824832916259766 epsilon 0.79335
28-Feb-25 11:06:55 - agent.DQN.DQN - INFO - episode 2 step 92 reward tensor([-6.9798]) loss 19.660018920898438 epsilon 0.79335
28-Feb-25 11:06:55 - agent.DQN.DQN - INFO - episode 2 step 93 reward tensor([-6.9803]) loss 15.526351928710938 epsilon 0.79335
28-Feb-25 11:06:55 - agent.DQN.DQN - INFO - episode 2 step 94 reward tensor([-6.9813]) loss 13.545971870422363 epsilon 0.79335
28-Feb-25 11:06:55 - agent.DQN.DQN - INFO - episode 2 step 95 reward tensor([-6.9819]) loss 32.1499137878418 epsilon 0.79335
28-Feb-25 11:06:55 - agent.DQN.DQN - INFO - episode 2 step 96 reward tensor([-6.9815]) loss 10.293132781982422 epsilon 0.79335
28-Feb-25 11:06:55 - agent.DQN.DQN - INFO - episode 2 step 97 reward tensor([-6.9754]) loss 31.424427032470703 epsilon 0.79335
28-Feb-25 11:06:55 - agent.DQN.DQN - INFO - episode 2 step 98 reward tensor([-6.9685]) loss 29.34780502319336 epsilon 0.79335
28-Feb-25 11:06:55 - agent.DQN.DQN - INFO - episode 2 step 99 reward tensor([-6.9602]) loss 5.918072700500488 epsilon 0.79335
28-Feb-25 11:06:55 - agent.DQN.DQN - INFO - episode 2 step 100 reward tensor([-6.9497]) loss 4.380971431732178 epsilon 0.79335
28-Feb-25 11:06:55 - agent.DQN.DQN - INFO - episode 2 step 101 reward tensor([-6.9434]) loss 2.5457589626312256 epsilon 0.79335
28-Feb-25 11:06:55 - agent.DQN.DQN - INFO - episode 2 step 102 reward tensor([-6.9457]) loss 4.5822577476501465 epsilon 0.79335
28-Feb-25 11:06:55 - agent.DQN.DQN - INFO - episode 2 step 103 reward tensor([-6.9513]) loss 3.3716881275177 epsilon 0.79335
28-Feb-25 11:06:55 - agent.DQN.DQN - INFO - episode 2 step 104 reward tensor([-6.9573]) loss 27.662668228149414 epsilon 0.79335
28-Feb-25 11:06:55 - agent.DQN.DQN - INFO - episode 2 step 105 reward tensor([-6.9623]) loss 3.133070945739746 epsilon 0.79335
28-Feb-25 11:06:55 - agent.DQN.DQN - INFO - episode 2 step 106 reward tensor([-6.9653]) loss 4.151169300079346 epsilon 0.79335
28-Feb-25 11:06:55 - agent.DQN.DQN - INFO - episode 2 step 107 reward tensor([-6.9657]) loss 3.387970447540283 epsilon 0.79335
28-Feb-25 11:06:55 - agent.DQN.DQN - INFO - episode 2 step 108 reward tensor([-6.9632]) loss 4.134832382202148 epsilon 0.79335
28-Feb-25 11:06:55 - agent.DQN.DQN - INFO - episode 2 step 109 reward tensor([-6.9498]) loss 3.1325087547302246 epsilon 0.79335
28-Feb-25 11:06:55 - agent.DQN.DQN - INFO - episode 2 step 110 reward tensor([-6.9220]) loss 3.904226303100586 epsilon 0.79335
28-Feb-25 11:06:55 - agent.DQN.DQN - INFO - episode 2 step 111 reward tensor([-6.8786]) loss 4.202700138092041 epsilon 0.79335
28-Feb-25 11:06:55 - agent.DQN.DQN - INFO - episode 2 step 112 reward tensor([-6.8283]) loss 2.9930195808410645 epsilon 0.79335
28-Feb-25 11:06:55 - agent.DQN.DQN - INFO - episode 2 step 113 reward tensor([-6.7806]) loss 3.0539751052856445 epsilon 0.79335
28-Feb-25 11:06:55 - agent.DQN.DQN - INFO - episode 2 step 114 reward tensor([-6.7427]) loss 31.433250427246094 epsilon 0.79335
28-Feb-25 11:06:55 - agent.DQN.DQN - INFO - episode 2 step 115 reward tensor([-6.7079]) loss 2.6961216926574707 epsilon 0.79335
28-Feb-25 11:06:55 - agent.DQN.DQN - INFO - episode 2 step 116 reward tensor([-6.6825]) loss 2.146817684173584 epsilon 0.79335
28-Feb-25 11:06:55 - agent.DQN.DQN - INFO - episode 2 step 117 reward tensor([-6.6599]) loss 2.6947145462036133 epsilon 0.79335
28-Feb-25 11:06:55 - agent.DQN.DQN - INFO - episode 2 step 118 reward tensor([-6.6368]) loss 2.0735514163970947 epsilon 0.79335
28-Feb-25 11:06:55 - agent.DQN.DQN - INFO - episode 2 step 119 reward tensor([-6.6120]) loss 20.460634231567383 epsilon 0.79335
28-Feb-25 11:06:55 - agent.DQN.DQN - INFO - episode 2 step 120 reward tensor([-6.5849]) loss 17.35496711730957 epsilon 0.79335
28-Feb-25 11:06:55 - agent.DQN.DQN - INFO - episode 2 step 121 reward tensor([-6.5464]) loss 16.03542709350586 epsilon 0.79335
28-Feb-25 11:06:55 - agent.DQN.DQN - INFO - episode 2 step 122 reward tensor([-6.5100]) loss 19.278854370117188 epsilon 0.79335
28-Feb-25 11:06:55 - agent.DQN.DQN - INFO - episode 2 step 123 reward tensor([-6.4730]) loss 46.704437255859375 epsilon 0.79335
28-Feb-25 11:06:55 - agent.DQN.DQN - INFO - episode 2 step 124 reward tensor([-6.4341]) loss 44.917388916015625 epsilon 0.79335
28-Feb-25 11:06:55 - agent.DQN.DQN - INFO - episode 2 step 125 reward tensor([-6.3843]) loss 41.944602966308594 epsilon 0.79335
28-Feb-25 11:06:55 - agent.DQN.DQN - INFO - episode 2 step 126 reward tensor([-6.3360]) loss 7.074541091918945 epsilon 0.79335
28-Feb-25 11:06:55 - agent.DQN.DQN - INFO - episode 2 step 127 reward tensor([-6.2871]) loss 38.231815338134766 epsilon 0.79335
28-Feb-25 11:06:55 - agent.DQN.DQN - INFO - episode 2 step 128 reward tensor([-6.2363]) loss 6.003055095672607 epsilon 0.79335
28-Feb-25 11:06:55 - agent.DQN.DQN - INFO - episode 2 step 129 reward tensor([-6.1834]) loss 3.6700949668884277 epsilon 0.79335
28-Feb-25 11:06:55 - agent.DQN.DQN - INFO - episode 2 step 130 reward tensor([-6.1282]) loss 3.3043601512908936 epsilon 0.79335
28-Feb-25 11:06:55 - agent.DQN.DQN - INFO - episode 2 step 131 reward tensor([-6.0709]) loss 3.321439266204834 epsilon 0.79335
28-Feb-25 11:06:55 - agent.DQN.DQN - INFO - episode 2 step 132 reward tensor([-6.0117]) loss 32.51831817626953 epsilon 0.79335
28-Feb-25 11:06:55 - agent.DQN.DQN - INFO - episode 2 step 133 reward tensor([-5.9508]) loss 2.734787940979004 epsilon 0.79335
28-Feb-25 11:06:55 - agent.DQN.DQN - INFO - episode 2 step 134 reward tensor([-5.8827]) loss 33.57908630371094 epsilon 0.79335
28-Feb-25 11:06:55 - agent.DQN.DQN - INFO - episode 2 step 135 reward tensor([-5.8168]) loss 3.382321357727051 epsilon 0.79335
28-Feb-25 11:06:56 - agent.DQN.DQN - INFO - episode 2 step 136 reward tensor([-5.7517]) loss 35.388885498046875 epsilon 0.79335
28-Feb-25 11:06:56 - agent.DQN.DQN - INFO - episode 2 step 137 reward tensor([-5.6871]) loss 4.049681663513184 epsilon 0.79335
28-Feb-25 11:06:56 - agent.DQN.DQN - INFO - episode 2 step 138 reward tensor([-5.6229]) loss 35.600425720214844 epsilon 0.79335
28-Feb-25 11:06:56 - agent.DQN.DQN - INFO - episode 2 step 139 reward tensor([-5.5551]) loss 6.243381977081299 epsilon 0.79335
28-Feb-25 11:06:56 - agent.DQN.DQN - INFO - episode 2 step 140 reward tensor([-5.4905]) loss 5.091335296630859 epsilon 0.79335
28-Feb-25 11:06:56 - agent.DQN.DQN - INFO - episode 2 step 141 reward tensor([-5.4252]) loss 33.219417572021484 epsilon 0.79335
28-Feb-25 11:06:56 - agent.DQN.DQN - INFO - episode 2 step 142 reward tensor([-5.3585]) loss 5.371590614318848 epsilon 0.79335
28-Feb-25 11:06:56 - agent.DQN.DQN - INFO - episode 2 step 143 reward tensor([-5.2928]) loss 4.408994197845459 epsilon 0.79335
28-Feb-25 11:06:56 - agent.DQN.DQN - INFO - episode 2 step 144 reward tensor([-5.2297]) loss 4.005486965179443 epsilon 0.79335
28-Feb-25 11:06:56 - agent.DQN.DQN - INFO - episode 2 step 145 reward tensor([-5.1691]) loss 2.8698556423187256 epsilon 0.79335
28-Feb-25 11:06:56 - agent.DQN.DQN - INFO - episode 2 step 146 reward tensor([-5.1118]) loss 2.187678575515747 epsilon 0.79335
28-Feb-25 11:06:56 - agent.DQN.DQN - INFO - episode 2 step 147 reward tensor([-5.0605]) loss 3.4389469623565674 epsilon 0.79335
28-Feb-25 11:06:56 - agent.DQN.DQN - INFO - episode 2 step 148 reward tensor([-5.0156]) loss 2.8150439262390137 epsilon 0.79335
28-Feb-25 11:06:56 - agent.DQN.DQN - INFO - episode 2 step 149 reward tensor([-4.9771]) loss 7.645274639129639 epsilon 0.79335
28-Feb-25 11:06:56 - agent.DQN.DQN - INFO - episode 2 step 150 reward tensor([-4.9460]) loss 39.7239875793457 epsilon 0.79335
28-Feb-25 11:06:56 - agent.DQN.DQN - INFO - episode 2 step 151 reward tensor([-4.9216]) loss 7.867094039916992 epsilon 0.79335
28-Feb-25 11:06:56 - agent.DQN.DQN - INFO - episode 2 step 152 reward tensor([-4.9043]) loss 8.61617374420166 epsilon 0.79335
28-Feb-25 11:06:56 - agent.DQN.DQN - INFO - episode 2 step 153 reward tensor([-4.8942]) loss 6.873190879821777 epsilon 0.79335
28-Feb-25 11:06:56 - agent.DQN.DQN - INFO - episode 2 step 154 reward tensor([-4.8912]) loss 6.564955711364746 epsilon 0.79335
28-Feb-25 11:06:56 - agent.DQN.DQN - INFO - episode 2 step 155 reward tensor([-4.8947]) loss 6.8577399253845215 epsilon 0.79335
28-Feb-25 11:06:56 - agent.DQN.DQN - INFO - episode 2 step 156 reward tensor([-4.9046]) loss 5.530196189880371 epsilon 0.79335
28-Feb-25 11:06:56 - agent.DQN.DQN - INFO - episode 2 step 157 reward tensor([-4.9204]) loss 3.8359057903289795 epsilon 0.79335
28-Feb-25 11:06:56 - agent.DQN.DQN - INFO - episode 2 step 158 reward tensor([-4.9424]) loss 42.38841247558594 epsilon 0.79335
28-Feb-25 11:06:56 - agent.DQN.DQN - INFO - episode 2 step 159 reward tensor([-4.9711]) loss 2.6228840351104736 epsilon 0.79335
28-Feb-25 11:06:56 - agent.DQN.DQN - INFO - episode 2 step 160 reward tensor([-5.0065]) loss 2.3552587032318115 epsilon 0.79335
28-Feb-25 11:06:56 - agent.DQN.DQN - INFO - episode 2 step 161 reward tensor([-5.0493]) loss 1.8411686420440674 epsilon 0.79335
28-Feb-25 11:06:56 - agent.DQN.DQN - INFO - episode 2 step 162 reward tensor([-5.0995]) loss 1.8790644407272339 epsilon 0.79335
28-Feb-25 11:06:56 - agent.DQN.DQN - INFO - episode 2 step 163 reward tensor([-5.1561]) loss 44.19285583496094 epsilon 0.79335
28-Feb-25 11:06:56 - agent.DQN.DQN - INFO - episode 2 step 164 reward tensor([-5.2170]) loss 43.826934814453125 epsilon 0.79335
28-Feb-25 11:06:56 - agent.DQN.DQN - INFO - episode 2 step 165 reward tensor([-5.2844]) loss 43.54548263549805 epsilon 0.79335
28-Feb-25 11:06:56 - agent.DQN.DQN - INFO - episode 2 step 166 reward tensor([-5.3554]) loss 1.8425943851470947 epsilon 0.79335
28-Feb-25 11:06:56 - agent.DQN.DQN - INFO - episode 2 step 167 reward tensor([-5.4264]) loss 2.364506721496582 epsilon 0.79335
28-Feb-25 11:06:56 - agent.DQN.DQN - INFO - episode 2 step 168 reward tensor([-5.4951]) loss 2.3832197189331055 epsilon 0.79335
28-Feb-25 11:06:56 - agent.DQN.DQN - INFO - episode 2 step 169 reward tensor([-5.5671]) loss 2.1815378665924072 epsilon 0.79335
28-Feb-25 11:06:56 - agent.DQN.DQN - INFO - episode 2 step 170 reward tensor([-5.6415]) loss 1.969539999961853 epsilon 0.79335
28-Feb-25 11:06:56 - agent.DQN.DQN - INFO - episode 2 step 171 reward tensor([-5.7178]) loss 38.85857009887695 epsilon 0.79335
28-Feb-25 11:06:56 - agent.DQN.DQN - INFO - episode 2 step 172 reward tensor([-5.8002]) loss 4.2004218101501465 epsilon 0.79335
28-Feb-25 11:06:56 - agent.DQN.DQN - INFO - episode 2 step 173 reward tensor([-5.8867]) loss 37.776004791259766 epsilon 0.79335
28-Feb-25 11:06:56 - agent.DQN.DQN - INFO - episode 2 step 174 reward tensor([-5.9758]) loss 4.065217971801758 epsilon 0.79335
28-Feb-25 11:06:56 - agent.DQN.DQN - INFO - episode 2 step 175 reward tensor([-6.0720]) loss 37.66016387939453 epsilon 0.79335
28-Feb-25 11:06:56 - agent.DQN.DQN - INFO - episode 2 step 176 reward tensor([-6.1731]) loss 37.16154098510742 epsilon 0.79335
28-Feb-25 11:06:56 - agent.DQN.DQN - INFO - episode 2 step 177 reward tensor([-6.2827]) loss 2.787708044052124 epsilon 0.79335
28-Feb-25 11:06:56 - agent.DQN.DQN - INFO - episode 2 step 178 reward tensor([-6.3926]) loss 34.49066925048828 epsilon 0.79335
28-Feb-25 11:06:56 - agent.DQN.DQN - INFO - episode 2 step 179 reward tensor([-6.5089]) loss 6.898350238800049 epsilon 0.79335
28-Feb-25 11:06:56 - agent.DQN.DQN - INFO - episode 2 step 180 reward tensor([-6.6343]) loss 4.179582118988037 epsilon 0.79335
28-Feb-25 11:06:56 - agent.DQN.DQN - INFO - episode 2 step 181 reward tensor([-6.7687]) loss 8.052445411682129 epsilon 0.79335
28-Feb-25 11:06:56 - agent.DQN.DQN - INFO - episode 2 step 182 reward tensor([-6.9092]) loss 36.82139587402344 epsilon 0.79335
28-Feb-25 11:06:56 - agent.DQN.DQN - INFO - episode 2 step 183 reward tensor([-7.0574]) loss 5.373229503631592 epsilon 0.79335
28-Feb-25 11:06:56 - agent.DQN.DQN - INFO - episode 2 step 184 reward tensor([-7.2109]) loss 7.101496696472168 epsilon 0.79335
28-Feb-25 11:06:56 - agent.DQN.DQN - INFO - episode 2 step 185 reward tensor([-7.3707]) loss 6.009154319763184 epsilon 0.79335
28-Feb-25 11:06:56 - agent.DQN.DQN - INFO - episode 2 step 186 reward tensor([-7.5311]) loss 34.20844650268555 epsilon 0.79335
28-Feb-25 11:06:56 - agent.DQN.DQN - INFO - episode 2 step 187 reward tensor([-7.6808]) loss 36.91767501831055 epsilon 0.79335
28-Feb-25 11:06:56 - agent.DQN.DQN - INFO - episode 2 step 188 reward tensor([-7.8084]) loss 5.46333646774292 epsilon 0.79335
28-Feb-25 11:06:56 - agent.DQN.DQN - INFO - episode 2 step 189 reward tensor([-7.9206]) loss 4.423445701599121 epsilon 0.79335
28-Feb-25 11:06:56 - agent.DQN.DQN - INFO - episode 2 step 190 reward tensor([-8.0320]) loss 4.968978404998779 epsilon 0.79335
28-Feb-25 11:06:56 - agent.DQN.DQN - INFO - episode 2 step 191 reward tensor([-8.1490]) loss 4.390449523925781 epsilon 0.79335
28-Feb-25 11:06:56 - agent.DQN.DQN - INFO - episode 2 step 192 reward tensor([-8.2731]) loss 35.60654067993164 epsilon 0.79335
28-Feb-25 11:06:56 - agent.DQN.DQN - INFO - episode 2 step 193 reward tensor([-8.4015]) loss 35.34749984741211 epsilon 0.79335
28-Feb-25 11:06:56 - agent.DQN.DQN - INFO - episode 2 step 194 reward tensor([-8.5349]) loss 3.8740451335906982 epsilon 0.79335
28-Feb-25 11:06:56 - agent.DQN.DQN - INFO - episode 2 step 195 reward tensor([-8.6667]) loss 36.93263244628906 epsilon 0.79335
28-Feb-25 11:06:56 - agent.DQN.DQN - INFO - episode 2 step 196 reward tensor([-8.7855]) loss 4.4524359703063965 epsilon 0.79335
28-Feb-25 11:06:56 - agent.DQN.DQN - INFO - episode 2 step 197 reward tensor([-8.9035]) loss 35.538753509521484 epsilon 0.79335
28-Feb-25 11:06:56 - agent.DQN.DQN - INFO - episode 2 step 198 reward tensor([-9.0252]) loss 2.6583595275878906 epsilon 0.79335
28-Feb-25 11:06:56 - agent.DQN.DQN - INFO - episode 2 step 199 reward tensor([-9.1437]) loss 35.143157958984375 epsilon 0.79335
28-Feb-25 11:06:56 - agent.DQN.DQN - INFO - episode 2 step 200 reward tensor([-9.2645]) loss 3.699662923812866 epsilon 0.79335
28-Feb-25 11:06:56 - agent.DQN.DQN - INFO - episode 2 step 201 reward tensor([-9.3872]) loss 36.34095764160156 epsilon 0.79335
28-Feb-25 11:06:56 - agent.DQN.DQN - INFO - episode 2 step 202 reward tensor([-9.5065]) loss 2.819913625717163 epsilon 0.79335
28-Feb-25 11:06:56 - agent.DQN.DQN - INFO - episode 2 step 203 reward tensor([-9.6225]) loss 36.122955322265625 epsilon 0.79335
28-Feb-25 11:06:56 - agent.DQN.DQN - INFO - episode 2 step 204 reward tensor([-9.7398]) loss 34.8440055847168 epsilon 0.79335
28-Feb-25 11:06:56 - agent.DQN.DQN - INFO - episode 2 step 205 reward tensor([-9.8559]) loss 3.688342332839966 epsilon 0.79335
28-Feb-25 11:06:56 - agent.DQN.DQN - INFO - episode 2 step 206 reward tensor([-9.9706]) loss 3.462700605392456 epsilon 0.79335
28-Feb-25 11:06:56 - agent.DQN.DQN - INFO - episode 2 step 207 reward tensor([-10.0855]) loss 33.53803634643555 epsilon 0.79335
28-Feb-25 11:06:56 - agent.DQN.DQN - INFO - episode 2 step 208 reward tensor([-10.1967]) loss 32.823585510253906 epsilon 0.79335
28-Feb-25 11:06:56 - agent.DQN.DQN - INFO - episode 2 step 209 reward tensor([-10.3046]) loss 5.92995548248291 epsilon 0.79335
28-Feb-25 11:06:56 - agent.DQN.DQN - INFO - episode 2 step 210 reward tensor([-10.4128]) loss 36.092071533203125 epsilon 0.79335
28-Feb-25 11:06:56 - agent.DQN.DQN - INFO - episode 2 step 211 reward tensor([-10.5206]) loss 7.693565368652344 epsilon 0.79335
28-Feb-25 11:06:56 - agent.DQN.DQN - INFO - episode 2 step 212 reward tensor([-10.6250]) loss 5.575155258178711 epsilon 0.79335
28-Feb-25 11:06:56 - agent.DQN.DQN - INFO - episode 2 step 213 reward tensor([-10.7265]) loss 35.415748596191406 epsilon 0.79335
28-Feb-25 11:06:56 - agent.DQN.DQN - INFO - episode 2 step 214 reward tensor([-10.8275]) loss 34.920249938964844 epsilon 0.79335
28-Feb-25 11:06:56 - agent.DQN.DQN - INFO - episode 2 step 215 reward tensor([-10.9264]) loss 6.180225849151611 epsilon 0.79335
28-Feb-25 11:06:56 - agent.DQN.DQN - INFO - episode 2 step 216 reward tensor([-11.0258]) loss 5.271481037139893 epsilon 0.79335
28-Feb-25 11:06:56 - agent.DQN.DQN - INFO - episode 2 step 217 reward tensor([-11.1239]) loss 6.492117404937744 epsilon 0.79335
28-Feb-25 11:06:56 - agent.DQN.DQN - INFO - episode 2 step 218 reward tensor([-11.2234]) loss 4.7120513916015625 epsilon 0.79335
28-Feb-25 11:06:56 - agent.DQN.DQN - INFO - episode 2 step 219 reward tensor([-11.3210]) loss 31.333005905151367 epsilon 0.79335
28-Feb-25 11:06:56 - agent.DQN.DQN - INFO - episode 2 step 220 reward tensor([-11.4070]) loss 5.156486511230469 epsilon 0.79335
28-Feb-25 11:06:56 - agent.DQN.DQN - INFO - episode 2 step 221 reward tensor([-11.4708]) loss 4.302773952484131 epsilon 0.79335
28-Feb-25 11:06:56 - agent.DQN.DQN - INFO - episode 2 step 222 reward tensor([-11.5279]) loss 3.6132686138153076 epsilon 0.79335
28-Feb-25 11:06:56 - agent.DQN.DQN - INFO - episode 2 step 223 reward tensor([-11.5702]) loss 3.4278478622436523 epsilon 0.79335
28-Feb-25 11:06:56 - agent.DQN.DQN - INFO - episode 2 step 224 reward tensor([-11.6093]) loss 3.150111675262451 epsilon 0.79335
28-Feb-25 11:06:56 - agent.DQN.DQN - INFO - episode 2 step 225 reward tensor([-11.6497]) loss 34.58436965942383 epsilon 0.79335
28-Feb-25 11:06:56 - agent.DQN.DQN - INFO - episode 2 step 226 reward tensor([-11.6920]) loss 5.795658588409424 epsilon 0.79335
28-Feb-25 11:06:56 - agent.DQN.DQN - INFO - episode 2 step 227 reward tensor([-11.7342]) loss 4.427132606506348 epsilon 0.79335
28-Feb-25 11:06:56 - agent.DQN.DQN - INFO - episode 2 step 228 reward tensor([-11.7762]) loss 3.0984277725219727 epsilon 0.79335
28-Feb-25 11:06:56 - agent.DQN.DQN - INFO - episode 2 step 229 reward tensor([-11.8126]) loss 2.975109577178955 epsilon 0.79335
28-Feb-25 11:06:56 - agent.DQN.DQN - INFO - episode 2 step 230 reward tensor([-11.8490]) loss 2.1765615940093994 epsilon 0.79335
28-Feb-25 11:06:56 - agent.DQN.DQN - INFO - episode 2 step 231 reward tensor([-11.8847]) loss 3.853971481323242 epsilon 0.79335
28-Feb-25 11:06:57 - agent.DQN.DQN - INFO - episode 2 step 232 reward tensor([-11.9210]) loss 3.803290367126465 epsilon 0.79335
28-Feb-25 11:06:57 - agent.DQN.DQN - INFO - episode 2 step 233 reward tensor([-11.9558]) loss 2.631896495819092 epsilon 0.79335
28-Feb-25 11:06:57 - agent.DQN.DQN - INFO - episode 2 step 234 reward tensor([-11.9889]) loss 3.87331485748291 epsilon 0.79335
28-Feb-25 11:06:57 - agent.DQN.DQN - INFO - episode 2 step 235 reward tensor([-12.0216]) loss 2.3927199840545654 epsilon 0.79335
28-Feb-25 11:06:57 - agent.DQN.DQN - INFO - episode 2 step 236 reward tensor([-12.0536]) loss 2.1107571125030518 epsilon 0.79335
28-Feb-25 11:06:57 - agent.DQN.DQN - INFO - episode 2 step 237 reward tensor([-12.0830]) loss 3.1273040771484375 epsilon 0.79335
28-Feb-25 11:06:57 - agent.DQN.DQN - INFO - episode 2 step 238 reward tensor([-12.1096]) loss 2.7614798545837402 epsilon 0.79335
28-Feb-25 11:06:57 - agent.DQN.DQN - INFO - episode 2 step 239 reward tensor([-12.1291]) loss 11.791182518005371 epsilon 0.79335
28-Feb-25 11:06:57 - agent.DQN.DQN - INFO - episode 2 step 240 reward tensor([-12.1377]) loss 49.871482849121094 epsilon 0.79335
28-Feb-25 11:06:57 - agent.DQN.DQN - INFO - episode 2 step 241 reward tensor([-12.1425]) loss 47.49420166015625 epsilon 0.79335
28-Feb-25 11:06:57 - agent.DQN.DQN - INFO - episode 2 step 242 reward tensor([-12.1410]) loss 8.334871292114258 epsilon 0.79335
28-Feb-25 11:06:57 - agent.DQN.DQN - INFO - episode 2 step 243 reward tensor([-12.1356]) loss 43.7723388671875 epsilon 0.79335
28-Feb-25 11:06:57 - agent.DQN.DQN - INFO - episode 2 step 244 reward tensor([-12.1280]) loss 8.458498001098633 epsilon 0.79335
28-Feb-25 11:06:57 - agent.DQN.DQN - INFO - episode 2 step 245 reward tensor([-12.1198]) loss 41.58731460571289 epsilon 0.79335
28-Feb-25 11:06:57 - agent.DQN.DQN - INFO - episode 2 step 246 reward tensor([-12.1119]) loss 4.502011775970459 epsilon 0.79335
28-Feb-25 11:06:57 - agent.DQN.DQN - INFO - episode 2 step 247 reward tensor([-12.1053]) loss 4.488171100616455 epsilon 0.79335
28-Feb-25 11:06:57 - agent.DQN.DQN - INFO - episode 2 step 248 reward tensor([-12.1008]) loss 3.007363796234131 epsilon 0.79335
28-Feb-25 11:06:57 - agent.DQN.DQN - INFO - episode 2 step 249 reward tensor([-12.0990]) loss 39.22724151611328 epsilon 0.79335
28-Feb-25 11:06:57 - agent.DQN.DQN - INFO - episode 2 step 250 reward tensor([-12.1006]) loss 2.1059529781341553 epsilon 0.79335
28-Feb-25 11:06:57 - agent.DQN.DQN - INFO - episode 2 step 251 reward tensor([-12.1061]) loss 4.170042514801025 epsilon 0.79335
28-Feb-25 11:06:57 - agent.DQN.DQN - INFO - episode 2 step 252 reward tensor([-12.1156]) loss 4.906332015991211 epsilon 0.79335
28-Feb-25 11:06:57 - agent.DQN.DQN - INFO - episode 2 step 253 reward tensor([-12.1293]) loss 5.01254415512085 epsilon 0.79335
28-Feb-25 11:06:57 - agent.DQN.DQN - INFO - episode 2 step 254 reward tensor([-12.1469]) loss 4.758896827697754 epsilon 0.79335
28-Feb-25 11:06:57 - agent.DQN.DQN - INFO - episode 2 step 255 reward tensor([-12.1681]) loss 4.687991142272949 epsilon 0.79335
28-Feb-25 11:06:57 - agent.DQN.DQN - INFO - episode 2 step 256 reward tensor([-12.1924]) loss 5.039682388305664 epsilon 0.79335
28-Feb-25 11:06:57 - agent.DQN.DQN - INFO - episode 2 step 257 reward tensor([-12.2194]) loss 40.03932571411133 epsilon 0.79335
28-Feb-25 11:06:57 - agent.DQN.DQN - INFO - episode 2 step 258 reward tensor([-12.2486]) loss 40.745765686035156 epsilon 0.79335
28-Feb-25 11:06:57 - agent.DQN.DQN - INFO - episode 2 step 259 reward tensor([-12.2794]) loss 39.1834831237793 epsilon 0.79335
28-Feb-25 11:06:57 - agent.DQN.DQN - INFO - episode 2 step 260 reward tensor([-12.3115]) loss 3.8805131912231445 epsilon 0.79335
28-Feb-25 11:06:57 - agent.DQN.DQN - INFO - episode 2 step 261 reward tensor([-12.3442]) loss 4.489760875701904 epsilon 0.79335
28-Feb-25 11:06:57 - agent.DQN.DQN - INFO - episode 2 step 262 reward tensor([-12.3770]) loss 38.30379867553711 epsilon 0.79335
28-Feb-25 11:06:57 - agent.DQN.DQN - INFO - episode 2 step 263 reward tensor([-12.4094]) loss 2.6473898887634277 epsilon 0.79335
28-Feb-25 11:06:57 - agent.DQN.DQN - INFO - episode 2 step 264 reward tensor([-12.4409]) loss 36.32063674926758 epsilon 0.79335
28-Feb-25 11:06:57 - agent.DQN.DQN - INFO - episode 2 step 265 reward tensor([-12.4710]) loss 6.067717552185059 epsilon 0.79335
28-Feb-25 11:06:57 - agent.DQN.DQN - INFO - episode 2 step 266 reward tensor([-12.4993]) loss 3.4506611824035645 epsilon 0.79335
28-Feb-25 11:06:57 - agent.DQN.DQN - INFO - episode 2 step 267 reward tensor([-12.5253]) loss 36.797027587890625 epsilon 0.79335
28-Feb-25 11:06:57 - agent.DQN.DQN - INFO - episode 2 step 268 reward tensor([-12.5487]) loss 3.6063413619995117 epsilon 0.79335
28-Feb-25 11:06:57 - agent.DQN.DQN - INFO - episode 2 step 269 reward tensor([-12.5691]) loss 7.402093410491943 epsilon 0.79335
28-Feb-25 11:06:57 - agent.DQN.DQN - INFO - episode 2 step 270 reward tensor([-12.5864]) loss 37.49747848510742 epsilon 0.79335
28-Feb-25 11:06:57 - agent.DQN.DQN - INFO - episode 2 step 271 reward tensor([-12.6001]) loss 6.326072692871094 epsilon 0.79335
28-Feb-25 11:06:57 - agent.DQN.DQN - INFO - episode 2 step 272 reward tensor([-12.6099]) loss 38.18500518798828 epsilon 0.79335
28-Feb-25 11:06:57 - agent.DQN.DQN - INFO - episode 2 step 273 reward tensor([-12.6156]) loss 5.663384437561035 epsilon 0.79335
28-Feb-25 11:06:57 - agent.DQN.DQN - INFO - episode 2 step 274 reward tensor([-12.6170]) loss 7.037661552429199 epsilon 0.79335
28-Feb-25 11:06:57 - agent.DQN.DQN - INFO - episode 2 step 275 reward tensor([-12.6137]) loss 36.06153869628906 epsilon 0.79335
28-Feb-25 11:06:57 - agent.DQN.DQN - INFO - episode 2 step 276 reward tensor([-12.6056]) loss 6.5735931396484375 epsilon 0.79335
28-Feb-25 11:06:57 - agent.DQN.DQN - INFO - episode 2 step 277 reward tensor([-12.5927]) loss 5.2586541175842285 epsilon 0.79335
28-Feb-25 11:06:57 - agent.DQN.DQN - INFO - episode 2 step 278 reward tensor([-12.5747]) loss 4.872834205627441 epsilon 0.79335
28-Feb-25 11:06:57 - agent.DQN.DQN - INFO - episode 2 step 279 reward tensor([-12.5592]) loss 4.843545436859131 epsilon 0.79335
28-Feb-25 11:06:57 - agent.DQN.DQN - INFO - episode 2 step 280 reward tensor([-12.5438]) loss 4.441036224365234 epsilon 0.79335
28-Feb-25 11:06:57 - agent.DQN.DQN - INFO - episode 2 step 281 reward tensor([-12.5199]) loss 5.8819193840026855 epsilon 0.79335
28-Feb-25 11:06:57 - agent.DQN.DQN - INFO - episode 2 step 282 reward tensor([-12.4885]) loss 4.416893482208252 epsilon 0.79335
28-Feb-25 11:06:57 - agent.DQN.DQN - INFO - episode 2 step 283 reward tensor([-12.4458]) loss 37.87376403808594 epsilon 0.79335
28-Feb-25 11:06:57 - agent.DQN.DQN - INFO - episode 2 step 284 reward tensor([-12.3929]) loss 3.776519298553467 epsilon 0.79335
28-Feb-25 11:06:57 - agent.DQN.DQN - INFO - episode 2 step 285 reward tensor([-12.3292]) loss 4.116079330444336 epsilon 0.79335
28-Feb-25 11:06:57 - agent.DQN.DQN - INFO - episode 2 step 286 reward tensor([-12.2585]) loss 3.6185173988342285 epsilon 0.79335
28-Feb-25 11:06:57 - agent.DQN.DQN - INFO - episode 2 step 287 reward tensor([-12.1808]) loss 2.9080119132995605 epsilon 0.79335
28-Feb-25 11:06:57 - agent.DQN.DQN - INFO - episode 2 step 288 reward tensor([-12.0935]) loss 3.943106174468994 epsilon 0.79335
28-Feb-25 11:06:57 - agent.DQN.DQN - INFO - episode 2 step 289 reward tensor([-11.9973]) loss 4.315167427062988 epsilon 0.79335
28-Feb-25 11:06:57 - agent.DQN.DQN - INFO - episode 2 step 290 reward tensor([-11.8925]) loss 41.237770080566406 epsilon 0.79335
28-Feb-25 11:06:57 - agent.DQN.DQN - INFO - episode 2 step 291 reward tensor([-11.7797]) loss 3.6838788986206055 epsilon 0.79335
28-Feb-25 11:06:57 - agent.DQN.DQN - INFO - episode 2 step 292 reward tensor([-11.6595]) loss 2.6688992977142334 epsilon 0.79335
28-Feb-25 11:06:57 - agent.DQN.DQN - INFO - episode 2 step 293 reward tensor([-11.5324]) loss 2.6738522052764893 epsilon 0.79335
28-Feb-25 11:06:57 - agent.DQN.DQN - INFO - episode 2 step 294 reward tensor([-11.3987]) loss 2.2627031803131104 epsilon 0.79335
28-Feb-25 11:06:57 - agent.DQN.DQN - INFO - episode 2 step 295 reward tensor([-11.2591]) loss 3.0840539932250977 epsilon 0.79335
28-Feb-25 11:06:57 - agent.DQN.DQN - INFO - episode 2 step 296 reward tensor([-11.1143]) loss 40.09469985961914 epsilon 0.79335
28-Feb-25 11:06:57 - agent.DQN.DQN - INFO - episode 2 step 297 reward tensor([-10.9653]) loss 2.6225473880767822 epsilon 0.79335
28-Feb-25 11:06:57 - agent.DQN.DQN - INFO - episode 2 step 298 reward tensor([-10.8123]) loss 2.2814717292785645 epsilon 0.79335
28-Feb-25 11:06:57 - agent.DQN.DQN - INFO - episode 2 step 299 reward tensor([-10.6553]) loss 8.619341850280762 epsilon 0.79335
28-Feb-25 11:06:57 - agent.DQN.DQN - INFO - episode 2 step 300 reward tensor([-10.4942]) loss 9.57524585723877 epsilon 0.79335
28-Feb-25 11:06:57 - agent.DQN.DQN - INFO - episode 2 step 301 reward tensor([-10.3298]) loss 8.017631530761719 epsilon 0.79335
28-Feb-25 11:06:57 - agent.DQN.DQN - INFO - episode 3 step 0 reward tensor([-1.9125]) loss 8.032341957092285 epsilon 0.767566125
28-Feb-25 11:06:57 - agent.DQN.DQN - INFO - episode 3 step 1 reward tensor([-1.9096]) loss 5.305436611175537 epsilon 0.767566125
28-Feb-25 11:06:57 - agent.DQN.DQN - INFO - episode 3 step 2 reward tensor([-1.9041]) loss 6.726799011230469 epsilon 0.767566125
28-Feb-25 11:06:57 - agent.DQN.DQN - INFO - episode 3 step 3 reward tensor([-1.8961]) loss 3.715148448944092 epsilon 0.767566125
28-Feb-25 11:06:57 - agent.DQN.DQN - INFO - episode 3 step 4 reward tensor([-1.8882]) loss 2.5393874645233154 epsilon 0.767566125
28-Feb-25 11:06:57 - agent.DQN.DQN - INFO - episode 3 step 5 reward tensor([-1.8778]) loss 2.351942777633667 epsilon 0.767566125
28-Feb-25 11:06:57 - agent.DQN.DQN - INFO - episode 3 step 6 reward tensor([-1.8675]) loss 2.5229883193969727 epsilon 0.767566125
28-Feb-25 11:06:57 - agent.DQN.DQN - INFO - episode 3 step 7 reward tensor([-1.8574]) loss 33.32329559326172 epsilon 0.767566125
28-Feb-25 11:06:57 - agent.DQN.DQN - INFO - episode 3 step 8 reward tensor([-1.8451]) loss 49.73060989379883 epsilon 0.767566125
28-Feb-25 11:06:57 - agent.DQN.DQN - INFO - episode 3 step 9 reward tensor([-1.8329]) loss 3.453725576400757 epsilon 0.767566125
28-Feb-25 11:06:57 - agent.DQN.DQN - INFO - episode 3 step 10 reward tensor([-1.8188]) loss 49.142791748046875 epsilon 0.767566125
28-Feb-25 11:06:57 - agent.DQN.DQN - INFO - episode 3 step 11 reward tensor([-1.8047]) loss 1.6628975868225098 epsilon 0.767566125
28-Feb-25 11:06:57 - agent.DQN.DQN - INFO - episode 3 step 12 reward tensor([-1.7890]) loss 3.510368824005127 epsilon 0.767566125
28-Feb-25 11:06:57 - agent.DQN.DQN - INFO - episode 3 step 13 reward tensor([-1.7738]) loss 3.241684913635254 epsilon 0.767566125
28-Feb-25 11:06:57 - agent.DQN.DQN - INFO - episode 3 step 14 reward tensor([-1.7593]) loss 45.97369384765625 epsilon 0.767566125
28-Feb-25 11:06:57 - agent.DQN.DQN - INFO - episode 3 step 15 reward tensor([-1.7514]) loss 3.369035482406616 epsilon 0.767566125
28-Feb-25 11:06:57 - agent.DQN.DQN - INFO - episode 3 step 16 reward tensor([-1.7497]) loss 30.546714782714844 epsilon 0.767566125
28-Feb-25 11:06:57 - agent.DQN.DQN - INFO - episode 3 step 17 reward tensor([-1.7614]) loss 42.48070526123047 epsilon 0.767566125
28-Feb-25 11:06:57 - agent.DQN.DQN - INFO - episode 3 step 18 reward tensor([-1.7845]) loss 3.2492730617523193 epsilon 0.767566125
28-Feb-25 11:06:57 - agent.DQN.DQN - INFO - episode 3 step 19 reward tensor([-1.8176]) loss 3.0110299587249756 epsilon 0.767566125
28-Feb-25 11:06:57 - agent.DQN.DQN - INFO - episode 3 step 20 reward tensor([-1.8596]) loss 3.025731325149536 epsilon 0.767566125
28-Feb-25 11:06:57 - agent.DQN.DQN - INFO - episode 3 step 21 reward tensor([-1.9094]) loss 41.87664794921875 epsilon 0.767566125
28-Feb-25 11:06:57 - agent.DQN.DQN - INFO - episode 3 step 22 reward tensor([-1.9662]) loss 3.1600747108459473 epsilon 0.767566125
28-Feb-25 11:06:57 - agent.DQN.DQN - INFO - episode 3 step 23 reward tensor([-2.0294]) loss 3.625499725341797 epsilon 0.767566125
28-Feb-25 11:06:57 - agent.DQN.DQN - INFO - episode 3 step 24 reward tensor([-2.0983]) loss 4.797791481018066 epsilon 0.767566125
28-Feb-25 11:06:57 - agent.DQN.DQN - INFO - episode 3 step 25 reward tensor([-2.1725]) loss 40.88923645019531 epsilon 0.767566125
28-Feb-25 11:06:57 - agent.DQN.DQN - INFO - episode 3 step 26 reward tensor([-2.2513]) loss 3.223379373550415 epsilon 0.767566125
28-Feb-25 11:06:57 - agent.DQN.DQN - INFO - episode 3 step 27 reward tensor([-2.3345]) loss 5.273728370666504 epsilon 0.767566125
28-Feb-25 11:06:57 - agent.DQN.DQN - INFO - episode 3 step 28 reward tensor([-2.4207]) loss 33.2926025390625 epsilon 0.767566125
28-Feb-25 11:06:57 - agent.DQN.DQN - INFO - episode 3 step 29 reward tensor([-2.5081]) loss 4.035258769989014 epsilon 0.767566125
28-Feb-25 11:06:57 - agent.DQN.DQN - INFO - episode 3 step 30 reward tensor([-2.5956]) loss 30.445941925048828 epsilon 0.767566125
28-Feb-25 11:06:57 - agent.DQN.DQN - INFO - episode 3 step 31 reward tensor([-2.6821]) loss 5.091663837432861 epsilon 0.767566125
28-Feb-25 11:06:57 - agent.DQN.DQN - INFO - episode 3 step 32 reward tensor([-2.7668]) loss 5.811393737792969 epsilon 0.767566125
28-Feb-25 11:06:57 - agent.DQN.DQN - INFO - episode 3 step 33 reward tensor([-2.8492]) loss 30.139842987060547 epsilon 0.767566125
28-Feb-25 11:06:57 - agent.DQN.DQN - INFO - episode 3 step 34 reward tensor([-2.9289]) loss 69.55824279785156 epsilon 0.767566125
28-Feb-25 11:06:57 - agent.DQN.DQN - INFO - episode 3 step 35 reward tensor([-3.0054]) loss 29.273624420166016 epsilon 0.767566125
28-Feb-25 11:06:57 - agent.DQN.DQN - INFO - episode 3 step 36 reward tensor([-3.0785]) loss 4.094857215881348 epsilon 0.767566125
28-Feb-25 11:06:57 - agent.DQN.DQN - INFO - episode 3 step 37 reward tensor([-3.1480]) loss 28.973833084106445 epsilon 0.767566125
28-Feb-25 11:06:57 - agent.DQN.DQN - INFO - episode 3 step 38 reward tensor([-3.2137]) loss 4.282100200653076 epsilon 0.767566125
28-Feb-25 11:06:57 - agent.DQN.DQN - INFO - episode 3 step 39 reward tensor([-3.2755]) loss 4.232332229614258 epsilon 0.767566125
28-Feb-25 11:06:57 - agent.DQN.DQN - INFO - episode 3 step 40 reward tensor([-3.3332]) loss 45.67916488647461 epsilon 0.767566125
28-Feb-25 11:06:57 - agent.DQN.DQN - INFO - episode 3 step 41 reward tensor([-3.3867]) loss 3.958034038543701 epsilon 0.767566125
28-Feb-25 11:06:57 - agent.DQN.DQN - INFO - episode 3 step 42 reward tensor([-3.4361]) loss 4.109307289123535 epsilon 0.767566125
28-Feb-25 11:06:57 - agent.DQN.DQN - INFO - episode 3 step 43 reward tensor([-3.4813]) loss 4.550118446350098 epsilon 0.767566125
28-Feb-25 11:06:57 - agent.DQN.DQN - INFO - episode 3 step 44 reward tensor([-3.5222]) loss 2.6134989261627197 epsilon 0.767566125
28-Feb-25 11:06:57 - agent.DQN.DQN - INFO - episode 3 step 45 reward tensor([-3.5589]) loss 3.627577304840088 epsilon 0.767566125
28-Feb-25 11:06:57 - agent.DQN.DQN - INFO - episode 3 step 46 reward tensor([-3.5913]) loss 46.54856491088867 epsilon 0.767566125
28-Feb-25 11:06:57 - agent.DQN.DQN - INFO - episode 3 step 47 reward tensor([-3.6195]) loss 26.873260498046875 epsilon 0.767566125
28-Feb-25 11:06:57 - agent.DQN.DQN - INFO - episode 3 step 48 reward tensor([-3.6436]) loss 3.373500347137451 epsilon 0.767566125
28-Feb-25 11:06:57 - agent.DQN.DQN - INFO - episode 3 step 49 reward tensor([-3.6635]) loss 43.9929313659668 epsilon 0.767566125
28-Feb-25 11:06:57 - agent.DQN.DQN - INFO - episode 3 step 50 reward tensor([-3.6794]) loss 4.473147869110107 epsilon 0.767566125
28-Feb-25 11:06:57 - agent.DQN.DQN - INFO - episode 3 step 51 reward tensor([-3.6913]) loss 4.183619499206543 epsilon 0.767566125
28-Feb-25 11:06:57 - agent.DQN.DQN - INFO - episode 3 step 52 reward tensor([-3.6995]) loss 26.052032470703125 epsilon 0.767566125
28-Feb-25 11:06:57 - agent.DQN.DQN - INFO - episode 3 step 53 reward tensor([-3.7039]) loss 25.415624618530273 epsilon 0.767566125
28-Feb-25 11:06:58 - agent.DQN.DQN - INFO - episode 3 step 54 reward tensor([-3.7048]) loss 3.6241633892059326 epsilon 0.767566125
28-Feb-25 11:06:58 - agent.DQN.DQN - INFO - episode 3 step 55 reward tensor([-3.7023]) loss 43.847469329833984 epsilon 0.767566125
28-Feb-25 11:06:58 - agent.DQN.DQN - INFO - episode 3 step 56 reward tensor([-3.7022]) loss 4.028141021728516 epsilon 0.767566125
28-Feb-25 11:06:58 - agent.DQN.DQN - INFO - episode 3 step 57 reward tensor([-3.7087]) loss 6.660876274108887 epsilon 0.767566125
28-Feb-25 11:06:58 - agent.DQN.DQN - INFO - episode 3 step 58 reward tensor([-3.7179]) loss 27.435264587402344 epsilon 0.767566125
28-Feb-25 11:06:58 - agent.DQN.DQN - INFO - episode 3 step 59 reward tensor([-3.7275]) loss 6.787067413330078 epsilon 0.767566125
28-Feb-25 11:06:58 - agent.DQN.DQN - INFO - episode 3 step 60 reward tensor([-3.7360]) loss 5.452821254730225 epsilon 0.767566125
28-Feb-25 11:06:58 - agent.DQN.DQN - INFO - episode 3 step 61 reward tensor([-3.7430]) loss 27.594234466552734 epsilon 0.767566125
28-Feb-25 11:06:58 - agent.DQN.DQN - INFO - episode 3 step 62 reward tensor([-3.7481]) loss 45.62038803100586 epsilon 0.767566125
28-Feb-25 11:06:58 - agent.DQN.DQN - INFO - episode 3 step 63 reward tensor([-3.7513]) loss 26.44039535522461 epsilon 0.767566125
28-Feb-25 11:06:58 - agent.DQN.DQN - INFO - episode 3 step 64 reward tensor([-3.7525]) loss 6.377793788909912 epsilon 0.767566125
28-Feb-25 11:06:58 - agent.DQN.DQN - INFO - episode 3 step 65 reward tensor([-3.7519]) loss 5.1660919189453125 epsilon 0.767566125
28-Feb-25 11:06:58 - agent.DQN.DQN - INFO - episode 3 step 66 reward tensor([-3.7497]) loss 3.774519920349121 epsilon 0.767566125
28-Feb-25 11:06:58 - agent.DQN.DQN - INFO - episode 3 step 67 reward tensor([-3.7461]) loss 3.5800814628601074 epsilon 0.767566125
28-Feb-25 11:06:58 - agent.DQN.DQN - INFO - episode 3 step 68 reward tensor([-3.7376]) loss 47.525413513183594 epsilon 0.767566125
28-Feb-25 11:06:58 - agent.DQN.DQN - INFO - episode 3 step 69 reward tensor([-3.7300]) loss 3.4706978797912598 epsilon 0.767566125
28-Feb-25 11:06:58 - agent.DQN.DQN - INFO - episode 3 step 70 reward tensor([-3.7265]) loss 46.17662048339844 epsilon 0.767566125
28-Feb-25 11:06:58 - agent.DQN.DQN - INFO - episode 3 step 71 reward tensor([-3.7244]) loss 2.8846094608306885 epsilon 0.767566125
28-Feb-25 11:06:58 - agent.DQN.DQN - INFO - episode 3 step 72 reward tensor([-3.7228]) loss 24.380189895629883 epsilon 0.767566125
28-Feb-25 11:06:58 - agent.DQN.DQN - INFO - episode 3 step 73 reward tensor([-3.7244]) loss 44.58772277832031 epsilon 0.767566125
28-Feb-25 11:06:58 - agent.DQN.DQN - INFO - episode 3 step 74 reward tensor([-3.7270]) loss 2.352386713027954 epsilon 0.767566125
28-Feb-25 11:06:58 - agent.DQN.DQN - INFO - episode 3 step 75 reward tensor([-3.7297]) loss 4.396306991577148 epsilon 0.767566125
28-Feb-25 11:06:58 - agent.DQN.DQN - INFO - episode 3 step 76 reward tensor([-3.7319]) loss 4.750237941741943 epsilon 0.767566125
28-Feb-25 11:06:58 - agent.DQN.DQN - INFO - episode 3 step 77 reward tensor([-3.7362]) loss 2.6601712703704834 epsilon 0.767566125
28-Feb-25 11:06:58 - agent.DQN.DQN - INFO - episode 3 step 78 reward tensor([-3.7432]) loss 2.6092774868011475 epsilon 0.767566125
28-Feb-25 11:06:58 - agent.DQN.DQN - INFO - episode 3 step 79 reward tensor([-3.7513]) loss 3.281362771987915 epsilon 0.767566125
28-Feb-25 11:06:58 - agent.DQN.DQN - INFO - episode 3 step 80 reward tensor([-3.7573]) loss 2.0055243968963623 epsilon 0.767566125
28-Feb-25 11:06:58 - agent.DQN.DQN - INFO - episode 3 step 81 reward tensor([-3.7618]) loss 3.4008543491363525 epsilon 0.767566125
28-Feb-25 11:06:58 - agent.DQN.DQN - INFO - episode 3 step 82 reward tensor([-3.7654]) loss 25.60831069946289 epsilon 0.767566125
28-Feb-25 11:06:58 - agent.DQN.DQN - INFO - episode 3 step 83 reward tensor([-3.7681]) loss 2.882871389389038 epsilon 0.767566125
28-Feb-25 11:06:58 - agent.DQN.DQN - INFO - episode 3 step 84 reward tensor([-3.7702]) loss 2.36922550201416 epsilon 0.767566125
28-Feb-25 11:06:58 - agent.DQN.DQN - INFO - episode 3 step 85 reward tensor([-3.7716]) loss 3.5310544967651367 epsilon 0.767566125
28-Feb-25 11:06:58 - agent.DQN.DQN - INFO - episode 3 step 86 reward tensor([-3.7739]) loss 3.596881866455078 epsilon 0.767566125
28-Feb-25 11:06:58 - agent.DQN.DQN - INFO - episode 3 step 87 reward tensor([-3.7772]) loss 6.313631534576416 epsilon 0.767566125
28-Feb-25 11:06:58 - agent.DQN.DQN - INFO - episode 3 step 88 reward tensor([-3.7810]) loss 5.095963001251221 epsilon 0.767566125
28-Feb-25 11:06:58 - agent.DQN.DQN - INFO - episode 3 step 89 reward tensor([-3.7847]) loss 48.651554107666016 epsilon 0.767566125
28-Feb-25 11:06:58 - agent.DQN.DQN - INFO - episode 3 step 90 reward tensor([-3.7883]) loss 4.131235599517822 epsilon 0.767566125
28-Feb-25 11:06:58 - agent.DQN.DQN - INFO - episode 3 step 91 reward tensor([-3.7906]) loss 4.181952953338623 epsilon 0.767566125
28-Feb-25 11:06:58 - agent.DQN.DQN - INFO - episode 3 step 92 reward tensor([-3.7913]) loss 2.6229984760284424 epsilon 0.767566125
28-Feb-25 11:06:58 - agent.DQN.DQN - INFO - episode 3 step 93 reward tensor([-3.7913]) loss 2.9484262466430664 epsilon 0.767566125
28-Feb-25 11:06:58 - agent.DQN.DQN - INFO - episode 3 step 94 reward tensor([-3.7912]) loss 25.774555206298828 epsilon 0.767566125
28-Feb-25 11:06:58 - agent.DQN.DQN - INFO - episode 3 step 95 reward tensor([-3.7911]) loss 2.2358710765838623 epsilon 0.767566125
28-Feb-25 11:06:58 - agent.DQN.DQN - INFO - episode 3 step 96 reward tensor([-3.7914]) loss 2.733347177505493 epsilon 0.767566125
28-Feb-25 11:06:58 - agent.DQN.DQN - INFO - episode 3 step 97 reward tensor([-3.7923]) loss 3.0873515605926514 epsilon 0.767566125
28-Feb-25 11:06:58 - agent.DQN.DQN - INFO - episode 3 step 98 reward tensor([-3.7936]) loss 2.6969552040100098 epsilon 0.767566125
28-Feb-25 11:06:58 - agent.DQN.DQN - INFO - episode 3 step 99 reward tensor([-3.7954]) loss 3.0148394107818604 epsilon 0.767566125
28-Feb-25 11:06:58 - agent.DQN.DQN - INFO - episode 3 step 100 reward tensor([-3.7977]) loss 2.7972497940063477 epsilon 0.767566125
28-Feb-25 11:06:58 - agent.DQN.DQN - INFO - episode 3 step 101 reward tensor([-3.8015]) loss 2.692668914794922 epsilon 0.767566125
28-Feb-25 11:06:58 - agent.DQN.DQN - INFO - episode 3 step 102 reward tensor([-3.8083]) loss 2.5236759185791016 epsilon 0.767566125
28-Feb-25 11:06:58 - agent.DQN.DQN - INFO - episode 3 step 103 reward tensor([-3.8166]) loss 2.722956418991089 epsilon 0.767566125
28-Feb-25 11:06:58 - agent.DQN.DQN - INFO - episode 3 step 104 reward tensor([-3.8243]) loss 2.239893913269043 epsilon 0.767566125
28-Feb-25 11:06:58 - agent.DQN.DQN - INFO - episode 3 step 105 reward tensor([-3.8319]) loss 1.9048259258270264 epsilon 0.767566125
28-Feb-25 11:06:58 - agent.DQN.DQN - INFO - episode 3 step 106 reward tensor([-3.8401]) loss 2.442251205444336 epsilon 0.767566125
28-Feb-25 11:06:58 - agent.DQN.DQN - INFO - episode 3 step 107 reward tensor([-3.8512]) loss 2.3722167015075684 epsilon 0.767566125
28-Feb-25 11:06:58 - agent.DQN.DQN - INFO - episode 3 step 108 reward tensor([-3.8673]) loss 2.5746912956237793 epsilon 0.767566125
28-Feb-25 11:06:58 - agent.DQN.DQN - INFO - episode 3 step 109 reward tensor([-3.8877]) loss 2.1430768966674805 epsilon 0.767566125
28-Feb-25 11:06:58 - agent.DQN.DQN - INFO - episode 3 step 110 reward tensor([-3.9127]) loss 2.4067342281341553 epsilon 0.767566125
28-Feb-25 11:06:58 - agent.DQN.DQN - INFO - episode 3 step 111 reward tensor([-3.9420]) loss 1.511605978012085 epsilon 0.767566125
28-Feb-25 11:06:58 - agent.DQN.DQN - INFO - episode 3 step 112 reward tensor([-3.9714]) loss 2.478990316390991 epsilon 0.767566125
28-Feb-25 11:06:58 - agent.DQN.DQN - INFO - episode 3 step 113 reward tensor([-3.9978]) loss 1.7141791582107544 epsilon 0.767566125
28-Feb-25 11:06:58 - agent.DQN.DQN - INFO - episode 3 step 114 reward tensor([-4.0236]) loss 55.12608337402344 epsilon 0.767566125
28-Feb-25 11:06:58 - agent.DQN.DQN - INFO - episode 3 step 115 reward tensor([-4.0538]) loss 2.383685827255249 epsilon 0.767566125
28-Feb-25 11:06:58 - agent.DQN.DQN - INFO - episode 3 step 116 reward tensor([-4.0827]) loss 1.5180916786193848 epsilon 0.767566125
28-Feb-25 11:06:58 - agent.DQN.DQN - INFO - episode 3 step 117 reward tensor([-4.1117]) loss 30.505971908569336 epsilon 0.767566125
28-Feb-25 11:06:58 - agent.DQN.DQN - INFO - episode 3 step 118 reward tensor([-4.1409]) loss 8.159804344177246 epsilon 0.767566125
28-Feb-25 11:06:58 - agent.DQN.DQN - INFO - episode 3 step 119 reward tensor([-4.1706]) loss 6.621115684509277 epsilon 0.767566125
28-Feb-25 11:06:58 - agent.DQN.DQN - INFO - episode 3 step 120 reward tensor([-4.2011]) loss 5.076629638671875 epsilon 0.767566125
28-Feb-25 11:06:58 - agent.DQN.DQN - INFO - episode 3 step 121 reward tensor([-4.2326]) loss 28.08399772644043 epsilon 0.767566125
28-Feb-25 11:06:58 - agent.DQN.DQN - INFO - episode 3 step 122 reward tensor([-4.2702]) loss 26.57720375061035 epsilon 0.767566125
28-Feb-25 11:06:58 - agent.DQN.DQN - INFO - episode 3 step 123 reward tensor([-4.3122]) loss 3.439765453338623 epsilon 0.767566125
28-Feb-25 11:06:58 - agent.DQN.DQN - INFO - episode 3 step 124 reward tensor([-4.3575]) loss 2.3041162490844727 epsilon 0.767566125
28-Feb-25 11:06:58 - agent.DQN.DQN - INFO - episode 3 step 125 reward tensor([-4.4061]) loss 2.5292794704437256 epsilon 0.767566125
28-Feb-25 11:06:58 - agent.DQN.DQN - INFO - episode 3 step 126 reward tensor([-4.4629]) loss 2.0309929847717285 epsilon 0.767566125
28-Feb-25 11:06:58 - agent.DQN.DQN - INFO - episode 3 step 127 reward tensor([-4.5296]) loss 2.6120858192443848 epsilon 0.767566125
28-Feb-25 11:06:58 - agent.DQN.DQN - INFO - episode 3 step 128 reward tensor([-4.6076]) loss 1.8157122135162354 epsilon 0.767566125
28-Feb-25 11:06:58 - agent.DQN.DQN - INFO - episode 3 step 129 reward tensor([-4.6910]) loss 2.0060532093048096 epsilon 0.767566125
28-Feb-25 11:06:58 - agent.DQN.DQN - INFO - episode 3 step 130 reward tensor([-4.7832]) loss 25.024639129638672 epsilon 0.767566125
28-Feb-25 11:06:58 - agent.DQN.DQN - INFO - episode 3 step 131 reward tensor([-4.8780]) loss 24.45908546447754 epsilon 0.767566125
28-Feb-25 11:06:58 - agent.DQN.DQN - INFO - episode 3 step 132 reward tensor([-4.9800]) loss 1.9985473155975342 epsilon 0.767566125
28-Feb-25 11:06:58 - agent.DQN.DQN - INFO - episode 3 step 133 reward tensor([-5.0883]) loss 1.7082687616348267 epsilon 0.767566125
28-Feb-25 11:06:58 - agent.DQN.DQN - INFO - episode 3 step 134 reward tensor([-5.2019]) loss 24.735679626464844 epsilon 0.767566125
28-Feb-25 11:06:58 - agent.DQN.DQN - INFO - episode 3 step 135 reward tensor([-5.3144]) loss 23.165132522583008 epsilon 0.767566125
28-Feb-25 11:06:58 - agent.DQN.DQN - INFO - episode 3 step 136 reward tensor([-5.4266]) loss 2.4680163860321045 epsilon 0.767566125
28-Feb-25 11:06:58 - agent.DQN.DQN - INFO - episode 3 step 137 reward tensor([-5.5394]) loss 23.101715087890625 epsilon 0.767566125
28-Feb-25 11:06:58 - agent.DQN.DQN - INFO - episode 3 step 138 reward tensor([-5.6530]) loss 2.4887659549713135 epsilon 0.767566125
28-Feb-25 11:06:58 - agent.DQN.DQN - INFO - episode 3 step 139 reward tensor([-5.7717]) loss 2.914529800415039 epsilon 0.767566125
28-Feb-25 11:06:58 - agent.DQN.DQN - INFO - episode 3 step 140 reward tensor([-5.8965]) loss 2.422288656234741 epsilon 0.767566125
28-Feb-25 11:06:58 - agent.DQN.DQN - INFO - episode 3 step 141 reward tensor([-6.0267]) loss 2.834737777709961 epsilon 0.767566125
28-Feb-25 11:06:58 - agent.DQN.DQN - INFO - episode 3 step 142 reward tensor([-6.1600]) loss 1.9300942420959473 epsilon 0.767566125
28-Feb-25 11:06:58 - agent.DQN.DQN - INFO - episode 3 step 143 reward tensor([-6.2969]) loss 1.6651904582977295 epsilon 0.767566125
28-Feb-25 11:06:58 - agent.DQN.DQN - INFO - episode 3 step 144 reward tensor([-6.4359]) loss 3.2086710929870605 epsilon 0.767566125
28-Feb-25 11:06:58 - agent.DQN.DQN - INFO - episode 3 step 145 reward tensor([-6.5775]) loss 3.123105049133301 epsilon 0.767566125
28-Feb-25 11:06:58 - agent.DQN.DQN - INFO - episode 3 step 146 reward tensor([-6.7213]) loss 1.2215826511383057 epsilon 0.767566125
28-Feb-25 11:06:58 - agent.DQN.DQN - INFO - episode 3 step 147 reward tensor([-6.8665]) loss 6.985586166381836 epsilon 0.767566125
28-Feb-25 11:06:58 - agent.DQN.DQN - INFO - episode 3 step 148 reward tensor([-7.0104]) loss 67.40835571289062 epsilon 0.767566125
28-Feb-25 11:06:58 - agent.DQN.DQN - INFO - episode 3 step 149 reward tensor([-7.1552]) loss 27.313812255859375 epsilon 0.767566125
28-Feb-25 11:06:59 - agent.DQN.DQN - INFO - episode 3 step 150 reward tensor([-7.3010]) loss 28.047515869140625 epsilon 0.767566125
28-Feb-25 11:06:59 - agent.DQN.DQN - INFO - episode 3 step 151 reward tensor([-7.4453]) loss 4.6752190589904785 epsilon 0.767566125
28-Feb-25 11:06:59 - agent.DQN.DQN - INFO - episode 3 step 152 reward tensor([-7.5903]) loss 24.663564682006836 epsilon 0.767566125
28-Feb-25 11:06:59 - agent.DQN.DQN - INFO - episode 3 step 153 reward tensor([-7.7358]) loss 26.199851989746094 epsilon 0.767566125
28-Feb-25 11:06:59 - agent.DQN.DQN - INFO - episode 3 step 154 reward tensor([-7.8813]) loss 5.488181114196777 epsilon 0.767566125
28-Feb-25 11:06:59 - agent.DQN.DQN - INFO - episode 3 step 155 reward tensor([-8.0264]) loss 3.9039907455444336 epsilon 0.767566125
28-Feb-25 11:06:59 - agent.DQN.DQN - INFO - episode 3 step 156 reward tensor([-8.1703]) loss 2.863086223602295 epsilon 0.767566125
28-Feb-25 11:06:59 - agent.DQN.DQN - INFO - episode 3 step 157 reward tensor([-8.3134]) loss 2.655872106552124 epsilon 0.767566125
28-Feb-25 11:06:59 - agent.DQN.DQN - INFO - episode 3 step 158 reward tensor([-8.4551]) loss 66.711181640625 epsilon 0.767566125
28-Feb-25 11:06:59 - agent.DQN.DQN - INFO - episode 3 step 159 reward tensor([-8.5949]) loss 21.509843826293945 epsilon 0.767566125
28-Feb-25 11:06:59 - agent.DQN.DQN - INFO - episode 3 step 160 reward tensor([-8.7325]) loss 2.0834429264068604 epsilon 0.767566125
28-Feb-25 11:06:59 - agent.DQN.DQN - INFO - episode 3 step 161 reward tensor([-8.8657]) loss 22.123807907104492 epsilon 0.767566125
28-Feb-25 11:06:59 - agent.DQN.DQN - INFO - episode 3 step 162 reward tensor([-8.9913]) loss 2.706575393676758 epsilon 0.767566125
28-Feb-25 11:06:59 - agent.DQN.DQN - INFO - episode 3 step 163 reward tensor([-9.1097]) loss 20.775556564331055 epsilon 0.767566125
28-Feb-25 11:06:59 - agent.DQN.DQN - INFO - episode 3 step 164 reward tensor([-9.2226]) loss 3.6616785526275635 epsilon 0.767566125
28-Feb-25 11:06:59 - agent.DQN.DQN - INFO - episode 3 step 165 reward tensor([-9.3313]) loss 3.3627734184265137 epsilon 0.767566125
28-Feb-25 11:06:59 - agent.DQN.DQN - INFO - episode 3 step 166 reward tensor([-9.4372]) loss 3.014645576477051 epsilon 0.767566125
28-Feb-25 11:06:59 - agent.DQN.DQN - INFO - episode 3 step 167 reward tensor([-9.5416]) loss 2.737727642059326 epsilon 0.767566125
28-Feb-25 11:06:59 - agent.DQN.DQN - INFO - episode 3 step 168 reward tensor([-9.6449]) loss 2.9659228324890137 epsilon 0.767566125
28-Feb-25 11:06:59 - agent.DQN.DQN - INFO - episode 3 step 169 reward tensor([-9.7468]) loss 19.662315368652344 epsilon 0.767566125
28-Feb-25 11:06:59 - agent.DQN.DQN - INFO - episode 3 step 170 reward tensor([-9.8458]) loss 3.608242988586426 epsilon 0.767566125
28-Feb-25 11:06:59 - agent.DQN.DQN - INFO - episode 3 step 171 reward tensor([-9.9438]) loss 67.56167602539062 epsilon 0.767566125
28-Feb-25 11:06:59 - agent.DQN.DQN - INFO - episode 3 step 172 reward tensor([-10.0410]) loss 2.128716230392456 epsilon 0.767566125
28-Feb-25 11:06:59 - agent.DQN.DQN - INFO - episode 3 step 173 reward tensor([-10.1350]) loss 2.987962007522583 epsilon 0.767566125
28-Feb-25 11:06:59 - agent.DQN.DQN - INFO - episode 3 step 174 reward tensor([-10.2257]) loss 17.961626052856445 epsilon 0.767566125
28-Feb-25 11:06:59 - agent.DQN.DQN - INFO - episode 3 step 175 reward tensor([-10.3161]) loss 1.9894232749938965 epsilon 0.767566125
28-Feb-25 11:06:59 - agent.DQN.DQN - INFO - episode 3 step 176 reward tensor([-10.4076]) loss 66.55039978027344 epsilon 0.767566125
28-Feb-25 11:06:59 - agent.DQN.DQN - INFO - episode 3 step 177 reward tensor([-10.5000]) loss 5.96692419052124 epsilon 0.767566125
28-Feb-25 11:06:59 - agent.DQN.DQN - INFO - episode 3 step 178 reward tensor([-10.5930]) loss 67.73089599609375 epsilon 0.767566125
28-Feb-25 11:06:59 - agent.DQN.DQN - INFO - episode 3 step 179 reward tensor([-10.6869]) loss 4.772822856903076 epsilon 0.767566125
28-Feb-25 11:06:59 - agent.DQN.DQN - INFO - episode 3 step 180 reward tensor([-10.7810]) loss 5.908158302307129 epsilon 0.767566125
28-Feb-25 11:06:59 - agent.DQN.DQN - INFO - episode 3 step 181 reward tensor([-10.8745]) loss 5.637258529663086 epsilon 0.767566125
28-Feb-25 11:06:59 - agent.DQN.DQN - INFO - episode 3 step 182 reward tensor([-10.9640]) loss 22.581857681274414 epsilon 0.767566125
28-Feb-25 11:06:59 - agent.DQN.DQN - INFO - episode 3 step 183 reward tensor([-11.0528]) loss 6.468398094177246 epsilon 0.767566125
28-Feb-25 11:06:59 - agent.DQN.DQN - INFO - episode 3 step 184 reward tensor([-11.1375]) loss 5.462565898895264 epsilon 0.767566125
28-Feb-25 11:06:59 - agent.DQN.DQN - INFO - episode 3 step 185 reward tensor([-11.2182]) loss 5.839119911193848 epsilon 0.767566125
28-Feb-25 11:06:59 - agent.DQN.DQN - INFO - episode 3 step 186 reward tensor([-11.2978]) loss 4.774962425231934 epsilon 0.767566125
28-Feb-25 11:06:59 - agent.DQN.DQN - INFO - episode 3 step 187 reward tensor([-11.3774]) loss 8.240365028381348 epsilon 0.767566125
28-Feb-25 11:06:59 - agent.DQN.DQN - INFO - episode 3 step 188 reward tensor([-11.4544]) loss 6.8238959312438965 epsilon 0.767566125
28-Feb-25 11:06:59 - agent.DQN.DQN - INFO - episode 3 step 189 reward tensor([-11.5286]) loss 63.474830627441406 epsilon 0.767566125
28-Feb-25 11:06:59 - agent.DQN.DQN - INFO - episode 3 step 190 reward tensor([-11.6002]) loss 21.19424057006836 epsilon 0.767566125
28-Feb-25 11:06:59 - agent.DQN.DQN - INFO - episode 3 step 191 reward tensor([-11.6685]) loss 20.379375457763672 epsilon 0.767566125
28-Feb-25 11:06:59 - agent.DQN.DQN - INFO - episode 3 step 192 reward tensor([-11.7336]) loss 4.544467926025391 epsilon 0.767566125
28-Feb-25 11:06:59 - agent.DQN.DQN - INFO - episode 3 step 193 reward tensor([-11.7973]) loss 3.243563413619995 epsilon 0.767566125
28-Feb-25 11:06:59 - agent.DQN.DQN - INFO - episode 3 step 194 reward tensor([-11.8594]) loss 2.5242762565612793 epsilon 0.767566125
28-Feb-25 11:06:59 - agent.DQN.DQN - INFO - episode 3 step 195 reward tensor([-11.9193]) loss 4.188272476196289 epsilon 0.767566125
28-Feb-25 11:06:59 - agent.DQN.DQN - INFO - episode 3 step 196 reward tensor([-11.9767]) loss 63.55706024169922 epsilon 0.767566125
28-Feb-25 11:06:59 - agent.DQN.DQN - INFO - episode 3 step 197 reward tensor([-12.0315]) loss 3.529170513153076 epsilon 0.767566125
28-Feb-25 11:06:59 - agent.DQN.DQN - INFO - episode 3 step 198 reward tensor([-12.0834]) loss 63.77705001831055 epsilon 0.767566125
28-Feb-25 11:06:59 - agent.DQN.DQN - INFO - episode 3 step 199 reward tensor([-12.1324]) loss 77.00495147705078 epsilon 0.767566125
28-Feb-25 11:06:59 - agent.DQN.DQN - INFO - episode 3 step 200 reward tensor([-12.1787]) loss 3.804497718811035 epsilon 0.767566125
28-Feb-25 11:06:59 - agent.DQN.DQN - INFO - episode 3 step 201 reward tensor([-12.2213]) loss 4.458857536315918 epsilon 0.767566125
28-Feb-25 11:06:59 - agent.DQN.DQN - INFO - episode 3 step 202 reward tensor([-12.2580]) loss 3.4988739490509033 epsilon 0.767566125
28-Feb-25 11:06:59 - agent.DQN.DQN - INFO - episode 3 step 203 reward tensor([-12.2896]) loss 57.39044952392578 epsilon 0.767566125
28-Feb-25 11:06:59 - agent.DQN.DQN - INFO - episode 3 step 204 reward tensor([-12.3171]) loss 5.094146728515625 epsilon 0.767566125
28-Feb-25 11:06:59 - agent.DQN.DQN - INFO - episode 3 step 205 reward tensor([-12.3414]) loss 7.510745525360107 epsilon 0.767566125
28-Feb-25 11:06:59 - agent.DQN.DQN - INFO - episode 3 step 206 reward tensor([-12.3616]) loss 7.240006446838379 epsilon 0.767566125
28-Feb-25 11:06:59 - agent.DQN.DQN - INFO - episode 3 step 207 reward tensor([-12.3770]) loss 10.746728897094727 epsilon 0.767566125
28-Feb-25 11:06:59 - agent.DQN.DQN - INFO - episode 3 step 208 reward tensor([-12.3890]) loss 5.764560222625732 epsilon 0.767566125
28-Feb-25 11:06:59 - agent.DQN.DQN - INFO - episode 3 step 209 reward tensor([-12.3964]) loss 12.914355278015137 epsilon 0.767566125
28-Feb-25 11:06:59 - agent.DQN.DQN - INFO - episode 3 step 210 reward tensor([-12.3998]) loss 22.393402099609375 epsilon 0.767566125
28-Feb-25 11:06:59 - agent.DQN.DQN - INFO - episode 3 step 211 reward tensor([-12.4013]) loss 6.465348243713379 epsilon 0.767566125
28-Feb-25 11:06:59 - agent.DQN.DQN - INFO - episode 3 step 212 reward tensor([-12.4022]) loss 23.885393142700195 epsilon 0.767566125
28-Feb-25 11:06:59 - agent.DQN.DQN - INFO - episode 3 step 213 reward tensor([-12.4024]) loss 5.222609043121338 epsilon 0.767566125
28-Feb-25 11:06:59 - agent.DQN.DQN - INFO - episode 3 step 214 reward tensor([-12.4024]) loss 5.402151584625244 epsilon 0.767566125
28-Feb-25 11:06:59 - agent.DQN.DQN - INFO - episode 3 step 215 reward tensor([-12.4029]) loss 4.125554084777832 epsilon 0.767566125
28-Feb-25 11:06:59 - agent.DQN.DQN - INFO - episode 3 step 216 reward tensor([-12.4039]) loss 8.227804183959961 epsilon 0.767566125
28-Feb-25 11:06:59 - agent.DQN.DQN - INFO - episode 3 step 217 reward tensor([-12.4057]) loss 4.365362644195557 epsilon 0.767566125
28-Feb-25 11:06:59 - agent.DQN.DQN - INFO - episode 3 step 218 reward tensor([-12.4094]) loss 4.673553466796875 epsilon 0.767566125
28-Feb-25 11:06:59 - agent.DQN.DQN - INFO - episode 3 step 219 reward tensor([-12.4158]) loss 73.22718811035156 epsilon 0.767566125
28-Feb-25 11:06:59 - agent.DQN.DQN - INFO - episode 3 step 220 reward tensor([-12.4249]) loss 3.7593772411346436 epsilon 0.767566125
28-Feb-25 11:06:59 - agent.DQN.DQN - INFO - episode 3 step 221 reward tensor([-12.4367]) loss 4.330042362213135 epsilon 0.767566125
28-Feb-25 11:06:59 - agent.DQN.DQN - INFO - episode 3 step 222 reward tensor([-12.4492]) loss 4.565341949462891 epsilon 0.767566125
28-Feb-25 11:06:59 - agent.DQN.DQN - INFO - episode 3 step 223 reward tensor([-12.4650]) loss 4.234249591827393 epsilon 0.767566125
28-Feb-25 11:06:59 - agent.DQN.DQN - INFO - episode 3 step 224 reward tensor([-12.4815]) loss 4.681729316711426 epsilon 0.767566125
28-Feb-25 11:06:59 - agent.DQN.DQN - INFO - episode 3 step 225 reward tensor([-12.4993]) loss 3.2530226707458496 epsilon 0.767566125
28-Feb-25 11:06:59 - agent.DQN.DQN - INFO - episode 3 step 226 reward tensor([-12.5188]) loss 4.026293754577637 epsilon 0.767566125
28-Feb-25 11:06:59 - agent.DQN.DQN - INFO - episode 3 step 227 reward tensor([-12.5429]) loss 4.534453868865967 epsilon 0.767566125
28-Feb-25 11:06:59 - agent.DQN.DQN - INFO - episode 3 step 228 reward tensor([-12.5731]) loss 3.124891519546509 epsilon 0.767566125
28-Feb-25 11:06:59 - agent.DQN.DQN - INFO - episode 3 step 229 reward tensor([-12.6060]) loss 2.978412628173828 epsilon 0.767566125
28-Feb-25 11:06:59 - agent.DQN.DQN - INFO - episode 3 step 230 reward tensor([-12.6380]) loss 2.5925729274749756 epsilon 0.767566125
28-Feb-25 11:06:59 - agent.DQN.DQN - INFO - episode 3 step 231 reward tensor([-12.6706]) loss 3.5189573764801025 epsilon 0.767566125
28-Feb-25 11:06:59 - agent.DQN.DQN - INFO - episode 3 step 232 reward tensor([-12.7082]) loss 6.080867290496826 epsilon 0.767566125
28-Feb-25 11:06:59 - agent.DQN.DQN - INFO - episode 3 step 233 reward tensor([-12.7499]) loss 18.283004760742188 epsilon 0.767566125
28-Feb-25 11:06:59 - agent.DQN.DQN - INFO - episode 3 step 234 reward tensor([-12.7952]) loss 4.488925933837891 epsilon 0.767566125
28-Feb-25 11:06:59 - agent.DQN.DQN - INFO - episode 3 step 235 reward tensor([-12.8396]) loss 2.4781110286712646 epsilon 0.767566125
28-Feb-25 11:06:59 - agent.DQN.DQN - INFO - episode 3 step 236 reward tensor([-12.8847]) loss 3.6534533500671387 epsilon 0.767566125
28-Feb-25 11:06:59 - agent.DQN.DQN - INFO - episode 3 step 237 reward tensor([-12.9314]) loss 5.133235454559326 epsilon 0.767566125
28-Feb-25 11:06:59 - agent.DQN.DQN - INFO - episode 3 step 238 reward tensor([-12.9801]) loss 6.0523481369018555 epsilon 0.767566125
28-Feb-25 11:06:59 - agent.DQN.DQN - INFO - episode 3 step 239 reward tensor([-13.0350]) loss 5.613217830657959 epsilon 0.767566125
28-Feb-25 11:06:59 - agent.DQN.DQN - INFO - episode 3 step 240 reward tensor([-13.0905]) loss 64.41292572021484 epsilon 0.767566125
28-Feb-25 11:06:59 - agent.DQN.DQN - INFO - episode 3 step 241 reward tensor([-13.1473]) loss 3.5776238441467285 epsilon 0.767566125
28-Feb-25 11:06:59 - agent.DQN.DQN - INFO - episode 3 step 242 reward tensor([-13.2061]) loss 2.340404987335205 epsilon 0.767566125
28-Feb-25 11:06:59 - agent.DQN.DQN - INFO - episode 3 step 243 reward tensor([-13.2669]) loss 3.6926403045654297 epsilon 0.767566125
28-Feb-25 11:06:59 - agent.DQN.DQN - INFO - episode 3 step 244 reward tensor([-13.3342]) loss 2.905216693878174 epsilon 0.767566125
28-Feb-25 11:06:59 - agent.DQN.DQN - INFO - episode 3 step 245 reward tensor([-13.4017]) loss 2.9039154052734375 epsilon 0.767566125
28-Feb-25 11:06:59 - agent.DQN.DQN - INFO - episode 3 step 246 reward tensor([-13.4705]) loss 2.7709555625915527 epsilon 0.767566125
28-Feb-25 11:06:59 - agent.DQN.DQN - INFO - episode 3 step 247 reward tensor([-13.5410]) loss 2.996668815612793 epsilon 0.767566125
28-Feb-25 11:06:59 - agent.DQN.DQN - INFO - episode 3 step 248 reward tensor([-13.6174]) loss 19.44874382019043 epsilon 0.767566125
28-Feb-25 11:06:59 - agent.DQN.DQN - INFO - episode 3 step 249 reward tensor([-13.6981]) loss 4.28267240524292 epsilon 0.767566125
28-Feb-25 11:06:59 - agent.DQN.DQN - INFO - episode 3 step 250 reward tensor([-13.7820]) loss 2.6885969638824463 epsilon 0.767566125
28-Feb-25 11:07:00 - agent.DQN.DQN - INFO - episode 3 step 251 reward tensor([-13.8719]) loss 1.9683281183242798 epsilon 0.767566125
28-Feb-25 11:07:00 - agent.DQN.DQN - INFO - episode 3 step 252 reward tensor([-13.9625]) loss 18.22684669494629 epsilon 0.767566125
28-Feb-25 11:07:00 - agent.DQN.DQN - INFO - episode 3 step 253 reward tensor([-14.0500]) loss 2.4070234298706055 epsilon 0.767566125
28-Feb-25 11:07:00 - agent.DQN.DQN - INFO - episode 3 step 254 reward tensor([-14.1366]) loss 63.24088668823242 epsilon 0.767566125
28-Feb-25 11:07:00 - agent.DQN.DQN - INFO - episode 3 step 255 reward tensor([-14.2236]) loss 2.437786340713501 epsilon 0.767566125
28-Feb-25 11:07:00 - agent.DQN.DQN - INFO - episode 3 step 256 reward tensor([-14.3149]) loss 2.862086296081543 epsilon 0.767566125
28-Feb-25 11:07:00 - agent.DQN.DQN - INFO - episode 3 step 257 reward tensor([-14.4118]) loss 2.9431755542755127 epsilon 0.767566125
28-Feb-25 11:07:00 - agent.DQN.DQN - INFO - episode 3 step 258 reward tensor([-14.5124]) loss 2.3669004440307617 epsilon 0.767566125
28-Feb-25 11:07:00 - agent.DQN.DQN - INFO - episode 3 step 259 reward tensor([-14.6157]) loss 2.951359510421753 epsilon 0.767566125
28-Feb-25 11:07:00 - agent.DQN.DQN - INFO - episode 3 step 260 reward tensor([-14.7208]) loss 2.277846574783325 epsilon 0.767566125
28-Feb-25 11:07:00 - agent.DQN.DQN - INFO - episode 3 step 261 reward tensor([-14.8271]) loss 16.721288681030273 epsilon 0.767566125
28-Feb-25 11:07:00 - agent.DQN.DQN - INFO - episode 3 step 262 reward tensor([-14.9314]) loss 16.56687355041504 epsilon 0.767566125
28-Feb-25 11:07:00 - agent.DQN.DQN - INFO - episode 3 step 263 reward tensor([-15.0320]) loss 2.404597520828247 epsilon 0.767566125
28-Feb-25 11:07:00 - agent.DQN.DQN - INFO - episode 3 step 264 reward tensor([-15.1310]) loss 3.145498514175415 epsilon 0.767566125
28-Feb-25 11:07:00 - agent.DQN.DQN - INFO - episode 3 step 265 reward tensor([-15.2294]) loss 61.632747650146484 epsilon 0.767566125
28-Feb-25 11:07:00 - agent.DQN.DQN - INFO - episode 3 step 266 reward tensor([-15.3278]) loss 2.9573051929473877 epsilon 0.767566125
28-Feb-25 11:07:00 - agent.DQN.DQN - INFO - episode 3 step 267 reward tensor([-15.4263]) loss 6.655022144317627 epsilon 0.767566125
28-Feb-25 11:07:00 - agent.DQN.DQN - INFO - episode 3 step 268 reward tensor([-15.5251]) loss 20.84242057800293 epsilon 0.767566125
28-Feb-25 11:07:00 - agent.DQN.DQN - INFO - episode 3 step 269 reward tensor([-15.6241]) loss 4.1325178146362305 epsilon 0.767566125
28-Feb-25 11:07:00 - agent.DQN.DQN - INFO - episode 3 step 270 reward tensor([-15.7233]) loss 5.872020721435547 epsilon 0.767566125
28-Feb-25 11:07:00 - agent.DQN.DQN - INFO - episode 3 step 271 reward tensor([-15.8225]) loss 63.00464630126953 epsilon 0.767566125
28-Feb-25 11:07:00 - agent.DQN.DQN - INFO - episode 3 step 272 reward tensor([-15.9223]) loss 5.0832295417785645 epsilon 0.767566125
28-Feb-25 11:07:00 - agent.DQN.DQN - INFO - episode 3 step 273 reward tensor([-16.0222]) loss 61.31803894042969 epsilon 0.767566125
28-Feb-25 11:07:00 - agent.DQN.DQN - INFO - episode 3 step 274 reward tensor([-16.1218]) loss 5.507238388061523 epsilon 0.767566125
28-Feb-25 11:07:00 - agent.DQN.DQN - INFO - episode 3 step 275 reward tensor([-16.2209]) loss 4.246913909912109 epsilon 0.767566125
28-Feb-25 11:07:00 - agent.DQN.DQN - INFO - episode 3 step 276 reward tensor([-16.3194]) loss 5.700294494628906 epsilon 0.767566125
28-Feb-25 11:07:00 - agent.DQN.DQN - INFO - episode 3 step 277 reward tensor([-16.4180]) loss 4.635830879211426 epsilon 0.767566125
28-Feb-25 11:07:00 - agent.DQN.DQN - INFO - episode 3 step 278 reward tensor([-16.5169]) loss 19.663841247558594 epsilon 0.767566125
28-Feb-25 11:07:00 - agent.DQN.DQN - INFO - episode 3 step 279 reward tensor([-16.6156]) loss 5.239238262176514 epsilon 0.767566125
28-Feb-25 11:07:00 - agent.DQN.DQN - INFO - episode 3 step 280 reward tensor([-16.7150]) loss 3.59706711769104 epsilon 0.767566125
28-Feb-25 11:07:00 - agent.DQN.DQN - INFO - episode 3 step 281 reward tensor([-16.8149]) loss 2.5182528495788574 epsilon 0.767566125
28-Feb-25 11:07:00 - agent.DQN.DQN - INFO - episode 3 step 282 reward tensor([-16.9140]) loss 4.386112213134766 epsilon 0.767566125
28-Feb-25 11:07:00 - agent.DQN.DQN - INFO - episode 3 step 283 reward tensor([-17.0126]) loss 4.61467170715332 epsilon 0.767566125
28-Feb-25 11:07:00 - agent.DQN.DQN - INFO - episode 3 step 284 reward tensor([-17.1122]) loss 3.849043130874634 epsilon 0.767566125
28-Feb-25 11:07:00 - agent.DQN.DQN - INFO - episode 3 step 285 reward tensor([-17.2125]) loss 57.470645904541016 epsilon 0.767566125
28-Feb-25 11:07:00 - agent.DQN.DQN - INFO - episode 3 step 286 reward tensor([-17.3130]) loss 59.112159729003906 epsilon 0.767566125
28-Feb-25 11:07:00 - agent.DQN.DQN - INFO - episode 3 step 287 reward tensor([-17.4154]) loss 4.824108600616455 epsilon 0.767566125
28-Feb-25 11:07:00 - agent.DQN.DQN - INFO - episode 3 step 288 reward tensor([-17.5190]) loss 17.312843322753906 epsilon 0.767566125
28-Feb-25 11:07:00 - agent.DQN.DQN - INFO - episode 3 step 289 reward tensor([-17.6250]) loss 3.687359094619751 epsilon 0.767566125
28-Feb-25 11:07:00 - agent.DQN.DQN - INFO - episode 3 step 290 reward tensor([-17.7329]) loss 3.2420942783355713 epsilon 0.767566125
28-Feb-25 11:07:00 - agent.DQN.DQN - INFO - episode 3 step 291 reward tensor([-17.8434]) loss 3.27683424949646 epsilon 0.767566125
28-Feb-25 11:07:00 - agent.DQN.DQN - INFO - episode 3 step 292 reward tensor([-17.9563]) loss 2.705364942550659 epsilon 0.767566125
28-Feb-25 11:07:00 - agent.DQN.DQN - INFO - episode 3 step 293 reward tensor([-18.0700]) loss 3.7171881198883057 epsilon 0.767566125
28-Feb-25 11:07:00 - agent.DQN.DQN - INFO - episode 3 step 294 reward tensor([-18.1818]) loss 3.876864194869995 epsilon 0.767566125
28-Feb-25 11:07:00 - agent.DQN.DQN - INFO - episode 3 step 295 reward tensor([-18.2946]) loss 55.339012145996094 epsilon 0.767566125
28-Feb-25 11:07:00 - agent.DQN.DQN - INFO - episode 3 step 296 reward tensor([-18.4053]) loss 16.9843692779541 epsilon 0.767566125
28-Feb-25 11:07:00 - agent.DQN.DQN - INFO - episode 3 step 297 reward tensor([-18.5140]) loss 7.828906059265137 epsilon 0.767566125
28-Feb-25 11:07:00 - agent.DQN.DQN - INFO - episode 3 step 298 reward tensor([-18.6206]) loss 8.407764434814453 epsilon 0.767566125
28-Feb-25 11:07:00 - agent.DQN.DQN - INFO - episode 3 step 299 reward tensor([-18.7287]) loss 5.419287204742432 epsilon 0.767566125
28-Feb-25 11:07:00 - agent.DQN.DQN - INFO - episode 3 step 300 reward tensor([-18.8402]) loss 3.096724033355713 epsilon 0.767566125
28-Feb-25 11:07:00 - agent.DQN.DQN - INFO - episode 3 step 301 reward tensor([-18.9543]) loss 4.639466762542725 epsilon 0.767566125
28-Feb-25 11:07:00 - agent.DQN.DQN - INFO - episode 4 step 0 reward tensor([-1.7358]) loss 4.225917339324951 epsilon 0.7426202259375
28-Feb-25 11:07:00 - agent.DQN.DQN - INFO - episode 4 step 1 reward tensor([-1.7261]) loss 18.821264266967773 epsilon 0.7426202259375
28-Feb-25 11:07:00 - agent.DQN.DQN - INFO - episode 4 step 2 reward tensor([-1.7165]) loss 5.298455715179443 epsilon 0.7426202259375
28-Feb-25 11:07:00 - agent.DQN.DQN - INFO - episode 4 step 3 reward tensor([-1.7070]) loss 6.0904035568237305 epsilon 0.7426202259375
28-Feb-25 11:07:00 - agent.DQN.DQN - INFO - episode 4 step 4 reward tensor([-1.6975]) loss 6.086605548858643 epsilon 0.7426202259375
28-Feb-25 11:07:00 - agent.DQN.DQN - INFO - episode 4 step 5 reward tensor([-1.6789]) loss 4.698542594909668 epsilon 0.7426202259375
28-Feb-25 11:07:00 - agent.DQN.DQN - INFO - episode 4 step 6 reward tensor([-1.6512]) loss 57.17863464355469 epsilon 0.7426202259375
28-Feb-25 11:07:00 - agent.DQN.DQN - INFO - episode 4 step 7 reward tensor([-1.6146]) loss 56.76332473754883 epsilon 0.7426202259375
