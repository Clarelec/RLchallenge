26-Feb-25 09:38:14 - agent.DQN.DQN - INFO - device is cpu
26-Feb-25 09:38:14 - numexpr.utils - INFO - Note: NumExpr detected 22 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
26-Feb-25 09:38:14 - numexpr.utils - INFO - NumExpr defaulting to 8 threads.
26-Feb-25 09:38:14 - __main__ - INFO - Libraries imported
26-Feb-25 09:38:14 - __main__ - INFO - Device: cpu
26-Feb-25 09:38:14 - __main__ - INFO - Starting training of DQN2 agent
26-Feb-25 09:38:14 - __main__ - INFO - Environment initialized
26-Feb-25 09:38:14 - __main__ - INFO - Starting epoch 1
26-Feb-25 09:38:14 - agent.DQN.DQN - INFO - QNetwork initialized with 10 observations and 9 actions
26-Feb-25 09:38:14 - agent.DQN.DQN - INFO - QNetwork initialized with 10 observations and 9 actions
26-Feb-25 09:38:14 - __main__ - INFO - Q-Networks initialized and synchronized
26-Feb-25 09:38:16 - __main__ - INFO - Optimizer, LR scheduler, and loss function initialized
26-Feb-25 09:38:16 - __main__ - INFO - Epsilon-greedy strategy initialized
26-Feb-25 09:38:16 - __main__ - INFO - Replay buffer initialized
26-Feb-25 09:38:16 - __main__ - INFO - Training DQN2 agent
26-Feb-25 09:38:16 - agent.DQN.DQN - INFO - episode 1 step 128 reward tensor([-1]) loss 644.2959594726562 epsilon 0.82
26-Feb-25 09:38:16 - agent.DQN.DQN - INFO - episode 1 step 129 reward tensor([-1]) loss 99.24894714355469 epsilon 0.82
26-Feb-25 09:38:16 - agent.DQN.DQN - INFO - episode 1 step 130 reward tensor([-1]) loss 130.99588012695312 epsilon 0.82
26-Feb-25 09:38:16 - agent.DQN.DQN - INFO - episode 1 step 131 reward tensor([-1]) loss 131.102294921875 epsilon 0.82
26-Feb-25 09:38:16 - agent.DQN.DQN - INFO - episode 1 step 132 reward tensor([-1]) loss 97.3490219116211 epsilon 0.82
26-Feb-25 09:38:16 - agent.DQN.DQN - INFO - episode 1 step 133 reward tensor([-1]) loss 52.73957061767578 epsilon 0.82
26-Feb-25 09:38:16 - agent.DQN.DQN - INFO - episode 1 step 134 reward tensor([-1]) loss 21.762767791748047 epsilon 0.82
26-Feb-25 09:38:16 - agent.DQN.DQN - INFO - episode 1 step 135 reward tensor([-1]) loss 18.505229949951172 epsilon 0.82
26-Feb-25 09:38:16 - agent.DQN.DQN - INFO - episode 1 step 136 reward tensor([-1]) loss 25.951488494873047 epsilon 0.82
26-Feb-25 09:38:16 - agent.DQN.DQN - INFO - episode 1 step 137 reward tensor([-1]) loss 33.93151092529297 epsilon 0.82
26-Feb-25 09:38:16 - agent.DQN.DQN - INFO - episode 1 step 138 reward tensor([-1]) loss 35.60586166381836 epsilon 0.82
26-Feb-25 09:38:16 - agent.DQN.DQN - INFO - episode 1 step 139 reward tensor([-1]) loss 32.66949462890625 epsilon 0.82
26-Feb-25 09:38:16 - agent.DQN.DQN - INFO - episode 1 step 140 reward tensor([-1]) loss 26.98431396484375 epsilon 0.82
26-Feb-25 09:38:16 - agent.DQN.DQN - INFO - episode 1 step 141 reward tensor([-1]) loss 23.905338287353516 epsilon 0.82
26-Feb-25 09:38:16 - agent.DQN.DQN - INFO - episode 1 step 142 reward tensor([-1]) loss 18.795156478881836 epsilon 0.82
26-Feb-25 09:38:16 - agent.DQN.DQN - INFO - episode 1 step 143 reward tensor([-1]) loss 13.07016658782959 epsilon 0.82
26-Feb-25 09:38:16 - agent.DQN.DQN - INFO - episode 1 step 144 reward tensor([-1]) loss 12.317169189453125 epsilon 0.82
26-Feb-25 09:38:16 - agent.DQN.DQN - INFO - episode 1 step 145 reward tensor([-1]) loss 9.513916015625 epsilon 0.82
26-Feb-25 09:38:16 - agent.DQN.DQN - INFO - episode 1 step 146 reward tensor([-1]) loss 8.342386245727539 epsilon 0.82
26-Feb-25 09:38:16 - agent.DQN.DQN - INFO - episode 1 step 147 reward tensor([-1]) loss 8.478158950805664 epsilon 0.82
26-Feb-25 09:38:16 - agent.DQN.DQN - INFO - episode 1 step 148 reward tensor([-1]) loss 7.505445957183838 epsilon 0.82
26-Feb-25 09:38:16 - agent.DQN.DQN - INFO - episode 1 step 149 reward tensor([-1]) loss 7.617330551147461 epsilon 0.82
26-Feb-25 09:38:16 - agent.DQN.DQN - INFO - episode 1 step 150 reward tensor([-1]) loss 7.75382137298584 epsilon 0.82
26-Feb-25 09:38:16 - agent.DQN.DQN - INFO - episode 1 step 151 reward tensor([-1]) loss 9.466672897338867 epsilon 0.82
26-Feb-25 09:38:16 - agent.DQN.DQN - INFO - episode 1 step 152 reward tensor([-1]) loss 10.283425331115723 epsilon 0.82
26-Feb-25 09:38:16 - agent.DQN.DQN - INFO - episode 1 step 153 reward tensor([-1]) loss 7.747591972351074 epsilon 0.82
26-Feb-25 09:38:16 - agent.DQN.DQN - INFO - episode 1 step 154 reward tensor([-1]) loss 5.543337345123291 epsilon 0.82
26-Feb-25 09:38:16 - agent.DQN.DQN - INFO - episode 1 step 155 reward tensor([-1]) loss 3.7364044189453125 epsilon 0.82
26-Feb-25 09:38:16 - agent.DQN.DQN - INFO - episode 1 step 156 reward tensor([-1]) loss 3.2106740474700928 epsilon 0.82
26-Feb-25 09:38:16 - agent.DQN.DQN - INFO - episode 1 step 157 reward tensor([-1]) loss 3.080111265182495 epsilon 0.82
26-Feb-25 09:38:16 - agent.DQN.DQN - INFO - episode 1 step 158 reward tensor([-1]) loss 3.230883836746216 epsilon 0.82
26-Feb-25 09:38:16 - agent.DQN.DQN - INFO - episode 1 step 159 reward tensor([-1]) loss 3.130120277404785 epsilon 0.82
26-Feb-25 09:38:16 - agent.DQN.DQN - INFO - episode 1 step 160 reward tensor([-1]) loss 3.3062849044799805 epsilon 0.82
26-Feb-25 09:38:16 - agent.DQN.DQN - INFO - episode 1 step 161 reward tensor([-1]) loss 3.121124744415283 epsilon 0.82
26-Feb-25 09:38:16 - agent.DQN.DQN - INFO - episode 1 step 162 reward tensor([-1]) loss 2.982050657272339 epsilon 0.82
26-Feb-25 09:38:17 - agent.DQN.DQN - INFO - episode 1 step 163 reward tensor([-1]) loss 2.8481245040893555 epsilon 0.82
26-Feb-25 09:38:17 - agent.DQN.DQN - INFO - episode 1 step 164 reward tensor([-1]) loss 2.5019519329071045 epsilon 0.82
26-Feb-25 09:38:17 - agent.DQN.DQN - INFO - episode 1 step 165 reward tensor([-1]) loss 2.1853933334350586 epsilon 0.82
26-Feb-25 09:38:17 - agent.DQN.DQN - INFO - episode 1 step 166 reward tensor([-1]) loss 1.6682778596878052 epsilon 0.82
26-Feb-25 09:38:17 - agent.DQN.DQN - INFO - episode 1 step 167 reward tensor([-1]) loss 1.7876505851745605 epsilon 0.82
26-Feb-25 09:38:17 - agent.DQN.DQN - INFO - episode 1 step 168 reward tensor([-1]) loss 1.5687403678894043 epsilon 0.82
26-Feb-25 09:38:17 - agent.DQN.DQN - INFO - episode 1 step 169 reward tensor([-1]) loss 1.539596676826477 epsilon 0.82
26-Feb-25 09:38:17 - agent.DQN.DQN - INFO - episode 1 step 170 reward tensor([-1]) loss 1.2911341190338135 epsilon 0.82
26-Feb-25 09:38:17 - agent.DQN.DQN - INFO - episode 1 step 171 reward tensor([-1]) loss 1.0838348865509033 epsilon 0.82
26-Feb-25 09:38:17 - agent.DQN.DQN - INFO - episode 1 step 172 reward tensor([-1]) loss 1.1198447942733765 epsilon 0.82
26-Feb-25 09:38:17 - agent.DQN.DQN - INFO - episode 1 step 173 reward tensor([-1]) loss 1.0187935829162598 epsilon 0.82
26-Feb-25 09:38:17 - agent.DQN.DQN - INFO - episode 1 step 174 reward tensor([-1]) loss 1.0908572673797607 epsilon 0.82
26-Feb-25 09:38:17 - agent.DQN.DQN - INFO - episode 1 step 175 reward tensor([-1]) loss 1.20929753780365 epsilon 0.82
26-Feb-25 09:38:17 - agent.DQN.DQN - INFO - episode 1 step 176 reward tensor([-1]) loss 1.435974359512329 epsilon 0.82
26-Feb-25 09:38:17 - agent.DQN.DQN - INFO - episode 1 step 177 reward tensor([-1]) loss 1.2073026895523071 epsilon 0.82
26-Feb-25 09:38:17 - agent.DQN.DQN - INFO - episode 1 step 178 reward tensor([-1]) loss 1.1178942918777466 epsilon 0.82
26-Feb-25 09:38:17 - agent.DQN.DQN - INFO - episode 1 step 179 reward tensor([-1]) loss 0.7953993678092957 epsilon 0.82
26-Feb-25 09:38:17 - agent.DQN.DQN - INFO - episode 1 step 180 reward tensor([-1]) loss 0.9700753688812256 epsilon 0.82
26-Feb-25 09:38:17 - agent.DQN.DQN - INFO - episode 1 step 181 reward tensor([-1]) loss 5.870707988739014 epsilon 0.82
26-Feb-25 09:38:17 - agent.DQN.DQN - INFO - episode 1 step 182 reward tensor([-1]) loss 4.512259006500244 epsilon 0.82
26-Feb-25 09:38:17 - agent.DQN.DQN - INFO - episode 1 step 183 reward tensor([-1]) loss 3.053915023803711 epsilon 0.82
26-Feb-25 09:38:17 - agent.DQN.DQN - INFO - episode 1 step 184 reward tensor([-1]) loss 1.694563627243042 epsilon 0.82
26-Feb-25 09:38:17 - agent.DQN.DQN - INFO - episode 1 step 185 reward tensor([-1]) loss 1.604673981666565 epsilon 0.82
26-Feb-25 09:38:17 - agent.DQN.DQN - INFO - episode 1 step 186 reward tensor([-1]) loss 2.012089252471924 epsilon 0.82
26-Feb-25 09:38:17 - agent.DQN.DQN - INFO - episode 1 step 187 reward tensor([-1]) loss 2.1909091472625732 epsilon 0.82
26-Feb-25 09:38:17 - agent.DQN.DQN - INFO - episode 1 step 188 reward tensor([-1]) loss 3.2841789722442627 epsilon 0.82
26-Feb-25 09:38:17 - agent.DQN.DQN - INFO - episode 1 step 189 reward tensor([-1]) loss 2.9870896339416504 epsilon 0.82
26-Feb-25 09:38:17 - agent.DQN.DQN - INFO - episode 1 step 190 reward tensor([-1]) loss 3.830991744995117 epsilon 0.82
26-Feb-25 09:38:17 - agent.DQN.DQN - INFO - episode 1 step 191 reward tensor([-1]) loss 3.6661126613616943 epsilon 0.82
26-Feb-25 09:38:17 - agent.DQN.DQN - INFO - episode 1 step 192 reward tensor([-1]) loss 2.9460771083831787 epsilon 0.82
26-Feb-25 09:38:17 - agent.DQN.DQN - INFO - episode 1 step 193 reward tensor([-1]) loss 2.4421067237854004 epsilon 0.82
26-Feb-25 09:38:17 - agent.DQN.DQN - INFO - episode 1 step 194 reward tensor([-1]) loss 1.937895655632019 epsilon 0.82
26-Feb-25 09:38:17 - agent.DQN.DQN - INFO - episode 1 step 195 reward tensor([-1]) loss 1.7188807725906372 epsilon 0.82
26-Feb-25 09:38:17 - agent.DQN.DQN - INFO - episode 1 step 196 reward tensor([-1]) loss 1.495648741722107 epsilon 0.82
26-Feb-25 09:38:17 - agent.DQN.DQN - INFO - episode 1 step 197 reward tensor([-1]) loss 2.800356864929199 epsilon 0.82
26-Feb-25 09:38:17 - agent.DQN.DQN - INFO - episode 1 step 198 reward tensor([-1]) loss 2.7854552268981934 epsilon 0.82
26-Feb-25 09:38:17 - agent.DQN.DQN - INFO - episode 1 step 199 reward tensor([-1]) loss 2.682530641555786 epsilon 0.82
26-Feb-25 09:38:17 - agent.DQN.DQN - INFO - episode 1 step 200 reward tensor([-1]) loss 2.3085765838623047 epsilon 0.82
26-Feb-25 09:38:17 - agent.DQN.DQN - INFO - episode 1 step 201 reward tensor([-1]) loss 3.2378711700439453 epsilon 0.82
26-Feb-25 09:38:17 - agent.DQN.DQN - INFO - episode 1 step 202 reward tensor([-1]) loss 3.130755662918091 epsilon 0.82
26-Feb-25 09:38:17 - agent.DQN.DQN - INFO - episode 1 step 203 reward tensor([-1]) loss 2.101010322570801 epsilon 0.82
26-Feb-25 09:38:17 - agent.DQN.DQN - INFO - episode 1 step 204 reward tensor([-1]) loss 2.165210247039795 epsilon 0.82
26-Feb-25 09:38:17 - agent.DQN.DQN - INFO - episode 1 step 205 reward tensor([-1]) loss 1.797298550605774 epsilon 0.82
26-Feb-25 09:38:17 - agent.DQN.DQN - INFO - episode 1 step 206 reward tensor([-1]) loss 1.527112364768982 epsilon 0.82
26-Feb-25 09:38:17 - agent.DQN.DQN - INFO - episode 1 step 207 reward tensor([-1]) loss 1.4926328659057617 epsilon 0.82
26-Feb-25 09:38:17 - agent.DQN.DQN - INFO - episode 1 step 208 reward tensor([-1]) loss 1.5531671047210693 epsilon 0.82
26-Feb-25 09:38:17 - agent.DQN.DQN - INFO - episode 1 step 209 reward tensor([-1]) loss 1.4082555770874023 epsilon 0.82
26-Feb-25 09:38:17 - agent.DQN.DQN - INFO - episode 1 step 210 reward tensor([-1]) loss 1.3096704483032227 epsilon 0.82
26-Feb-25 09:38:17 - agent.DQN.DQN - INFO - episode 1 step 211 reward tensor([-1]) loss 3.791482448577881 epsilon 0.82
26-Feb-25 09:38:17 - agent.DQN.DQN - INFO - episode 1 step 212 reward tensor([-1]) loss 4.52869987487793 epsilon 0.82
26-Feb-25 09:38:17 - agent.DQN.DQN - INFO - episode 1 step 213 reward tensor([-1]) loss 4.291656494140625 epsilon 0.82
26-Feb-25 09:38:17 - agent.DQN.DQN - INFO - episode 1 step 214 reward tensor([-1]) loss 3.013646125793457 epsilon 0.82
26-Feb-25 09:38:17 - agent.DQN.DQN - INFO - episode 1 step 215 reward tensor([-1]) loss 6.632943153381348 epsilon 0.82
26-Feb-25 09:38:17 - agent.DQN.DQN - INFO - episode 1 step 216 reward tensor([-1]) loss 5.451320171356201 epsilon 0.82
26-Feb-25 09:38:17 - agent.DQN.DQN - INFO - episode 1 step 217 reward tensor([-1]) loss 4.2296342849731445 epsilon 0.82
26-Feb-25 09:38:17 - agent.DQN.DQN - INFO - episode 1 step 218 reward tensor([-1]) loss 3.147448778152466 epsilon 0.82
26-Feb-25 09:38:17 - agent.DQN.DQN - INFO - episode 1 step 219 reward tensor([-1]) loss 2.9507319927215576 epsilon 0.82
26-Feb-25 09:38:17 - agent.DQN.DQN - INFO - episode 1 step 220 reward tensor([-1]) loss 2.974138021469116 epsilon 0.82
26-Feb-25 09:38:17 - agent.DQN.DQN - INFO - episode 1 step 221 reward tensor([-1]) loss 1.7098896503448486 epsilon 0.82
26-Feb-25 09:38:17 - agent.DQN.DQN - INFO - episode 1 step 222 reward tensor([-1]) loss 2.1848387718200684 epsilon 0.82
26-Feb-25 09:38:17 - agent.DQN.DQN - INFO - episode 1 step 223 reward tensor([-1]) loss 2.156219482421875 epsilon 0.82
26-Feb-25 09:38:17 - agent.DQN.DQN - INFO - episode 1 step 224 reward tensor([-1]) loss 1.967559814453125 epsilon 0.82
26-Feb-25 09:38:17 - agent.DQN.DQN - INFO - episode 1 step 225 reward tensor([-1]) loss 2.030341386795044 epsilon 0.82
26-Feb-25 09:38:17 - agent.DQN.DQN - INFO - episode 1 step 226 reward tensor([-1]) loss 1.7396342754364014 epsilon 0.82
26-Feb-25 09:38:17 - agent.DQN.DQN - INFO - episode 1 step 227 reward tensor([-1]) loss 1.6142206192016602 epsilon 0.82
26-Feb-25 09:38:17 - agent.DQN.DQN - INFO - episode 1 step 228 reward tensor([-1]) loss 1.6356315612792969 epsilon 0.82
26-Feb-25 09:38:17 - agent.DQN.DQN - INFO - episode 1 step 229 reward tensor([-1]) loss 1.5475353002548218 epsilon 0.82
26-Feb-25 09:38:17 - agent.DQN.DQN - INFO - episode 1 step 230 reward tensor([-1]) loss 1.1658341884613037 epsilon 0.82
26-Feb-25 09:38:17 - agent.DQN.DQN - INFO - episode 1 step 231 reward tensor([-1]) loss 1.1840509176254272 epsilon 0.82
26-Feb-25 09:38:17 - agent.DQN.DQN - INFO - episode 1 step 232 reward tensor([-1]) loss 1.254067063331604 epsilon 0.82
26-Feb-25 09:38:17 - agent.DQN.DQN - INFO - episode 1 step 233 reward tensor([-1]) loss 1.0401214361190796 epsilon 0.82
26-Feb-25 09:38:17 - agent.DQN.DQN - INFO - episode 1 step 234 reward tensor([-1]) loss 0.7705898880958557 epsilon 0.82
26-Feb-25 09:38:17 - agent.DQN.DQN - INFO - episode 1 step 235 reward tensor([-1]) loss 1.0254180431365967 epsilon 0.82
26-Feb-25 09:38:17 - agent.DQN.DQN - INFO - episode 1 step 236 reward tensor([-1]) loss 0.888210654258728 epsilon 0.82
26-Feb-25 09:38:17 - agent.DQN.DQN - INFO - episode 1 step 237 reward tensor([-1]) loss 0.8825564384460449 epsilon 0.82
26-Feb-25 09:38:17 - agent.DQN.DQN - INFO - episode 1 step 238 reward tensor([-1]) loss 0.9590482711791992 epsilon 0.82
26-Feb-25 09:38:17 - agent.DQN.DQN - INFO - episode 1 step 239 reward tensor([-1]) loss 0.8317657709121704 epsilon 0.82
26-Feb-25 09:38:17 - agent.DQN.DQN - INFO - episode 1 step 240 reward tensor([-1]) loss 0.9605071544647217 epsilon 0.82
26-Feb-25 09:38:18 - agent.DQN.DQN - INFO - episode 1 step 241 reward tensor([-1]) loss 8.469499588012695 epsilon 0.82
26-Feb-25 09:38:18 - agent.DQN.DQN - INFO - episode 1 step 242 reward tensor([-1]) loss 7.815728187561035 epsilon 0.82
26-Feb-25 09:38:18 - agent.DQN.DQN - INFO - episode 1 step 243 reward tensor([-1]) loss 5.3054070472717285 epsilon 0.82
26-Feb-25 09:38:18 - agent.DQN.DQN - INFO - episode 1 step 244 reward tensor([-1]) loss 4.596086025238037 epsilon 0.82
26-Feb-25 09:38:18 - agent.DQN.DQN - INFO - episode 1 step 245 reward tensor([-1]) loss 3.1499338150024414 epsilon 0.82
26-Feb-25 09:38:18 - agent.DQN.DQN - INFO - episode 1 step 246 reward tensor([-1]) loss 2.493973970413208 epsilon 0.82
26-Feb-25 09:38:18 - agent.DQN.DQN - INFO - episode 1 step 247 reward tensor([-1]) loss 1.7804903984069824 epsilon 0.82
26-Feb-25 09:38:18 - agent.DQN.DQN - INFO - episode 1 step 248 reward tensor([-1]) loss 1.5367553234100342 epsilon 0.82
26-Feb-25 09:38:18 - agent.DQN.DQN - INFO - episode 1 step 249 reward tensor([-1]) loss 1.2061587572097778 epsilon 0.82
26-Feb-25 09:38:18 - agent.DQN.DQN - INFO - episode 1 step 250 reward tensor([-1]) loss 1.5074599981307983 epsilon 0.82
26-Feb-25 09:38:18 - agent.DQN.DQN - INFO - episode 1 step 251 reward tensor([-1]) loss 1.7768168449401855 epsilon 0.82
26-Feb-25 09:38:18 - agent.DQN.DQN - INFO - episode 1 step 252 reward tensor([-1]) loss 1.9873106479644775 epsilon 0.82
26-Feb-25 09:38:18 - agent.DQN.DQN - INFO - episode 1 step 253 reward tensor([-1]) loss 2.1639621257781982 epsilon 0.82
26-Feb-25 09:38:18 - agent.DQN.DQN - INFO - episode 1 step 254 reward tensor([-1]) loss 2.4835362434387207 epsilon 0.82
26-Feb-25 09:38:18 - agent.DQN.DQN - INFO - episode 1 step 255 reward tensor([-1]) loss 1.752199649810791 epsilon 0.82
26-Feb-25 09:38:18 - agent.DQN.DQN - INFO - episode 1 step 256 reward tensor([-1]) loss 1.6695019006729126 epsilon 0.82
26-Feb-25 09:38:18 - agent.DQN.DQN - INFO - episode 1 step 257 reward tensor([-1]) loss 1.6889687776565552 epsilon 0.82
26-Feb-25 09:38:18 - agent.DQN.DQN - INFO - episode 1 step 258 reward tensor([-1]) loss 1.4382688999176025 epsilon 0.82
26-Feb-25 09:38:18 - agent.DQN.DQN - INFO - episode 1 step 259 reward tensor([-1]) loss 1.114809513092041 epsilon 0.82
26-Feb-25 09:38:18 - agent.DQN.DQN - INFO - episode 1 step 260 reward tensor([-1]) loss 0.9824358224868774 epsilon 0.82
26-Feb-25 09:38:18 - agent.DQN.DQN - INFO - episode 1 step 261 reward tensor([-1]) loss 0.8571594953536987 epsilon 0.82
26-Feb-25 09:38:18 - agent.DQN.DQN - INFO - episode 1 step 262 reward tensor([-1]) loss 1.039782166481018 epsilon 0.82
26-Feb-25 09:38:18 - agent.DQN.DQN - INFO - episode 1 step 263 reward tensor([-1]) loss 0.776405930519104 epsilon 0.82
26-Feb-25 09:38:18 - agent.DQN.DQN - INFO - episode 1 step 264 reward tensor([-1]) loss 0.9176973104476929 epsilon 0.82
26-Feb-25 09:38:18 - agent.DQN.DQN - INFO - episode 1 step 265 reward tensor([-1]) loss 0.8024563789367676 epsilon 0.82
26-Feb-25 09:38:18 - agent.DQN.DQN - INFO - episode 1 step 266 reward tensor([-1]) loss 1.0359883308410645 epsilon 0.82
26-Feb-25 09:38:18 - agent.DQN.DQN - INFO - episode 1 step 267 reward tensor([-1]) loss 0.9672687649726868 epsilon 0.82
26-Feb-25 09:38:18 - agent.DQN.DQN - INFO - episode 1 step 268 reward tensor([-1]) loss 0.7966960072517395 epsilon 0.82
26-Feb-25 09:38:18 - agent.DQN.DQN - INFO - episode 1 step 269 reward tensor([-1]) loss 0.8260661363601685 epsilon 0.82
26-Feb-25 09:38:18 - agent.DQN.DQN - INFO - episode 1 step 270 reward tensor([-1]) loss 0.8105813264846802 epsilon 0.82
26-Feb-25 09:38:18 - agent.DQN.DQN - INFO - episode 1 step 271 reward tensor([-1]) loss 10.986865997314453 epsilon 0.82
26-Feb-25 09:38:18 - agent.DQN.DQN - INFO - episode 1 step 272 reward tensor([-1]) loss 10.41260051727295 epsilon 0.82
26-Feb-25 09:38:18 - agent.DQN.DQN - INFO - episode 1 step 273 reward tensor([-1]) loss 7.028238773345947 epsilon 0.82
26-Feb-25 09:38:18 - agent.DQN.DQN - INFO - episode 1 step 274 reward tensor([-1]) loss 5.27082633972168 epsilon 0.82
26-Feb-25 09:38:18 - agent.DQN.DQN - INFO - episode 1 step 275 reward tensor([-1]) loss 4.008459568023682 epsilon 0.82
26-Feb-25 09:38:18 - agent.DQN.DQN - INFO - episode 1 step 276 reward tensor([-1]) loss 2.5073256492614746 epsilon 0.82
26-Feb-25 09:38:18 - agent.DQN.DQN - INFO - episode 1 step 277 reward tensor([-1]) loss 2.3145217895507812 epsilon 0.82
26-Feb-25 09:38:18 - agent.DQN.DQN - INFO - episode 1 step 278 reward tensor([-1]) loss 1.709364891052246 epsilon 0.82
26-Feb-25 09:38:18 - agent.DQN.DQN - INFO - episode 1 step 279 reward tensor([-1]) loss 2.2983500957489014 epsilon 0.82
26-Feb-25 09:38:18 - agent.DQN.DQN - INFO - episode 1 step 280 reward tensor([-1]) loss 2.8421218395233154 epsilon 0.82
26-Feb-25 09:38:18 - agent.DQN.DQN - INFO - episode 1 step 281 reward tensor([-1]) loss 2.979142904281616 epsilon 0.82
26-Feb-25 09:38:18 - agent.DQN.DQN - INFO - episode 1 step 282 reward tensor([-1]) loss 3.2738726139068604 epsilon 0.82
26-Feb-25 09:38:18 - agent.DQN.DQN - INFO - episode 1 step 283 reward tensor([-1]) loss 2.952871799468994 epsilon 0.82
26-Feb-25 09:38:18 - agent.DQN.DQN - INFO - episode 1 step 284 reward tensor([-1]) loss 3.0385994911193848 epsilon 0.82
26-Feb-25 09:38:18 - agent.DQN.DQN - INFO - episode 1 step 285 reward tensor([-1]) loss 2.3005504608154297 epsilon 0.82
26-Feb-25 09:38:18 - agent.DQN.DQN - INFO - episode 1 step 286 reward tensor([-1]) loss 1.9519596099853516 epsilon 0.82
26-Feb-25 09:38:18 - agent.DQN.DQN - INFO - episode 1 step 287 reward tensor([-1]) loss 2.2352705001831055 epsilon 0.82
26-Feb-25 09:38:18 - agent.DQN.DQN - INFO - episode 1 step 288 reward tensor([-1]) loss 2.4190733432769775 epsilon 0.82
26-Feb-25 09:38:18 - agent.DQN.DQN - INFO - episode 1 step 289 reward tensor([-1]) loss 2.318539619445801 epsilon 0.82
26-Feb-25 09:38:18 - agent.DQN.DQN - INFO - episode 1 step 290 reward tensor([-1]) loss 1.496993064880371 epsilon 0.82
26-Feb-25 09:38:18 - agent.DQN.DQN - INFO - episode 1 step 291 reward tensor([-1]) loss 1.156245231628418 epsilon 0.82
26-Feb-25 09:38:18 - agent.DQN.DQN - INFO - episode 1 step 292 reward tensor([-1]) loss 1.2257673740386963 epsilon 0.82
26-Feb-25 09:38:18 - agent.DQN.DQN - INFO - episode 1 step 293 reward tensor([-1]) loss 1.411710500717163 epsilon 0.82
26-Feb-25 09:38:18 - agent.DQN.DQN - INFO - episode 1 step 294 reward tensor([-1]) loss 0.9589314460754395 epsilon 0.82
26-Feb-25 09:38:18 - agent.DQN.DQN - INFO - episode 1 step 295 reward tensor([-1]) loss 0.8632343411445618 epsilon 0.82
26-Feb-25 09:38:18 - agent.DQN.DQN - INFO - episode 1 step 296 reward tensor([-1]) loss 1.2172988653182983 epsilon 0.82
26-Feb-25 09:38:18 - agent.DQN.DQN - INFO - episode 1 step 297 reward tensor([-1]) loss 1.2748334407806396 epsilon 0.82
26-Feb-25 09:38:18 - agent.DQN.DQN - INFO - episode 1 step 298 reward tensor([-1]) loss 1.1652896404266357 epsilon 0.82
26-Feb-25 09:38:18 - agent.DQN.DQN - INFO - episode 1 step 299 reward tensor([-1]) loss 1.3010963201522827 epsilon 0.82
26-Feb-25 09:38:18 - agent.DQN.DQN - INFO - episode 1 step 300 reward tensor([-1]) loss 1.2108049392700195 epsilon 0.82
26-Feb-25 09:38:18 - agent.DQN.DQN - INFO - episode 1 step 301 reward tensor([-1]) loss 68.87251281738281 epsilon 0.82
26-Feb-25 09:38:18 - agent.DQN.DQN - INFO - episode 2 step 0 reward tensor([-1]) loss 67.00418853759766 epsilon 0.79335
26-Feb-25 09:38:18 - agent.DQN.DQN - INFO - episode 2 step 1 reward tensor([-1]) loss 57.929176330566406 epsilon 0.79335
26-Feb-25 09:38:18 - agent.DQN.DQN - INFO - episode 2 step 2 reward tensor([-1]) loss 51.67774963378906 epsilon 0.79335
26-Feb-25 09:38:18 - agent.DQN.DQN - INFO - episode 2 step 3 reward tensor([-1]) loss 45.915836334228516 epsilon 0.79335
26-Feb-25 09:38:18 - agent.DQN.DQN - INFO - episode 2 step 4 reward tensor([-1]) loss 6.114375591278076 epsilon 0.79335
26-Feb-25 09:38:18 - agent.DQN.DQN - INFO - episode 2 step 5 reward tensor([-1]) loss 41.99412155151367 epsilon 0.79335
26-Feb-25 09:38:18 - agent.DQN.DQN - INFO - episode 2 step 6 reward tensor([-1]) loss 11.385002136230469 epsilon 0.79335
26-Feb-25 09:38:18 - agent.DQN.DQN - INFO - episode 2 step 7 reward tensor([-1]) loss 10.4944486618042 epsilon 0.79335
26-Feb-25 09:38:18 - agent.DQN.DQN - INFO - episode 2 step 8 reward tensor([-1]) loss 16.91120719909668 epsilon 0.79335
26-Feb-25 09:38:19 - agent.DQN.DQN - INFO - episode 2 step 9 reward tensor([-1]) loss 10.187146186828613 epsilon 0.79335
26-Feb-25 09:38:19 - agent.DQN.DQN - INFO - episode 2 step 10 reward tensor([-1]) loss 40.31380844116211 epsilon 0.79335
26-Feb-25 09:38:19 - agent.DQN.DQN - INFO - episode 2 step 11 reward tensor([-1]) loss 40.24530792236328 epsilon 0.79335
26-Feb-25 09:38:19 - agent.DQN.DQN - INFO - episode 2 step 12 reward tensor([-1]) loss 36.139888763427734 epsilon 0.79335
26-Feb-25 09:38:19 - agent.DQN.DQN - INFO - episode 2 step 13 reward tensor([-1]) loss 6.809981346130371 epsilon 0.79335
26-Feb-25 09:38:19 - agent.DQN.DQN - INFO - episode 2 step 14 reward tensor([-1]) loss 5.787102699279785 epsilon 0.79335
26-Feb-25 09:38:19 - agent.DQN.DQN - INFO - episode 2 step 15 reward tensor([-1]) loss 5.913208961486816 epsilon 0.79335
26-Feb-25 09:38:19 - agent.DQN.DQN - INFO - episode 2 step 16 reward tensor([-1]) loss 4.126765727996826 epsilon 0.79335
26-Feb-25 09:38:19 - agent.DQN.DQN - INFO - episode 2 step 17 reward tensor([-1]) loss 40.28318786621094 epsilon 0.79335
26-Feb-25 09:38:19 - agent.DQN.DQN - INFO - episode 2 step 18 reward tensor([-1]) loss 3.6132168769836426 epsilon 0.79335
26-Feb-25 09:38:19 - agent.DQN.DQN - INFO - episode 2 step 19 reward tensor([-1]) loss 41.546321868896484 epsilon 0.79335
26-Feb-25 09:38:19 - agent.DQN.DQN - INFO - episode 2 step 20 reward tensor([-1]) loss 40.063507080078125 epsilon 0.79335
26-Feb-25 09:38:19 - agent.DQN.DQN - INFO - episode 2 step 21 reward tensor([-1]) loss 39.04139709472656 epsilon 0.79335
26-Feb-25 09:38:19 - agent.DQN.DQN - INFO - episode 2 step 22 reward tensor([-1]) loss 3.2151601314544678 epsilon 0.79335
26-Feb-25 09:38:19 - agent.DQN.DQN - INFO - episode 2 step 23 reward tensor([-1]) loss 3.014969825744629 epsilon 0.79335
26-Feb-25 09:38:19 - agent.DQN.DQN - INFO - episode 2 step 24 reward tensor([-1]) loss 3.6858766078948975 epsilon 0.79335
26-Feb-25 09:38:19 - agent.DQN.DQN - INFO - episode 2 step 25 reward tensor([-1]) loss 3.267212390899658 epsilon 0.79335
26-Feb-25 09:38:19 - agent.DQN.DQN - INFO - episode 2 step 26 reward tensor([-1]) loss 3.1908774375915527 epsilon 0.79335
26-Feb-25 09:38:19 - agent.DQN.DQN - INFO - episode 2 step 27 reward tensor([-1]) loss 2.8846302032470703 epsilon 0.79335
26-Feb-25 09:38:19 - agent.DQN.DQN - INFO - episode 2 step 28 reward tensor([-1]) loss 3.087864637374878 epsilon 0.79335
26-Feb-25 09:38:19 - agent.DQN.DQN - INFO - episode 2 step 29 reward tensor([-1]) loss 45.02016830444336 epsilon 0.79335
26-Feb-25 09:38:19 - agent.DQN.DQN - INFO - episode 2 step 30 reward tensor([-1]) loss 8.25102424621582 epsilon 0.79335
26-Feb-25 09:38:19 - agent.DQN.DQN - INFO - episode 2 step 31 reward tensor([-1]) loss 7.0180583000183105 epsilon 0.79335
26-Feb-25 09:38:19 - agent.DQN.DQN - INFO - episode 2 step 32 reward tensor([-1]) loss 37.713680267333984 epsilon 0.79335
26-Feb-25 09:38:19 - agent.DQN.DQN - INFO - episode 2 step 33 reward tensor([-1]) loss 4.72127628326416 epsilon 0.79335
26-Feb-25 09:38:19 - agent.DQN.DQN - INFO - episode 2 step 34 reward tensor([-1]) loss 2.970191717147827 epsilon 0.79335
26-Feb-25 09:38:19 - agent.DQN.DQN - INFO - episode 2 step 35 reward tensor([-1]) loss 3.2497920989990234 epsilon 0.79335
26-Feb-25 09:38:19 - agent.DQN.DQN - INFO - episode 2 step 36 reward tensor([-1]) loss 2.6964476108551025 epsilon 0.79335
26-Feb-25 09:38:19 - agent.DQN.DQN - INFO - episode 2 step 37 reward tensor([-1]) loss 32.21373748779297 epsilon 0.79335
26-Feb-25 09:38:19 - agent.DQN.DQN - INFO - episode 2 step 38 reward tensor([-1]) loss 3.164137363433838 epsilon 0.79335
26-Feb-25 09:38:19 - agent.DQN.DQN - INFO - episode 2 step 39 reward tensor([-1]) loss 2.928579568862915 epsilon 0.79335
26-Feb-25 09:38:19 - agent.DQN.DQN - INFO - episode 2 step 40 reward tensor([-1]) loss 31.717851638793945 epsilon 0.79335
26-Feb-25 09:38:19 - agent.DQN.DQN - INFO - episode 2 step 41 reward tensor([-1]) loss 30.82166862487793 epsilon 0.79335
26-Feb-25 09:38:19 - agent.DQN.DQN - INFO - episode 2 step 42 reward tensor([-1]) loss 3.3072566986083984 epsilon 0.79335
26-Feb-25 09:38:19 - agent.DQN.DQN - INFO - episode 2 step 43 reward tensor([-1]) loss 3.144318103790283 epsilon 0.79335
26-Feb-25 09:38:19 - agent.DQN.DQN - INFO - episode 2 step 44 reward tensor([-1]) loss 29.56456184387207 epsilon 0.79335
26-Feb-25 09:38:19 - agent.DQN.DQN - INFO - episode 2 step 45 reward tensor([-1]) loss 3.3956212997436523 epsilon 0.79335
26-Feb-25 09:38:19 - agent.DQN.DQN - INFO - episode 2 step 46 reward tensor([-1]) loss 3.1487815380096436 epsilon 0.79335
26-Feb-25 09:38:19 - agent.DQN.DQN - INFO - episode 2 step 47 reward tensor([-1]) loss 2.669032096862793 epsilon 0.79335
26-Feb-25 09:38:19 - agent.DQN.DQN - INFO - episode 2 step 48 reward tensor([-1]) loss 2.597743034362793 epsilon 0.79335
26-Feb-25 09:38:19 - agent.DQN.DQN - INFO - episode 2 step 49 reward tensor([-1]) loss 28.68448829650879 epsilon 0.79335
26-Feb-25 09:38:19 - agent.DQN.DQN - INFO - episode 2 step 50 reward tensor([-1]) loss 2.5812482833862305 epsilon 0.79335
26-Feb-25 09:38:19 - agent.DQN.DQN - INFO - episode 2 step 51 reward tensor([-1]) loss 1.9753953218460083 epsilon 0.79335
26-Feb-25 09:38:19 - agent.DQN.DQN - INFO - episode 2 step 52 reward tensor([-1]) loss 2.196763515472412 epsilon 0.79335
26-Feb-25 09:38:19 - agent.DQN.DQN - INFO - episode 2 step 53 reward tensor([-1]) loss 27.218717575073242 epsilon 0.79335
26-Feb-25 09:38:19 - agent.DQN.DQN - INFO - episode 2 step 54 reward tensor([-1]) loss 2.258348226547241 epsilon 0.79335
26-Feb-25 09:38:19 - agent.DQN.DQN - INFO - episode 2 step 55 reward tensor([-1]) loss 28.469104766845703 epsilon 0.79335
26-Feb-25 09:38:19 - agent.DQN.DQN - INFO - episode 2 step 56 reward tensor([-1]) loss 2.7501471042633057 epsilon 0.79335
26-Feb-25 09:38:19 - agent.DQN.DQN - INFO - episode 2 step 57 reward tensor([-1]) loss 27.419166564941406 epsilon 0.79335
26-Feb-25 09:38:19 - agent.DQN.DQN - INFO - episode 2 step 58 reward tensor([-1]) loss 27.29585838317871 epsilon 0.79335
26-Feb-25 09:38:19 - agent.DQN.DQN - INFO - episode 2 step 59 reward tensor([-1]) loss 31.432289123535156 epsilon 0.79335
26-Feb-25 09:38:19 - agent.DQN.DQN - INFO - episode 2 step 60 reward tensor([-1]) loss 7.311919212341309 epsilon 0.79335
26-Feb-25 09:38:19 - agent.DQN.DQN - INFO - episode 2 step 61 reward tensor([-1]) loss 7.274445056915283 epsilon 0.79335
26-Feb-25 09:38:19 - agent.DQN.DQN - INFO - episode 2 step 62 reward tensor([-1]) loss 4.894084453582764 epsilon 0.79335
26-Feb-25 09:38:19 - agent.DQN.DQN - INFO - episode 2 step 63 reward tensor([-1]) loss 24.419309616088867 epsilon 0.79335
26-Feb-25 09:38:19 - agent.DQN.DQN - INFO - episode 2 step 64 reward tensor([-1]) loss 4.329287528991699 epsilon 0.79335
26-Feb-25 09:38:19 - agent.DQN.DQN - INFO - episode 2 step 65 reward tensor([-1]) loss 23.75056266784668 epsilon 0.79335
26-Feb-25 09:38:19 - agent.DQN.DQN - INFO - episode 2 step 66 reward tensor([-1]) loss 3.0393693447113037 epsilon 0.79335
26-Feb-25 09:38:19 - agent.DQN.DQN - INFO - episode 2 step 67 reward tensor([-1]) loss 3.2954583168029785 epsilon 0.79335
26-Feb-25 09:38:19 - agent.DQN.DQN - INFO - episode 2 step 68 reward tensor([-1]) loss 3.436026096343994 epsilon 0.79335
26-Feb-25 09:38:19 - agent.DQN.DQN - INFO - episode 2 step 69 reward tensor([-1]) loss 21.180980682373047 epsilon 0.79335
26-Feb-25 09:38:19 - agent.DQN.DQN - INFO - episode 2 step 70 reward tensor([-1]) loss 3.578077793121338 epsilon 0.79335
26-Feb-25 09:38:19 - agent.DQN.DQN - INFO - episode 2 step 71 reward tensor([-1]) loss 3.3206937313079834 epsilon 0.79335
26-Feb-25 09:38:19 - agent.DQN.DQN - INFO - episode 2 step 72 reward tensor([-1]) loss 21.69012451171875 epsilon 0.79335
26-Feb-25 09:38:19 - agent.DQN.DQN - INFO - episode 2 step 73 reward tensor([-1]) loss 2.908865451812744 epsilon 0.79335
26-Feb-25 09:38:19 - agent.DQN.DQN - INFO - episode 2 step 74 reward tensor([-1]) loss 3.192805767059326 epsilon 0.79335
26-Feb-25 09:38:19 - agent.DQN.DQN - INFO - episode 2 step 75 reward tensor([-1]) loss 3.866353988647461 epsilon 0.79335
26-Feb-25 09:38:19 - agent.DQN.DQN - INFO - episode 2 step 76 reward tensor([-1]) loss 3.505862236022949 epsilon 0.79335
26-Feb-25 09:38:19 - agent.DQN.DQN - INFO - episode 2 step 77 reward tensor([-1]) loss 26.277690887451172 epsilon 0.79335
26-Feb-25 09:38:19 - agent.DQN.DQN - INFO - episode 2 step 78 reward tensor([-1]) loss 25.193702697753906 epsilon 0.79335
26-Feb-25 09:38:19 - agent.DQN.DQN - INFO - episode 2 step 79 reward tensor([-1]) loss 2.7506425380706787 epsilon 0.79335
26-Feb-25 09:38:19 - agent.DQN.DQN - INFO - episode 2 step 80 reward tensor([-1]) loss 2.4220917224884033 epsilon 0.79335
26-Feb-25 09:38:19 - agent.DQN.DQN - INFO - episode 2 step 81 reward tensor([-1]) loss 1.8277000188827515 epsilon 0.79335
26-Feb-25 09:38:19 - agent.DQN.DQN - INFO - episode 2 step 82 reward tensor([-1]) loss 22.962501525878906 epsilon 0.79335
26-Feb-25 09:38:19 - agent.DQN.DQN - INFO - episode 2 step 83 reward tensor([-1]) loss 2.4288814067840576 epsilon 0.79335
26-Feb-25 09:38:19 - agent.DQN.DQN - INFO - episode 2 step 84 reward tensor([-1]) loss 22.6193790435791 epsilon 0.79335
26-Feb-25 09:38:19 - agent.DQN.DQN - INFO - episode 2 step 85 reward tensor([-1]) loss 2.389004707336426 epsilon 0.79335
26-Feb-25 09:38:19 - agent.DQN.DQN - INFO - episode 2 step 86 reward tensor([-1]) loss 2.4141855239868164 epsilon 0.79335
26-Feb-25 09:38:19 - agent.DQN.DQN - INFO - episode 2 step 87 reward tensor([-1]) loss 2.9093680381774902 epsilon 0.79335
26-Feb-25 09:38:20 - agent.DQN.DQN - INFO - episode 2 step 88 reward tensor([-1]) loss 7.070162296295166 epsilon 0.79335
26-Feb-25 09:38:20 - agent.DQN.DQN - INFO - episode 2 step 89 reward tensor([-1]) loss 32.30437469482422 epsilon 0.79335
26-Feb-25 09:38:20 - agent.DQN.DQN - INFO - episode 2 step 90 reward tensor([-1]) loss 28.459575653076172 epsilon 0.79335
26-Feb-25 09:38:20 - agent.DQN.DQN - INFO - episode 2 step 91 reward tensor([-1]) loss 7.425620079040527 epsilon 0.79335
26-Feb-25 09:38:20 - agent.DQN.DQN - INFO - episode 2 step 92 reward tensor([-1]) loss 6.859930992126465 epsilon 0.79335
26-Feb-25 09:38:20 - agent.DQN.DQN - INFO - episode 2 step 93 reward tensor([-1]) loss 5.429693222045898 epsilon 0.79335
26-Feb-25 09:38:20 - agent.DQN.DQN - INFO - episode 2 step 94 reward tensor([-1]) loss 27.46162223815918 epsilon 0.79335
26-Feb-25 09:38:20 - agent.DQN.DQN - INFO - episode 2 step 95 reward tensor([-1]) loss 3.538144111633301 epsilon 0.79335
26-Feb-25 09:38:20 - agent.DQN.DQN - INFO - episode 2 step 96 reward tensor([-1]) loss 20.66120147705078 epsilon 0.79335
26-Feb-25 09:38:20 - agent.DQN.DQN - INFO - episode 2 step 97 reward tensor([-1]) loss 22.394378662109375 epsilon 0.79335
26-Feb-25 09:38:20 - agent.DQN.DQN - INFO - episode 2 step 98 reward tensor([-1]) loss 7.453953266143799 epsilon 0.79335
26-Feb-25 09:38:20 - agent.DQN.DQN - INFO - episode 2 step 99 reward tensor([-1]) loss 18.044042587280273 epsilon 0.79335
26-Feb-25 09:38:20 - agent.DQN.DQN - INFO - episode 2 step 100 reward tensor([-1]) loss 6.882571697235107 epsilon 0.79335
26-Feb-25 09:38:20 - agent.DQN.DQN - INFO - episode 2 step 101 reward tensor([-1]) loss 5.6631855964660645 epsilon 0.79335
26-Feb-25 09:38:20 - agent.DQN.DQN - INFO - episode 2 step 102 reward tensor([-1]) loss 10.235227584838867 epsilon 0.79335
26-Feb-25 09:38:20 - agent.DQN.DQN - INFO - episode 2 step 103 reward tensor([-1]) loss 17.980093002319336 epsilon 0.79335
26-Feb-25 09:38:20 - agent.DQN.DQN - INFO - episode 2 step 104 reward tensor([-1]) loss 5.944244384765625 epsilon 0.79335
26-Feb-25 09:38:20 - agent.DQN.DQN - INFO - episode 2 step 105 reward tensor([-1]) loss 3.7343363761901855 epsilon 0.79335
26-Feb-25 09:38:20 - agent.DQN.DQN - INFO - episode 2 step 106 reward tensor([-1]) loss 12.438908576965332 epsilon 0.79335
26-Feb-25 09:38:20 - agent.DQN.DQN - INFO - episode 2 step 107 reward tensor([-1]) loss 5.899007797241211 epsilon 0.79335
26-Feb-25 09:38:20 - agent.DQN.DQN - INFO - episode 2 step 108 reward tensor([-1]) loss 20.187618255615234 epsilon 0.79335
26-Feb-25 09:38:20 - agent.DQN.DQN - INFO - episode 2 step 109 reward tensor([-1]) loss 30.365800857543945 epsilon 0.79335
26-Feb-25 09:38:20 - agent.DQN.DQN - INFO - episode 2 step 110 reward tensor([-1]) loss 3.2185254096984863 epsilon 0.79335
26-Feb-25 09:38:20 - agent.DQN.DQN - INFO - episode 2 step 111 reward tensor([-1]) loss 26.263959884643555 epsilon 0.79335
26-Feb-25 09:38:20 - agent.DQN.DQN - INFO - episode 2 step 112 reward tensor([-1]) loss 25.08495330810547 epsilon 0.79335
26-Feb-25 09:38:20 - agent.DQN.DQN - INFO - episode 2 step 113 reward tensor([-1]) loss 2.927433729171753 epsilon 0.79335
26-Feb-25 09:38:20 - agent.DQN.DQN - INFO - episode 2 step 114 reward tensor([-1]) loss 11.598453521728516 epsilon 0.79335
26-Feb-25 09:38:20 - agent.DQN.DQN - INFO - episode 2 step 115 reward tensor([-1]) loss 10.10362434387207 epsilon 0.79335
26-Feb-25 09:38:20 - agent.DQN.DQN - INFO - episode 2 step 116 reward tensor([-1]) loss 8.88404655456543 epsilon 0.79335
26-Feb-25 09:38:20 - agent.DQN.DQN - INFO - episode 2 step 117 reward tensor([-1]) loss 24.977657318115234 epsilon 0.79335
26-Feb-25 09:38:20 - agent.DQN.DQN - INFO - episode 2 step 118 reward tensor([-1]) loss 8.540979385375977 epsilon 0.79335
26-Feb-25 09:38:20 - agent.DQN.DQN - INFO - episode 2 step 119 reward tensor([-1]) loss 24.233097076416016 epsilon 0.79335
26-Feb-25 09:38:20 - agent.DQN.DQN - INFO - episode 2 step 120 reward tensor([-1]) loss 24.818645477294922 epsilon 0.79335
26-Feb-25 09:38:20 - agent.DQN.DQN - INFO - episode 2 step 121 reward tensor([-1]) loss 10.639873504638672 epsilon 0.79335
26-Feb-25 09:38:20 - agent.DQN.DQN - INFO - episode 2 step 122 reward tensor([-1]) loss 11.901397705078125 epsilon 0.79335
26-Feb-25 09:38:20 - agent.DQN.DQN - INFO - episode 2 step 123 reward tensor([-1]) loss 10.407600402832031 epsilon 0.79335
26-Feb-25 09:38:20 - agent.DQN.DQN - INFO - episode 2 step 124 reward tensor([-1]) loss 20.625024795532227 epsilon 0.79335
26-Feb-25 09:38:20 - agent.DQN.DQN - INFO - episode 2 step 125 reward tensor([-1]) loss 4.202386856079102 epsilon 0.79335
26-Feb-25 09:38:20 - agent.DQN.DQN - INFO - episode 2 step 126 reward tensor([-1]) loss 6.283343315124512 epsilon 0.79335
26-Feb-25 09:38:20 - agent.DQN.DQN - INFO - episode 2 step 127 reward tensor([-1]) loss 8.489851951599121 epsilon 0.79335
26-Feb-25 09:38:20 - agent.DQN.DQN - INFO - episode 2 step 128 reward tensor([-1]) loss 6.497901439666748 epsilon 0.79335
26-Feb-25 09:38:20 - agent.DQN.DQN - INFO - episode 2 step 129 reward tensor([-1]) loss 16.966718673706055 epsilon 0.79335
26-Feb-25 09:38:20 - agent.DQN.DQN - INFO - episode 2 step 130 reward tensor([-1]) loss 16.729778289794922 epsilon 0.79335
26-Feb-25 09:38:20 - agent.DQN.DQN - INFO - episode 2 step 131 reward tensor([-1]) loss 17.29806900024414 epsilon 0.79335
26-Feb-25 09:38:20 - agent.DQN.DQN - INFO - episode 2 step 132 reward tensor([-1]) loss 5.899010181427002 epsilon 0.79335
26-Feb-25 09:38:20 - agent.DQN.DQN - INFO - episode 2 step 133 reward tensor([-1]) loss 6.224923133850098 epsilon 0.79335
26-Feb-25 09:38:20 - agent.DQN.DQN - INFO - episode 2 step 134 reward tensor([-1]) loss 3.3173890113830566 epsilon 0.79335
26-Feb-25 09:38:20 - agent.DQN.DQN - INFO - episode 2 step 135 reward tensor([-1]) loss 5.22216272354126 epsilon 0.79335
26-Feb-25 09:38:20 - agent.DQN.DQN - INFO - episode 2 step 136 reward tensor([-1]) loss 5.33594274520874 epsilon 0.79335
26-Feb-25 09:38:20 - agent.DQN.DQN - INFO - episode 2 step 137 reward tensor([-1]) loss 4.344862461090088 epsilon 0.79335
26-Feb-25 09:38:20 - agent.DQN.DQN - INFO - episode 2 step 138 reward tensor([-1]) loss 16.558740615844727 epsilon 0.79335
26-Feb-25 09:38:20 - agent.DQN.DQN - INFO - episode 2 step 139 reward tensor([-1]) loss 15.458017349243164 epsilon 0.79335
26-Feb-25 09:38:20 - agent.DQN.DQN - INFO - episode 2 step 140 reward tensor([-1]) loss 2.819692850112915 epsilon 0.79335
26-Feb-25 09:38:20 - agent.DQN.DQN - INFO - episode 2 step 141 reward tensor([-1]) loss 2.6493723392486572 epsilon 0.79335
26-Feb-25 09:38:20 - agent.DQN.DQN - INFO - episode 2 step 142 reward tensor([-1]) loss 4.102564334869385 epsilon 0.79335
26-Feb-25 09:38:20 - agent.DQN.DQN - INFO - episode 2 step 143 reward tensor([-1]) loss 15.467836380004883 epsilon 0.79335
26-Feb-25 09:38:20 - agent.DQN.DQN - INFO - episode 2 step 144 reward tensor([-1]) loss 2.711474895477295 epsilon 0.79335
26-Feb-25 09:38:20 - agent.DQN.DQN - INFO - episode 2 step 145 reward tensor([-1]) loss 4.195235252380371 epsilon 0.79335
26-Feb-25 09:38:20 - agent.DQN.DQN - INFO - episode 2 step 146 reward tensor([-1]) loss 3.016536235809326 epsilon 0.79335
26-Feb-25 09:38:20 - agent.DQN.DQN - INFO - episode 2 step 147 reward tensor([-1]) loss 3.5498883724212646 epsilon 0.79335
26-Feb-25 09:38:20 - agent.DQN.DQN - INFO - episode 2 step 148 reward tensor([-1]) loss 14.936959266662598 epsilon 0.79335
26-Feb-25 09:38:20 - agent.DQN.DQN - INFO - episode 2 step 149 reward tensor([-1]) loss 6.786502838134766 epsilon 0.79335
26-Feb-25 09:38:20 - agent.DQN.DQN - INFO - episode 2 step 150 reward tensor([-1]) loss 16.60589599609375 epsilon 0.79335
26-Feb-25 09:38:20 - agent.DQN.DQN - INFO - episode 2 step 151 reward tensor([-1]) loss 4.596311092376709 epsilon 0.79335
26-Feb-25 09:38:20 - agent.DQN.DQN - INFO - episode 2 step 152 reward tensor([-1]) loss 4.8686747550964355 epsilon 0.79335
26-Feb-25 09:38:20 - agent.DQN.DQN - INFO - episode 2 step 153 reward tensor([-1]) loss 14.123228073120117 epsilon 0.79335
26-Feb-25 09:38:20 - agent.DQN.DQN - INFO - episode 2 step 154 reward tensor([-1]) loss 3.820432424545288 epsilon 0.79335
26-Feb-25 09:38:20 - agent.DQN.DQN - INFO - episode 2 step 155 reward tensor([-1]) loss 3.750202178955078 epsilon 0.79335
26-Feb-25 09:38:20 - agent.DQN.DQN - INFO - episode 2 step 156 reward tensor([-1]) loss 12.463561058044434 epsilon 0.79335
26-Feb-25 09:38:20 - agent.DQN.DQN - INFO - episode 2 step 157 reward tensor([-1]) loss 12.276861190795898 epsilon 0.79335
26-Feb-25 09:38:20 - agent.DQN.DQN - INFO - episode 2 step 158 reward tensor([-1]) loss 3.803678274154663 epsilon 0.79335
26-Feb-25 09:38:20 - agent.DQN.DQN - INFO - episode 2 step 159 reward tensor([-1]) loss 3.6523842811584473 epsilon 0.79335
26-Feb-25 09:38:20 - agent.DQN.DQN - INFO - episode 2 step 160 reward tensor([-1]) loss 12.347639083862305 epsilon 0.79335
26-Feb-25 09:38:21 - agent.DQN.DQN - INFO - episode 2 step 161 reward tensor([-1]) loss 3.571530818939209 epsilon 0.79335
26-Feb-25 09:38:21 - agent.DQN.DQN - INFO - episode 2 step 162 reward tensor([-1]) loss 3.142930269241333 epsilon 0.79335
26-Feb-25 09:38:21 - agent.DQN.DQN - INFO - episode 2 step 163 reward tensor([-1]) loss 2.9335641860961914 epsilon 0.79335
26-Feb-25 09:38:21 - agent.DQN.DQN - INFO - episode 2 step 164 reward tensor([-1]) loss 3.81984806060791 epsilon 0.79335
26-Feb-25 09:38:21 - agent.DQN.DQN - INFO - episode 2 step 165 reward tensor([-1]) loss 2.4680473804473877 epsilon 0.79335
26-Feb-25 09:38:21 - agent.DQN.DQN - INFO - episode 2 step 166 reward tensor([-1]) loss 2.026857614517212 epsilon 0.79335
26-Feb-25 09:38:21 - agent.DQN.DQN - INFO - episode 2 step 167 reward tensor([-1]) loss 10.3653564453125 epsilon 0.79335
26-Feb-25 09:38:21 - agent.DQN.DQN - INFO - episode 2 step 168 reward tensor([-1]) loss 2.4314355850219727 epsilon 0.79335
26-Feb-25 09:38:21 - agent.DQN.DQN - INFO - episode 2 step 169 reward tensor([-1]) loss 1.6682147979736328 epsilon 0.79335
26-Feb-25 09:38:21 - agent.DQN.DQN - INFO - episode 2 step 170 reward tensor([-1]) loss 11.346050262451172 epsilon 0.79335
26-Feb-25 09:38:21 - agent.DQN.DQN - INFO - episode 2 step 171 reward tensor([-1]) loss 2.562065601348877 epsilon 0.79335
26-Feb-25 09:38:21 - agent.DQN.DQN - INFO - episode 2 step 172 reward tensor([-1]) loss 1.571204423904419 epsilon 0.79335
26-Feb-25 09:38:21 - agent.DQN.DQN - INFO - episode 2 step 173 reward tensor([-1]) loss 2.1261258125305176 epsilon 0.79335
26-Feb-25 09:38:21 - agent.DQN.DQN - INFO - episode 2 step 174 reward tensor([-1]) loss 10.989152908325195 epsilon 0.79335
26-Feb-25 09:38:21 - agent.DQN.DQN - INFO - episode 2 step 175 reward tensor([-1]) loss 1.360695242881775 epsilon 0.79335
26-Feb-25 09:38:21 - agent.DQN.DQN - INFO - episode 2 step 176 reward tensor([-1]) loss 1.5844712257385254 epsilon 0.79335
26-Feb-25 09:38:21 - agent.DQN.DQN - INFO - episode 2 step 177 reward tensor([-1]) loss 10.223605155944824 epsilon 0.79335
26-Feb-25 09:38:21 - agent.DQN.DQN - INFO - episode 2 step 178 reward tensor([-1]) loss 1.9132356643676758 epsilon 0.79335
26-Feb-25 09:38:21 - agent.DQN.DQN - INFO - episode 2 step 179 reward tensor([-1]) loss 5.1983842849731445 epsilon 0.79335
26-Feb-25 09:38:21 - agent.DQN.DQN - INFO - episode 2 step 180 reward tensor([-1]) loss 5.8309526443481445 epsilon 0.79335
26-Feb-25 09:38:21 - agent.DQN.DQN - INFO - episode 2 step 181 reward tensor([-1]) loss 13.333322525024414 epsilon 0.79335
26-Feb-25 09:38:21 - agent.DQN.DQN - INFO - episode 2 step 182 reward tensor([-1]) loss 11.078742980957031 epsilon 0.79335
26-Feb-25 09:38:21 - agent.DQN.DQN - INFO - episode 2 step 183 reward tensor([-1]) loss 10.837868690490723 epsilon 0.79335
26-Feb-25 09:38:21 - agent.DQN.DQN - INFO - episode 2 step 184 reward tensor([-1]) loss 9.980934143066406 epsilon 0.79335
26-Feb-25 09:38:21 - agent.DQN.DQN - INFO - episode 2 step 185 reward tensor([-1]) loss 3.099088668823242 epsilon 0.79335
26-Feb-25 09:38:21 - agent.DQN.DQN - INFO - episode 2 step 186 reward tensor([-1]) loss 7.954431533813477 epsilon 0.79335
26-Feb-25 09:38:21 - agent.DQN.DQN - INFO - episode 2 step 187 reward tensor([-1]) loss 8.114521980285645 epsilon 0.79335
26-Feb-25 09:38:21 - agent.DQN.DQN - INFO - episode 2 step 188 reward tensor([-1]) loss 1.7079923152923584 epsilon 0.79335
26-Feb-25 09:38:21 - agent.DQN.DQN - INFO - episode 2 step 189 reward tensor([-1]) loss 7.893746376037598 epsilon 0.79335
26-Feb-25 09:38:21 - agent.DQN.DQN - INFO - episode 2 step 190 reward tensor([-1]) loss 2.4863200187683105 epsilon 0.79335
26-Feb-25 09:38:21 - agent.DQN.DQN - INFO - episode 2 step 191 reward tensor([-1]) loss 3.1687440872192383 epsilon 0.79335
26-Feb-25 09:38:21 - agent.DQN.DQN - INFO - episode 2 step 192 reward tensor([-1]) loss 2.2658751010894775 epsilon 0.79335
26-Feb-25 09:38:21 - agent.DQN.DQN - INFO - episode 2 step 193 reward tensor([-1]) loss 3.1288704872131348 epsilon 0.79335
26-Feb-25 09:38:21 - agent.DQN.DQN - INFO - episode 2 step 194 reward tensor([-1]) loss 8.268854141235352 epsilon 0.79335
26-Feb-25 09:38:21 - agent.DQN.DQN - INFO - episode 2 step 195 reward tensor([-1]) loss 6.819127082824707 epsilon 0.79335
26-Feb-25 09:38:21 - agent.DQN.DQN - INFO - episode 2 step 196 reward tensor([-1]) loss 1.3590056896209717 epsilon 0.79335
26-Feb-25 09:38:21 - agent.DQN.DQN - INFO - episode 2 step 197 reward tensor([-1]) loss 2.2326931953430176 epsilon 0.79335
26-Feb-25 09:38:21 - agent.DQN.DQN - INFO - episode 2 step 198 reward tensor([-1]) loss 6.325087547302246 epsilon 0.79335
26-Feb-25 09:38:21 - agent.DQN.DQN - INFO - episode 2 step 199 reward tensor([-1]) loss 2.4209365844726562 epsilon 0.79335
26-Feb-25 09:38:21 - agent.DQN.DQN - INFO - episode 2 step 200 reward tensor([-1]) loss 3.3718769550323486 epsilon 0.79335
26-Feb-25 09:38:21 - agent.DQN.DQN - INFO - episode 2 step 201 reward tensor([-1]) loss 2.011974573135376 epsilon 0.79335
26-Feb-25 09:38:21 - agent.DQN.DQN - INFO - episode 2 step 202 reward tensor([-1]) loss 2.063673257827759 epsilon 0.79335
26-Feb-25 09:38:21 - agent.DQN.DQN - INFO - episode 2 step 203 reward tensor([-1]) loss 2.949026346206665 epsilon 0.79335
26-Feb-25 09:38:21 - agent.DQN.DQN - INFO - episode 2 step 204 reward tensor([-1]) loss 2.608341932296753 epsilon 0.79335
26-Feb-25 09:38:21 - agent.DQN.DQN - INFO - episode 2 step 205 reward tensor([-1]) loss 2.2740602493286133 epsilon 0.79335
26-Feb-25 09:38:21 - agent.DQN.DQN - INFO - episode 2 step 206 reward tensor([-1]) loss 8.446964263916016 epsilon 0.79335
26-Feb-25 09:38:21 - agent.DQN.DQN - INFO - episode 2 step 207 reward tensor([-1]) loss 2.1797049045562744 epsilon 0.79335
26-Feb-25 09:38:21 - agent.DQN.DQN - INFO - episode 2 step 208 reward tensor([-1]) loss 7.865016460418701 epsilon 0.79335
26-Feb-25 09:38:21 - agent.DQN.DQN - INFO - episode 2 step 209 reward tensor([-1]) loss 6.3758955001831055 epsilon 0.79335
26-Feb-25 09:38:21 - agent.DQN.DQN - INFO - episode 2 step 210 reward tensor([-1]) loss 11.4768705368042 epsilon 0.79335
26-Feb-25 09:38:21 - agent.DQN.DQN - INFO - episode 2 step 211 reward tensor([-1]) loss 4.497289180755615 epsilon 0.79335
26-Feb-25 09:38:21 - agent.DQN.DQN - INFO - episode 2 step 212 reward tensor([-1]) loss 3.4110896587371826 epsilon 0.79335
26-Feb-25 09:38:21 - agent.DQN.DQN - INFO - episode 2 step 213 reward tensor([-1]) loss 3.190570592880249 epsilon 0.79335
26-Feb-25 09:38:21 - agent.DQN.DQN - INFO - episode 2 step 214 reward tensor([-1]) loss 2.8703019618988037 epsilon 0.79335
26-Feb-25 09:38:21 - agent.DQN.DQN - INFO - episode 2 step 215 reward tensor([-1]) loss 8.580978393554688 epsilon 0.79335
26-Feb-25 09:38:21 - agent.DQN.DQN - INFO - episode 2 step 216 reward tensor([-1]) loss 7.827796936035156 epsilon 0.79335
26-Feb-25 09:38:21 - agent.DQN.DQN - INFO - episode 2 step 217 reward tensor([-1]) loss 4.179262161254883 epsilon 0.79335
26-Feb-25 09:38:21 - agent.DQN.DQN - INFO - episode 2 step 218 reward tensor([-1]) loss 2.0994908809661865 epsilon 0.79335
26-Feb-25 09:38:21 - agent.DQN.DQN - INFO - episode 2 step 219 reward tensor([-1]) loss 3.5126678943634033 epsilon 0.79335
26-Feb-25 09:38:21 - agent.DQN.DQN - INFO - episode 2 step 220 reward tensor([-1]) loss 4.302642822265625 epsilon 0.79335
26-Feb-25 09:38:21 - agent.DQN.DQN - INFO - episode 2 step 221 reward tensor([-1]) loss 7.151298522949219 epsilon 0.79335
26-Feb-25 09:38:21 - agent.DQN.DQN - INFO - episode 2 step 222 reward tensor([-1]) loss 7.658648490905762 epsilon 0.79335
26-Feb-25 09:38:21 - agent.DQN.DQN - INFO - episode 2 step 223 reward tensor([-1]) loss 7.066553115844727 epsilon 0.79335
26-Feb-25 09:38:21 - agent.DQN.DQN - INFO - episode 2 step 224 reward tensor([-1]) loss 2.9572925567626953 epsilon 0.79335
26-Feb-25 09:38:21 - agent.DQN.DQN - INFO - episode 2 step 225 reward tensor([-1]) loss 6.264577865600586 epsilon 0.79335
26-Feb-25 09:38:21 - agent.DQN.DQN - INFO - episode 2 step 226 reward tensor([-1]) loss 3.0364742279052734 epsilon 0.79335
26-Feb-25 09:38:21 - agent.DQN.DQN - INFO - episode 2 step 227 reward tensor([-1]) loss 2.1416850090026855 epsilon 0.79335
26-Feb-25 09:38:21 - agent.DQN.DQN - INFO - episode 2 step 228 reward tensor([-1]) loss 2.734680414199829 epsilon 0.79335
26-Feb-25 09:38:21 - agent.DQN.DQN - INFO - episode 2 step 229 reward tensor([-1]) loss 1.72645902633667 epsilon 0.79335
26-Feb-25 09:38:21 - agent.DQN.DQN - INFO - episode 2 step 230 reward tensor([-1]) loss 2.5959582328796387 epsilon 0.79335
26-Feb-25 09:38:21 - agent.DQN.DQN - INFO - episode 2 step 231 reward tensor([-1]) loss 1.6689313650131226 epsilon 0.79335
26-Feb-25 09:38:21 - agent.DQN.DQN - INFO - episode 2 step 232 reward tensor([-1]) loss 1.648658275604248 epsilon 0.79335
26-Feb-25 09:38:21 - agent.DQN.DQN - INFO - episode 2 step 233 reward tensor([-1]) loss 6.219506740570068 epsilon 0.79335
26-Feb-25 09:38:21 - agent.DQN.DQN - INFO - episode 2 step 234 reward tensor([-1]) loss 1.9234305620193481 epsilon 0.79335
26-Feb-25 09:38:22 - agent.DQN.DQN - INFO - episode 2 step 235 reward tensor([-1]) loss 1.8677380084991455 epsilon 0.79335
26-Feb-25 09:38:22 - agent.DQN.DQN - INFO - episode 2 step 236 reward tensor([-1]) loss 5.808704853057861 epsilon 0.79335
26-Feb-25 09:38:22 - agent.DQN.DQN - INFO - episode 2 step 237 reward tensor([-1]) loss 1.812917947769165 epsilon 0.79335
26-Feb-25 09:38:22 - agent.DQN.DQN - INFO - episode 2 step 238 reward tensor([-1]) loss 2.325425386428833 epsilon 0.79335
26-Feb-25 09:38:22 - agent.DQN.DQN - INFO - episode 2 step 239 reward tensor([-1]) loss 6.27618932723999 epsilon 0.79335
26-Feb-25 09:38:22 - agent.DQN.DQN - INFO - episode 2 step 240 reward tensor([-1]) loss 5.805538654327393 epsilon 0.79335
26-Feb-25 09:38:22 - agent.DQN.DQN - INFO - episode 2 step 241 reward tensor([-1]) loss 4.089625358581543 epsilon 0.79335
26-Feb-25 09:38:22 - agent.DQN.DQN - INFO - episode 2 step 242 reward tensor([-1]) loss 3.378713607788086 epsilon 0.79335
26-Feb-25 09:38:22 - agent.DQN.DQN - INFO - episode 2 step 243 reward tensor([-1]) loss 3.0827019214630127 epsilon 0.79335
26-Feb-25 09:38:22 - agent.DQN.DQN - INFO - episode 2 step 244 reward tensor([-1]) loss 3.1874663829803467 epsilon 0.79335
26-Feb-25 09:38:22 - agent.DQN.DQN - INFO - episode 2 step 245 reward tensor([-1]) loss 3.568329334259033 epsilon 0.79335
26-Feb-25 09:38:22 - agent.DQN.DQN - INFO - episode 2 step 246 reward tensor([-1]) loss 3.4490253925323486 epsilon 0.79335
26-Feb-25 09:38:22 - agent.DQN.DQN - INFO - episode 2 step 247 reward tensor([-1]) loss 6.3671345710754395 epsilon 0.79335
26-Feb-25 09:38:22 - agent.DQN.DQN - INFO - episode 2 step 248 reward tensor([-1]) loss 1.8919641971588135 epsilon 0.79335
26-Feb-25 09:38:22 - agent.DQN.DQN - INFO - episode 2 step 249 reward tensor([-1]) loss 6.066604137420654 epsilon 0.79335
26-Feb-25 09:38:22 - agent.DQN.DQN - INFO - episode 2 step 250 reward tensor([-1]) loss 2.942039728164673 epsilon 0.79335
26-Feb-25 09:38:22 - agent.DQN.DQN - INFO - episode 2 step 251 reward tensor([-1]) loss 2.912322521209717 epsilon 0.79335
26-Feb-25 09:38:22 - agent.DQN.DQN - INFO - episode 2 step 252 reward tensor([-1]) loss 2.03322172164917 epsilon 0.79335
26-Feb-25 09:38:22 - agent.DQN.DQN - INFO - episode 2 step 253 reward tensor([-1]) loss 1.6189180612564087 epsilon 0.79335
26-Feb-25 09:38:22 - agent.DQN.DQN - INFO - episode 2 step 254 reward tensor([-1]) loss 1.7778716087341309 epsilon 0.79335
26-Feb-25 09:38:22 - agent.DQN.DQN - INFO - episode 2 step 255 reward tensor([-1]) loss 1.4229027032852173 epsilon 0.79335
26-Feb-25 09:38:22 - agent.DQN.DQN - INFO - episode 2 step 256 reward tensor([-1]) loss 1.9816694259643555 epsilon 0.79335
26-Feb-25 09:38:22 - agent.DQN.DQN - INFO - episode 2 step 257 reward tensor([-1]) loss 1.782408595085144 epsilon 0.79335
26-Feb-25 09:38:22 - agent.DQN.DQN - INFO - episode 2 step 258 reward tensor([-1]) loss 5.195842742919922 epsilon 0.79335
26-Feb-25 09:38:22 - agent.DQN.DQN - INFO - episode 2 step 259 reward tensor([-1]) loss 1.8607311248779297 epsilon 0.79335
26-Feb-25 09:38:22 - agent.DQN.DQN - INFO - episode 2 step 260 reward tensor([-1]) loss 1.8988585472106934 epsilon 0.79335
26-Feb-25 09:38:22 - agent.DQN.DQN - INFO - episode 2 step 261 reward tensor([-1]) loss 1.939639687538147 epsilon 0.79335
26-Feb-25 09:38:22 - agent.DQN.DQN - INFO - episode 2 step 262 reward tensor([-1]) loss 1.4740312099456787 epsilon 0.79335
26-Feb-25 09:38:22 - agent.DQN.DQN - INFO - episode 2 step 263 reward tensor([-1]) loss 1.6698083877563477 epsilon 0.79335
26-Feb-25 09:38:22 - agent.DQN.DQN - INFO - episode 2 step 264 reward tensor([-1]) loss 1.0246751308441162 epsilon 0.79335
26-Feb-25 09:38:22 - agent.DQN.DQN - INFO - episode 2 step 265 reward tensor([-1]) loss 1.5205323696136475 epsilon 0.79335
26-Feb-25 09:38:22 - agent.DQN.DQN - INFO - episode 2 step 266 reward tensor([-1]) loss 1.821040391921997 epsilon 0.79335
26-Feb-25 09:38:22 - agent.DQN.DQN - INFO - episode 2 step 267 reward tensor([-1]) loss 1.2394700050354004 epsilon 0.79335
26-Feb-25 09:38:22 - agent.DQN.DQN - INFO - episode 2 step 268 reward tensor([-1]) loss 1.7405815124511719 epsilon 0.79335
26-Feb-25 09:38:22 - agent.DQN.DQN - INFO - episode 2 step 269 reward tensor([-1]) loss 7.566689491271973 epsilon 0.79335
26-Feb-25 09:38:22 - agent.DQN.DQN - INFO - episode 2 step 270 reward tensor([-1]) loss 9.240501403808594 epsilon 0.79335
26-Feb-25 09:38:22 - agent.DQN.DQN - INFO - episode 2 step 271 reward tensor([-1]) loss 4.5354719161987305 epsilon 0.79335
26-Feb-25 09:38:22 - agent.DQN.DQN - INFO - episode 2 step 272 reward tensor([-1]) loss 2.7981486320495605 epsilon 0.79335
26-Feb-25 09:38:22 - agent.DQN.DQN - INFO - episode 2 step 273 reward tensor([-1]) loss 2.3800642490386963 epsilon 0.79335
26-Feb-25 09:38:22 - agent.DQN.DQN - INFO - episode 2 step 274 reward tensor([-1]) loss 2.1934053897857666 epsilon 0.79335
26-Feb-25 09:38:22 - agent.DQN.DQN - INFO - episode 2 step 275 reward tensor([-1]) loss 2.893010377883911 epsilon 0.79335
26-Feb-25 09:38:22 - agent.DQN.DQN - INFO - episode 2 step 276 reward tensor([-1]) loss 2.607419013977051 epsilon 0.79335
26-Feb-25 09:38:22 - agent.DQN.DQN - INFO - episode 2 step 277 reward tensor([-1]) loss 3.011028289794922 epsilon 0.79335
26-Feb-25 09:38:22 - agent.DQN.DQN - INFO - episode 2 step 278 reward tensor([-1]) loss 2.868312358856201 epsilon 0.79335
26-Feb-25 09:38:22 - agent.DQN.DQN - INFO - episode 2 step 279 reward tensor([-1]) loss 2.6546967029571533 epsilon 0.79335
26-Feb-25 09:38:22 - agent.DQN.DQN - INFO - episode 2 step 280 reward tensor([-1]) loss 5.420297145843506 epsilon 0.79335
26-Feb-25 09:38:22 - agent.DQN.DQN - INFO - episode 2 step 281 reward tensor([-1]) loss 5.23664665222168 epsilon 0.79335
26-Feb-25 09:38:22 - agent.DQN.DQN - INFO - episode 2 step 282 reward tensor([-1]) loss 1.9945154190063477 epsilon 0.79335
26-Feb-25 09:38:22 - agent.DQN.DQN - INFO - episode 2 step 283 reward tensor([-1]) loss 4.777176856994629 epsilon 0.79335
26-Feb-25 09:38:22 - agent.DQN.DQN - INFO - episode 2 step 284 reward tensor([-1]) loss 4.793642997741699 epsilon 0.79335
26-Feb-25 09:38:22 - agent.DQN.DQN - INFO - episode 2 step 285 reward tensor([-1]) loss 1.571799397468567 epsilon 0.79335
26-Feb-25 09:38:22 - agent.DQN.DQN - INFO - episode 2 step 286 reward tensor([-1]) loss 1.8129875659942627 epsilon 0.79335
26-Feb-25 09:38:22 - agent.DQN.DQN - INFO - episode 2 step 287 reward tensor([-1]) loss 1.9021885395050049 epsilon 0.79335
26-Feb-25 09:38:22 - agent.DQN.DQN - INFO - episode 2 step 288 reward tensor([-1]) loss 3.947256565093994 epsilon 0.79335
26-Feb-25 09:38:22 - agent.DQN.DQN - INFO - episode 2 step 289 reward tensor([-1]) loss 2.2512476444244385 epsilon 0.79335
26-Feb-25 09:38:22 - agent.DQN.DQN - INFO - episode 2 step 290 reward tensor([-1]) loss 2.135582685470581 epsilon 0.79335
26-Feb-25 09:38:22 - agent.DQN.DQN - INFO - episode 2 step 291 reward tensor([-1]) loss 1.3972769975662231 epsilon 0.79335
26-Feb-25 09:38:22 - agent.DQN.DQN - INFO - episode 2 step 292 reward tensor([-1]) loss 1.2671191692352295 epsilon 0.79335
26-Feb-25 09:38:22 - agent.DQN.DQN - INFO - episode 2 step 293 reward tensor([-1]) loss 1.3751267194747925 epsilon 0.79335
26-Feb-25 09:38:22 - agent.DQN.DQN - INFO - episode 2 step 294 reward tensor([-1]) loss 1.2652143239974976 epsilon 0.79335
26-Feb-25 09:38:22 - agent.DQN.DQN - INFO - episode 2 step 295 reward tensor([-1]) loss 2.407660961151123 epsilon 0.79335
26-Feb-25 09:38:22 - agent.DQN.DQN - INFO - episode 2 step 296 reward tensor([-1]) loss 2.11210298538208 epsilon 0.79335
26-Feb-25 09:38:22 - agent.DQN.DQN - INFO - episode 2 step 297 reward tensor([-1]) loss 1.3134008646011353 epsilon 0.79335
26-Feb-25 09:38:22 - agent.DQN.DQN - INFO - episode 2 step 298 reward tensor([-1]) loss 2.109621047973633 epsilon 0.79335
26-Feb-25 09:38:22 - agent.DQN.DQN - INFO - episode 2 step 299 reward tensor([-1]) loss 6.549763202667236 epsilon 0.79335
26-Feb-25 09:38:22 - agent.DQN.DQN - INFO - episode 2 step 300 reward tensor([-1]) loss 6.130898952484131 epsilon 0.79335
26-Feb-25 09:38:22 - agent.DQN.DQN - INFO - episode 2 step 301 reward tensor([-1]) loss 4.2938103675842285 epsilon 0.79335
26-Feb-25 09:38:22 - agent.DQN.DQN - INFO - episode 3 step 0 reward tensor([-1]) loss 6.451133728027344 epsilon 0.767566125
26-Feb-25 09:38:22 - agent.DQN.DQN - INFO - episode 3 step 1 reward tensor([-1]) loss 2.6078994274139404 epsilon 0.767566125
26-Feb-25 09:38:22 - agent.DQN.DQN - INFO - episode 3 step 2 reward tensor([-1]) loss 1.439818024635315 epsilon 0.767566125
26-Feb-25 09:38:22 - agent.DQN.DQN - INFO - episode 3 step 3 reward tensor([-1]) loss 1.8174412250518799 epsilon 0.767566125
26-Feb-25 09:38:22 - agent.DQN.DQN - INFO - episode 3 step 4 reward tensor([-1]) loss 2.230018138885498 epsilon 0.767566125
26-Feb-25 09:38:23 - agent.DQN.DQN - INFO - episode 3 step 5 reward tensor([-1]) loss 4.985079288482666 epsilon 0.767566125
26-Feb-25 09:38:23 - agent.DQN.DQN - INFO - episode 3 step 6 reward tensor([-1]) loss 6.603787422180176 epsilon 0.767566125
26-Feb-25 09:38:23 - agent.DQN.DQN - INFO - episode 3 step 7 reward tensor([-1]) loss 3.302133560180664 epsilon 0.767566125
26-Feb-25 09:38:23 - agent.DQN.DQN - INFO - episode 3 step 8 reward tensor([-1]) loss 3.625124454498291 epsilon 0.767566125
26-Feb-25 09:38:23 - agent.DQN.DQN - INFO - episode 3 step 9 reward tensor([-1]) loss 2.495220184326172 epsilon 0.767566125
26-Feb-25 09:38:23 - agent.DQN.DQN - INFO - episode 3 step 10 reward tensor([-1]) loss 42.040260314941406 epsilon 0.767566125
26-Feb-25 09:38:23 - agent.DQN.DQN - INFO - episode 3 step 11 reward tensor([-1]) loss 2.5819671154022217 epsilon 0.767566125
26-Feb-25 09:38:23 - agent.DQN.DQN - INFO - episode 3 step 12 reward tensor([-1]) loss 4.477547645568848 epsilon 0.767566125
26-Feb-25 09:38:23 - agent.DQN.DQN - INFO - episode 3 step 13 reward tensor([-1]) loss 3.561227560043335 epsilon 0.767566125
26-Feb-25 09:38:23 - agent.DQN.DQN - INFO - episode 3 step 14 reward tensor([-1]) loss 3.5866260528564453 epsilon 0.767566125
26-Feb-25 09:38:23 - agent.DQN.DQN - INFO - episode 3 step 15 reward tensor([-1]) loss 4.0250701904296875 epsilon 0.767566125
26-Feb-25 09:38:23 - agent.DQN.DQN - INFO - episode 3 step 16 reward tensor([-1]) loss 1.8594127893447876 epsilon 0.767566125
26-Feb-25 09:38:23 - agent.DQN.DQN - INFO - episode 3 step 17 reward tensor([-1]) loss 37.49601364135742 epsilon 0.767566125
26-Feb-25 09:38:23 - agent.DQN.DQN - INFO - episode 3 step 18 reward tensor([-1]) loss 37.31450653076172 epsilon 0.767566125
26-Feb-25 09:38:23 - agent.DQN.DQN - INFO - episode 3 step 19 reward tensor([-1]) loss 3.2085378170013428 epsilon 0.767566125
26-Feb-25 09:38:23 - agent.DQN.DQN - INFO - episode 3 step 20 reward tensor([-1]) loss 29.97153091430664 epsilon 0.767566125
26-Feb-25 09:38:23 - agent.DQN.DQN - INFO - episode 3 step 21 reward tensor([-1]) loss 8.691807746887207 epsilon 0.767566125
26-Feb-25 09:38:23 - agent.DQN.DQN - INFO - episode 3 step 22 reward tensor([-1]) loss 5.512547492980957 epsilon 0.767566125
26-Feb-25 09:38:23 - agent.DQN.DQN - INFO - episode 3 step 23 reward tensor([-1]) loss 4.992402076721191 epsilon 0.767566125
26-Feb-25 09:38:23 - agent.DQN.DQN - INFO - episode 3 step 24 reward tensor([-1]) loss 4.519814968109131 epsilon 0.767566125
26-Feb-25 09:38:23 - agent.DQN.DQN - INFO - episode 3 step 25 reward tensor([-1]) loss 4.200377941131592 epsilon 0.767566125
26-Feb-25 09:38:23 - agent.DQN.DQN - INFO - episode 3 step 26 reward tensor([-1]) loss 30.97012710571289 epsilon 0.767566125
26-Feb-25 09:38:23 - agent.DQN.DQN - INFO - episode 3 step 27 reward tensor([-1]) loss 4.684909820556641 epsilon 0.767566125
26-Feb-25 09:38:23 - agent.DQN.DQN - INFO - episode 3 step 28 reward tensor([-1]) loss 5.919341087341309 epsilon 0.767566125
26-Feb-25 09:38:23 - agent.DQN.DQN - INFO - episode 3 step 29 reward tensor([-1]) loss 4.039328098297119 epsilon 0.767566125
26-Feb-25 09:38:23 - agent.DQN.DQN - INFO - episode 3 step 30 reward tensor([-1]) loss 6.091309547424316 epsilon 0.767566125
26-Feb-25 09:38:23 - agent.DQN.DQN - INFO - episode 3 step 31 reward tensor([-1]) loss 33.6159782409668 epsilon 0.767566125
26-Feb-25 09:38:23 - agent.DQN.DQN - INFO - episode 3 step 32 reward tensor([-1]) loss 2.0357887744903564 epsilon 0.767566125
26-Feb-25 09:38:23 - agent.DQN.DQN - INFO - episode 3 step 33 reward tensor([-1]) loss 2.148705244064331 epsilon 0.767566125
26-Feb-25 09:38:23 - agent.DQN.DQN - INFO - episode 3 step 34 reward tensor([-1]) loss 2.3488707542419434 epsilon 0.767566125
26-Feb-25 09:38:23 - agent.DQN.DQN - INFO - episode 3 step 35 reward tensor([-1]) loss 27.242277145385742 epsilon 0.767566125
26-Feb-25 09:38:23 - agent.DQN.DQN - INFO - episode 3 step 36 reward tensor([-1]) loss 3.5978944301605225 epsilon 0.767566125
26-Feb-25 09:38:23 - agent.DQN.DQN - INFO - episode 3 step 37 reward tensor([-1]) loss 2.183873176574707 epsilon 0.767566125
26-Feb-25 09:38:23 - agent.DQN.DQN - INFO - episode 3 step 38 reward tensor([-1]) loss 4.239752769470215 epsilon 0.767566125
26-Feb-25 09:38:23 - agent.DQN.DQN - INFO - episode 3 step 39 reward tensor([-1]) loss 6.069779396057129 epsilon 0.767566125
26-Feb-25 09:38:23 - agent.DQN.DQN - INFO - episode 3 step 40 reward tensor([-1]) loss 26.47220230102539 epsilon 0.767566125
26-Feb-25 09:38:23 - agent.DQN.DQN - INFO - episode 3 step 41 reward tensor([-1]) loss 2.784931182861328 epsilon 0.767566125
26-Feb-25 09:38:23 - agent.DQN.DQN - INFO - episode 3 step 42 reward tensor([-1]) loss 2.8803350925445557 epsilon 0.767566125
26-Feb-25 09:38:23 - agent.DQN.DQN - INFO - episode 3 step 43 reward tensor([-1]) loss 2.186513662338257 epsilon 0.767566125
26-Feb-25 09:38:23 - agent.DQN.DQN - INFO - episode 3 step 44 reward tensor([-1]) loss 1.8658819198608398 epsilon 0.767566125
26-Feb-25 09:38:23 - agent.DQN.DQN - INFO - episode 3 step 45 reward tensor([-1]) loss 2.307832717895508 epsilon 0.767566125
26-Feb-25 09:38:23 - agent.DQN.DQN - INFO - episode 3 step 46 reward tensor([-1]) loss 2.0840327739715576 epsilon 0.767566125
26-Feb-25 09:38:23 - agent.DQN.DQN - INFO - episode 3 step 47 reward tensor([-1]) loss 1.8551254272460938 epsilon 0.767566125
26-Feb-25 09:38:23 - agent.DQN.DQN - INFO - episode 3 step 48 reward tensor([-1]) loss 3.7181336879730225 epsilon 0.767566125
26-Feb-25 09:38:23 - agent.DQN.DQN - INFO - episode 3 step 49 reward tensor([-1]) loss 2.657125949859619 epsilon 0.767566125
26-Feb-25 09:38:23 - agent.DQN.DQN - INFO - episode 3 step 50 reward tensor([-1]) loss 1.8740466833114624 epsilon 0.767566125
26-Feb-25 09:38:23 - agent.DQN.DQN - INFO - episode 3 step 51 reward tensor([-1]) loss 3.9436023235321045 epsilon 0.767566125
26-Feb-25 09:38:23 - agent.DQN.DQN - INFO - episode 3 step 52 reward tensor([-1]) loss 1.550652027130127 epsilon 0.767566125
26-Feb-25 09:38:23 - agent.DQN.DQN - INFO - episode 3 step 53 reward tensor([-1]) loss 1.2849889993667603 epsilon 0.767566125
26-Feb-25 09:38:23 - agent.DQN.DQN - INFO - episode 3 step 54 reward tensor([-1]) loss 1.3863328695297241 epsilon 0.767566125
26-Feb-25 09:38:23 - agent.DQN.DQN - INFO - episode 3 step 55 reward tensor([-1]) loss 2.850837230682373 epsilon 0.767566125
26-Feb-25 09:38:23 - agent.DQN.DQN - INFO - episode 3 step 56 reward tensor([-1]) loss 1.5830118656158447 epsilon 0.767566125
26-Feb-25 09:38:23 - agent.DQN.DQN - INFO - episode 3 step 57 reward tensor([-1]) loss 33.05121612548828 epsilon 0.767566125
26-Feb-25 09:38:23 - agent.DQN.DQN - INFO - episode 3 step 58 reward tensor([-1]) loss 4.089665412902832 epsilon 0.767566125
26-Feb-25 09:38:23 - agent.DQN.DQN - INFO - episode 3 step 59 reward tensor([-1]) loss 4.581298828125 epsilon 0.767566125
26-Feb-25 09:38:23 - agent.DQN.DQN - INFO - episode 3 step 60 reward tensor([-1]) loss 2.2870380878448486 epsilon 0.767566125
26-Feb-25 09:38:23 - agent.DQN.DQN - INFO - episode 3 step 61 reward tensor([-1]) loss 24.699871063232422 epsilon 0.767566125
26-Feb-25 09:38:23 - agent.DQN.DQN - INFO - episode 3 step 62 reward tensor([-1]) loss 2.688632011413574 epsilon 0.767566125
26-Feb-25 09:38:23 - agent.DQN.DQN - INFO - episode 3 step 63 reward tensor([-1]) loss 2.7788994312286377 epsilon 0.767566125
26-Feb-25 09:38:23 - agent.DQN.DQN - INFO - episode 3 step 64 reward tensor([-1]) loss 22.725486755371094 epsilon 0.767566125
26-Feb-25 09:38:23 - agent.DQN.DQN - INFO - episode 3 step 65 reward tensor([-1]) loss 5.803981781005859 epsilon 0.767566125
26-Feb-25 09:38:23 - agent.DQN.DQN - INFO - episode 3 step 66 reward tensor([-1]) loss 3.4048943519592285 epsilon 0.767566125
26-Feb-25 09:38:23 - agent.DQN.DQN - INFO - episode 3 step 67 reward tensor([-1]) loss 21.484764099121094 epsilon 0.767566125
26-Feb-25 09:38:23 - agent.DQN.DQN - INFO - episode 3 step 68 reward tensor([-1]) loss 2.9880268573760986 epsilon 0.767566125
26-Feb-25 09:38:23 - agent.DQN.DQN - INFO - episode 3 step 69 reward tensor([-1]) loss 3.699237823486328 epsilon 0.767566125
26-Feb-25 09:38:23 - agent.DQN.DQN - INFO - episode 3 step 70 reward tensor([-1]) loss 3.658879280090332 epsilon 0.767566125
26-Feb-25 09:38:23 - agent.DQN.DQN - INFO - episode 3 step 71 reward tensor([-1]) loss 1.9291921854019165 epsilon 0.767566125
26-Feb-25 09:38:23 - agent.DQN.DQN - INFO - episode 3 step 72 reward tensor([-1]) loss 1.5714750289916992 epsilon 0.767566125
26-Feb-25 09:38:24 - agent.DQN.DQN - INFO - episode 3 step 73 reward tensor([-1]) loss 1.4373340606689453 epsilon 0.767566125
26-Feb-25 09:38:24 - agent.DQN.DQN - INFO - episode 3 step 74 reward tensor([-1]) loss 26.148548126220703 epsilon 0.767566125
26-Feb-25 09:38:24 - agent.DQN.DQN - INFO - episode 3 step 75 reward tensor([-1]) loss 24.524402618408203 epsilon 0.767566125
26-Feb-25 09:38:24 - agent.DQN.DQN - INFO - episode 3 step 76 reward tensor([-1]) loss 1.9863654375076294 epsilon 0.767566125
26-Feb-25 09:38:24 - agent.DQN.DQN - INFO - episode 3 step 77 reward tensor([-1]) loss 1.3168823719024658 epsilon 0.767566125
26-Feb-25 09:38:24 - agent.DQN.DQN - INFO - episode 3 step 78 reward tensor([-1]) loss 2.1020126342773438 epsilon 0.767566125
26-Feb-25 09:38:24 - agent.DQN.DQN - INFO - episode 3 step 79 reward tensor([-1]) loss 1.8975787162780762 epsilon 0.767566125
26-Feb-25 09:38:24 - agent.DQN.DQN - INFO - episode 3 step 80 reward tensor([-1]) loss 2.4430699348449707 epsilon 0.767566125
26-Feb-25 09:38:24 - agent.DQN.DQN - INFO - episode 3 step 81 reward tensor([-1]) loss 22.83348846435547 epsilon 0.767566125
26-Feb-25 09:38:24 - agent.DQN.DQN - INFO - episode 3 step 82 reward tensor([-1]) loss 21.954404830932617 epsilon 0.767566125
26-Feb-25 09:38:24 - agent.DQN.DQN - INFO - episode 3 step 83 reward tensor([-1]) loss 2.5717902183532715 epsilon 0.767566125
26-Feb-25 09:38:24 - agent.DQN.DQN - INFO - episode 3 step 84 reward tensor([-1]) loss 21.207311630249023 epsilon 0.767566125
26-Feb-25 09:38:24 - agent.DQN.DQN - INFO - episode 3 step 85 reward tensor([-1]) loss 0.9284399747848511 epsilon 0.767566125
26-Feb-25 09:38:24 - agent.DQN.DQN - INFO - episode 3 step 86 reward tensor([-1]) loss 20.09295082092285 epsilon 0.767566125
26-Feb-25 09:38:24 - agent.DQN.DQN - INFO - episode 3 step 87 reward tensor([-1]) loss 20.204790115356445 epsilon 0.767566125
26-Feb-25 09:38:24 - agent.DQN.DQN - INFO - episode 3 step 88 reward tensor([-1]) loss 4.438203811645508 epsilon 0.767566125
26-Feb-25 09:38:24 - agent.DQN.DQN - INFO - episode 3 step 89 reward tensor([-1]) loss 3.719905376434326 epsilon 0.767566125
26-Feb-25 09:38:24 - agent.DQN.DQN - INFO - episode 3 step 90 reward tensor([-1]) loss 6.535050392150879 epsilon 0.767566125
26-Feb-25 09:38:24 - agent.DQN.DQN - INFO - episode 3 step 91 reward tensor([-1]) loss 7.621674537658691 epsilon 0.767566125
26-Feb-25 09:38:24 - agent.DQN.DQN - INFO - episode 3 step 92 reward tensor([-1]) loss 2.117650032043457 epsilon 0.767566125
26-Feb-25 09:38:24 - agent.DQN.DQN - INFO - episode 3 step 93 reward tensor([-1]) loss 3.6108779907226562 epsilon 0.767566125
26-Feb-25 09:38:24 - agent.DQN.DQN - INFO - episode 3 step 94 reward tensor([-1]) loss 1.3525274991989136 epsilon 0.767566125
26-Feb-25 09:38:24 - agent.DQN.DQN - INFO - episode 3 step 95 reward tensor([-1]) loss 2.4286677837371826 epsilon 0.767566125
26-Feb-25 09:38:24 - agent.DQN.DQN - INFO - episode 3 step 96 reward tensor([-1]) loss 2.739821195602417 epsilon 0.767566125
26-Feb-25 09:38:24 - agent.DQN.DQN - INFO - episode 3 step 97 reward tensor([-1]) loss 22.244979858398438 epsilon 0.767566125
26-Feb-25 09:38:24 - agent.DQN.DQN - INFO - episode 3 step 98 reward tensor([-1]) loss 21.619192123413086 epsilon 0.767566125
26-Feb-25 09:38:24 - agent.DQN.DQN - INFO - episode 3 step 99 reward tensor([-1]) loss 2.610358476638794 epsilon 0.767566125
26-Feb-25 09:38:24 - agent.DQN.DQN - INFO - episode 3 step 100 reward tensor([-1]) loss 2.590334177017212 epsilon 0.767566125
26-Feb-25 09:38:24 - agent.DQN.DQN - INFO - episode 3 step 101 reward tensor([-1]) loss 5.189433574676514 epsilon 0.767566125
26-Feb-25 09:38:24 - agent.DQN.DQN - INFO - episode 3 step 102 reward tensor([-1]) loss 2.6229236125946045 epsilon 0.767566125
26-Feb-25 09:38:24 - agent.DQN.DQN - INFO - episode 3 step 103 reward tensor([-1]) loss 1.992068886756897 epsilon 0.767566125
26-Feb-25 09:38:24 - agent.DQN.DQN - INFO - episode 3 step 104 reward tensor([-1]) loss 20.619609832763672 epsilon 0.767566125
26-Feb-25 09:38:24 - agent.DQN.DQN - INFO - episode 3 step 105 reward tensor([-1]) loss 19.421621322631836 epsilon 0.767566125
26-Feb-25 09:38:24 - agent.DQN.DQN - INFO - episode 3 step 106 reward tensor([-1]) loss 3.4558796882629395 epsilon 0.767566125
26-Feb-25 09:38:24 - agent.DQN.DQN - INFO - episode 3 step 107 reward tensor([-1]) loss 18.66534996032715 epsilon 0.767566125
26-Feb-25 09:38:24 - agent.DQN.DQN - INFO - episode 3 step 108 reward tensor([-1]) loss 19.35346221923828 epsilon 0.767566125
26-Feb-25 09:38:24 - agent.DQN.DQN - INFO - episode 3 step 109 reward tensor([-1]) loss 2.649946689605713 epsilon 0.767566125
26-Feb-25 09:38:24 - agent.DQN.DQN - INFO - episode 3 step 110 reward tensor([-1]) loss 3.489398956298828 epsilon 0.767566125
26-Feb-25 09:38:24 - agent.DQN.DQN - INFO - episode 3 step 111 reward tensor([-1]) loss 3.9668774604797363 epsilon 0.767566125
26-Feb-25 09:38:24 - agent.DQN.DQN - INFO - episode 3 step 112 reward tensor([-1]) loss 2.784285306930542 epsilon 0.767566125
26-Feb-25 09:38:24 - agent.DQN.DQN - INFO - episode 3 step 113 reward tensor([-1]) loss 0.9341787695884705 epsilon 0.767566125
26-Feb-25 09:38:24 - agent.DQN.DQN - INFO - episode 3 step 114 reward tensor([-1]) loss 18.96717071533203 epsilon 0.767566125
26-Feb-25 09:38:24 - agent.DQN.DQN - INFO - episode 3 step 115 reward tensor([-1]) loss 1.625741720199585 epsilon 0.767566125
26-Feb-25 09:38:24 - agent.DQN.DQN - INFO - episode 3 step 116 reward tensor([-1]) loss 2.065690755844116 epsilon 0.767566125
26-Feb-25 09:38:24 - agent.DQN.DQN - INFO - episode 3 step 117 reward tensor([-1]) loss 4.273936748504639 epsilon 0.767566125
26-Feb-25 09:38:24 - agent.DQN.DQN - INFO - episode 3 step 118 reward tensor([-1]) loss 2.8865509033203125 epsilon 0.767566125
26-Feb-25 09:38:24 - agent.DQN.DQN - INFO - episode 3 step 119 reward tensor([-1]) loss 2.202683448791504 epsilon 0.767566125
26-Feb-25 09:38:24 - agent.DQN.DQN - INFO - episode 3 step 120 reward tensor([-1]) loss 19.985057830810547 epsilon 0.767566125
26-Feb-25 09:38:24 - agent.DQN.DQN - INFO - episode 3 step 121 reward tensor([-1]) loss 1.95436692237854 epsilon 0.767566125
26-Feb-25 09:38:24 - agent.DQN.DQN - INFO - episode 3 step 122 reward tensor([-1]) loss 1.674730658531189 epsilon 0.767566125
26-Feb-25 09:38:24 - agent.DQN.DQN - INFO - episode 3 step 123 reward tensor([-1]) loss 1.3588405847549438 epsilon 0.767566125
26-Feb-25 09:38:24 - agent.DQN.DQN - INFO - episode 3 step 124 reward tensor([-1]) loss 1.06985604763031 epsilon 0.767566125
26-Feb-25 09:38:24 - agent.DQN.DQN - INFO - episode 3 step 125 reward tensor([-1]) loss 2.2641429901123047 epsilon 0.767566125
26-Feb-25 09:38:24 - agent.DQN.DQN - INFO - episode 3 step 126 reward tensor([-1]) loss 2.0214195251464844 epsilon 0.767566125
26-Feb-25 09:38:24 - agent.DQN.DQN - INFO - episode 3 step 127 reward tensor([-1]) loss 1.8240718841552734 epsilon 0.767566125
26-Feb-25 09:38:24 - agent.DQN.DQN - INFO - episode 3 step 128 reward tensor([-1]) loss 1.5885179042816162 epsilon 0.767566125
26-Feb-25 09:38:24 - agent.DQN.DQN - INFO - episode 3 step 129 reward tensor([-1]) loss 1.1812117099761963 epsilon 0.767566125
26-Feb-25 09:38:24 - agent.DQN.DQN - INFO - episode 3 step 130 reward tensor([-1]) loss 1.1807279586791992 epsilon 0.767566125
26-Feb-25 09:38:24 - agent.DQN.DQN - INFO - episode 3 step 131 reward tensor([-1]) loss 17.63852310180664 epsilon 0.767566125
26-Feb-25 09:38:24 - agent.DQN.DQN - INFO - episode 3 step 132 reward tensor([-1]) loss 1.608744502067566 epsilon 0.767566125
26-Feb-25 09:38:24 - agent.DQN.DQN - INFO - episode 3 step 133 reward tensor([-1]) loss 1.779725193977356 epsilon 0.767566125
26-Feb-25 09:38:24 - agent.DQN.DQN - INFO - episode 3 step 134 reward tensor([-1]) loss 16.779617309570312 epsilon 0.767566125
26-Feb-25 09:38:24 - agent.DQN.DQN - INFO - episode 3 step 135 reward tensor([-1]) loss 1.2316020727157593 epsilon 0.767566125
26-Feb-25 09:38:24 - agent.DQN.DQN - INFO - episode 3 step 136 reward tensor([-1]) loss 15.95934772491455 epsilon 0.767566125
26-Feb-25 09:38:24 - agent.DQN.DQN - INFO - episode 3 step 137 reward tensor([-1]) loss 2.2573328018188477 epsilon 0.767566125
26-Feb-25 09:38:24 - agent.DQN.DQN - INFO - episode 3 step 138 reward tensor([-1]) loss 1.9163874387741089 epsilon 0.767566125
26-Feb-25 09:38:24 - agent.DQN.DQN - INFO - episode 3 step 139 reward tensor([-1]) loss 2.279266834259033 epsilon 0.767566125
26-Feb-25 09:38:24 - agent.DQN.DQN - INFO - episode 3 step 140 reward tensor([-1]) loss 1.618964433670044 epsilon 0.767566125
26-Feb-25 09:38:24 - agent.DQN.DQN - INFO - episode 3 step 141 reward tensor([-1]) loss 16.122167587280273 epsilon 0.767566125
26-Feb-25 09:38:24 - agent.DQN.DQN - INFO - episode 3 step 142 reward tensor([-1]) loss 0.8280593752861023 epsilon 0.767566125
26-Feb-25 09:38:24 - agent.DQN.DQN - INFO - episode 3 step 143 reward tensor([-1]) loss 1.1827024221420288 epsilon 0.767566125
26-Feb-25 09:38:24 - agent.DQN.DQN - INFO - episode 3 step 144 reward tensor([-1]) loss 1.0254628658294678 epsilon 0.767566125
26-Feb-25 09:38:24 - agent.DQN.DQN - INFO - episode 3 step 145 reward tensor([-1]) loss 1.5339548587799072 epsilon 0.767566125
26-Feb-25 09:38:25 - agent.DQN.DQN - INFO - episode 3 step 146 reward tensor([-1]) loss 17.068634033203125 epsilon 0.767566125
26-Feb-25 09:38:25 - agent.DQN.DQN - INFO - episode 3 step 147 reward tensor([-1]) loss 3.141195297241211 epsilon 0.767566125
26-Feb-25 09:38:25 - agent.DQN.DQN - INFO - episode 3 step 148 reward tensor([-1]) loss 3.1247639656066895 epsilon 0.767566125
26-Feb-25 09:38:25 - agent.DQN.DQN - INFO - episode 3 step 149 reward tensor([-1]) loss 2.484684467315674 epsilon 0.767566125
26-Feb-25 09:38:25 - agent.DQN.DQN - INFO - episode 3 step 150 reward tensor([-1]) loss 1.6966969966888428 epsilon 0.767566125
26-Feb-25 09:38:25 - agent.DQN.DQN - INFO - episode 3 step 151 reward tensor([-1]) loss 2.026865005493164 epsilon 0.767566125
26-Feb-25 09:38:25 - agent.DQN.DQN - INFO - episode 3 step 152 reward tensor([-1]) loss 13.870948791503906 epsilon 0.767566125
26-Feb-25 09:38:25 - agent.DQN.DQN - INFO - episode 3 step 153 reward tensor([-1]) loss 1.5708764791488647 epsilon 0.767566125
26-Feb-25 09:38:25 - agent.DQN.DQN - INFO - episode 3 step 154 reward tensor([-1]) loss 13.28771686553955 epsilon 0.767566125
26-Feb-25 09:38:25 - agent.DQN.DQN - INFO - episode 3 step 155 reward tensor([-1]) loss 1.7326775789260864 epsilon 0.767566125
26-Feb-25 09:38:25 - agent.DQN.DQN - INFO - episode 3 step 156 reward tensor([-1]) loss 2.80733585357666 epsilon 0.767566125
26-Feb-25 09:38:25 - agent.DQN.DQN - INFO - episode 3 step 157 reward tensor([-1]) loss 1.3523286581039429 epsilon 0.767566125
26-Feb-25 09:38:25 - agent.DQN.DQN - INFO - episode 3 step 158 reward tensor([-1]) loss 2.0208377838134766 epsilon 0.767566125
26-Feb-25 09:38:25 - agent.DQN.DQN - INFO - episode 3 step 159 reward tensor([-1]) loss 5.7545318603515625 epsilon 0.767566125
26-Feb-25 09:38:25 - agent.DQN.DQN - INFO - episode 3 step 160 reward tensor([-1]) loss 11.949155807495117 epsilon 0.767566125
26-Feb-25 09:38:25 - agent.DQN.DQN - INFO - episode 3 step 161 reward tensor([-1]) loss 1.6864986419677734 epsilon 0.767566125
26-Feb-25 09:38:25 - agent.DQN.DQN - INFO - episode 3 step 162 reward tensor([-1]) loss 3.1814327239990234 epsilon 0.767566125
26-Feb-25 09:38:25 - agent.DQN.DQN - INFO - episode 3 step 163 reward tensor([-1]) loss 1.8812845945358276 epsilon 0.767566125
26-Feb-25 09:38:25 - agent.DQN.DQN - INFO - episode 3 step 164 reward tensor([-1]) loss 1.5546605587005615 epsilon 0.767566125
26-Feb-25 09:38:25 - agent.DQN.DQN - INFO - episode 3 step 165 reward tensor([-1]) loss 1.0501525402069092 epsilon 0.767566125
26-Feb-25 09:38:25 - agent.DQN.DQN - INFO - episode 3 step 166 reward tensor([-1]) loss 1.2586899995803833 epsilon 0.767566125
26-Feb-25 09:38:25 - agent.DQN.DQN - INFO - episode 3 step 167 reward tensor([-1]) loss 0.7751522064208984 epsilon 0.767566125
26-Feb-25 09:38:25 - agent.DQN.DQN - INFO - episode 3 step 168 reward tensor([-1]) loss 15.783705711364746 epsilon 0.767566125
26-Feb-25 09:38:25 - agent.DQN.DQN - INFO - episode 3 step 169 reward tensor([-1]) loss 0.9467019438743591 epsilon 0.767566125
26-Feb-25 09:38:25 - agent.DQN.DQN - INFO - episode 3 step 170 reward tensor([-1]) loss 1.0713258981704712 epsilon 0.767566125
26-Feb-25 09:38:25 - agent.DQN.DQN - INFO - episode 3 step 171 reward tensor([-1]) loss 0.7456051111221313 epsilon 0.767566125
26-Feb-25 09:38:25 - agent.DQN.DQN - INFO - episode 3 step 172 reward tensor([-1]) loss 1.1815340518951416 epsilon 0.767566125
26-Feb-25 09:38:25 - agent.DQN.DQN - INFO - episode 3 step 173 reward tensor([-1]) loss 14.513644218444824 epsilon 0.767566125
26-Feb-25 09:38:25 - agent.DQN.DQN - INFO - episode 3 step 174 reward tensor([-1]) loss 1.6274936199188232 epsilon 0.767566125
26-Feb-25 09:38:25 - agent.DQN.DQN - INFO - episode 3 step 175 reward tensor([-1]) loss 1.1176602840423584 epsilon 0.767566125
26-Feb-25 09:38:25 - agent.DQN.DQN - INFO - episode 3 step 176 reward tensor([-1]) loss 1.0120983123779297 epsilon 0.767566125
26-Feb-25 09:38:25 - agent.DQN.DQN - INFO - episode 3 step 177 reward tensor([-1]) loss 14.77477741241455 epsilon 0.767566125
26-Feb-25 09:38:25 - agent.DQN.DQN - INFO - episode 3 step 178 reward tensor([-1]) loss 2.506443738937378 epsilon 0.767566125
26-Feb-25 09:38:25 - agent.DQN.DQN - INFO - episode 3 step 179 reward tensor([-1]) loss 2.2612109184265137 epsilon 0.767566125
26-Feb-25 09:38:25 - agent.DQN.DQN - INFO - episode 3 step 180 reward tensor([-1]) loss 12.375802040100098 epsilon 0.767566125
26-Feb-25 09:38:25 - agent.DQN.DQN - INFO - episode 3 step 181 reward tensor([-1]) loss 2.034543991088867 epsilon 0.767566125
26-Feb-25 09:38:25 - agent.DQN.DQN - INFO - episode 3 step 182 reward tensor([-1]) loss 1.893179178237915 epsilon 0.767566125
26-Feb-25 09:38:25 - agent.DQN.DQN - INFO - episode 3 step 183 reward tensor([-1]) loss 1.7237814664840698 epsilon 0.767566125
26-Feb-25 09:38:25 - agent.DQN.DQN - INFO - episode 3 step 184 reward tensor([-1]) loss 2.9822700023651123 epsilon 0.767566125
26-Feb-25 09:38:25 - agent.DQN.DQN - INFO - episode 3 step 185 reward tensor([-1]) loss 0.8410118222236633 epsilon 0.767566125
26-Feb-25 09:38:25 - agent.DQN.DQN - INFO - episode 3 step 186 reward tensor([-1]) loss 10.569499015808105 epsilon 0.767566125
26-Feb-25 09:38:25 - agent.DQN.DQN - INFO - episode 3 step 187 reward tensor([-1]) loss 1.6023929119110107 epsilon 0.767566125
26-Feb-25 09:38:25 - agent.DQN.DQN - INFO - episode 3 step 188 reward tensor([-1]) loss 1.782633900642395 epsilon 0.767566125
26-Feb-25 09:38:25 - agent.DQN.DQN - INFO - episode 3 step 189 reward tensor([-1]) loss 1.9888041019439697 epsilon 0.767566125
26-Feb-25 09:38:25 - agent.DQN.DQN - INFO - episode 3 step 190 reward tensor([-1]) loss 1.698533296585083 epsilon 0.767566125
26-Feb-25 09:38:25 - agent.DQN.DQN - INFO - episode 3 step 191 reward tensor([-1]) loss 1.5763086080551147 epsilon 0.767566125
26-Feb-25 09:38:25 - agent.DQN.DQN - INFO - episode 3 step 192 reward tensor([-1]) loss 1.187512993812561 epsilon 0.767566125
26-Feb-25 09:38:25 - agent.DQN.DQN - INFO - episode 3 step 193 reward tensor([-1]) loss 1.7239171266555786 epsilon 0.767566125
26-Feb-25 09:38:25 - agent.DQN.DQN - INFO - episode 3 step 194 reward tensor([-1]) loss 1.197373867034912 epsilon 0.767566125
26-Feb-25 09:38:25 - agent.DQN.DQN - INFO - episode 3 step 195 reward tensor([-1]) loss 12.261908531188965 epsilon 0.767566125
26-Feb-25 09:38:25 - agent.DQN.DQN - INFO - episode 3 step 196 reward tensor([-1]) loss 1.408029317855835 epsilon 0.767566125
26-Feb-25 09:38:25 - agent.DQN.DQN - INFO - episode 3 step 197 reward tensor([-1]) loss 0.6695223450660706 epsilon 0.767566125
26-Feb-25 09:38:25 - agent.DQN.DQN - INFO - episode 3 step 198 reward tensor([-1]) loss 0.9599448442459106 epsilon 0.767566125
26-Feb-25 09:38:25 - agent.DQN.DQN - INFO - episode 3 step 199 reward tensor([-1]) loss 0.8030558228492737 epsilon 0.767566125
26-Feb-25 09:38:25 - agent.DQN.DQN - INFO - episode 3 step 200 reward tensor([-1]) loss 11.961997985839844 epsilon 0.767566125
26-Feb-25 09:38:25 - agent.DQN.DQN - INFO - episode 3 step 201 reward tensor([-1]) loss 1.0503325462341309 epsilon 0.767566125
26-Feb-25 09:38:25 - agent.DQN.DQN - INFO - episode 3 step 202 reward tensor([-1]) loss 1.6893465518951416 epsilon 0.767566125
26-Feb-25 09:38:25 - agent.DQN.DQN - INFO - episode 3 step 203 reward tensor([-1]) loss 1.2082805633544922 epsilon 0.767566125
26-Feb-25 09:38:25 - agent.DQN.DQN - INFO - episode 3 step 204 reward tensor([-1]) loss 1.1557769775390625 epsilon 0.767566125
26-Feb-25 09:38:25 - agent.DQN.DQN - INFO - episode 3 step 205 reward tensor([-1]) loss 0.9218013286590576 epsilon 0.767566125
26-Feb-25 09:38:25 - agent.DQN.DQN - INFO - episode 3 step 206 reward tensor([-1]) loss 1.350892424583435 epsilon 0.767566125
26-Feb-25 09:38:25 - agent.DQN.DQN - INFO - episode 3 step 207 reward tensor([-1]) loss 2.6892201900482178 epsilon 0.767566125
26-Feb-25 09:38:25 - agent.DQN.DQN - INFO - episode 3 step 208 reward tensor([-1]) loss 2.9037375450134277 epsilon 0.767566125
26-Feb-25 09:38:25 - agent.DQN.DQN - INFO - episode 3 step 209 reward tensor([-1]) loss 15.75561809539795 epsilon 0.767566125
26-Feb-25 09:38:25 - agent.DQN.DQN - INFO - episode 3 step 210 reward tensor([-1]) loss 1.3654513359069824 epsilon 0.767566125
26-Feb-25 09:38:25 - agent.DQN.DQN - INFO - episode 3 step 211 reward tensor([-1]) loss 1.2368261814117432 epsilon 0.767566125
26-Feb-25 09:38:25 - agent.DQN.DQN - INFO - episode 3 step 212 reward tensor([-1]) loss 1.3981175422668457 epsilon 0.767566125
26-Feb-25 09:38:25 - agent.DQN.DQN - INFO - episode 3 step 213 reward tensor([-1]) loss 0.634508490562439 epsilon 0.767566125
26-Feb-25 09:38:25 - agent.DQN.DQN - INFO - episode 3 step 214 reward tensor([-1]) loss 0.9013379812240601 epsilon 0.767566125
26-Feb-25 09:38:25 - agent.DQN.DQN - INFO - episode 3 step 215 reward tensor([-1]) loss 1.0818599462509155 epsilon 0.767566125
26-Feb-25 09:38:26 - agent.DQN.DQN - INFO - episode 3 step 216 reward tensor([-1]) loss 10.35361385345459 epsilon 0.767566125
26-Feb-25 09:38:26 - agent.DQN.DQN - INFO - episode 3 step 217 reward tensor([-1]) loss 1.6240054368972778 epsilon 0.767566125
26-Feb-25 09:38:26 - agent.DQN.DQN - INFO - episode 3 step 218 reward tensor([-1]) loss 2.4268171787261963 epsilon 0.767566125
26-Feb-25 09:38:26 - agent.DQN.DQN - INFO - episode 3 step 219 reward tensor([-1]) loss 1.4214930534362793 epsilon 0.767566125
26-Feb-25 09:38:26 - agent.DQN.DQN - INFO - episode 3 step 220 reward tensor([-1]) loss 1.6767988204956055 epsilon 0.767566125
26-Feb-25 09:38:26 - agent.DQN.DQN - INFO - episode 3 step 221 reward tensor([-1]) loss 2.2690160274505615 epsilon 0.767566125
26-Feb-25 09:38:26 - agent.DQN.DQN - INFO - episode 3 step 222 reward tensor([-1]) loss 1.003783106803894 epsilon 0.767566125
26-Feb-25 09:38:26 - agent.DQN.DQN - INFO - episode 3 step 223 reward tensor([-1]) loss 1.547938346862793 epsilon 0.767566125
26-Feb-25 09:38:26 - agent.DQN.DQN - INFO - episode 3 step 224 reward tensor([-1]) loss 0.8766669034957886 epsilon 0.767566125
26-Feb-25 09:38:26 - agent.DQN.DQN - INFO - episode 3 step 225 reward tensor([-1]) loss 1.2967636585235596 epsilon 0.767566125
26-Feb-25 09:38:26 - agent.DQN.DQN - INFO - episode 3 step 226 reward tensor([-1]) loss 1.1819064617156982 epsilon 0.767566125
26-Feb-25 09:38:26 - agent.DQN.DQN - INFO - episode 3 step 227 reward tensor([-1]) loss 1.2030234336853027 epsilon 0.767566125
26-Feb-25 09:38:26 - agent.DQN.DQN - INFO - episode 3 step 228 reward tensor([-1]) loss 0.8721766471862793 epsilon 0.767566125
26-Feb-25 09:38:26 - agent.DQN.DQN - INFO - episode 3 step 229 reward tensor([-1]) loss 1.031930685043335 epsilon 0.767566125
26-Feb-25 09:38:26 - agent.DQN.DQN - INFO - episode 3 step 230 reward tensor([-1]) loss 13.080432891845703 epsilon 0.767566125
26-Feb-25 09:38:26 - agent.DQN.DQN - INFO - episode 3 step 231 reward tensor([-1]) loss 12.382516860961914 epsilon 0.767566125
26-Feb-25 09:38:26 - agent.DQN.DQN - INFO - episode 3 step 232 reward tensor([-1]) loss 0.8918521404266357 epsilon 0.767566125
26-Feb-25 09:38:26 - agent.DQN.DQN - INFO - episode 3 step 233 reward tensor([-1]) loss 1.468762755393982 epsilon 0.767566125
26-Feb-25 09:38:26 - agent.DQN.DQN - INFO - episode 3 step 234 reward tensor([-1]) loss 0.5995832085609436 epsilon 0.767566125
26-Feb-25 09:38:26 - agent.DQN.DQN - INFO - episode 3 step 235 reward tensor([-1]) loss 1.7738418579101562 epsilon 0.767566125
26-Feb-25 09:38:26 - agent.DQN.DQN - INFO - episode 3 step 236 reward tensor([-1]) loss 1.515082836151123 epsilon 0.767566125
26-Feb-25 09:38:26 - agent.DQN.DQN - INFO - episode 3 step 237 reward tensor([-1]) loss 2.627048969268799 epsilon 0.767566125
26-Feb-25 09:38:26 - agent.DQN.DQN - INFO - episode 3 step 238 reward tensor([-1]) loss 2.3230197429656982 epsilon 0.767566125
26-Feb-25 09:38:26 - agent.DQN.DQN - INFO - episode 3 step 239 reward tensor([-1]) loss 1.9333335161209106 epsilon 0.767566125
26-Feb-25 09:38:26 - agent.DQN.DQN - INFO - episode 3 step 240 reward tensor([-1]) loss 1.241553544998169 epsilon 0.767566125
26-Feb-25 09:38:26 - agent.DQN.DQN - INFO - episode 3 step 241 reward tensor([-1]) loss 1.2071301937103271 epsilon 0.767566125
26-Feb-25 09:38:26 - agent.DQN.DQN - INFO - episode 3 step 242 reward tensor([-1]) loss 0.9242501854896545 epsilon 0.767566125
26-Feb-25 09:38:26 - agent.DQN.DQN - INFO - episode 3 step 243 reward tensor([-1]) loss 1.2181737422943115 epsilon 0.767566125
26-Feb-25 09:38:26 - agent.DQN.DQN - INFO - episode 3 step 244 reward tensor([-1]) loss 1.226564884185791 epsilon 0.767566125
26-Feb-25 09:38:26 - agent.DQN.DQN - INFO - episode 3 step 245 reward tensor([-1]) loss 0.9493718147277832 epsilon 0.767566125
26-Feb-25 09:38:26 - agent.DQN.DQN - INFO - episode 3 step 246 reward tensor([-1]) loss 0.8471256494522095 epsilon 0.767566125
26-Feb-25 09:38:26 - agent.DQN.DQN - INFO - episode 3 step 247 reward tensor([-1]) loss 1.4240140914916992 epsilon 0.767566125
26-Feb-25 09:38:26 - agent.DQN.DQN - INFO - episode 3 step 248 reward tensor([-1]) loss 10.374967575073242 epsilon 0.767566125
26-Feb-25 09:38:26 - agent.DQN.DQN - INFO - episode 3 step 249 reward tensor([-1]) loss 1.2594844102859497 epsilon 0.767566125
26-Feb-25 09:38:26 - agent.DQN.DQN - INFO - episode 3 step 250 reward tensor([-1]) loss 9.324301719665527 epsilon 0.767566125
26-Feb-25 09:38:26 - agent.DQN.DQN - INFO - episode 3 step 251 reward tensor([-1]) loss 1.0792710781097412 epsilon 0.767566125
26-Feb-25 09:38:26 - agent.DQN.DQN - INFO - episode 3 step 252 reward tensor([-1]) loss 1.2609609365463257 epsilon 0.767566125
26-Feb-25 09:38:26 - agent.DQN.DQN - INFO - episode 3 step 253 reward tensor([-1]) loss 1.8644403219223022 epsilon 0.767566125
26-Feb-25 09:38:26 - agent.DQN.DQN - INFO - episode 3 step 254 reward tensor([-1]) loss 1.1033344268798828 epsilon 0.767566125
26-Feb-25 09:38:26 - agent.DQN.DQN - INFO - episode 3 step 255 reward tensor([-1]) loss 1.202039361000061 epsilon 0.767566125
26-Feb-25 09:38:26 - agent.DQN.DQN - INFO - episode 3 step 256 reward tensor([-1]) loss 1.3050308227539062 epsilon 0.767566125
26-Feb-25 09:38:26 - agent.DQN.DQN - INFO - episode 3 step 257 reward tensor([-1]) loss 1.0333212614059448 epsilon 0.767566125
26-Feb-25 09:38:26 - agent.DQN.DQN - INFO - episode 3 step 258 reward tensor([-1]) loss 8.148029327392578 epsilon 0.767566125
26-Feb-25 09:38:26 - agent.DQN.DQN - INFO - episode 3 step 259 reward tensor([-1]) loss 0.8184174299240112 epsilon 0.767566125
26-Feb-25 09:38:26 - agent.DQN.DQN - INFO - episode 3 step 260 reward tensor([-1]) loss 1.2785813808441162 epsilon 0.767566125
26-Feb-25 09:38:26 - agent.DQN.DQN - INFO - episode 3 step 261 reward tensor([-1]) loss 1.8310942649841309 epsilon 0.767566125
26-Feb-25 09:38:26 - agent.DQN.DQN - INFO - episode 3 step 262 reward tensor([-1]) loss 0.9871208071708679 epsilon 0.767566125
26-Feb-25 09:38:26 - agent.DQN.DQN - INFO - episode 3 step 263 reward tensor([-1]) loss 0.6375272870063782 epsilon 0.767566125
26-Feb-25 09:38:26 - agent.DQN.DQN - INFO - episode 3 step 264 reward tensor([-1]) loss 1.174270510673523 epsilon 0.767566125
26-Feb-25 09:38:26 - agent.DQN.DQN - INFO - episode 3 step 265 reward tensor([-1]) loss 1.3336544036865234 epsilon 0.767566125
26-Feb-25 09:38:26 - agent.DQN.DQN - INFO - episode 3 step 266 reward tensor([-1]) loss 9.786872863769531 epsilon 0.767566125
26-Feb-25 09:38:26 - agent.DQN.DQN - INFO - episode 3 step 267 reward tensor([-1]) loss 2.1286869049072266 epsilon 0.767566125
26-Feb-25 09:38:26 - agent.DQN.DQN - INFO - episode 3 step 268 reward tensor([-1]) loss 1.571374773979187 epsilon 0.767566125
26-Feb-25 09:38:26 - agent.DQN.DQN - INFO - episode 3 step 269 reward tensor([-1]) loss 1.4523884057998657 epsilon 0.767566125
26-Feb-25 09:38:26 - agent.DQN.DQN - INFO - episode 3 step 270 reward tensor([-1]) loss 1.6279741525650024 epsilon 0.767566125
26-Feb-25 09:38:26 - agent.DQN.DQN - INFO - episode 3 step 271 reward tensor([-1]) loss 1.1873390674591064 epsilon 0.767566125
26-Feb-25 09:38:26 - agent.DQN.DQN - INFO - episode 3 step 272 reward tensor([-1]) loss 1.1367406845092773 epsilon 0.767566125
26-Feb-25 09:38:26 - agent.DQN.DQN - INFO - episode 3 step 273 reward tensor([-1]) loss 1.528369665145874 epsilon 0.767566125
26-Feb-25 09:38:26 - agent.DQN.DQN - INFO - episode 3 step 274 reward tensor([-1]) loss 1.0021761655807495 epsilon 0.767566125
26-Feb-25 09:38:26 - agent.DQN.DQN - INFO - episode 3 step 275 reward tensor([-1]) loss 0.8507170081138611 epsilon 0.767566125
26-Feb-25 09:38:26 - agent.DQN.DQN - INFO - episode 3 step 276 reward tensor([-1]) loss 1.2606713771820068 epsilon 0.767566125
26-Feb-25 09:38:26 - agent.DQN.DQN - INFO - episode 3 step 277 reward tensor([-1]) loss 7.258161544799805 epsilon 0.767566125
26-Feb-25 09:38:26 - agent.DQN.DQN - INFO - episode 3 step 278 reward tensor([-1]) loss 0.8578370213508606 epsilon 0.767566125
26-Feb-25 09:38:26 - agent.DQN.DQN - INFO - episode 3 step 279 reward tensor([-1]) loss 1.458277702331543 epsilon 0.767566125
26-Feb-25 09:38:26 - agent.DQN.DQN - INFO - episode 3 step 280 reward tensor([-1]) loss 1.1948868036270142 epsilon 0.767566125
26-Feb-25 09:38:26 - agent.DQN.DQN - INFO - episode 3 step 281 reward tensor([-1]) loss 1.1013391017913818 epsilon 0.767566125
26-Feb-25 09:38:26 - agent.DQN.DQN - INFO - episode 3 step 282 reward tensor([-1]) loss 1.3566652536392212 epsilon 0.767566125
26-Feb-25 09:38:26 - agent.DQN.DQN - INFO - episode 3 step 283 reward tensor([-1]) loss 0.9749849438667297 epsilon 0.767566125
26-Feb-25 09:38:26 - agent.DQN.DQN - INFO - episode 3 step 284 reward tensor([-1]) loss 1.3375523090362549 epsilon 0.767566125
26-Feb-25 09:38:26 - agent.DQN.DQN - INFO - episode 3 step 285 reward tensor([-1]) loss 1.202682375907898 epsilon 0.767566125
26-Feb-25 09:38:26 - agent.DQN.DQN - INFO - episode 3 step 286 reward tensor([-1]) loss 0.6720923185348511 epsilon 0.767566125
26-Feb-25 09:38:26 - agent.DQN.DQN - INFO - episode 3 step 287 reward tensor([-1]) loss 0.8933146595954895 epsilon 0.767566125
26-Feb-25 09:38:26 - agent.DQN.DQN - INFO - episode 3 step 288 reward tensor([-1]) loss 1.2428902387619019 epsilon 0.767566125
26-Feb-25 09:38:26 - agent.DQN.DQN - INFO - episode 3 step 289 reward tensor([-1]) loss 1.1680090427398682 epsilon 0.767566125
26-Feb-25 09:38:27 - agent.DQN.DQN - INFO - episode 3 step 290 reward tensor([-1]) loss 7.524931907653809 epsilon 0.767566125
26-Feb-25 09:38:27 - agent.DQN.DQN - INFO - episode 3 step 291 reward tensor([-1]) loss 0.8655295968055725 epsilon 0.767566125
26-Feb-25 09:38:27 - agent.DQN.DQN - INFO - episode 3 step 292 reward tensor([-1]) loss 0.7405943274497986 epsilon 0.767566125
26-Feb-25 09:38:27 - agent.DQN.DQN - INFO - episode 3 step 293 reward tensor([-1]) loss 7.664285182952881 epsilon 0.767566125
26-Feb-25 09:38:27 - agent.DQN.DQN - INFO - episode 3 step 294 reward tensor([-1]) loss 1.0991392135620117 epsilon 0.767566125
26-Feb-25 09:38:27 - agent.DQN.DQN - INFO - episode 3 step 295 reward tensor([-1]) loss 1.508746862411499 epsilon 0.767566125
26-Feb-25 09:38:27 - agent.DQN.DQN - INFO - episode 3 step 296 reward tensor([-1]) loss 1.0860596895217896 epsilon 0.767566125
26-Feb-25 09:38:27 - agent.DQN.DQN - INFO - episode 3 step 297 reward tensor([-1]) loss 8.94400691986084 epsilon 0.767566125
26-Feb-25 09:38:27 - agent.DQN.DQN - INFO - episode 3 step 298 reward tensor([-1]) loss 2.0689282417297363 epsilon 0.767566125
26-Feb-25 09:38:27 - agent.DQN.DQN - INFO - episode 3 step 299 reward tensor([-1]) loss 1.5777390003204346 epsilon 0.767566125
26-Feb-25 09:38:27 - agent.DQN.DQN - INFO - episode 3 step 300 reward tensor([-1]) loss 1.8578886985778809 epsilon 0.767566125
26-Feb-25 09:38:27 - agent.DQN.DQN - INFO - episode 3 step 301 reward tensor([-1]) loss 1.8787739276885986 epsilon 0.767566125
26-Feb-25 09:38:27 - agent.DQN.DQN - INFO - episode 4 step 0 reward tensor([-1]) loss 1.25834321975708 epsilon 0.7426202259375
26-Feb-25 09:38:27 - agent.DQN.DQN - INFO - episode 4 step 1 reward tensor([-1]) loss 0.978310763835907 epsilon 0.7426202259375
26-Feb-25 09:38:27 - agent.DQN.DQN - INFO - episode 4 step 2 reward tensor([-1]) loss 0.7951623201370239 epsilon 0.7426202259375
26-Feb-25 09:38:27 - agent.DQN.DQN - INFO - episode 4 step 3 reward tensor([-1]) loss 7.405895233154297 epsilon 0.7426202259375
26-Feb-25 09:38:27 - agent.DQN.DQN - INFO - episode 4 step 4 reward tensor([-1]) loss 6.917230606079102 epsilon 0.7426202259375
26-Feb-25 09:38:27 - agent.DQN.DQN - INFO - episode 4 step 5 reward tensor([-1]) loss 1.2108745574951172 epsilon 0.7426202259375
26-Feb-25 09:38:27 - agent.DQN.DQN - INFO - episode 4 step 6 reward tensor([-1]) loss 1.9069461822509766 epsilon 0.7426202259375
26-Feb-25 09:38:27 - agent.DQN.DQN - INFO - episode 4 step 7 reward tensor([-1]) loss 1.7916300296783447 epsilon 0.7426202259375
26-Feb-25 09:38:27 - agent.DQN.DQN - INFO - episode 4 step 8 reward tensor([-1]) loss 0.8552044630050659 epsilon 0.7426202259375
26-Feb-25 09:38:27 - agent.DQN.DQN - INFO - episode 4 step 9 reward tensor([-1]) loss 5.889740943908691 epsilon 0.7426202259375
26-Feb-25 09:38:27 - agent.DQN.DQN - INFO - episode 4 step 10 reward tensor([-1]) loss 1.139526605606079 epsilon 0.7426202259375
26-Feb-25 09:38:27 - agent.DQN.DQN - INFO - episode 4 step 11 reward tensor([-1]) loss 0.8028843402862549 epsilon 0.7426202259375
26-Feb-25 09:38:27 - agent.DQN.DQN - INFO - episode 4 step 12 reward tensor([-1]) loss 5.670120716094971 epsilon 0.7426202259375
26-Feb-25 09:38:27 - agent.DQN.DQN - INFO - episode 4 step 13 reward tensor([-1]) loss 1.1166231632232666 epsilon 0.7426202259375
26-Feb-25 09:38:27 - agent.DQN.DQN - INFO - episode 4 step 14 reward tensor([-1]) loss 1.3405288457870483 epsilon 0.7426202259375
26-Feb-25 09:38:27 - agent.DQN.DQN - INFO - episode 4 step 15 reward tensor([-1]) loss 0.9604319334030151 epsilon 0.7426202259375
26-Feb-25 09:38:27 - agent.DQN.DQN - INFO - episode 4 step 16 reward tensor([-1]) loss 1.8178898096084595 epsilon 0.7426202259375
26-Feb-25 09:38:27 - agent.DQN.DQN - INFO - episode 4 step 17 reward tensor([-1]) loss 1.4235161542892456 epsilon 0.7426202259375
26-Feb-25 09:38:27 - agent.DQN.DQN - INFO - episode 4 step 18 reward tensor([-1]) loss 1.2666975259780884 epsilon 0.7426202259375
26-Feb-25 09:38:27 - agent.DQN.DQN - INFO - episode 4 step 19 reward tensor([-1]) loss 1.4804960489273071 epsilon 0.7426202259375
26-Feb-25 09:38:27 - agent.DQN.DQN - INFO - episode 4 step 20 reward tensor([-1]) loss 0.7169320583343506 epsilon 0.7426202259375
26-Feb-25 09:38:27 - agent.DQN.DQN - INFO - episode 4 step 21 reward tensor([-1]) loss 1.1862810850143433 epsilon 0.7426202259375
26-Feb-25 09:38:27 - agent.DQN.DQN - INFO - episode 4 step 22 reward tensor([-1]) loss 0.8181917667388916 epsilon 0.7426202259375
26-Feb-25 09:38:27 - agent.DQN.DQN - INFO - episode 4 step 23 reward tensor([-1]) loss 7.254880428314209 epsilon 0.7426202259375
26-Feb-25 09:38:27 - agent.DQN.DQN - INFO - episode 4 step 24 reward tensor([-1]) loss 0.7151078581809998 epsilon 0.7426202259375
26-Feb-25 09:38:27 - agent.DQN.DQN - INFO - episode 4 step 25 reward tensor([-1]) loss 1.352477788925171 epsilon 0.7426202259375
26-Feb-25 09:38:27 - agent.DQN.DQN - INFO - episode 4 step 26 reward tensor([-1]) loss 1.6081188917160034 epsilon 0.7426202259375
26-Feb-25 09:38:27 - agent.DQN.DQN - INFO - episode 4 step 27 reward tensor([-1]) loss 7.402124881744385 epsilon 0.7426202259375
26-Feb-25 09:38:27 - agent.DQN.DQN - INFO - episode 4 step 28 reward tensor([-1]) loss 6.570608615875244 epsilon 0.7426202259375
26-Feb-25 09:38:27 - agent.DQN.DQN - INFO - episode 4 step 29 reward tensor([-1]) loss 0.8599588871002197 epsilon 0.7426202259375
26-Feb-25 09:38:27 - agent.DQN.DQN - INFO - episode 4 step 30 reward tensor([-1]) loss 1.0121512413024902 epsilon 0.7426202259375
26-Feb-25 09:38:27 - agent.DQN.DQN - INFO - episode 4 step 31 reward tensor([-1]) loss 0.8275728225708008 epsilon 0.7426202259375
26-Feb-25 09:38:27 - agent.DQN.DQN - INFO - episode 4 step 32 reward tensor([-1]) loss 1.2211792469024658 epsilon 0.7426202259375
26-Feb-25 09:38:27 - agent.DQN.DQN - INFO - episode 4 step 33 reward tensor([-1]) loss 1.0880765914916992 epsilon 0.7426202259375
26-Feb-25 09:38:27 - agent.DQN.DQN - INFO - episode 4 step 34 reward tensor([-1]) loss 4.108801364898682 epsilon 0.7426202259375
26-Feb-25 09:38:27 - agent.DQN.DQN - INFO - episode 4 step 35 reward tensor([-1]) loss 1.8740264177322388 epsilon 0.7426202259375
26-Feb-25 09:38:27 - agent.DQN.DQN - INFO - episode 4 step 36 reward tensor([-1]) loss 1.2710139751434326 epsilon 0.7426202259375
26-Feb-25 09:38:27 - agent.DQN.DQN - INFO - episode 4 step 37 reward tensor([-1]) loss 5.685091018676758 epsilon 0.7426202259375
26-Feb-25 09:38:27 - agent.DQN.DQN - INFO - episode 4 step 38 reward tensor([-1]) loss 2.146008014678955 epsilon 0.7426202259375
26-Feb-25 09:38:27 - agent.DQN.DQN - INFO - episode 4 step 39 reward tensor([-1]) loss 1.5798356533050537 epsilon 0.7426202259375
26-Feb-25 09:38:27 - agent.DQN.DQN - INFO - episode 4 step 40 reward tensor([-1]) loss 4.8172831535339355 epsilon 0.7426202259375
26-Feb-25 09:38:27 - agent.DQN.DQN - INFO - episode 4 step 41 reward tensor([-1]) loss 1.7621313333511353 epsilon 0.7426202259375
26-Feb-25 09:38:27 - agent.DQN.DQN - INFO - episode 4 step 42 reward tensor([-1]) loss 1.0271236896514893 epsilon 0.7426202259375
26-Feb-25 09:38:27 - agent.DQN.DQN - INFO - episode 4 step 43 reward tensor([-1]) loss 1.1769213676452637 epsilon 0.7426202259375
26-Feb-25 09:38:27 - agent.DQN.DQN - INFO - episode 4 step 44 reward tensor([-1]) loss 0.9654443264007568 epsilon 0.7426202259375
26-Feb-25 09:38:27 - agent.DQN.DQN - INFO - episode 4 step 45 reward tensor([-1]) loss 6.004375457763672 epsilon 0.7426202259375
26-Feb-25 09:38:27 - agent.DQN.DQN - INFO - episode 4 step 46 reward tensor([-1]) loss 1.3617911338806152 epsilon 0.7426202259375
26-Feb-25 09:38:27 - agent.DQN.DQN - INFO - episode 4 step 47 reward tensor([-1]) loss 0.6713534593582153 epsilon 0.7426202259375
26-Feb-25 09:38:27 - agent.DQN.DQN - INFO - episode 4 step 48 reward tensor([-1]) loss 0.8665515184402466 epsilon 0.7426202259375
26-Feb-25 09:38:27 - agent.DQN.DQN - INFO - episode 4 step 49 reward tensor([-1]) loss 6.445132732391357 epsilon 0.7426202259375
26-Feb-25 09:38:27 - agent.DQN.DQN - INFO - episode 4 step 50 reward tensor([-1]) loss 0.9138079285621643 epsilon 0.7426202259375
26-Feb-25 09:38:27 - agent.DQN.DQN - INFO - episode 4 step 51 reward tensor([-1]) loss 1.0276811122894287 epsilon 0.7426202259375
26-Feb-25 09:38:27 - agent.DQN.DQN - INFO - episode 4 step 52 reward tensor([-1]) loss 0.8174865245819092 epsilon 0.7426202259375
26-Feb-25 09:38:27 - agent.DQN.DQN - INFO - episode 4 step 53 reward tensor([-1]) loss 0.7923244833946228 epsilon 0.7426202259375
26-Feb-25 09:38:27 - agent.DQN.DQN - INFO - episode 4 step 54 reward tensor([-1]) loss 0.7384050488471985 epsilon 0.7426202259375
26-Feb-25 09:38:27 - agent.DQN.DQN - INFO - episode 4 step 55 reward tensor([-1]) loss 1.5848878622055054 epsilon 0.7426202259375
26-Feb-25 09:38:27 - agent.DQN.DQN - INFO - episode 4 step 56 reward tensor([-1]) loss 1.6172772645950317 epsilon 0.7426202259375
26-Feb-25 09:38:27 - agent.DQN.DQN - INFO - episode 4 step 57 reward tensor([-1]) loss 1.0273158550262451 epsilon 0.7426202259375
26-Feb-25 09:38:27 - agent.DQN.DQN - INFO - episode 4 step 58 reward tensor([-1]) loss 1.1183534860610962 epsilon 0.7426202259375
26-Feb-25 09:38:28 - agent.DQN.DQN - INFO - episode 4 step 59 reward tensor([-1]) loss 1.2127496004104614 epsilon 0.7426202259375
26-Feb-25 09:38:28 - agent.DQN.DQN - INFO - episode 4 step 60 reward tensor([-1]) loss 1.0093024969100952 epsilon 0.7426202259375
26-Feb-25 09:38:28 - agent.DQN.DQN - INFO - episode 4 step 61 reward tensor([-1]) loss 0.7435882687568665 epsilon 0.7426202259375
26-Feb-25 09:38:28 - agent.DQN.DQN - INFO - episode 4 step 62 reward tensor([-1]) loss 5.2129645347595215 epsilon 0.7426202259375
26-Feb-25 09:38:28 - agent.DQN.DQN - INFO - episode 4 step 63 reward tensor([-1]) loss 0.6658600568771362 epsilon 0.7426202259375
26-Feb-25 09:38:28 - agent.DQN.DQN - INFO - episode 4 step 64 reward tensor([-1]) loss 0.7213740944862366 epsilon 0.7426202259375
26-Feb-25 09:38:28 - agent.DQN.DQN - INFO - episode 4 step 65 reward tensor([-1]) loss 0.7621846795082092 epsilon 0.7426202259375
26-Feb-25 09:38:28 - agent.DQN.DQN - INFO - episode 4 step 66 reward tensor([-1]) loss 0.6571006178855896 epsilon 0.7426202259375
26-Feb-25 09:38:28 - agent.DQN.DQN - INFO - episode 4 step 67 reward tensor([-1]) loss 0.8424883484840393 epsilon 0.7426202259375
26-Feb-25 09:38:28 - agent.DQN.DQN - INFO - episode 4 step 68 reward tensor([-1]) loss 1.1235383749008179 epsilon 0.7426202259375
26-Feb-25 09:38:28 - agent.DQN.DQN - INFO - episode 4 step 69 reward tensor([-1]) loss 1.2070817947387695 epsilon 0.7426202259375
26-Feb-25 09:38:28 - agent.DQN.DQN - INFO - episode 4 step 70 reward tensor([-1]) loss 0.6366580128669739 epsilon 0.7426202259375
26-Feb-25 09:38:28 - agent.DQN.DQN - INFO - episode 4 step 71 reward tensor([-1]) loss 1.0204235315322876 epsilon 0.7426202259375
26-Feb-25 09:38:28 - agent.DQN.DQN - INFO - episode 4 step 72 reward tensor([-1]) loss 0.5717895030975342 epsilon 0.7426202259375
26-Feb-25 09:38:28 - agent.DQN.DQN - INFO - episode 4 step 73 reward tensor([-1]) loss 0.523566722869873 epsilon 0.7426202259375
26-Feb-25 09:38:28 - agent.DQN.DQN - INFO - episode 4 step 74 reward tensor([-1]) loss 0.6566202044487 epsilon 0.7426202259375
26-Feb-25 09:38:28 - agent.DQN.DQN - INFO - episode 4 step 75 reward tensor([-1]) loss 0.5364564061164856 epsilon 0.7426202259375
26-Feb-25 09:38:28 - agent.DQN.DQN - INFO - episode 4 step 76 reward tensor([-1]) loss 0.7626295685768127 epsilon 0.7426202259375
26-Feb-25 09:38:28 - agent.DQN.DQN - INFO - episode 4 step 77 reward tensor([-1]) loss 0.5400899648666382 epsilon 0.7426202259375
26-Feb-25 09:38:28 - agent.DQN.DQN - INFO - episode 4 step 78 reward tensor([-1]) loss 0.9153630137443542 epsilon 0.7426202259375
26-Feb-25 09:38:28 - agent.DQN.DQN - INFO - episode 4 step 79 reward tensor([-1]) loss 0.5560512542724609 epsilon 0.7426202259375
26-Feb-25 09:38:28 - agent.DQN.DQN - INFO - episode 4 step 80 reward tensor([-1]) loss 0.6561481952667236 epsilon 0.7426202259375
26-Feb-25 09:38:28 - agent.DQN.DQN - INFO - episode 4 step 81 reward tensor([-1]) loss 0.6132639050483704 epsilon 0.7426202259375
26-Feb-25 09:38:28 - agent.DQN.DQN - INFO - episode 4 step 82 reward tensor([-1]) loss 0.8030538558959961 epsilon 0.7426202259375
26-Feb-25 09:38:28 - agent.DQN.DQN - INFO - episode 4 step 83 reward tensor([-1]) loss 0.6243870854377747 epsilon 0.7426202259375
26-Feb-25 09:38:28 - agent.DQN.DQN - INFO - episode 4 step 84 reward tensor([-1]) loss 0.5565057992935181 epsilon 0.7426202259375
26-Feb-25 09:38:28 - agent.DQN.DQN - INFO - episode 4 step 85 reward tensor([-1]) loss 1.9675096273422241 epsilon 0.7426202259375
26-Feb-25 09:38:28 - agent.DQN.DQN - INFO - episode 4 step 86 reward tensor([-1]) loss 1.315119981765747 epsilon 0.7426202259375
26-Feb-25 09:38:28 - agent.DQN.DQN - INFO - episode 4 step 87 reward tensor([-1]) loss 1.217739224433899 epsilon 0.7426202259375
26-Feb-25 09:38:28 - agent.DQN.DQN - INFO - episode 4 step 88 reward tensor([-1]) loss 5.7381062507629395 epsilon 0.7426202259375
26-Feb-25 09:38:28 - agent.DQN.DQN - INFO - episode 4 step 89 reward tensor([-1]) loss 0.7920844554901123 epsilon 0.7426202259375
26-Feb-25 09:38:28 - agent.DQN.DQN - INFO - episode 4 step 90 reward tensor([-1]) loss 4.535891056060791 epsilon 0.7426202259375
26-Feb-25 09:38:28 - agent.DQN.DQN - INFO - episode 4 step 91 reward tensor([-1]) loss 4.171914577484131 epsilon 0.7426202259375
26-Feb-25 09:38:28 - agent.DQN.DQN - INFO - episode 4 step 92 reward tensor([-1]) loss 0.800019383430481 epsilon 0.7426202259375
26-Feb-25 09:38:28 - agent.DQN.DQN - INFO - episode 4 step 93 reward tensor([-1]) loss 0.6928923726081848 epsilon 0.7426202259375
26-Feb-25 09:38:28 - agent.DQN.DQN - INFO - episode 4 step 94 reward tensor([-1]) loss 0.7293513417243958 epsilon 0.7426202259375
26-Feb-25 09:38:28 - agent.DQN.DQN - INFO - episode 4 step 95 reward tensor([-1]) loss 2.221956729888916 epsilon 0.7426202259375
26-Feb-25 09:38:28 - agent.DQN.DQN - INFO - episode 4 step 96 reward tensor([-1]) loss 4.401307582855225 epsilon 0.7426202259375
26-Feb-25 09:38:28 - agent.DQN.DQN - INFO - episode 4 step 97 reward tensor([-1]) loss 1.4440979957580566 epsilon 0.7426202259375
26-Feb-25 09:38:28 - agent.DQN.DQN - INFO - episode 4 step 98 reward tensor([-1]) loss 1.2731611728668213 epsilon 0.7426202259375
26-Feb-25 09:38:28 - agent.DQN.DQN - INFO - episode 4 step 99 reward tensor([-1]) loss 1.5627069473266602 epsilon 0.7426202259375
26-Feb-25 09:38:28 - agent.DQN.DQN - INFO - episode 4 step 100 reward tensor([-1]) loss 0.9928882122039795 epsilon 0.7426202259375
26-Feb-25 09:38:28 - agent.DQN.DQN - INFO - episode 4 step 101 reward tensor([-1]) loss 0.8719310164451599 epsilon 0.7426202259375
26-Feb-25 09:38:28 - agent.DQN.DQN - INFO - episode 4 step 102 reward tensor([-1]) loss 1.4984248876571655 epsilon 0.7426202259375
26-Feb-25 09:38:28 - agent.DQN.DQN - INFO - episode 4 step 103 reward tensor([-1]) loss 0.9534420371055603 epsilon 0.7426202259375
26-Feb-25 09:38:28 - agent.DQN.DQN - INFO - episode 4 step 104 reward tensor([-1]) loss 0.7253382205963135 epsilon 0.7426202259375
26-Feb-25 09:38:28 - agent.DQN.DQN - INFO - episode 4 step 105 reward tensor([-1]) loss 0.6388041377067566 epsilon 0.7426202259375
26-Feb-25 09:38:28 - agent.DQN.DQN - INFO - episode 4 step 106 reward tensor([-1]) loss 0.7385699152946472 epsilon 0.7426202259375
26-Feb-25 09:38:28 - agent.DQN.DQN - INFO - episode 4 step 107 reward tensor([-1]) loss 0.6807724237442017 epsilon 0.7426202259375
26-Feb-25 09:38:28 - agent.DQN.DQN - INFO - episode 4 step 108 reward tensor([-1]) loss 1.1954175233840942 epsilon 0.7426202259375
26-Feb-25 09:38:28 - agent.DQN.DQN - INFO - episode 4 step 109 reward tensor([-1]) loss 1.1419649124145508 epsilon 0.7426202259375
26-Feb-25 09:38:28 - agent.DQN.DQN - INFO - episode 4 step 110 reward tensor([-1]) loss 1.0411335229873657 epsilon 0.7426202259375
26-Feb-25 09:38:28 - agent.DQN.DQN - INFO - episode 4 step 111 reward tensor([-1]) loss 0.6426982283592224 epsilon 0.7426202259375
26-Feb-25 09:38:28 - agent.DQN.DQN - INFO - episode 4 step 112 reward tensor([-1]) loss 0.5882557034492493 epsilon 0.7426202259375
26-Feb-25 09:38:28 - agent.DQN.DQN - INFO - episode 4 step 113 reward tensor([-1]) loss 0.6974279880523682 epsilon 0.7426202259375
26-Feb-25 09:38:28 - agent.DQN.DQN - INFO - episode 4 step 114 reward tensor([-1]) loss 4.449682712554932 epsilon 0.7426202259375
26-Feb-25 09:38:28 - agent.DQN.DQN - INFO - episode 4 step 115 reward tensor([-1]) loss 1.2162340879440308 epsilon 0.7426202259375
26-Feb-25 09:38:28 - agent.DQN.DQN - INFO - episode 4 step 116 reward tensor([-1]) loss 1.4010297060012817 epsilon 0.7426202259375
26-Feb-25 09:38:28 - agent.DQN.DQN - INFO - episode 4 step 117 reward tensor([-1]) loss 1.0371655225753784 epsilon 0.7426202259375
26-Feb-25 09:38:28 - agent.DQN.DQN - INFO - episode 4 step 118 reward tensor([-1]) loss 0.9077638387680054 epsilon 0.7426202259375
26-Feb-25 09:38:28 - agent.DQN.DQN - INFO - episode 4 step 119 reward tensor([-1]) loss 4.095296382904053 epsilon 0.7426202259375
26-Feb-25 09:38:28 - agent.DQN.DQN - INFO - episode 4 step 120 reward tensor([-1]) loss 0.671531081199646 epsilon 0.7426202259375
26-Feb-25 09:38:28 - agent.DQN.DQN - INFO - episode 4 step 121 reward tensor([-1]) loss 1.5586600303649902 epsilon 0.7426202259375
26-Feb-25 09:38:28 - agent.DQN.DQN - INFO - episode 4 step 122 reward tensor([-1]) loss 3.219923973083496 epsilon 0.7426202259375
26-Feb-25 09:38:28 - agent.DQN.DQN - INFO - episode 4 step 123 reward tensor([-1]) loss 1.2735612392425537 epsilon 0.7426202259375
26-Feb-25 09:38:28 - agent.DQN.DQN - INFO - episode 4 step 124 reward tensor([-1]) loss 0.964175820350647 epsilon 0.7426202259375
26-Feb-25 09:38:28 - agent.DQN.DQN - INFO - episode 4 step 125 reward tensor([-1]) loss 2.4065659046173096 epsilon 0.7426202259375
26-Feb-25 09:38:28 - agent.DQN.DQN - INFO - episode 4 step 126 reward tensor([-1]) loss 1.0509541034698486 epsilon 0.7426202259375
26-Feb-25 09:38:28 - agent.DQN.DQN - INFO - episode 4 step 127 reward tensor([-1]) loss 1.0764397382736206 epsilon 0.7426202259375
26-Feb-25 09:38:28 - agent.DQN.DQN - INFO - episode 4 step 128 reward tensor([-1]) loss 1.2518402338027954 epsilon 0.7426202259375
26-Feb-25 09:38:28 - agent.DQN.DQN - INFO - episode 4 step 129 reward tensor([-1]) loss 2.5396268367767334 epsilon 0.7426202259375
26-Feb-25 09:38:28 - agent.DQN.DQN - INFO - episode 4 step 130 reward tensor([-1]) loss 0.7758576273918152 epsilon 0.7426202259375
26-Feb-25 09:38:28 - agent.DQN.DQN - INFO - episode 4 step 131 reward tensor([-1]) loss 0.7928382158279419 epsilon 0.7426202259375
26-Feb-25 09:38:28 - agent.DQN.DQN - INFO - episode 4 step 132 reward tensor([-1]) loss 1.254923701286316 epsilon 0.7426202259375
26-Feb-25 09:38:28 - agent.DQN.DQN - INFO - episode 4 step 133 reward tensor([-1]) loss 0.7921563982963562 epsilon 0.7426202259375
26-Feb-25 09:38:28 - agent.DQN.DQN - INFO - episode 4 step 134 reward tensor([-1]) loss 0.8502047061920166 epsilon 0.7426202259375
26-Feb-25 09:38:28 - agent.DQN.DQN - INFO - episode 4 step 135 reward tensor([-1]) loss 1.4101500511169434 epsilon 0.7426202259375
26-Feb-25 09:38:28 - agent.DQN.DQN - INFO - episode 4 step 136 reward tensor([-1]) loss 0.44889935851097107 epsilon 0.7426202259375
26-Feb-25 09:38:28 - agent.DQN.DQN - INFO - episode 4 step 137 reward tensor([-1]) loss 1.0856223106384277 epsilon 0.7426202259375
26-Feb-25 09:38:28 - agent.DQN.DQN - INFO - episode 4 step 138 reward tensor([-1]) loss 0.6585813164710999 epsilon 0.7426202259375
26-Feb-25 09:38:29 - agent.DQN.DQN - INFO - episode 4 step 139 reward tensor([-1]) loss 1.1332156658172607 epsilon 0.7426202259375
26-Feb-25 09:38:29 - agent.DQN.DQN - INFO - episode 4 step 140 reward tensor([-1]) loss 1.1218334436416626 epsilon 0.7426202259375
26-Feb-25 09:38:29 - agent.DQN.DQN - INFO - episode 4 step 141 reward tensor([-1]) loss 1.9566763639450073 epsilon 0.7426202259375
26-Feb-25 09:38:29 - agent.DQN.DQN - INFO - episode 4 step 142 reward tensor([-1]) loss 1.7541728019714355 epsilon 0.7426202259375
26-Feb-25 09:38:29 - agent.DQN.DQN - INFO - episode 4 step 143 reward tensor([-1]) loss 0.6664917469024658 epsilon 0.7426202259375
26-Feb-25 09:38:29 - agent.DQN.DQN - INFO - episode 4 step 144 reward tensor([-1]) loss 0.7298789024353027 epsilon 0.7426202259375
26-Feb-25 09:38:29 - agent.DQN.DQN - INFO - episode 4 step 145 reward tensor([-1]) loss 4.360586643218994 epsilon 0.7426202259375
26-Feb-25 09:38:29 - agent.DQN.DQN - INFO - episode 4 step 146 reward tensor([-1]) loss 1.4530649185180664 epsilon 0.7426202259375
26-Feb-25 09:38:29 - agent.DQN.DQN - INFO - episode 4 step 147 reward tensor([-1]) loss 4.514488220214844 epsilon 0.7426202259375
26-Feb-25 09:38:29 - agent.DQN.DQN - INFO - episode 4 step 148 reward tensor([-1]) loss 1.9545345306396484 epsilon 0.7426202259375
26-Feb-25 09:38:29 - agent.DQN.DQN - INFO - episode 4 step 149 reward tensor([-1]) loss 1.4453744888305664 epsilon 0.7426202259375
26-Feb-25 09:38:29 - agent.DQN.DQN - INFO - episode 4 step 150 reward tensor([-1]) loss 0.6367419362068176 epsilon 0.7426202259375
26-Feb-25 09:38:29 - agent.DQN.DQN - INFO - episode 4 step 151 reward tensor([-1]) loss 0.8219062685966492 epsilon 0.7426202259375
26-Feb-25 09:38:29 - agent.DQN.DQN - INFO - episode 4 step 152 reward tensor([-1]) loss 3.1488828659057617 epsilon 0.7426202259375
26-Feb-25 09:38:29 - agent.DQN.DQN - INFO - episode 4 step 153 reward tensor([-1]) loss 1.5125629901885986 epsilon 0.7426202259375
26-Feb-25 09:38:29 - agent.DQN.DQN - INFO - episode 4 step 154 reward tensor([-1]) loss 1.2315047979354858 epsilon 0.7426202259375
26-Feb-25 09:38:29 - agent.DQN.DQN - INFO - episode 4 step 155 reward tensor([-1]) loss 0.5359475016593933 epsilon 0.7426202259375
26-Feb-25 09:38:29 - agent.DQN.DQN - INFO - episode 4 step 156 reward tensor([-1]) loss 3.5376460552215576 epsilon 0.7426202259375
26-Feb-25 09:38:29 - agent.DQN.DQN - INFO - episode 4 step 157 reward tensor([-1]) loss 0.649761438369751 epsilon 0.7426202259375
26-Feb-25 09:38:29 - agent.DQN.DQN - INFO - episode 4 step 158 reward tensor([-1]) loss 1.1861485242843628 epsilon 0.7426202259375
26-Feb-25 09:38:29 - agent.DQN.DQN - INFO - episode 4 step 159 reward tensor([-1]) loss 1.3183400630950928 epsilon 0.7426202259375
26-Feb-25 09:38:29 - agent.DQN.DQN - INFO - episode 4 step 160 reward tensor([-1]) loss 3.1448922157287598 epsilon 0.7426202259375
26-Feb-25 09:38:29 - agent.DQN.DQN - INFO - episode 4 step 161 reward tensor([-1]) loss 1.115807056427002 epsilon 0.7426202259375
26-Feb-25 09:38:29 - agent.DQN.DQN - INFO - episode 4 step 162 reward tensor([-1]) loss 2.656623601913452 epsilon 0.7426202259375
26-Feb-25 09:38:29 - agent.DQN.DQN - INFO - episode 4 step 163 reward tensor([-1]) loss 1.2294166088104248 epsilon 0.7426202259375
26-Feb-25 09:38:29 - agent.DQN.DQN - INFO - episode 4 step 164 reward tensor([-1]) loss 1.4567065238952637 epsilon 0.7426202259375
26-Feb-25 09:38:29 - agent.DQN.DQN - INFO - episode 4 step 165 reward tensor([-1]) loss 0.8337312936782837 epsilon 0.7426202259375
26-Feb-25 09:38:29 - agent.DQN.DQN - INFO - episode 4 step 166 reward tensor([-1]) loss 1.5487972497940063 epsilon 0.7426202259375
26-Feb-25 09:38:29 - agent.DQN.DQN - INFO - episode 4 step 167 reward tensor([-1]) loss 1.1149940490722656 epsilon 0.7426202259375
26-Feb-25 09:38:29 - agent.DQN.DQN - INFO - episode 4 step 168 reward tensor([-1]) loss 1.0297425985336304 epsilon 0.7426202259375
26-Feb-25 09:38:29 - agent.DQN.DQN - INFO - episode 4 step 169 reward tensor([-1]) loss 0.9947924017906189 epsilon 0.7426202259375
26-Feb-25 09:38:29 - agent.DQN.DQN - INFO - episode 4 step 170 reward tensor([-1]) loss 0.8468949198722839 epsilon 0.7426202259375
26-Feb-25 09:38:29 - agent.DQN.DQN - INFO - episode 4 step 171 reward tensor([-1]) loss 0.7766135334968567 epsilon 0.7426202259375
26-Feb-25 09:38:29 - agent.DQN.DQN - INFO - episode 4 step 172 reward tensor([-1]) loss 0.9045396447181702 epsilon 0.7426202259375
26-Feb-25 09:38:29 - agent.DQN.DQN - INFO - episode 4 step 173 reward tensor([-1]) loss 0.9329520463943481 epsilon 0.7426202259375
26-Feb-25 09:38:29 - agent.DQN.DQN - INFO - episode 4 step 174 reward tensor([-1]) loss 1.0590673685073853 epsilon 0.7426202259375
26-Feb-25 09:38:29 - agent.DQN.DQN - INFO - episode 4 step 175 reward tensor([-1]) loss 4.1310834884643555 epsilon 0.7426202259375
26-Feb-25 09:38:29 - agent.DQN.DQN - INFO - episode 4 step 176 reward tensor([-1]) loss 1.600868821144104 epsilon 0.7426202259375
26-Feb-25 09:38:29 - agent.DQN.DQN - INFO - episode 4 step 177 reward tensor([-1]) loss 0.9790514707565308 epsilon 0.7426202259375
26-Feb-25 09:38:29 - agent.DQN.DQN - INFO - episode 4 step 178 reward tensor([-1]) loss 0.9197139739990234 epsilon 0.7426202259375
26-Feb-25 09:38:29 - agent.DQN.DQN - INFO - episode 4 step 179 reward tensor([-1]) loss 0.7492539882659912 epsilon 0.7426202259375
26-Feb-25 09:38:29 - agent.DQN.DQN - INFO - episode 4 step 180 reward tensor([-1]) loss 0.8666390180587769 epsilon 0.7426202259375
26-Feb-25 09:38:29 - agent.DQN.DQN - INFO - episode 4 step 181 reward tensor([-1]) loss 0.5924312472343445 epsilon 0.7426202259375
26-Feb-25 09:38:29 - agent.DQN.DQN - INFO - episode 4 step 182 reward tensor([-1]) loss 0.6179928183555603 epsilon 0.7426202259375
26-Feb-25 09:38:29 - agent.DQN.DQN - INFO - episode 4 step 183 reward tensor([-1]) loss 0.7844579815864563 epsilon 0.7426202259375
26-Feb-25 09:38:29 - agent.DQN.DQN - INFO - episode 4 step 184 reward tensor([-1]) loss 2.633129119873047 epsilon 0.7426202259375
26-Feb-25 09:38:29 - agent.DQN.DQN - INFO - episode 4 step 185 reward tensor([-1]) loss 1.1055794954299927 epsilon 0.7426202259375
26-Feb-25 09:38:29 - agent.DQN.DQN - INFO - episode 4 step 186 reward tensor([-1]) loss 0.8402174115180969 epsilon 0.7426202259375
26-Feb-25 09:38:29 - agent.DQN.DQN - INFO - episode 4 step 187 reward tensor([-1]) loss 0.6954533457756042 epsilon 0.7426202259375
26-Feb-25 09:38:29 - agent.DQN.DQN - INFO - episode 4 step 188 reward tensor([-1]) loss 0.5463999509811401 epsilon 0.7426202259375
26-Feb-25 09:38:29 - agent.DQN.DQN - INFO - episode 4 step 189 reward tensor([-1]) loss 0.5910438299179077 epsilon 0.7426202259375
26-Feb-25 09:38:29 - agent.DQN.DQN - INFO - episode 4 step 190 reward tensor([-1]) loss 0.8276268243789673 epsilon 0.7426202259375
26-Feb-25 09:38:29 - agent.DQN.DQN - INFO - episode 4 step 191 reward tensor([-1]) loss 0.5858325958251953 epsilon 0.7426202259375
26-Feb-25 09:38:29 - agent.DQN.DQN - INFO - episode 4 step 192 reward tensor([-1]) loss 2.6832900047302246 epsilon 0.7426202259375
26-Feb-25 09:38:29 - agent.DQN.DQN - INFO - episode 4 step 193 reward tensor([-1]) loss 0.7499113082885742 epsilon 0.7426202259375
26-Feb-25 09:38:29 - agent.DQN.DQN - INFO - episode 4 step 194 reward tensor([-1]) loss 0.710482656955719 epsilon 0.7426202259375
26-Feb-25 09:38:29 - agent.DQN.DQN - INFO - episode 4 step 195 reward tensor([-1]) loss 1.127533197402954 epsilon 0.7426202259375
26-Feb-25 09:38:29 - agent.DQN.DQN - INFO - episode 4 step 196 reward tensor([-1]) loss 0.6086541414260864 epsilon 0.7426202259375
26-Feb-25 09:38:29 - agent.DQN.DQN - INFO - episode 4 step 197 reward tensor([-1]) loss 0.4596444368362427 epsilon 0.7426202259375
26-Feb-25 09:38:29 - agent.DQN.DQN - INFO - episode 4 step 198 reward tensor([-1]) loss 2.895792007446289 epsilon 0.7426202259375
26-Feb-25 09:38:29 - agent.DQN.DQN - INFO - episode 4 step 199 reward tensor([-1]) loss 0.5930355191230774 epsilon 0.7426202259375
26-Feb-25 09:38:29 - agent.DQN.DQN - INFO - episode 4 step 200 reward tensor([-1]) loss 0.5028030276298523 epsilon 0.7426202259375
26-Feb-25 09:38:29 - agent.DQN.DQN - INFO - episode 4 step 201 reward tensor([-1]) loss 0.5405484437942505 epsilon 0.7426202259375
26-Feb-25 09:38:29 - agent.DQN.DQN - INFO - episode 4 step 202 reward tensor([-1]) loss 2.5948572158813477 epsilon 0.7426202259375
26-Feb-25 09:38:29 - agent.DQN.DQN - INFO - episode 4 step 203 reward tensor([-1]) loss 2.3884012699127197 epsilon 0.7426202259375
26-Feb-25 09:38:29 - agent.DQN.DQN - INFO - episode 4 step 204 reward tensor([-1]) loss 0.857748806476593 epsilon 0.7426202259375
26-Feb-25 09:38:29 - agent.DQN.DQN - INFO - episode 4 step 205 reward tensor([-1]) loss 2.7785966396331787 epsilon 0.7426202259375
26-Feb-25 09:38:29 - agent.DQN.DQN - INFO - episode 4 step 206 reward tensor([-1]) loss 1.4638736248016357 epsilon 0.7426202259375
26-Feb-25 09:38:29 - agent.DQN.DQN - INFO - episode 4 step 207 reward tensor([-1]) loss 1.1058331727981567 epsilon 0.7426202259375
26-Feb-25 09:38:29 - agent.DQN.DQN - INFO - episode 4 step 208 reward tensor([-1]) loss 0.7214733958244324 epsilon 0.7426202259375
26-Feb-25 09:38:29 - agent.DQN.DQN - INFO - episode 4 step 209 reward tensor([-1]) loss 0.6978177428245544 epsilon 0.7426202259375
26-Feb-25 09:38:29 - agent.DQN.DQN - INFO - episode 4 step 210 reward tensor([-1]) loss 1.9793858528137207 epsilon 0.7426202259375
26-Feb-25 09:38:29 - agent.DQN.DQN - INFO - episode 4 step 211 reward tensor([-1]) loss 2.052354097366333 epsilon 0.7426202259375
26-Feb-25 09:38:29 - agent.DQN.DQN - INFO - episode 4 step 212 reward tensor([-1]) loss 0.7644204497337341 epsilon 0.7426202259375
26-Feb-25 09:38:29 - agent.DQN.DQN - INFO - episode 4 step 213 reward tensor([-1]) loss 0.6622068285942078 epsilon 0.7426202259375
26-Feb-25 09:38:29 - agent.DQN.DQN - INFO - episode 4 step 214 reward tensor([-1]) loss 0.57243812084198 epsilon 0.7426202259375
26-Feb-25 09:38:29 - agent.DQN.DQN - INFO - episode 4 step 215 reward tensor([-1]) loss 1.711836338043213 epsilon 0.7426202259375
26-Feb-25 09:38:29 - agent.DQN.DQN - INFO - episode 4 step 216 reward tensor([-1]) loss 0.7636108994483948 epsilon 0.7426202259375
26-Feb-25 09:38:29 - agent.DQN.DQN - INFO - episode 4 step 217 reward tensor([-1]) loss 1.5914511680603027 epsilon 0.7426202259375
26-Feb-25 09:38:29 - agent.DQN.DQN - INFO - episode 4 step 218 reward tensor([-1]) loss 1.0376474857330322 epsilon 0.7426202259375
26-Feb-25 09:38:29 - agent.DQN.DQN - INFO - episode 4 step 219 reward tensor([-1]) loss 0.539145827293396 epsilon 0.7426202259375
26-Feb-25 09:38:29 - agent.DQN.DQN - INFO - episode 4 step 220 reward tensor([-1]) loss 0.6494492888450623 epsilon 0.7426202259375
26-Feb-25 09:38:29 - agent.DQN.DQN - INFO - episode 4 step 221 reward tensor([-1]) loss 1.3992900848388672 epsilon 0.7426202259375
26-Feb-25 09:38:29 - agent.DQN.DQN - INFO - episode 4 step 222 reward tensor([-1]) loss 0.762190043926239 epsilon 0.7426202259375
26-Feb-25 09:38:30 - agent.DQN.DQN - INFO - episode 4 step 223 reward tensor([-1]) loss 0.4880335032939911 epsilon 0.7426202259375
26-Feb-25 09:38:30 - agent.DQN.DQN - INFO - episode 4 step 224 reward tensor([-1]) loss 0.5033268332481384 epsilon 0.7426202259375
26-Feb-25 09:38:30 - agent.DQN.DQN - INFO - episode 4 step 225 reward tensor([-1]) loss 0.6766186952590942 epsilon 0.7426202259375
26-Feb-25 09:38:30 - agent.DQN.DQN - INFO - episode 4 step 226 reward tensor([-1]) loss 0.7445761561393738 epsilon 0.7426202259375
26-Feb-25 09:38:30 - agent.DQN.DQN - INFO - episode 4 step 227 reward tensor([-1]) loss 0.5962011814117432 epsilon 0.7426202259375
26-Feb-25 09:38:30 - agent.DQN.DQN - INFO - episode 4 step 228 reward tensor([-1]) loss 0.765894889831543 epsilon 0.7426202259375
26-Feb-25 09:38:30 - agent.DQN.DQN - INFO - episode 4 step 229 reward tensor([-1]) loss 0.7896733283996582 epsilon 0.7426202259375
26-Feb-25 09:38:30 - agent.DQN.DQN - INFO - episode 4 step 230 reward tensor([-1]) loss 0.5208162069320679 epsilon 0.7426202259375
26-Feb-25 09:38:30 - agent.DQN.DQN - INFO - episode 4 step 231 reward tensor([-1]) loss 0.5536500811576843 epsilon 0.7426202259375
26-Feb-25 09:38:30 - agent.DQN.DQN - INFO - episode 4 step 232 reward tensor([-1]) loss 0.5480685234069824 epsilon 0.7426202259375
26-Feb-25 09:38:30 - agent.DQN.DQN - INFO - episode 4 step 233 reward tensor([-1]) loss 0.7692376971244812 epsilon 0.7426202259375
26-Feb-25 09:38:30 - agent.DQN.DQN - INFO - episode 4 step 234 reward tensor([-1]) loss 0.47823524475097656 epsilon 0.7426202259375
26-Feb-25 09:38:30 - agent.DQN.DQN - INFO - episode 4 step 235 reward tensor([-1]) loss 0.8372237086296082 epsilon 0.7426202259375
26-Feb-25 09:38:30 - agent.DQN.DQN - INFO - episode 4 step 236 reward tensor([-1]) loss 2.2596359252929688 epsilon 0.7426202259375
26-Feb-25 09:38:30 - agent.DQN.DQN - INFO - episode 4 step 237 reward tensor([-1]) loss 2.117560863494873 epsilon 0.7426202259375
26-Feb-25 09:38:30 - agent.DQN.DQN - INFO - episode 4 step 238 reward tensor([-1]) loss 0.7119171023368835 epsilon 0.7426202259375
26-Feb-25 09:38:30 - agent.DQN.DQN - INFO - episode 4 step 239 reward tensor([-1]) loss 0.7159911394119263 epsilon 0.7426202259375
26-Feb-25 09:38:30 - agent.DQN.DQN - INFO - episode 4 step 240 reward tensor([-1]) loss 0.7803295254707336 epsilon 0.7426202259375
26-Feb-25 09:38:30 - agent.DQN.DQN - INFO - episode 4 step 241 reward tensor([-1]) loss 0.5954625606536865 epsilon 0.7426202259375
26-Feb-25 09:38:30 - agent.DQN.DQN - INFO - episode 4 step 242 reward tensor([-1]) loss 0.6516928672790527 epsilon 0.7426202259375
26-Feb-25 09:38:30 - agent.DQN.DQN - INFO - episode 4 step 243 reward tensor([-1]) loss 0.649471640586853 epsilon 0.7426202259375
26-Feb-25 09:38:30 - agent.DQN.DQN - INFO - episode 4 step 244 reward tensor([-1]) loss 0.5307199358940125 epsilon 0.7426202259375
26-Feb-25 09:38:30 - agent.DQN.DQN - INFO - episode 4 step 245 reward tensor([-1]) loss 0.6791419386863708 epsilon 0.7426202259375
26-Feb-25 09:38:30 - agent.DQN.DQN - INFO - episode 4 step 246 reward tensor([-1]) loss 1.6721014976501465 epsilon 0.7426202259375
26-Feb-25 09:38:30 - agent.DQN.DQN - INFO - episode 4 step 247 reward tensor([-1]) loss 0.5927297472953796 epsilon 0.7426202259375
26-Feb-25 09:38:30 - agent.DQN.DQN - INFO - episode 4 step 248 reward tensor([-1]) loss 0.6394835710525513 epsilon 0.7426202259375
26-Feb-25 09:38:30 - agent.DQN.DQN - INFO - episode 4 step 249 reward tensor([-1]) loss 1.5779613256454468 epsilon 0.7426202259375
26-Feb-25 09:38:30 - agent.DQN.DQN - INFO - episode 4 step 250 reward tensor([-1]) loss 0.47019055485725403 epsilon 0.7426202259375
26-Feb-25 09:38:30 - agent.DQN.DQN - INFO - episode 4 step 251 reward tensor([-1]) loss 0.48537272214889526 epsilon 0.7426202259375
26-Feb-25 09:38:30 - agent.DQN.DQN - INFO - episode 4 step 252 reward tensor([-1]) loss 1.388070821762085 epsilon 0.7426202259375
26-Feb-25 09:38:30 - agent.DQN.DQN - INFO - episode 4 step 253 reward tensor([-1]) loss 1.170593023300171 epsilon 0.7426202259375
26-Feb-25 09:38:30 - agent.DQN.DQN - INFO - episode 4 step 254 reward tensor([-1]) loss 0.5365797281265259 epsilon 0.7426202259375
26-Feb-25 09:38:30 - agent.DQN.DQN - INFO - episode 4 step 255 reward tensor([-1]) loss 0.7951367497444153 epsilon 0.7426202259375
26-Feb-25 09:38:30 - agent.DQN.DQN - INFO - episode 4 step 256 reward tensor([-1]) loss 0.8071547150611877 epsilon 0.7426202259375
26-Feb-25 09:38:30 - agent.DQN.DQN - INFO - episode 4 step 257 reward tensor([-1]) loss 1.480877161026001 epsilon 0.7426202259375
26-Feb-25 09:38:30 - agent.DQN.DQN - INFO - episode 4 step 258 reward tensor([-1]) loss 0.4485047459602356 epsilon 0.7426202259375
26-Feb-25 09:38:30 - agent.DQN.DQN - INFO - episode 4 step 259 reward tensor([-1]) loss 0.7968120574951172 epsilon 0.7426202259375
26-Feb-25 09:38:30 - agent.DQN.DQN - INFO - episode 4 step 260 reward tensor([-1]) loss 0.4635837972164154 epsilon 0.7426202259375
26-Feb-25 09:38:30 - agent.DQN.DQN - INFO - episode 4 step 261 reward tensor([-1]) loss 0.5825462341308594 epsilon 0.7426202259375
26-Feb-25 09:38:30 - agent.DQN.DQN - INFO - episode 4 step 262 reward tensor([-1]) loss 0.5959409475326538 epsilon 0.7426202259375
26-Feb-25 09:38:30 - agent.DQN.DQN - INFO - episode 4 step 263 reward tensor([-1]) loss 0.6489644646644592 epsilon 0.7426202259375
26-Feb-25 09:38:30 - agent.DQN.DQN - INFO - episode 4 step 264 reward tensor([-1]) loss 1.6225244998931885 epsilon 0.7426202259375
26-Feb-25 09:38:30 - agent.DQN.DQN - INFO - episode 4 step 265 reward tensor([-1]) loss 1.8535507917404175 epsilon 0.7426202259375
26-Feb-25 09:38:30 - agent.DQN.DQN - INFO - episode 4 step 266 reward tensor([-1]) loss 0.7874606847763062 epsilon 0.7426202259375
26-Feb-25 09:38:30 - agent.DQN.DQN - INFO - episode 4 step 267 reward tensor([-1]) loss 0.8502219319343567 epsilon 0.7426202259375
26-Feb-25 09:38:30 - agent.DQN.DQN - INFO - episode 4 step 268 reward tensor([-1]) loss 0.6750097274780273 epsilon 0.7426202259375
26-Feb-25 09:38:30 - agent.DQN.DQN - INFO - episode 4 step 269 reward tensor([-1]) loss 0.7333080768585205 epsilon 0.7426202259375
26-Feb-25 09:38:30 - agent.DQN.DQN - INFO - episode 4 step 270 reward tensor([-1]) loss 1.5502831935882568 epsilon 0.7426202259375
26-Feb-25 09:38:30 - agent.DQN.DQN - INFO - episode 4 step 271 reward tensor([-1]) loss 0.5885984897613525 epsilon 0.7426202259375
26-Feb-25 09:38:30 - agent.DQN.DQN - INFO - episode 4 step 272 reward tensor([-1]) loss 0.49426332116127014 epsilon 0.7426202259375
26-Feb-25 09:38:30 - agent.DQN.DQN - INFO - episode 4 step 273 reward tensor([-1]) loss 0.7403160929679871 epsilon 0.7426202259375
26-Feb-25 09:38:30 - agent.DQN.DQN - INFO - episode 4 step 274 reward tensor([-1]) loss 0.686088502407074 epsilon 0.7426202259375
26-Feb-25 09:38:30 - agent.DQN.DQN - INFO - episode 4 step 275 reward tensor([-1]) loss 1.2376468181610107 epsilon 0.7426202259375
26-Feb-25 09:38:30 - agent.DQN.DQN - INFO - episode 4 step 276 reward tensor([-1]) loss 0.7680829763412476 epsilon 0.7426202259375
26-Feb-25 09:38:30 - agent.DQN.DQN - INFO - episode 4 step 277 reward tensor([-1]) loss 0.7084468603134155 epsilon 0.7426202259375
26-Feb-25 09:38:30 - agent.DQN.DQN - INFO - episode 4 step 278 reward tensor([-1]) loss 1.8540862798690796 epsilon 0.7426202259375
26-Feb-25 09:38:30 - agent.DQN.DQN - INFO - episode 4 step 279 reward tensor([-1]) loss 1.2157890796661377 epsilon 0.7426202259375
26-Feb-25 09:38:30 - agent.DQN.DQN - INFO - episode 4 step 280 reward tensor([-1]) loss 0.5772925615310669 epsilon 0.7426202259375
26-Feb-25 09:38:30 - agent.DQN.DQN - INFO - episode 4 step 281 reward tensor([-1]) loss 1.2489992380142212 epsilon 0.7426202259375
26-Feb-25 09:38:30 - agent.DQN.DQN - INFO - episode 4 step 282 reward tensor([-1]) loss 0.5886757373809814 epsilon 0.7426202259375
26-Feb-25 09:38:30 - agent.DQN.DQN - INFO - episode 4 step 283 reward tensor([-1]) loss 0.401649534702301 epsilon 0.7426202259375
26-Feb-25 09:38:30 - agent.DQN.DQN - INFO - episode 4 step 284 reward tensor([-1]) loss 1.6097861528396606 epsilon 0.7426202259375
26-Feb-25 09:38:30 - agent.DQN.DQN - INFO - episode 4 step 285 reward tensor([-1]) loss 0.9192830920219421 epsilon 0.7426202259375
26-Feb-25 09:38:30 - agent.DQN.DQN - INFO - episode 4 step 286 reward tensor([-1]) loss 0.6905601620674133 epsilon 0.7426202259375
26-Feb-25 09:38:30 - agent.DQN.DQN - INFO - episode 4 step 287 reward tensor([-1]) loss 1.016864538192749 epsilon 0.7426202259375
26-Feb-25 09:38:30 - agent.DQN.DQN - INFO - episode 4 step 288 reward tensor([-1]) loss 1.2874170541763306 epsilon 0.7426202259375
26-Feb-25 09:38:30 - agent.DQN.DQN - INFO - episode 4 step 289 reward tensor([-1]) loss 2.7367823123931885 epsilon 0.7426202259375
26-Feb-25 09:38:30 - agent.DQN.DQN - INFO - episode 4 step 290 reward tensor([-1]) loss 2.963527202606201 epsilon 0.7426202259375
26-Feb-25 09:38:30 - agent.DQN.DQN - INFO - episode 4 step 291 reward tensor([-1]) loss 1.4743010997772217 epsilon 0.7426202259375
26-Feb-25 09:38:30 - agent.DQN.DQN - INFO - episode 4 step 292 reward tensor([-1]) loss 1.1615262031555176 epsilon 0.7426202259375
26-Feb-25 09:38:30 - agent.DQN.DQN - INFO - episode 4 step 293 reward tensor([-1]) loss 1.4069526195526123 epsilon 0.7426202259375
26-Feb-25 09:38:30 - agent.DQN.DQN - INFO - episode 4 step 294 reward tensor([-1]) loss 1.0169541835784912 epsilon 0.7426202259375
26-Feb-25 09:38:30 - agent.DQN.DQN - INFO - episode 4 step 295 reward tensor([-1]) loss 1.0308120250701904 epsilon 0.7426202259375
26-Feb-25 09:38:30 - agent.DQN.DQN - INFO - episode 4 step 296 reward tensor([-1]) loss 1.7763636112213135 epsilon 0.7426202259375
26-Feb-25 09:38:30 - agent.DQN.DQN - INFO - episode 4 step 297 reward tensor([-1]) loss 1.2285733222961426 epsilon 0.7426202259375
26-Feb-25 09:38:30 - agent.DQN.DQN - INFO - episode 4 step 298 reward tensor([-1]) loss 1.0513579845428467 epsilon 0.7426202259375
26-Feb-25 09:38:30 - agent.DQN.DQN - INFO - episode 4 step 299 reward tensor([-1]) loss 1.154660701751709 epsilon 0.7426202259375
26-Feb-25 09:38:30 - agent.DQN.DQN - INFO - episode 4 step 300 reward tensor([-1]) loss 1.0303137302398682 epsilon 0.7426202259375
26-Feb-25 09:38:30 - agent.DQN.DQN - INFO - episode 4 step 301 reward tensor([-1]) loss 1.0213450193405151 epsilon 0.7426202259375
26-Feb-25 09:38:31 - agent.DQN.DQN - INFO - episode 5 step 0 reward tensor([-1]) loss 0.7796667814254761 epsilon 0.7184850685945312
26-Feb-25 09:38:31 - agent.DQN.DQN - INFO - episode 5 step 1 reward tensor([-1]) loss 1.0833483934402466 epsilon 0.7184850685945312
26-Feb-25 09:38:31 - agent.DQN.DQN - INFO - episode 5 step 2 reward tensor([-1]) loss 2.035536289215088 epsilon 0.7184850685945312
26-Feb-25 09:38:31 - agent.DQN.DQN - INFO - episode 5 step 3 reward tensor([-1]) loss 0.7994969487190247 epsilon 0.7184850685945312
26-Feb-25 09:38:31 - agent.DQN.DQN - INFO - episode 5 step 4 reward tensor([-1]) loss 1.0308947563171387 epsilon 0.7184850685945312
26-Feb-25 09:38:31 - agent.DQN.DQN - INFO - episode 5 step 5 reward tensor([-1]) loss 0.9542292356491089 epsilon 0.7184850685945312
26-Feb-25 09:38:31 - agent.DQN.DQN - INFO - episode 5 step 6 reward tensor([-1]) loss 0.8751775622367859 epsilon 0.7184850685945312
26-Feb-25 09:38:31 - agent.DQN.DQN - INFO - episode 5 step 7 reward tensor([-1]) loss 0.5659015774726868 epsilon 0.7184850685945312
26-Feb-25 09:38:31 - agent.DQN.DQN - INFO - episode 5 step 8 reward tensor([-1]) loss 0.9555744528770447 epsilon 0.7184850685945312
26-Feb-25 09:38:31 - agent.DQN.DQN - INFO - episode 5 step 9 reward tensor([-1]) loss 0.556113064289093 epsilon 0.7184850685945312
26-Feb-25 09:38:31 - agent.DQN.DQN - INFO - episode 5 step 10 reward tensor([-1]) loss 0.8476564884185791 epsilon 0.7184850685945312
26-Feb-25 09:38:31 - agent.DQN.DQN - INFO - episode 5 step 11 reward tensor([-1]) loss 0.8200748562812805 epsilon 0.7184850685945312
26-Feb-25 09:38:31 - agent.DQN.DQN - INFO - episode 5 step 12 reward tensor([-1]) loss 1.5995311737060547 epsilon 0.7184850685945312
26-Feb-25 09:38:31 - agent.DQN.DQN - INFO - episode 5 step 13 reward tensor([-1]) loss 0.7020482420921326 epsilon 0.7184850685945312
26-Feb-25 09:38:31 - agent.DQN.DQN - INFO - episode 5 step 14 reward tensor([-1]) loss 0.7771248817443848 epsilon 0.7184850685945312
26-Feb-25 09:38:31 - agent.DQN.DQN - INFO - episode 5 step 15 reward tensor([-1]) loss 0.4843136668205261 epsilon 0.7184850685945312
26-Feb-25 09:38:31 - agent.DQN.DQN - INFO - episode 5 step 16 reward tensor([-1]) loss 1.0168670415878296 epsilon 0.7184850685945312
26-Feb-25 09:38:31 - agent.DQN.DQN - INFO - episode 5 step 17 reward tensor([-1]) loss 0.9425084590911865 epsilon 0.7184850685945312
26-Feb-25 09:38:31 - agent.DQN.DQN - INFO - episode 5 step 18 reward tensor([-1]) loss 0.582943856716156 epsilon 0.7184850685945312
26-Feb-25 09:38:31 - agent.DQN.DQN - INFO - episode 5 step 19 reward tensor([-1]) loss 0.7781276702880859 epsilon 0.7184850685945312
26-Feb-25 09:38:31 - agent.DQN.DQN - INFO - episode 5 step 20 reward tensor([-1]) loss 0.5491865873336792 epsilon 0.7184850685945312
26-Feb-25 09:38:31 - agent.DQN.DQN - INFO - episode 5 step 21 reward tensor([-1]) loss 0.5960415005683899 epsilon 0.7184850685945312
26-Feb-25 09:38:31 - agent.DQN.DQN - INFO - episode 5 step 22 reward tensor([-1]) loss 0.5172387361526489 epsilon 0.7184850685945312
26-Feb-25 09:38:31 - agent.DQN.DQN - INFO - episode 5 step 23 reward tensor([-1]) loss 0.9956572651863098 epsilon 0.7184850685945312
26-Feb-25 09:38:31 - agent.DQN.DQN - INFO - episode 5 step 24 reward tensor([-1]) loss 0.6668769121170044 epsilon 0.7184850685945312
26-Feb-25 09:38:31 - agent.DQN.DQN - INFO - episode 5 step 25 reward tensor([-1]) loss 0.68141108751297 epsilon 0.7184850685945312
26-Feb-25 09:38:31 - agent.DQN.DQN - INFO - episode 5 step 26 reward tensor([-1]) loss 0.9577823281288147 epsilon 0.7184850685945312
26-Feb-25 09:38:31 - agent.DQN.DQN - INFO - episode 5 step 27 reward tensor([-1]) loss 0.6889593601226807 epsilon 0.7184850685945312
26-Feb-25 09:38:31 - agent.DQN.DQN - INFO - episode 5 step 28 reward tensor([-1]) loss 0.6045321226119995 epsilon 0.7184850685945312
26-Feb-25 09:38:31 - agent.DQN.DQN - INFO - episode 5 step 29 reward tensor([-1]) loss 0.6919015645980835 epsilon 0.7184850685945312
26-Feb-25 09:38:31 - agent.DQN.DQN - INFO - episode 5 step 30 reward tensor([-1]) loss 0.6159309148788452 epsilon 0.7184850685945312
26-Feb-25 09:38:31 - agent.DQN.DQN - INFO - episode 5 step 31 reward tensor([-1]) loss 0.5556960701942444 epsilon 0.7184850685945312
26-Feb-25 09:38:31 - agent.DQN.DQN - INFO - episode 5 step 32 reward tensor([-1]) loss 0.45420029759407043 epsilon 0.7184850685945312
26-Feb-25 09:38:31 - agent.DQN.DQN - INFO - episode 5 step 33 reward tensor([-1]) loss 0.5020870566368103 epsilon 0.7184850685945312
26-Feb-25 09:38:31 - agent.DQN.DQN - INFO - episode 5 step 34 reward tensor([-1]) loss 0.673512876033783 epsilon 0.7184850685945312
26-Feb-25 09:38:31 - agent.DQN.DQN - INFO - episode 5 step 35 reward tensor([-1]) loss 0.6345167756080627 epsilon 0.7184850685945312
26-Feb-25 09:38:31 - agent.DQN.DQN - INFO - episode 5 step 36 reward tensor([-1]) loss 0.5741409063339233 epsilon 0.7184850685945312
26-Feb-25 09:38:31 - agent.DQN.DQN - INFO - episode 5 step 37 reward tensor([-1]) loss 1.5580321550369263 epsilon 0.7184850685945312
26-Feb-25 09:38:31 - agent.DQN.DQN - INFO - episode 5 step 38 reward tensor([-1]) loss 0.6617695689201355 epsilon 0.7184850685945312
26-Feb-25 09:38:31 - agent.DQN.DQN - INFO - episode 5 step 39 reward tensor([-1]) loss 0.5424153804779053 epsilon 0.7184850685945312
26-Feb-25 09:38:31 - agent.DQN.DQN - INFO - episode 5 step 40 reward tensor([-1]) loss 0.5089675188064575 epsilon 0.7184850685945312
26-Feb-25 09:38:31 - agent.DQN.DQN - INFO - episode 5 step 41 reward tensor([-1]) loss 0.4673103392124176 epsilon 0.7184850685945312
26-Feb-25 09:38:31 - agent.DQN.DQN - INFO - episode 5 step 42 reward tensor([-1]) loss 0.507868230342865 epsilon 0.7184850685945312
26-Feb-25 09:38:31 - agent.DQN.DQN - INFO - episode 5 step 43 reward tensor([-1]) loss 0.6273213028907776 epsilon 0.7184850685945312
26-Feb-25 09:38:31 - agent.DQN.DQN - INFO - episode 5 step 44 reward tensor([-1]) loss 1.1422395706176758 epsilon 0.7184850685945312
26-Feb-25 09:38:31 - agent.DQN.DQN - INFO - episode 5 step 45 reward tensor([-1]) loss 0.3891371488571167 epsilon 0.7184850685945312
26-Feb-25 09:38:31 - agent.DQN.DQN - INFO - episode 5 step 46 reward tensor([-1]) loss 1.1330853700637817 epsilon 0.7184850685945312
26-Feb-25 09:38:31 - agent.DQN.DQN - INFO - episode 5 step 47 reward tensor([-1]) loss 0.5113455653190613 epsilon 0.7184850685945312
26-Feb-25 09:38:31 - agent.DQN.DQN - INFO - episode 5 step 48 reward tensor([-1]) loss 0.4874597191810608 epsilon 0.7184850685945312
26-Feb-25 09:38:31 - agent.DQN.DQN - INFO - episode 5 step 49 reward tensor([-1]) loss 0.5747839212417603 epsilon 0.7184850685945312
26-Feb-25 09:38:31 - agent.DQN.DQN - INFO - episode 5 step 50 reward tensor([-1]) loss 0.5287104845046997 epsilon 0.7184850685945312
26-Feb-25 09:38:31 - agent.DQN.DQN - INFO - episode 5 step 51 reward tensor([-1]) loss 0.48494625091552734 epsilon 0.7184850685945312
26-Feb-25 09:38:31 - agent.DQN.DQN - INFO - episode 5 step 52 reward tensor([-1]) loss 0.7127116918563843 epsilon 0.7184850685945312
26-Feb-25 09:38:31 - agent.DQN.DQN - INFO - episode 5 step 53 reward tensor([-1]) loss 1.5583162307739258 epsilon 0.7184850685945312
26-Feb-25 09:38:31 - agent.DQN.DQN - INFO - episode 5 step 54 reward tensor([-1]) loss 0.6139586567878723 epsilon 0.7184850685945312
26-Feb-25 09:38:31 - agent.DQN.DQN - INFO - episode 5 step 55 reward tensor([-1]) loss 0.6898667216300964 epsilon 0.7184850685945312
26-Feb-25 09:38:31 - agent.DQN.DQN - INFO - episode 5 step 56 reward tensor([-1]) loss 0.6084399223327637 epsilon 0.7184850685945312
26-Feb-25 09:38:31 - agent.DQN.DQN - INFO - episode 5 step 57 reward tensor([-1]) loss 0.5468704104423523 epsilon 0.7184850685945312
26-Feb-25 09:38:31 - agent.DQN.DQN - INFO - episode 5 step 58 reward tensor([-1]) loss 0.9953223466873169 epsilon 0.7184850685945312
26-Feb-25 09:38:31 - agent.DQN.DQN - INFO - episode 5 step 59 reward tensor([-1]) loss 0.9350069165229797 epsilon 0.7184850685945312
26-Feb-25 09:38:31 - agent.DQN.DQN - INFO - episode 5 step 60 reward tensor([-1]) loss 0.5855469703674316 epsilon 0.7184850685945312
26-Feb-25 09:38:31 - agent.DQN.DQN - INFO - episode 5 step 61 reward tensor([-1]) loss 0.4731917679309845 epsilon 0.7184850685945312
26-Feb-25 09:38:31 - agent.DQN.DQN - INFO - episode 5 step 62 reward tensor([-1]) loss 0.6796807646751404 epsilon 0.7184850685945312
26-Feb-25 09:38:31 - agent.DQN.DQN - INFO - episode 5 step 63 reward tensor([-1]) loss 0.5954667925834656 epsilon 0.7184850685945312
26-Feb-25 09:38:31 - agent.DQN.DQN - INFO - episode 5 step 64 reward tensor([-1]) loss 0.4355999827384949 epsilon 0.7184850685945312
26-Feb-25 09:38:31 - agent.DQN.DQN - INFO - episode 5 step 65 reward tensor([-1]) loss 0.5967839360237122 epsilon 0.7184850685945312
26-Feb-25 09:38:31 - agent.DQN.DQN - INFO - episode 5 step 66 reward tensor([-1]) loss 0.5581521987915039 epsilon 0.7184850685945312
26-Feb-25 09:38:31 - agent.DQN.DQN - INFO - episode 5 step 67 reward tensor([-1]) loss 0.4854816794395447 epsilon 0.7184850685945312
26-Feb-25 09:38:31 - agent.DQN.DQN - INFO - episode 5 step 68 reward tensor([-1]) loss 0.7851108908653259 epsilon 0.7184850685945312
26-Feb-25 09:38:31 - agent.DQN.DQN - INFO - episode 5 step 69 reward tensor([-1]) loss 0.8564256429672241 epsilon 0.7184850685945312
26-Feb-25 09:38:31 - agent.DQN.DQN - INFO - episode 5 step 70 reward tensor([-1]) loss 0.9551584720611572 epsilon 0.7184850685945312
26-Feb-25 09:38:31 - agent.DQN.DQN - INFO - episode 5 step 71 reward tensor([-1]) loss 0.44978559017181396 epsilon 0.7184850685945312
26-Feb-25 09:38:31 - agent.DQN.DQN - INFO - episode 5 step 72 reward tensor([-1]) loss 0.7854365110397339 epsilon 0.7184850685945312
26-Feb-25 09:38:31 - agent.DQN.DQN - INFO - episode 5 step 73 reward tensor([-1]) loss 0.46980640292167664 epsilon 0.7184850685945312
26-Feb-25 09:38:31 - agent.DQN.DQN - INFO - episode 5 step 74 reward tensor([-1]) loss 0.7104971408843994 epsilon 0.7184850685945312
26-Feb-25 09:38:31 - agent.DQN.DQN - INFO - episode 5 step 75 reward tensor([-1]) loss 0.470024973154068 epsilon 0.7184850685945312
26-Feb-25 09:38:31 - agent.DQN.DQN - INFO - episode 5 step 76 reward tensor([-1]) loss 0.8078649640083313 epsilon 0.7184850685945312
26-Feb-25 09:38:31 - agent.DQN.DQN - INFO - episode 5 step 77 reward tensor([-1]) loss 0.7010685205459595 epsilon 0.7184850685945312
26-Feb-25 09:38:31 - agent.DQN.DQN - INFO - episode 5 step 78 reward tensor([-1]) loss 0.40936142206192017 epsilon 0.7184850685945312
26-Feb-25 09:38:31 - agent.DQN.DQN - INFO - episode 5 step 79 reward tensor([-1]) loss 0.451531320810318 epsilon 0.7184850685945312
26-Feb-25 09:38:31 - agent.DQN.DQN - INFO - episode 5 step 80 reward tensor([-1]) loss 0.4570002555847168 epsilon 0.7184850685945312
26-Feb-25 09:38:32 - agent.DQN.DQN - INFO - episode 5 step 81 reward tensor([-1]) loss 0.3975561261177063 epsilon 0.7184850685945312
26-Feb-25 09:38:32 - agent.DQN.DQN - INFO - episode 5 step 82 reward tensor([-1]) loss 0.4235199987888336 epsilon 0.7184850685945312
26-Feb-25 09:38:32 - agent.DQN.DQN - INFO - episode 5 step 83 reward tensor([-1]) loss 0.7007546424865723 epsilon 0.7184850685945312
26-Feb-25 09:38:32 - agent.DQN.DQN - INFO - episode 5 step 84 reward tensor([-1]) loss 0.6029468774795532 epsilon 0.7184850685945312
26-Feb-25 09:38:32 - agent.DQN.DQN - INFO - episode 5 step 85 reward tensor([-1]) loss 0.6381064653396606 epsilon 0.7184850685945312
26-Feb-25 09:38:32 - agent.DQN.DQN - INFO - episode 5 step 86 reward tensor([-1]) loss 0.5709273815155029 epsilon 0.7184850685945312
26-Feb-25 09:38:32 - agent.DQN.DQN - INFO - episode 5 step 87 reward tensor([-1]) loss 0.5017367601394653 epsilon 0.7184850685945312
26-Feb-25 09:38:32 - agent.DQN.DQN - INFO - episode 5 step 88 reward tensor([-1]) loss 0.5642457008361816 epsilon 0.7184850685945312
26-Feb-25 09:38:32 - agent.DQN.DQN - INFO - episode 5 step 89 reward tensor([-1]) loss 0.5405111908912659 epsilon 0.7184850685945312
26-Feb-25 09:38:32 - agent.DQN.DQN - INFO - episode 5 step 90 reward tensor([-1]) loss 0.5556592345237732 epsilon 0.7184850685945312
26-Feb-25 09:38:32 - agent.DQN.DQN - INFO - episode 5 step 91 reward tensor([-1]) loss 0.5065407156944275 epsilon 0.7184850685945312
26-Feb-25 09:38:32 - agent.DQN.DQN - INFO - episode 5 step 92 reward tensor([-1]) loss 0.4353657364845276 epsilon 0.7184850685945312
26-Feb-25 09:38:32 - agent.DQN.DQN - INFO - episode 5 step 93 reward tensor([-1]) loss 0.4762909710407257 epsilon 0.7184850685945312
26-Feb-25 09:38:32 - agent.DQN.DQN - INFO - episode 5 step 94 reward tensor([-1]) loss 0.6763590574264526 epsilon 0.7184850685945312
26-Feb-25 09:38:32 - agent.DQN.DQN - INFO - episode 5 step 95 reward tensor([-1]) loss 0.9144129157066345 epsilon 0.7184850685945312
26-Feb-25 09:38:32 - agent.DQN.DQN - INFO - episode 5 step 96 reward tensor([-1]) loss 0.4125082194805145 epsilon 0.7184850685945312
26-Feb-25 09:38:32 - agent.DQN.DQN - INFO - episode 5 step 97 reward tensor([-1]) loss 0.4299800395965576 epsilon 0.7184850685945312
26-Feb-25 09:38:32 - agent.DQN.DQN - INFO - episode 5 step 98 reward tensor([-1]) loss 0.7078707814216614 epsilon 0.7184850685945312
26-Feb-25 09:38:32 - agent.DQN.DQN - INFO - episode 5 step 99 reward tensor([-1]) loss 0.5694963335990906 epsilon 0.7184850685945312
26-Feb-25 09:38:32 - agent.DQN.DQN - INFO - episode 5 step 100 reward tensor([-1]) loss 0.5643921494483948 epsilon 0.7184850685945312
26-Feb-25 09:38:32 - agent.DQN.DQN - INFO - episode 5 step 101 reward tensor([-1]) loss 0.7089587450027466 epsilon 0.7184850685945312
26-Feb-25 09:38:32 - agent.DQN.DQN - INFO - episode 5 step 102 reward tensor([-1]) loss 0.6466559171676636 epsilon 0.7184850685945312
26-Feb-25 09:38:32 - agent.DQN.DQN - INFO - episode 5 step 103 reward tensor([-1]) loss 0.42768633365631104 epsilon 0.7184850685945312
26-Feb-25 09:38:32 - agent.DQN.DQN - INFO - episode 5 step 104 reward tensor([-1]) loss 0.5520834922790527 epsilon 0.7184850685945312
26-Feb-25 09:38:32 - agent.DQN.DQN - INFO - episode 5 step 105 reward tensor([-1]) loss 0.3525286316871643 epsilon 0.7184850685945312
26-Feb-25 09:38:32 - agent.DQN.DQN - INFO - episode 5 step 106 reward tensor([-1]) loss 0.5730628371238708 epsilon 0.7184850685945312
26-Feb-25 09:38:32 - agent.DQN.DQN - INFO - episode 5 step 107 reward tensor([-1]) loss 0.5236353278160095 epsilon 0.7184850685945312
26-Feb-25 09:38:32 - agent.DQN.DQN - INFO - episode 5 step 108 reward tensor([-1]) loss 0.5012854337692261 epsilon 0.7184850685945312
26-Feb-25 09:38:32 - agent.DQN.DQN - INFO - episode 5 step 109 reward tensor([-1]) loss 0.576241672039032 epsilon 0.7184850685945312
26-Feb-25 09:38:32 - agent.DQN.DQN - INFO - episode 5 step 110 reward tensor([-1]) loss 0.484214186668396 epsilon 0.7184850685945312
26-Feb-25 09:38:32 - agent.DQN.DQN - INFO - episode 5 step 111 reward tensor([-1]) loss 0.5684092044830322 epsilon 0.7184850685945312
26-Feb-25 09:38:32 - agent.DQN.DQN - INFO - episode 5 step 112 reward tensor([-1]) loss 1.1997236013412476 epsilon 0.7184850685945312
26-Feb-25 09:38:32 - agent.DQN.DQN - INFO - episode 5 step 113 reward tensor([-1]) loss 0.863160252571106 epsilon 0.7184850685945312
26-Feb-25 09:38:32 - agent.DQN.DQN - INFO - episode 5 step 114 reward tensor([-1]) loss 0.7974765300750732 epsilon 0.7184850685945312
26-Feb-25 09:38:32 - agent.DQN.DQN - INFO - episode 5 step 115 reward tensor([-1]) loss 0.5179922580718994 epsilon 0.7184850685945312
26-Feb-25 09:38:32 - agent.DQN.DQN - INFO - episode 5 step 116 reward tensor([-1]) loss 0.5139406323432922 epsilon 0.7184850685945312
26-Feb-25 09:38:32 - agent.DQN.DQN - INFO - episode 5 step 117 reward tensor([-1]) loss 0.7335763573646545 epsilon 0.7184850685945312
26-Feb-25 09:38:32 - agent.DQN.DQN - INFO - episode 5 step 118 reward tensor([-1]) loss 0.6554331183433533 epsilon 0.7184850685945312
26-Feb-25 09:38:32 - agent.DQN.DQN - INFO - episode 5 step 119 reward tensor([-1]) loss 1.0882692337036133 epsilon 0.7184850685945312
26-Feb-25 09:38:32 - agent.DQN.DQN - INFO - episode 5 step 120 reward tensor([-1]) loss 1.1423842906951904 epsilon 0.7184850685945312
26-Feb-25 09:38:32 - agent.DQN.DQN - INFO - episode 5 step 121 reward tensor([-1]) loss 0.7475594282150269 epsilon 0.7184850685945312
26-Feb-25 09:38:32 - agent.DQN.DQN - INFO - episode 5 step 122 reward tensor([-1]) loss 0.42103275656700134 epsilon 0.7184850685945312
26-Feb-25 09:38:32 - agent.DQN.DQN - INFO - episode 5 step 123 reward tensor([-1]) loss 0.7800444960594177 epsilon 0.7184850685945312
26-Feb-25 09:38:32 - agent.DQN.DQN - INFO - episode 5 step 124 reward tensor([-1]) loss 0.4117230176925659 epsilon 0.7184850685945312
26-Feb-25 09:38:32 - agent.DQN.DQN - INFO - episode 5 step 125 reward tensor([-1]) loss 0.7470411062240601 epsilon 0.7184850685945312
26-Feb-25 09:38:32 - agent.DQN.DQN - INFO - episode 5 step 126 reward tensor([-1]) loss 0.6225311756134033 epsilon 0.7184850685945312
26-Feb-25 09:38:32 - agent.DQN.DQN - INFO - episode 5 step 127 reward tensor([-1]) loss 0.480867862701416 epsilon 0.7184850685945312
26-Feb-25 09:38:32 - agent.DQN.DQN - INFO - episode 5 step 128 reward tensor([-1]) loss 0.5842174291610718 epsilon 0.7184850685945312
26-Feb-25 09:38:32 - agent.DQN.DQN - INFO - episode 5 step 129 reward tensor([-1]) loss 0.4499976634979248 epsilon 0.7184850685945312
26-Feb-25 09:38:32 - agent.DQN.DQN - INFO - episode 5 step 130 reward tensor([-1]) loss 0.9725000262260437 epsilon 0.7184850685945312
26-Feb-25 09:38:32 - agent.DQN.DQN - INFO - episode 5 step 131 reward tensor([-1]) loss 0.4058857560157776 epsilon 0.7184850685945312
26-Feb-25 09:38:32 - agent.DQN.DQN - INFO - episode 5 step 132 reward tensor([-1]) loss 0.5143210887908936 epsilon 0.7184850685945312
26-Feb-25 09:38:32 - agent.DQN.DQN - INFO - episode 5 step 133 reward tensor([-1]) loss 0.4774823784828186 epsilon 0.7184850685945312
26-Feb-25 09:38:32 - agent.DQN.DQN - INFO - episode 5 step 134 reward tensor([-1]) loss 0.3516353666782379 epsilon 0.7184850685945312
26-Feb-25 09:38:32 - agent.DQN.DQN - INFO - episode 5 step 135 reward tensor([-1]) loss 0.6902903318405151 epsilon 0.7184850685945312
26-Feb-25 09:38:32 - agent.DQN.DQN - INFO - episode 5 step 136 reward tensor([-1]) loss 0.44113534688949585 epsilon 0.7184850685945312
26-Feb-25 09:38:32 - agent.DQN.DQN - INFO - episode 5 step 137 reward tensor([-1]) loss 0.6203879714012146 epsilon 0.7184850685945312
26-Feb-25 09:38:32 - agent.DQN.DQN - INFO - episode 5 step 138 reward tensor([-1]) loss 0.4377076029777527 epsilon 0.7184850685945312
26-Feb-25 09:38:32 - agent.DQN.DQN - INFO - episode 5 step 139 reward tensor([-1]) loss 0.4502091705799103 epsilon 0.7184850685945312
26-Feb-25 09:38:32 - agent.DQN.DQN - INFO - episode 5 step 140 reward tensor([-1]) loss 0.359658807516098 epsilon 0.7184850685945312
26-Feb-25 09:38:32 - agent.DQN.DQN - INFO - episode 5 step 141 reward tensor([-1]) loss 0.42714768648147583 epsilon 0.7184850685945312
26-Feb-25 09:38:32 - agent.DQN.DQN - INFO - episode 5 step 142 reward tensor([-1]) loss 0.5704097151756287 epsilon 0.7184850685945312
26-Feb-25 09:38:32 - agent.DQN.DQN - INFO - episode 5 step 143 reward tensor([-1]) loss 0.5580703020095825 epsilon 0.7184850685945312
26-Feb-25 09:38:32 - agent.DQN.DQN - INFO - episode 5 step 144 reward tensor([-1]) loss 0.5074567198753357 epsilon 0.7184850685945312
26-Feb-25 09:38:32 - agent.DQN.DQN - INFO - episode 5 step 145 reward tensor([-1]) loss 0.5882822275161743 epsilon 0.7184850685945312
26-Feb-25 09:38:32 - agent.DQN.DQN - INFO - episode 5 step 146 reward tensor([-1]) loss 0.45005694031715393 epsilon 0.7184850685945312
26-Feb-25 09:38:32 - agent.DQN.DQN - INFO - episode 5 step 147 reward tensor([-1]) loss 0.51505047082901 epsilon 0.7184850685945312
26-Feb-25 09:38:32 - agent.DQN.DQN - INFO - episode 5 step 148 reward tensor([-1]) loss 0.4937326908111572 epsilon 0.7184850685945312
26-Feb-25 09:38:32 - agent.DQN.DQN - INFO - episode 5 step 149 reward tensor([-1]) loss 0.5494063496589661 epsilon 0.7184850685945312
26-Feb-25 09:38:32 - agent.DQN.DQN - INFO - episode 5 step 150 reward tensor([-1]) loss 0.528165340423584 epsilon 0.7184850685945312
26-Feb-25 09:38:32 - agent.DQN.DQN - INFO - episode 5 step 151 reward tensor([-1]) loss 0.529198408126831 epsilon 0.7184850685945312
26-Feb-25 09:38:32 - agent.DQN.DQN - INFO - episode 5 step 152 reward tensor([-1]) loss 0.45120200514793396 epsilon 0.7184850685945312
26-Feb-25 09:38:33 - agent.DQN.DQN - INFO - episode 5 step 153 reward tensor([-1]) loss 0.5413222312927246 epsilon 0.7184850685945312
26-Feb-25 09:38:33 - agent.DQN.DQN - INFO - episode 5 step 154 reward tensor([-1]) loss 0.7917454838752747 epsilon 0.7184850685945312
26-Feb-25 09:38:33 - agent.DQN.DQN - INFO - episode 5 step 155 reward tensor([-1]) loss 0.6993665099143982 epsilon 0.7184850685945312
26-Feb-25 09:38:33 - agent.DQN.DQN - INFO - episode 5 step 156 reward tensor([-1]) loss 0.7598459720611572 epsilon 0.7184850685945312
26-Feb-25 09:38:33 - agent.DQN.DQN - INFO - episode 5 step 157 reward tensor([-1]) loss 0.5086987018585205 epsilon 0.7184850685945312
26-Feb-25 09:38:33 - agent.DQN.DQN - INFO - episode 5 step 158 reward tensor([-1]) loss 0.5623663067817688 epsilon 0.7184850685945312
26-Feb-25 09:38:33 - agent.DQN.DQN - INFO - episode 5 step 159 reward tensor([-1]) loss 0.33031705021858215 epsilon 0.7184850685945312
26-Feb-25 09:38:33 - agent.DQN.DQN - INFO - episode 5 step 160 reward tensor([-1]) loss 0.6082792282104492 epsilon 0.7184850685945312
26-Feb-25 09:38:33 - agent.DQN.DQN - INFO - episode 5 step 161 reward tensor([-1]) loss 0.5441157817840576 epsilon 0.7184850685945312
26-Feb-25 09:38:33 - agent.DQN.DQN - INFO - episode 5 step 162 reward tensor([-1]) loss 0.3242102563381195 epsilon 0.7184850685945312
26-Feb-25 09:38:33 - agent.DQN.DQN - INFO - episode 5 step 163 reward tensor([-1]) loss 0.8409532308578491 epsilon 0.7184850685945312
26-Feb-25 09:38:33 - agent.DQN.DQN - INFO - episode 5 step 164 reward tensor([-1]) loss 0.36091938614845276 epsilon 0.7184850685945312
26-Feb-25 09:38:33 - agent.DQN.DQN - INFO - episode 5 step 165 reward tensor([-1]) loss 0.48625367879867554 epsilon 0.7184850685945312
26-Feb-25 09:38:33 - agent.DQN.DQN - INFO - episode 5 step 166 reward tensor([-1]) loss 0.5369250178337097 epsilon 0.7184850685945312
26-Feb-25 09:38:33 - agent.DQN.DQN - INFO - episode 5 step 167 reward tensor([-1]) loss 0.8524836301803589 epsilon 0.7184850685945312
26-Feb-25 09:38:33 - agent.DQN.DQN - INFO - episode 5 step 168 reward tensor([-1]) loss 0.5116230249404907 epsilon 0.7184850685945312
26-Feb-25 09:38:33 - agent.DQN.DQN - INFO - episode 5 step 169 reward tensor([-1]) loss 0.5110752582550049 epsilon 0.7184850685945312
26-Feb-25 09:38:33 - agent.DQN.DQN - INFO - episode 5 step 170 reward tensor([-1]) loss 0.5463634729385376 epsilon 0.7184850685945312
26-Feb-25 09:38:33 - agent.DQN.DQN - INFO - episode 5 step 171 reward tensor([-1]) loss 0.655180811882019 epsilon 0.7184850685945312
26-Feb-25 09:38:33 - agent.DQN.DQN - INFO - episode 5 step 172 reward tensor([-1]) loss 0.3797479271888733 epsilon 0.7184850685945312
26-Feb-25 09:38:33 - agent.DQN.DQN - INFO - episode 5 step 173 reward tensor([-1]) loss 0.7055655121803284 epsilon 0.7184850685945312
26-Feb-25 09:38:33 - agent.DQN.DQN - INFO - episode 5 step 174 reward tensor([-1]) loss 0.38716942071914673 epsilon 0.7184850685945312
26-Feb-25 09:38:33 - agent.DQN.DQN - INFO - episode 5 step 175 reward tensor([-1]) loss 0.4576070308685303 epsilon 0.7184850685945312
26-Feb-25 09:38:33 - agent.DQN.DQN - INFO - episode 5 step 176 reward tensor([-1]) loss 0.5711057782173157 epsilon 0.7184850685945312
26-Feb-25 09:38:33 - agent.DQN.DQN - INFO - episode 5 step 177 reward tensor([-1]) loss 0.39109236001968384 epsilon 0.7184850685945312
26-Feb-25 09:38:33 - agent.DQN.DQN - INFO - episode 5 step 178 reward tensor([-1]) loss 0.5243076682090759 epsilon 0.7184850685945312
26-Feb-25 09:38:33 - agent.DQN.DQN - INFO - episode 5 step 179 reward tensor([-1]) loss 0.4771167039871216 epsilon 0.7184850685945312
26-Feb-25 09:38:33 - agent.DQN.DQN - INFO - episode 5 step 180 reward tensor([-1]) loss 0.42736828327178955 epsilon 0.7184850685945312
26-Feb-25 09:38:33 - agent.DQN.DQN - INFO - episode 5 step 181 reward tensor([-1]) loss 0.4331243336200714 epsilon 0.7184850685945312
26-Feb-25 09:38:33 - agent.DQN.DQN - INFO - episode 5 step 182 reward tensor([-1]) loss 0.4252013564109802 epsilon 0.7184850685945312
26-Feb-25 09:38:33 - agent.DQN.DQN - INFO - episode 5 step 183 reward tensor([-1]) loss 0.5172267556190491 epsilon 0.7184850685945312
26-Feb-25 09:38:33 - agent.DQN.DQN - INFO - episode 5 step 184 reward tensor([-1]) loss 0.49667254090309143 epsilon 0.7184850685945312
26-Feb-25 09:38:33 - agent.DQN.DQN - INFO - episode 5 step 185 reward tensor([-1]) loss 0.4156244993209839 epsilon 0.7184850685945312
26-Feb-25 09:38:33 - agent.DQN.DQN - INFO - episode 5 step 186 reward tensor([-1]) loss 0.4887086749076843 epsilon 0.7184850685945312
26-Feb-25 09:38:33 - agent.DQN.DQN - INFO - episode 5 step 187 reward tensor([-1]) loss 0.5543434023857117 epsilon 0.7184850685945312
26-Feb-25 09:38:33 - agent.DQN.DQN - INFO - episode 5 step 188 reward tensor([-1]) loss 0.41439270973205566 epsilon 0.7184850685945312
26-Feb-25 09:38:33 - agent.DQN.DQN - INFO - episode 5 step 189 reward tensor([-1]) loss 0.580704927444458 epsilon 0.7184850685945312
26-Feb-25 09:38:33 - agent.DQN.DQN - INFO - episode 5 step 190 reward tensor([-1]) loss 0.5615643262863159 epsilon 0.7184850685945312
26-Feb-25 09:38:33 - agent.DQN.DQN - INFO - episode 5 step 191 reward tensor([-1]) loss 0.48933523893356323 epsilon 0.7184850685945312
26-Feb-25 09:38:33 - agent.DQN.DQN - INFO - episode 5 step 192 reward tensor([-1]) loss 0.5449386239051819 epsilon 0.7184850685945312
26-Feb-25 09:38:33 - agent.DQN.DQN - INFO - episode 5 step 193 reward tensor([-1]) loss 0.4930800497531891 epsilon 0.7184850685945312
26-Feb-25 09:38:33 - agent.DQN.DQN - INFO - episode 5 step 194 reward tensor([-1]) loss 0.4421052932739258 epsilon 0.7184850685945312
26-Feb-25 09:38:33 - agent.DQN.DQN - INFO - episode 5 step 195 reward tensor([-1]) loss 0.8281787633895874 epsilon 0.7184850685945312
26-Feb-25 09:38:33 - agent.DQN.DQN - INFO - episode 5 step 196 reward tensor([-1]) loss 0.6068353652954102 epsilon 0.7184850685945312
26-Feb-25 09:38:33 - agent.DQN.DQN - INFO - episode 5 step 197 reward tensor([-1]) loss 0.41742756962776184 epsilon 0.7184850685945312
26-Feb-25 09:38:33 - agent.DQN.DQN - INFO - episode 5 step 198 reward tensor([-1]) loss 0.4153788089752197 epsilon 0.7184850685945312
26-Feb-25 09:38:33 - agent.DQN.DQN - INFO - episode 5 step 199 reward tensor([-1]) loss 0.6306297779083252 epsilon 0.7184850685945312
26-Feb-25 09:38:33 - agent.DQN.DQN - INFO - episode 5 step 200 reward tensor([-1]) loss 0.41691863536834717 epsilon 0.7184850685945312
26-Feb-25 09:38:33 - agent.DQN.DQN - INFO - episode 5 step 201 reward tensor([-1]) loss 0.3083569407463074 epsilon 0.7184850685945312
26-Feb-25 09:38:33 - agent.DQN.DQN - INFO - episode 5 step 202 reward tensor([-1]) loss 0.5067753791809082 epsilon 0.7184850685945312
26-Feb-25 09:38:33 - agent.DQN.DQN - INFO - episode 5 step 203 reward tensor([-1]) loss 0.5670789480209351 epsilon 0.7184850685945312
26-Feb-25 09:38:33 - agent.DQN.DQN - INFO - episode 5 step 204 reward tensor([-1]) loss 0.5843483209609985 epsilon 0.7184850685945312
26-Feb-25 09:38:33 - agent.DQN.DQN - INFO - episode 5 step 205 reward tensor([-1]) loss 0.5793281197547913 epsilon 0.7184850685945312
26-Feb-25 09:38:33 - agent.DQN.DQN - INFO - episode 5 step 206 reward tensor([-1]) loss 0.4979313611984253 epsilon 0.7184850685945312
26-Feb-25 09:38:33 - agent.DQN.DQN - INFO - episode 5 step 207 reward tensor([-1]) loss 0.4842931032180786 epsilon 0.7184850685945312
26-Feb-25 09:38:33 - agent.DQN.DQN - INFO - episode 5 step 208 reward tensor([-1]) loss 0.4347497820854187 epsilon 0.7184850685945312
26-Feb-25 09:38:33 - agent.DQN.DQN - INFO - episode 5 step 209 reward tensor([-1]) loss 0.46878236532211304 epsilon 0.7184850685945312
26-Feb-25 09:38:33 - agent.DQN.DQN - INFO - episode 5 step 210 reward tensor([-1]) loss 0.4180021286010742 epsilon 0.7184850685945312
26-Feb-25 09:38:33 - agent.DQN.DQN - INFO - episode 5 step 211 reward tensor([-1]) loss 0.35983866453170776 epsilon 0.7184850685945312
26-Feb-25 09:38:33 - agent.DQN.DQN - INFO - episode 5 step 212 reward tensor([-1]) loss 0.6125366687774658 epsilon 0.7184850685945312
26-Feb-25 09:38:33 - agent.DQN.DQN - INFO - episode 5 step 213 reward tensor([-1]) loss 0.40442967414855957 epsilon 0.7184850685945312
26-Feb-25 09:38:33 - agent.DQN.DQN - INFO - episode 5 step 214 reward tensor([-1]) loss 0.3765677511692047 epsilon 0.7184850685945312
26-Feb-25 09:38:33 - agent.DQN.DQN - INFO - episode 5 step 215 reward tensor([-1]) loss 0.3901802897453308 epsilon 0.7184850685945312
26-Feb-25 09:38:33 - agent.DQN.DQN - INFO - episode 5 step 216 reward tensor([-1]) loss 0.6115585565567017 epsilon 0.7184850685945312
26-Feb-25 09:38:33 - agent.DQN.DQN - INFO - episode 5 step 217 reward tensor([-1]) loss 0.5583311915397644 epsilon 0.7184850685945312
26-Feb-25 09:38:33 - agent.DQN.DQN - INFO - episode 5 step 218 reward tensor([-1]) loss 0.4108395576477051 epsilon 0.7184850685945312
26-Feb-25 09:38:33 - agent.DQN.DQN - INFO - episode 5 step 219 reward tensor([-1]) loss 0.3663029968738556 epsilon 0.7184850685945312
26-Feb-25 09:38:33 - agent.DQN.DQN - INFO - episode 5 step 220 reward tensor([-1]) loss 0.38467937707901 epsilon 0.7184850685945312
26-Feb-25 09:38:33 - agent.DQN.DQN - INFO - episode 5 step 221 reward tensor([-1]) loss 0.3371294140815735 epsilon 0.7184850685945312
26-Feb-25 09:38:33 - agent.DQN.DQN - INFO - episode 5 step 222 reward tensor([-1]) loss 0.4090496301651001 epsilon 0.7184850685945312
26-Feb-25 09:38:33 - agent.DQN.DQN - INFO - episode 5 step 223 reward tensor([-1]) loss 0.40252238512039185 epsilon 0.7184850685945312
26-Feb-25 09:38:33 - agent.DQN.DQN - INFO - episode 5 step 224 reward tensor([-1]) loss 0.4306970536708832 epsilon 0.7184850685945312
26-Feb-25 09:38:33 - agent.DQN.DQN - INFO - episode 5 step 225 reward tensor([-1]) loss 0.3352257311344147 epsilon 0.7184850685945312
26-Feb-25 09:38:33 - agent.DQN.DQN - INFO - episode 5 step 226 reward tensor([-1]) loss 0.3782551884651184 epsilon 0.7184850685945312
26-Feb-25 09:38:33 - agent.DQN.DQN - INFO - episode 5 step 227 reward tensor([-1]) loss 0.3097155690193176 epsilon 0.7184850685945312
26-Feb-25 09:38:33 - agent.DQN.DQN - INFO - episode 5 step 228 reward tensor([-1]) loss 0.45768147706985474 epsilon 0.7184850685945312
26-Feb-25 09:38:33 - agent.DQN.DQN - INFO - episode 5 step 229 reward tensor([-1]) loss 0.3783189058303833 epsilon 0.7184850685945312
26-Feb-25 09:38:33 - agent.DQN.DQN - INFO - episode 5 step 230 reward tensor([-1]) loss 0.3173712491989136 epsilon 0.7184850685945312
26-Feb-25 09:38:33 - agent.DQN.DQN - INFO - episode 5 step 231 reward tensor([-1]) loss 0.389743447303772 epsilon 0.7184850685945312
26-Feb-25 09:38:33 - agent.DQN.DQN - INFO - episode 5 step 232 reward tensor([-1]) loss 0.49414414167404175 epsilon 0.7184850685945312
26-Feb-25 09:38:33 - agent.DQN.DQN - INFO - episode 5 step 233 reward tensor([-1]) loss 0.7176885008811951 epsilon 0.7184850685945312
26-Feb-25 09:38:34 - agent.DQN.DQN - INFO - episode 5 step 234 reward tensor([-1]) loss 0.5040204524993896 epsilon 0.7184850685945312
26-Feb-25 09:38:34 - agent.DQN.DQN - INFO - episode 5 step 235 reward tensor([-1]) loss 0.42992842197418213 epsilon 0.7184850685945312
26-Feb-25 09:38:34 - agent.DQN.DQN - INFO - episode 5 step 236 reward tensor([-1]) loss 0.40180131793022156 epsilon 0.7184850685945312
26-Feb-25 09:38:34 - agent.DQN.DQN - INFO - episode 5 step 237 reward tensor([-1]) loss 0.47819915413856506 epsilon 0.7184850685945312
26-Feb-25 09:38:34 - agent.DQN.DQN - INFO - episode 5 step 238 reward tensor([-1]) loss 0.3774487376213074 epsilon 0.7184850685945312
26-Feb-25 09:38:34 - agent.DQN.DQN - INFO - episode 5 step 239 reward tensor([-1]) loss 0.4409635365009308 epsilon 0.7184850685945312
26-Feb-25 09:38:34 - agent.DQN.DQN - INFO - episode 5 step 240 reward tensor([-1]) loss 0.41921669244766235 epsilon 0.7184850685945312
26-Feb-25 09:38:34 - agent.DQN.DQN - INFO - episode 5 step 241 reward tensor([-1]) loss 0.426994264125824 epsilon 0.7184850685945312
26-Feb-25 09:38:34 - agent.DQN.DQN - INFO - episode 5 step 242 reward tensor([-1]) loss 0.39877185225486755 epsilon 0.7184850685945312
26-Feb-25 09:38:34 - agent.DQN.DQN - INFO - episode 5 step 243 reward tensor([-1]) loss 0.5340537428855896 epsilon 0.7184850685945312
26-Feb-25 09:38:34 - agent.DQN.DQN - INFO - episode 5 step 244 reward tensor([-1]) loss 0.7194401025772095 epsilon 0.7184850685945312
26-Feb-25 09:38:34 - agent.DQN.DQN - INFO - episode 5 step 245 reward tensor([-1]) loss 0.38619425892829895 epsilon 0.7184850685945312
26-Feb-25 09:38:34 - agent.DQN.DQN - INFO - episode 5 step 246 reward tensor([-1]) loss 0.4953351318836212 epsilon 0.7184850685945312
26-Feb-25 09:38:34 - agent.DQN.DQN - INFO - episode 5 step 247 reward tensor([-1]) loss 0.4566688537597656 epsilon 0.7184850685945312
26-Feb-25 09:38:34 - agent.DQN.DQN - INFO - episode 5 step 248 reward tensor([-1]) loss 0.34100961685180664 epsilon 0.7184850685945312
26-Feb-25 09:38:34 - agent.DQN.DQN - INFO - episode 5 step 249 reward tensor([-1]) loss 0.7764225602149963 epsilon 0.7184850685945312
26-Feb-25 09:38:34 - agent.DQN.DQN - INFO - episode 5 step 250 reward tensor([-1]) loss 0.4145456850528717 epsilon 0.7184850685945312
26-Feb-25 09:38:34 - agent.DQN.DQN - INFO - episode 5 step 251 reward tensor([-1]) loss 0.6385576725006104 epsilon 0.7184850685945312
26-Feb-25 09:38:34 - agent.DQN.DQN - INFO - episode 5 step 252 reward tensor([-1]) loss 0.29017549753189087 epsilon 0.7184850685945312
26-Feb-25 09:38:34 - agent.DQN.DQN - INFO - episode 5 step 253 reward tensor([-1]) loss 0.7122790217399597 epsilon 0.7184850685945312
26-Feb-25 09:38:34 - agent.DQN.DQN - INFO - episode 5 step 254 reward tensor([-1]) loss 0.4373927116394043 epsilon 0.7184850685945312
26-Feb-25 09:38:34 - agent.DQN.DQN - INFO - episode 5 step 255 reward tensor([-1]) loss 0.6477216482162476 epsilon 0.7184850685945312
26-Feb-25 09:38:34 - agent.DQN.DQN - INFO - episode 5 step 256 reward tensor([-1]) loss 0.4862944185733795 epsilon 0.7184850685945312
26-Feb-25 09:38:34 - agent.DQN.DQN - INFO - episode 5 step 257 reward tensor([-1]) loss 0.7042796611785889 epsilon 0.7184850685945312
26-Feb-25 09:38:34 - agent.DQN.DQN - INFO - episode 5 step 258 reward tensor([-1]) loss 0.5360796451568604 epsilon 0.7184850685945312
26-Feb-25 09:38:34 - agent.DQN.DQN - INFO - episode 5 step 259 reward tensor([-1]) loss 0.4534728527069092 epsilon 0.7184850685945312
26-Feb-25 09:38:34 - agent.DQN.DQN - INFO - episode 5 step 260 reward tensor([-1]) loss 0.45763063430786133 epsilon 0.7184850685945312
26-Feb-25 09:38:34 - agent.DQN.DQN - INFO - episode 5 step 261 reward tensor([-1]) loss 0.3317856788635254 epsilon 0.7184850685945312
26-Feb-25 09:38:34 - agent.DQN.DQN - INFO - episode 5 step 262 reward tensor([-1]) loss 0.4492979645729065 epsilon 0.7184850685945312
26-Feb-25 09:38:34 - agent.DQN.DQN - INFO - episode 5 step 263 reward tensor([-1]) loss 0.7064779996871948 epsilon 0.7184850685945312
26-Feb-25 09:38:34 - agent.DQN.DQN - INFO - episode 5 step 264 reward tensor([-1]) loss 0.5334842205047607 epsilon 0.7184850685945312
26-Feb-25 09:38:34 - agent.DQN.DQN - INFO - episode 5 step 265 reward tensor([-1]) loss 0.5768347978591919 epsilon 0.7184850685945312
26-Feb-25 09:38:34 - agent.DQN.DQN - INFO - episode 5 step 266 reward tensor([-1]) loss 0.430245041847229 epsilon 0.7184850685945312
26-Feb-25 09:38:34 - agent.DQN.DQN - INFO - episode 5 step 267 reward tensor([-1]) loss 0.45168519020080566 epsilon 0.7184850685945312
26-Feb-25 09:38:34 - agent.DQN.DQN - INFO - episode 5 step 268 reward tensor([-1]) loss 0.3336598873138428 epsilon 0.7184850685945312
26-Feb-25 09:38:34 - agent.DQN.DQN - INFO - episode 5 step 269 reward tensor([-1]) loss 0.2653280794620514 epsilon 0.7184850685945312
26-Feb-25 09:38:34 - agent.DQN.DQN - INFO - episode 5 step 270 reward tensor([-1]) loss 0.4880741238594055 epsilon 0.7184850685945312
26-Feb-25 09:38:34 - agent.DQN.DQN - INFO - episode 5 step 271 reward tensor([-1]) loss 0.4964887201786041 epsilon 0.7184850685945312
26-Feb-25 09:38:34 - agent.DQN.DQN - INFO - episode 5 step 272 reward tensor([-1]) loss 0.392570436000824 epsilon 0.7184850685945312
26-Feb-25 09:38:34 - agent.DQN.DQN - INFO - episode 5 step 273 reward tensor([-1]) loss 0.5323856472969055 epsilon 0.7184850685945312
26-Feb-25 09:38:34 - agent.DQN.DQN - INFO - episode 5 step 274 reward tensor([-1]) loss 0.5404044389724731 epsilon 0.7184850685945312
26-Feb-25 09:38:34 - agent.DQN.DQN - INFO - episode 5 step 275 reward tensor([-1]) loss 0.3379914462566376 epsilon 0.7184850685945312
26-Feb-25 09:38:34 - agent.DQN.DQN - INFO - episode 5 step 276 reward tensor([-1]) loss 0.3817116320133209 epsilon 0.7184850685945312
26-Feb-25 09:38:34 - agent.DQN.DQN - INFO - episode 5 step 277 reward tensor([-1]) loss 0.35612165927886963 epsilon 0.7184850685945312
26-Feb-25 09:38:34 - agent.DQN.DQN - INFO - episode 5 step 278 reward tensor([-1]) loss 0.43253380060195923 epsilon 0.7184850685945312
26-Feb-25 09:38:34 - agent.DQN.DQN - INFO - episode 5 step 279 reward tensor([-1]) loss 0.3679192364215851 epsilon 0.7184850685945312
26-Feb-25 09:38:34 - agent.DQN.DQN - INFO - episode 5 step 280 reward tensor([-1]) loss 0.62004554271698 epsilon 0.7184850685945312
26-Feb-25 09:38:34 - agent.DQN.DQN - INFO - episode 5 step 281 reward tensor([-1]) loss 0.34663403034210205 epsilon 0.7184850685945312
26-Feb-25 09:38:34 - agent.DQN.DQN - INFO - episode 5 step 282 reward tensor([-1]) loss 0.38195857405662537 epsilon 0.7184850685945312
26-Feb-25 09:38:34 - agent.DQN.DQN - INFO - episode 5 step 283 reward tensor([-1]) loss 0.3239932060241699 epsilon 0.7184850685945312
26-Feb-25 09:38:34 - agent.DQN.DQN - INFO - episode 5 step 284 reward tensor([-1]) loss 0.4515455365180969 epsilon 0.7184850685945312
26-Feb-25 09:38:34 - agent.DQN.DQN - INFO - episode 5 step 285 reward tensor([-1]) loss 0.4044480621814728 epsilon 0.7184850685945312
26-Feb-25 09:38:34 - agent.DQN.DQN - INFO - episode 5 step 286 reward tensor([-1]) loss 0.41756197810173035 epsilon 0.7184850685945312
26-Feb-25 09:38:34 - agent.DQN.DQN - INFO - episode 5 step 287 reward tensor([-1]) loss 0.3018825054168701 epsilon 0.7184850685945312
26-Feb-25 09:38:34 - agent.DQN.DQN - INFO - episode 5 step 288 reward tensor([-1]) loss 0.3623899817466736 epsilon 0.7184850685945312
26-Feb-25 09:38:34 - agent.DQN.DQN - INFO - episode 5 step 289 reward tensor([-1]) loss 0.5750608444213867 epsilon 0.7184850685945312
26-Feb-25 09:38:34 - agent.DQN.DQN - INFO - episode 5 step 290 reward tensor([-1]) loss 0.3888956904411316 epsilon 0.7184850685945312
26-Feb-25 09:38:34 - agent.DQN.DQN - INFO - episode 5 step 291 reward tensor([-1]) loss 0.6485438346862793 epsilon 0.7184850685945312
26-Feb-25 09:38:34 - agent.DQN.DQN - INFO - episode 5 step 292 reward tensor([-1]) loss 0.4585679769515991 epsilon 0.7184850685945312
26-Feb-25 09:38:34 - agent.DQN.DQN - INFO - episode 5 step 293 reward tensor([-1]) loss 0.4656350016593933 epsilon 0.7184850685945312
26-Feb-25 09:38:34 - agent.DQN.DQN - INFO - episode 5 step 294 reward tensor([-1]) loss 0.5331100821495056 epsilon 0.7184850685945312
26-Feb-25 09:38:34 - agent.DQN.DQN - INFO - episode 5 step 295 reward tensor([-1]) loss 0.44166240096092224 epsilon 0.7184850685945312
26-Feb-25 09:38:34 - agent.DQN.DQN - INFO - episode 5 step 296 reward tensor([-1]) loss 0.438690721988678 epsilon 0.7184850685945312
26-Feb-25 09:38:34 - agent.DQN.DQN - INFO - episode 5 step 297 reward tensor([-1]) loss 0.46899744868278503 epsilon 0.7184850685945312
26-Feb-25 09:38:34 - agent.DQN.DQN - INFO - episode 5 step 298 reward tensor([-1]) loss 0.4076828062534332 epsilon 0.7184850685945312
26-Feb-25 09:38:34 - agent.DQN.DQN - INFO - episode 5 step 299 reward tensor([-1]) loss 0.4927740693092346 epsilon 0.7184850685945312
26-Feb-25 09:38:34 - agent.DQN.DQN - INFO - episode 5 step 300 reward tensor([-1]) loss 0.38975846767425537 epsilon 0.7184850685945312
26-Feb-25 09:38:34 - agent.DQN.DQN - INFO - episode 5 step 301 reward tensor([-1]) loss 0.5081709027290344 epsilon 0.7184850685945312
26-Feb-25 09:38:34 - agent.DQN.DQN - INFO - episode 6 step 0 reward tensor([-1]) loss 0.35549691319465637 epsilon 0.6951343038652089
26-Feb-25 09:38:34 - agent.DQN.DQN - INFO - episode 6 step 1 reward tensor([-1]) loss 0.4892377257347107 epsilon 0.6951343038652089
26-Feb-25 09:38:34 - agent.DQN.DQN - INFO - episode 6 step 2 reward tensor([-1]) loss 0.2972182035446167 epsilon 0.6951343038652089
26-Feb-25 09:38:34 - agent.DQN.DQN - INFO - episode 6 step 3 reward tensor([-1]) loss 0.3294176161289215 epsilon 0.6951343038652089
26-Feb-25 09:38:34 - agent.DQN.DQN - INFO - episode 6 step 4 reward tensor([-1]) loss 0.4068983793258667 epsilon 0.6951343038652089
26-Feb-25 09:38:34 - agent.DQN.DQN - INFO - episode 6 step 5 reward tensor([-1]) loss 0.27306628227233887 epsilon 0.6951343038652089
26-Feb-25 09:38:34 - agent.DQN.DQN - INFO - episode 6 step 6 reward tensor([-1]) loss 0.3974204361438751 epsilon 0.6951343038652089
26-Feb-25 09:38:35 - agent.DQN.DQN - INFO - episode 6 step 7 reward tensor([-1]) loss 0.41851362586021423 epsilon 0.6951343038652089
26-Feb-25 09:38:35 - agent.DQN.DQN - INFO - episode 6 step 8 reward tensor([-1]) loss 0.3188364505767822 epsilon 0.6951343038652089
26-Feb-25 09:38:35 - agent.DQN.DQN - INFO - episode 6 step 9 reward tensor([-1]) loss 0.6817267537117004 epsilon 0.6951343038652089
26-Feb-25 09:38:35 - agent.DQN.DQN - INFO - episode 6 step 10 reward tensor([-1]) loss 0.6483792662620544 epsilon 0.6951343038652089
26-Feb-25 09:38:35 - agent.DQN.DQN - INFO - episode 6 step 11 reward tensor([-1]) loss 0.27295440435409546 epsilon 0.6951343038652089
26-Feb-25 09:38:35 - agent.DQN.DQN - INFO - episode 6 step 12 reward tensor([-1]) loss 0.5838744640350342 epsilon 0.6951343038652089
26-Feb-25 09:38:35 - agent.DQN.DQN - INFO - episode 6 step 13 reward tensor([-1]) loss 0.2755727767944336 epsilon 0.6951343038652089
26-Feb-25 09:38:35 - agent.DQN.DQN - INFO - episode 6 step 14 reward tensor([-1]) loss 0.3320162892341614 epsilon 0.6951343038652089
26-Feb-25 09:38:35 - agent.DQN.DQN - INFO - episode 6 step 15 reward tensor([-1]) loss 0.5454511642456055 epsilon 0.6951343038652089
26-Feb-25 09:38:35 - agent.DQN.DQN - INFO - episode 6 step 16 reward tensor([-1]) loss 0.3895071744918823 epsilon 0.6951343038652089
26-Feb-25 09:38:35 - agent.DQN.DQN - INFO - episode 6 step 17 reward tensor([-1]) loss 0.3817031979560852 epsilon 0.6951343038652089
26-Feb-25 09:38:35 - agent.DQN.DQN - INFO - episode 6 step 18 reward tensor([-1]) loss 0.5789625644683838 epsilon 0.6951343038652089
26-Feb-25 09:38:35 - agent.DQN.DQN - INFO - episode 6 step 19 reward tensor([-1]) loss 0.3202510476112366 epsilon 0.6951343038652089
26-Feb-25 09:38:35 - agent.DQN.DQN - INFO - episode 6 step 20 reward tensor([-1]) loss 0.4814836084842682 epsilon 0.6951343038652089
26-Feb-25 09:38:35 - agent.DQN.DQN - INFO - episode 6 step 21 reward tensor([-1]) loss 0.8059201240539551 epsilon 0.6951343038652089
26-Feb-25 09:38:35 - agent.DQN.DQN - INFO - episode 6 step 22 reward tensor([-1]) loss 0.4338117241859436 epsilon 0.6951343038652089
26-Feb-25 09:38:35 - agent.DQN.DQN - INFO - episode 6 step 23 reward tensor([-1]) loss 0.5222399234771729 epsilon 0.6951343038652089
26-Feb-25 09:38:35 - agent.DQN.DQN - INFO - episode 6 step 24 reward tensor([-1]) loss 0.2788747549057007 epsilon 0.6951343038652089
26-Feb-25 09:38:35 - agent.DQN.DQN - INFO - episode 6 step 25 reward tensor([-1]) loss 0.41177433729171753 epsilon 0.6951343038652089
26-Feb-25 09:38:35 - agent.DQN.DQN - INFO - episode 6 step 26 reward tensor([-1]) loss 0.4806683659553528 epsilon 0.6951343038652089
26-Feb-25 09:38:35 - agent.DQN.DQN - INFO - episode 6 step 27 reward tensor([-1]) loss 0.465328186750412 epsilon 0.6951343038652089
26-Feb-25 09:38:35 - agent.DQN.DQN - INFO - episode 6 step 28 reward tensor([-1]) loss 0.44859108328819275 epsilon 0.6951343038652089
26-Feb-25 09:38:35 - agent.DQN.DQN - INFO - episode 6 step 29 reward tensor([-1]) loss 0.3186236321926117 epsilon 0.6951343038652089
26-Feb-25 09:38:35 - agent.DQN.DQN - INFO - episode 6 step 30 reward tensor([-1]) loss 0.38568463921546936 epsilon 0.6951343038652089
26-Feb-25 09:38:35 - agent.DQN.DQN - INFO - episode 6 step 31 reward tensor([-1]) loss 0.45526236295700073 epsilon 0.6951343038652089
26-Feb-25 09:38:35 - agent.DQN.DQN - INFO - episode 6 step 32 reward tensor([-1]) loss 0.2951582372188568 epsilon 0.6951343038652089
26-Feb-25 09:38:35 - agent.DQN.DQN - INFO - episode 6 step 33 reward tensor([-1]) loss 0.34797850251197815 epsilon 0.6951343038652089
26-Feb-25 09:38:35 - agent.DQN.DQN - INFO - episode 6 step 34 reward tensor([-1]) loss 0.4722819924354553 epsilon 0.6951343038652089
26-Feb-25 09:38:35 - agent.DQN.DQN - INFO - episode 6 step 35 reward tensor([-1]) loss 0.3617209196090698 epsilon 0.6951343038652089
26-Feb-25 09:38:35 - agent.DQN.DQN - INFO - episode 6 step 36 reward tensor([-1]) loss 0.3609204590320587 epsilon 0.6951343038652089
26-Feb-25 09:38:35 - agent.DQN.DQN - INFO - episode 6 step 37 reward tensor([-1]) loss 0.32483068108558655 epsilon 0.6951343038652089
26-Feb-25 09:38:35 - agent.DQN.DQN - INFO - episode 6 step 38 reward tensor([-1]) loss 0.3972042202949524 epsilon 0.6951343038652089
26-Feb-25 09:38:35 - agent.DQN.DQN - INFO - episode 6 step 39 reward tensor([-1]) loss 0.3587227165699005 epsilon 0.6951343038652089
26-Feb-25 09:38:35 - agent.DQN.DQN - INFO - episode 6 step 40 reward tensor([-1]) loss 0.32752543687820435 epsilon 0.6951343038652089
26-Feb-25 09:38:35 - agent.DQN.DQN - INFO - episode 6 step 41 reward tensor([-1]) loss 0.5713747143745422 epsilon 0.6951343038652089
26-Feb-25 09:38:35 - agent.DQN.DQN - INFO - episode 6 step 42 reward tensor([-1]) loss 0.36431047320365906 epsilon 0.6951343038652089
26-Feb-25 09:38:35 - agent.DQN.DQN - INFO - episode 6 step 43 reward tensor([-1]) loss 0.40563130378723145 epsilon 0.6951343038652089
26-Feb-25 09:38:35 - agent.DQN.DQN - INFO - episode 6 step 44 reward tensor([-1]) loss 0.36039790511131287 epsilon 0.6951343038652089
26-Feb-25 09:38:35 - agent.DQN.DQN - INFO - episode 6 step 45 reward tensor([-1]) loss 0.3369602560997009 epsilon 0.6951343038652089
26-Feb-25 09:38:35 - agent.DQN.DQN - INFO - episode 6 step 46 reward tensor([-1]) loss 0.37053585052490234 epsilon 0.6951343038652089
26-Feb-25 09:38:35 - agent.DQN.DQN - INFO - episode 6 step 47 reward tensor([-1]) loss 0.39134037494659424 epsilon 0.6951343038652089
26-Feb-25 09:38:35 - agent.DQN.DQN - INFO - episode 6 step 48 reward tensor([-1]) loss 0.30374395847320557 epsilon 0.6951343038652089
26-Feb-25 09:38:35 - agent.DQN.DQN - INFO - episode 6 step 49 reward tensor([-1]) loss 0.4044971168041229 epsilon 0.6951343038652089
26-Feb-25 09:38:35 - agent.DQN.DQN - INFO - episode 6 step 50 reward tensor([-1]) loss 0.6170293092727661 epsilon 0.6951343038652089
26-Feb-25 09:38:35 - agent.DQN.DQN - INFO - episode 6 step 51 reward tensor([-1]) loss 0.7169350385665894 epsilon 0.6951343038652089
26-Feb-25 09:38:35 - agent.DQN.DQN - INFO - episode 6 step 52 reward tensor([-1]) loss 0.4960893392562866 epsilon 0.6951343038652089
26-Feb-25 09:38:35 - agent.DQN.DQN - INFO - episode 6 step 53 reward tensor([-1]) loss 0.418087899684906 epsilon 0.6951343038652089
26-Feb-25 09:38:35 - agent.DQN.DQN - INFO - episode 6 step 54 reward tensor([-1]) loss 0.6103252172470093 epsilon 0.6951343038652089
26-Feb-25 09:38:35 - agent.DQN.DQN - INFO - episode 6 step 55 reward tensor([-1]) loss 0.40899521112442017 epsilon 0.6951343038652089
26-Feb-25 09:38:35 - agent.DQN.DQN - INFO - episode 6 step 56 reward tensor([-1]) loss 0.49049466848373413 epsilon 0.6951343038652089
26-Feb-25 09:38:35 - agent.DQN.DQN - INFO - episode 6 step 57 reward tensor([-1]) loss 0.45825809240341187 epsilon 0.6951343038652089
26-Feb-25 09:38:35 - agent.DQN.DQN - INFO - episode 6 step 58 reward tensor([-1]) loss 0.40943753719329834 epsilon 0.6951343038652089
26-Feb-25 09:38:35 - agent.DQN.DQN - INFO - episode 6 step 59 reward tensor([-1]) loss 0.36919960379600525 epsilon 0.6951343038652089
26-Feb-25 09:38:35 - agent.DQN.DQN - INFO - episode 6 step 60 reward tensor([-1]) loss 0.4422072768211365 epsilon 0.6951343038652089
26-Feb-25 09:38:35 - agent.DQN.DQN - INFO - episode 6 step 61 reward tensor([-1]) loss 0.40344515442848206 epsilon 0.6951343038652089
26-Feb-25 09:38:35 - agent.DQN.DQN - INFO - episode 6 step 62 reward tensor([-1]) loss 0.4432377517223358 epsilon 0.6951343038652089
26-Feb-25 09:38:35 - agent.DQN.DQN - INFO - episode 6 step 63 reward tensor([-1]) loss 0.3007194995880127 epsilon 0.6951343038652089
26-Feb-25 09:38:35 - agent.DQN.DQN - INFO - episode 6 step 64 reward tensor([-1]) loss 0.39972788095474243 epsilon 0.6951343038652089
26-Feb-25 09:38:35 - agent.DQN.DQN - INFO - episode 6 step 65 reward tensor([-1]) loss 0.3702983260154724 epsilon 0.6951343038652089
26-Feb-25 09:38:35 - agent.DQN.DQN - INFO - episode 6 step 66 reward tensor([-1]) loss 0.39042162895202637 epsilon 0.6951343038652089
26-Feb-25 09:38:35 - agent.DQN.DQN - INFO - episode 6 step 67 reward tensor([-1]) loss 0.43413254618644714 epsilon 0.6951343038652089
26-Feb-25 09:38:35 - agent.DQN.DQN - INFO - episode 6 step 68 reward tensor([-1]) loss 0.5083346962928772 epsilon 0.6951343038652089
26-Feb-25 09:38:35 - agent.DQN.DQN - INFO - episode 6 step 69 reward tensor([-1]) loss 0.4362037777900696 epsilon 0.6951343038652089
26-Feb-25 09:38:35 - agent.DQN.DQN - INFO - episode 6 step 70 reward tensor([-1]) loss 0.3443021774291992 epsilon 0.6951343038652089
26-Feb-25 09:38:35 - agent.DQN.DQN - INFO - episode 6 step 71 reward tensor([-1]) loss 0.2933245897293091 epsilon 0.6951343038652089
26-Feb-25 09:38:35 - agent.DQN.DQN - INFO - episode 6 step 72 reward tensor([-1]) loss 0.4662686884403229 epsilon 0.6951343038652089
26-Feb-25 09:38:35 - agent.DQN.DQN - INFO - episode 6 step 73 reward tensor([-1]) loss 0.4295503497123718 epsilon 0.6951343038652089
26-Feb-25 09:38:35 - agent.DQN.DQN - INFO - episode 6 step 74 reward tensor([-1]) loss 0.366142213344574 epsilon 0.6951343038652089
26-Feb-25 09:38:35 - agent.DQN.DQN - INFO - episode 6 step 75 reward tensor([-1]) loss 0.30105558037757874 epsilon 0.6951343038652089
26-Feb-25 09:38:35 - agent.DQN.DQN - INFO - episode 6 step 76 reward tensor([-1]) loss 0.3254687488079071 epsilon 0.6951343038652089
26-Feb-25 09:38:35 - agent.DQN.DQN - INFO - episode 6 step 77 reward tensor([-1]) loss 0.42927759885787964 epsilon 0.6951343038652089
26-Feb-25 09:38:35 - agent.DQN.DQN - INFO - episode 6 step 78 reward tensor([-1]) loss 0.4309830665588379 epsilon 0.6951343038652089
26-Feb-25 09:38:35 - agent.DQN.DQN - INFO - episode 6 step 79 reward tensor([-1]) loss 0.35528796911239624 epsilon 0.6951343038652089
26-Feb-25 09:38:35 - agent.DQN.DQN - INFO - episode 6 step 80 reward tensor([-1]) loss 0.38239866495132446 epsilon 0.6951343038652089
26-Feb-25 09:38:35 - agent.DQN.DQN - INFO - episode 6 step 81 reward tensor([-1]) loss 0.4211263954639435 epsilon 0.6951343038652089
26-Feb-25 09:38:35 - agent.DQN.DQN - INFO - episode 6 step 82 reward tensor([-1]) loss 0.43553590774536133 epsilon 0.6951343038652089
26-Feb-25 09:38:35 - agent.DQN.DQN - INFO - episode 6 step 83 reward tensor([-1]) loss 0.35683926939964294 epsilon 0.6951343038652089
26-Feb-25 09:38:35 - agent.DQN.DQN - INFO - episode 6 step 84 reward tensor([-1]) loss 0.37827104330062866 epsilon 0.6951343038652089
26-Feb-25 09:38:35 - agent.DQN.DQN - INFO - episode 6 step 85 reward tensor([-1]) loss 0.36432087421417236 epsilon 0.6951343038652089
26-Feb-25 09:38:35 - agent.DQN.DQN - INFO - episode 6 step 86 reward tensor([-1]) loss 0.283991277217865 epsilon 0.6951343038652089
26-Feb-25 09:38:35 - agent.DQN.DQN - INFO - episode 6 step 87 reward tensor([-1]) loss 0.4464862048625946 epsilon 0.6951343038652089
26-Feb-25 09:38:35 - agent.DQN.DQN - INFO - episode 6 step 88 reward tensor([-1]) loss 0.3920057415962219 epsilon 0.6951343038652089
26-Feb-25 09:38:35 - agent.DQN.DQN - INFO - episode 6 step 89 reward tensor([-1]) loss 0.4349549412727356 epsilon 0.6951343038652089
26-Feb-25 09:38:36 - agent.DQN.DQN - INFO - episode 6 step 90 reward tensor([-1]) loss 0.32191741466522217 epsilon 0.6951343038652089
26-Feb-25 09:38:36 - agent.DQN.DQN - INFO - episode 6 step 91 reward tensor([-1]) loss 0.3603892922401428 epsilon 0.6951343038652089
26-Feb-25 09:38:36 - agent.DQN.DQN - INFO - episode 6 step 92 reward tensor([-1]) loss 0.4915984869003296 epsilon 0.6951343038652089
26-Feb-25 09:38:36 - agent.DQN.DQN - INFO - episode 6 step 93 reward tensor([-1]) loss 0.38362810015678406 epsilon 0.6951343038652089
26-Feb-25 09:38:36 - agent.DQN.DQN - INFO - episode 6 step 94 reward tensor([-1]) loss 0.3750331401824951 epsilon 0.6951343038652089
26-Feb-25 09:38:36 - agent.DQN.DQN - INFO - episode 6 step 95 reward tensor([-1]) loss 0.2831823229789734 epsilon 0.6951343038652089
26-Feb-25 09:38:36 - agent.DQN.DQN - INFO - episode 6 step 96 reward tensor([-1]) loss 0.33949679136276245 epsilon 0.6951343038652089
26-Feb-25 09:38:36 - agent.DQN.DQN - INFO - episode 6 step 97 reward tensor([-1]) loss 0.3118022680282593 epsilon 0.6951343038652089
26-Feb-25 09:38:36 - agent.DQN.DQN - INFO - episode 6 step 98 reward tensor([-1]) loss 0.32610559463500977 epsilon 0.6951343038652089
26-Feb-25 09:38:36 - agent.DQN.DQN - INFO - episode 6 step 99 reward tensor([-1]) loss 0.33923661708831787 epsilon 0.6951343038652089
26-Feb-25 09:38:36 - agent.DQN.DQN - INFO - episode 6 step 100 reward tensor([-1]) loss 0.40533703565597534 epsilon 0.6951343038652089
26-Feb-25 09:38:36 - agent.DQN.DQN - INFO - episode 6 step 101 reward tensor([-1]) loss 0.32242852449417114 epsilon 0.6951343038652089
26-Feb-25 09:38:36 - agent.DQN.DQN - INFO - episode 6 step 102 reward tensor([-1]) loss 0.32971063256263733 epsilon 0.6951343038652089
26-Feb-25 09:38:36 - agent.DQN.DQN - INFO - episode 6 step 103 reward tensor([-1]) loss 0.3766695261001587 epsilon 0.6951343038652089
26-Feb-25 09:38:36 - agent.DQN.DQN - INFO - episode 6 step 104 reward tensor([-1]) loss 0.36574167013168335 epsilon 0.6951343038652089
26-Feb-25 09:38:36 - agent.DQN.DQN - INFO - episode 6 step 105 reward tensor([-1]) loss 0.8937434554100037 epsilon 0.6951343038652089
26-Feb-25 09:38:36 - agent.DQN.DQN - INFO - episode 6 step 106 reward tensor([-1]) loss 0.3473733961582184 epsilon 0.6951343038652089
26-Feb-25 09:38:36 - agent.DQN.DQN - INFO - episode 6 step 107 reward tensor([-1]) loss 0.3191320598125458 epsilon 0.6951343038652089
26-Feb-25 09:38:36 - agent.DQN.DQN - INFO - episode 6 step 108 reward tensor([-1]) loss 0.40725767612457275 epsilon 0.6951343038652089
26-Feb-25 09:38:36 - agent.DQN.DQN - INFO - episode 6 step 109 reward tensor([-1]) loss 0.30145350098609924 epsilon 0.6951343038652089
26-Feb-25 09:38:36 - agent.DQN.DQN - INFO - episode 6 step 110 reward tensor([-1]) loss 0.3672328591346741 epsilon 0.6951343038652089
26-Feb-25 09:38:36 - agent.DQN.DQN - INFO - episode 6 step 111 reward tensor([-1]) loss 0.42150214314460754 epsilon 0.6951343038652089
26-Feb-25 09:38:36 - agent.DQN.DQN - INFO - episode 6 step 112 reward tensor([-1]) loss 0.3892999589443207 epsilon 0.6951343038652089
26-Feb-25 09:38:36 - agent.DQN.DQN - INFO - episode 6 step 113 reward tensor([-1]) loss 0.3411642014980316 epsilon 0.6951343038652089
26-Feb-25 09:38:36 - agent.DQN.DQN - INFO - episode 6 step 114 reward tensor([-1]) loss 0.34276634454727173 epsilon 0.6951343038652089
26-Feb-25 09:38:36 - agent.DQN.DQN - INFO - episode 6 step 115 reward tensor([-1]) loss 0.37407931685447693 epsilon 0.6951343038652089
26-Feb-25 09:38:36 - agent.DQN.DQN - INFO - episode 6 step 116 reward tensor([-1]) loss 0.34005969762802124 epsilon 0.6951343038652089
26-Feb-25 09:38:36 - agent.DQN.DQN - INFO - episode 6 step 117 reward tensor([-1]) loss 0.3326120972633362 epsilon 0.6951343038652089
26-Feb-25 09:38:36 - agent.DQN.DQN - INFO - episode 6 step 118 reward tensor([-1]) loss 0.3799893260002136 epsilon 0.6951343038652089
26-Feb-25 09:38:36 - agent.DQN.DQN - INFO - episode 6 step 119 reward tensor([-1]) loss 0.3405328392982483 epsilon 0.6951343038652089
26-Feb-25 09:38:36 - agent.DQN.DQN - INFO - episode 6 step 120 reward tensor([-1]) loss 0.3867265284061432 epsilon 0.6951343038652089
26-Feb-25 09:38:36 - agent.DQN.DQN - INFO - episode 6 step 121 reward tensor([-1]) loss 0.2706076204776764 epsilon 0.6951343038652089
26-Feb-25 09:38:36 - agent.DQN.DQN - INFO - episode 6 step 122 reward tensor([-1]) loss 0.2850457727909088 epsilon 0.6951343038652089
26-Feb-25 09:38:36 - agent.DQN.DQN - INFO - episode 6 step 123 reward tensor([-1]) loss 0.33730748295783997 epsilon 0.6951343038652089
26-Feb-25 09:38:36 - agent.DQN.DQN - INFO - episode 6 step 124 reward tensor([-1]) loss 0.37982553243637085 epsilon 0.6951343038652089
26-Feb-25 09:38:36 - agent.DQN.DQN - INFO - episode 6 step 125 reward tensor([-1]) loss 0.33030107617378235 epsilon 0.6951343038652089
26-Feb-25 09:38:36 - agent.DQN.DQN - INFO - episode 6 step 126 reward tensor([-1]) loss 0.37612324953079224 epsilon 0.6951343038652089
26-Feb-25 09:38:36 - agent.DQN.DQN - INFO - episode 6 step 127 reward tensor([-1]) loss 0.2612142562866211 epsilon 0.6951343038652089
26-Feb-25 09:38:36 - agent.DQN.DQN - INFO - episode 6 step 128 reward tensor([-1]) loss 0.2718144953250885 epsilon 0.6951343038652089
26-Feb-25 09:38:36 - agent.DQN.DQN - INFO - episode 6 step 129 reward tensor([-1]) loss 0.297972708940506 epsilon 0.6951343038652089
26-Feb-25 09:38:36 - agent.DQN.DQN - INFO - episode 6 step 130 reward tensor([-1]) loss 0.360964834690094 epsilon 0.6951343038652089
26-Feb-25 09:38:36 - agent.DQN.DQN - INFO - episode 6 step 131 reward tensor([-1]) loss 0.2796136140823364 epsilon 0.6951343038652089
26-Feb-25 09:38:36 - agent.DQN.DQN - INFO - episode 6 step 132 reward tensor([-1]) loss 0.3783154785633087 epsilon 0.6951343038652089
26-Feb-25 09:38:36 - agent.DQN.DQN - INFO - episode 6 step 133 reward tensor([-1]) loss 0.6980270743370056 epsilon 0.6951343038652089
26-Feb-25 09:38:36 - agent.DQN.DQN - INFO - episode 6 step 134 reward tensor([-1]) loss 0.34539586305618286 epsilon 0.6951343038652089
26-Feb-25 09:38:36 - agent.DQN.DQN - INFO - episode 6 step 135 reward tensor([-1]) loss 0.6598666906356812 epsilon 0.6951343038652089
26-Feb-25 09:38:36 - agent.DQN.DQN - INFO - episode 6 step 136 reward tensor([-1]) loss 0.33880382776260376 epsilon 0.6951343038652089
26-Feb-25 09:38:36 - agent.DQN.DQN - INFO - episode 6 step 137 reward tensor([-1]) loss 0.3445037305355072 epsilon 0.6951343038652089
26-Feb-25 09:38:36 - agent.DQN.DQN - INFO - episode 6 step 138 reward tensor([-1]) loss 0.42311787605285645 epsilon 0.6951343038652089
26-Feb-25 09:38:36 - agent.DQN.DQN - INFO - episode 6 step 139 reward tensor([-1]) loss 0.31409937143325806 epsilon 0.6951343038652089
26-Feb-25 09:38:36 - agent.DQN.DQN - INFO - episode 6 step 140 reward tensor([-1]) loss 0.40272825956344604 epsilon 0.6951343038652089
26-Feb-25 09:38:36 - agent.DQN.DQN - INFO - episode 6 step 141 reward tensor([-1]) loss 0.46366801857948303 epsilon 0.6951343038652089
26-Feb-25 09:38:36 - agent.DQN.DQN - INFO - episode 6 step 142 reward tensor([-1]) loss 0.4073476791381836 epsilon 0.6951343038652089
26-Feb-25 09:38:36 - agent.DQN.DQN - INFO - episode 6 step 143 reward tensor([-1]) loss 0.7593842148780823 epsilon 0.6951343038652089
26-Feb-25 09:38:36 - agent.DQN.DQN - INFO - episode 6 step 144 reward tensor([-1]) loss 0.3206771910190582 epsilon 0.6951343038652089
26-Feb-25 09:38:36 - agent.DQN.DQN - INFO - episode 6 step 145 reward tensor([-1]) loss 0.6809628009796143 epsilon 0.6951343038652089
26-Feb-25 09:38:36 - agent.DQN.DQN - INFO - episode 6 step 146 reward tensor([-1]) loss 0.5688987374305725 epsilon 0.6951343038652089
26-Feb-25 09:38:36 - agent.DQN.DQN - INFO - episode 6 step 147 reward tensor([-1]) loss 0.7748836278915405 epsilon 0.6951343038652089
26-Feb-25 09:38:36 - agent.DQN.DQN - INFO - episode 6 step 148 reward tensor([-1]) loss 0.36039304733276367 epsilon 0.6951343038652089
26-Feb-25 09:38:36 - agent.DQN.DQN - INFO - episode 6 step 149 reward tensor([-1]) loss 0.6256112456321716 epsilon 0.6951343038652089
26-Feb-25 09:38:36 - agent.DQN.DQN - INFO - episode 6 step 150 reward tensor([-1]) loss 0.3880424499511719 epsilon 0.6951343038652089
26-Feb-25 09:38:36 - agent.DQN.DQN - INFO - episode 6 step 151 reward tensor([-1]) loss 1.7904598712921143 epsilon 0.6951343038652089
26-Feb-25 09:38:36 - agent.DQN.DQN - INFO - episode 6 step 152 reward tensor([-1]) loss 0.40564948320388794 epsilon 0.6951343038652089
26-Feb-25 09:38:36 - agent.DQN.DQN - INFO - episode 6 step 153 reward tensor([-1]) loss 1.6132147312164307 epsilon 0.6951343038652089
26-Feb-25 09:38:36 - agent.DQN.DQN - INFO - episode 6 step 154 reward tensor([-1]) loss 0.49456965923309326 epsilon 0.6951343038652089
26-Feb-25 09:38:36 - agent.DQN.DQN - INFO - episode 6 step 155 reward tensor([-1]) loss 0.7184513211250305 epsilon 0.6951343038652089
26-Feb-25 09:38:36 - agent.DQN.DQN - INFO - episode 6 step 156 reward tensor([-1]) loss 0.9602965712547302 epsilon 0.6951343038652089
26-Feb-25 09:38:36 - agent.DQN.DQN - INFO - episode 6 step 157 reward tensor([-1]) loss 0.5712515115737915 epsilon 0.6951343038652089
26-Feb-25 09:38:36 - agent.DQN.DQN - INFO - episode 6 step 158 reward tensor([-1]) loss 0.36463791131973267 epsilon 0.6951343038652089
26-Feb-25 09:38:36 - agent.DQN.DQN - INFO - episode 6 step 159 reward tensor([-1]) loss 0.4329927861690521 epsilon 0.6951343038652089
26-Feb-25 09:38:36 - agent.DQN.DQN - INFO - episode 6 step 160 reward tensor([-1]) loss 0.4885796010494232 epsilon 0.6951343038652089
26-Feb-25 09:38:36 - agent.DQN.DQN - INFO - episode 6 step 161 reward tensor([-1]) loss 0.3973855972290039 epsilon 0.6951343038652089
26-Feb-25 09:38:36 - agent.DQN.DQN - INFO - episode 6 step 162 reward tensor([-1]) loss 0.6823245882987976 epsilon 0.6951343038652089
26-Feb-25 09:38:36 - agent.DQN.DQN - INFO - episode 6 step 163 reward tensor([-1]) loss 0.43391984701156616 epsilon 0.6951343038652089
26-Feb-25 09:38:36 - agent.DQN.DQN - INFO - episode 6 step 164 reward tensor([-1]) loss 0.8355115652084351 epsilon 0.6951343038652089
26-Feb-25 09:38:37 - agent.DQN.DQN - INFO - episode 6 step 165 reward tensor([-1]) loss 0.3958618640899658 epsilon 0.6951343038652089
26-Feb-25 09:38:37 - agent.DQN.DQN - INFO - episode 6 step 166 reward tensor([-1]) loss 0.9335783123970032 epsilon 0.6951343038652089
26-Feb-25 09:38:37 - agent.DQN.DQN - INFO - episode 6 step 167 reward tensor([-1]) loss 0.31161054968833923 epsilon 0.6951343038652089
26-Feb-25 09:38:37 - agent.DQN.DQN - INFO - episode 6 step 168 reward tensor([-1]) loss 2.101952075958252 epsilon 0.6951343038652089
26-Feb-25 09:38:37 - agent.DQN.DQN - INFO - episode 6 step 169 reward tensor([-1]) loss 0.8419831991195679 epsilon 0.6951343038652089
26-Feb-25 09:38:37 - agent.DQN.DQN - INFO - episode 6 step 170 reward tensor([-1]) loss 0.6801059246063232 epsilon 0.6951343038652089
26-Feb-25 09:38:37 - agent.DQN.DQN - INFO - episode 6 step 171 reward tensor([-1]) loss 1.858338713645935 epsilon 0.6951343038652089
26-Feb-25 09:38:37 - agent.DQN.DQN - INFO - episode 6 step 172 reward tensor([-1]) loss 0.41947200894355774 epsilon 0.6951343038652089
26-Feb-25 09:38:37 - agent.DQN.DQN - INFO - episode 6 step 173 reward tensor([-1]) loss 0.436298131942749 epsilon 0.6951343038652089
26-Feb-25 09:38:37 - agent.DQN.DQN - INFO - episode 6 step 174 reward tensor([-1]) loss 0.7508428692817688 epsilon 0.6951343038652089
26-Feb-25 09:38:37 - agent.DQN.DQN - INFO - episode 6 step 175 reward tensor([-1]) loss 2.1558330059051514 epsilon 0.6951343038652089
26-Feb-25 09:38:37 - agent.DQN.DQN - INFO - episode 6 step 176 reward tensor([-1]) loss 0.3261489272117615 epsilon 0.6951343038652089
26-Feb-25 09:38:37 - agent.DQN.DQN - INFO - episode 6 step 177 reward tensor([-1]) loss 0.3147130608558655 epsilon 0.6951343038652089
26-Feb-25 09:38:37 - agent.DQN.DQN - INFO - episode 6 step 178 reward tensor([-1]) loss 0.7904596328735352 epsilon 0.6951343038652089
26-Feb-25 09:38:37 - agent.DQN.DQN - INFO - episode 6 step 179 reward tensor([-1]) loss 0.8678843975067139 epsilon 0.6951343038652089
26-Feb-25 09:38:37 - agent.DQN.DQN - INFO - episode 6 step 180 reward tensor([-1]) loss 0.7563959360122681 epsilon 0.6951343038652089
26-Feb-25 09:38:37 - agent.DQN.DQN - INFO - episode 6 step 181 reward tensor([-1]) loss 0.5508940815925598 epsilon 0.6951343038652089
26-Feb-25 09:38:37 - agent.DQN.DQN - INFO - episode 6 step 182 reward tensor([-1]) loss 0.5758667588233948 epsilon 0.6951343038652089
26-Feb-25 09:38:37 - agent.DQN.DQN - INFO - episode 6 step 183 reward tensor([-1]) loss 0.5747884511947632 epsilon 0.6951343038652089
26-Feb-25 09:38:37 - agent.DQN.DQN - INFO - episode 6 step 184 reward tensor([-1]) loss 0.524991512298584 epsilon 0.6951343038652089
26-Feb-25 09:38:37 - agent.DQN.DQN - INFO - episode 6 step 185 reward tensor([-1]) loss 0.3827507197856903 epsilon 0.6951343038652089
26-Feb-25 09:38:37 - agent.DQN.DQN - INFO - episode 6 step 186 reward tensor([-1]) loss 0.3275035321712494 epsilon 0.6951343038652089
26-Feb-25 09:38:37 - agent.DQN.DQN - INFO - episode 6 step 187 reward tensor([-1]) loss 0.4673304259777069 epsilon 0.6951343038652089
26-Feb-25 09:38:37 - agent.DQN.DQN - INFO - episode 6 step 188 reward tensor([-1]) loss 0.43414604663848877 epsilon 0.6951343038652089
26-Feb-25 09:38:37 - agent.DQN.DQN - INFO - episode 6 step 189 reward tensor([-1]) loss 0.7229659557342529 epsilon 0.6951343038652089
26-Feb-25 09:38:37 - agent.DQN.DQN - INFO - episode 6 step 190 reward tensor([-1]) loss 0.5343128442764282 epsilon 0.6951343038652089
26-Feb-25 09:38:37 - agent.DQN.DQN - INFO - episode 6 step 191 reward tensor([-1]) loss 0.8887686729431152 epsilon 0.6951343038652089
26-Feb-25 09:38:37 - agent.DQN.DQN - INFO - episode 6 step 192 reward tensor([-1]) loss 0.5423312783241272 epsilon 0.6951343038652089
26-Feb-25 09:38:37 - agent.DQN.DQN - INFO - episode 6 step 193 reward tensor([-1]) loss 0.8789128661155701 epsilon 0.6951343038652089
26-Feb-25 09:38:37 - agent.DQN.DQN - INFO - episode 6 step 194 reward tensor([-1]) loss 0.824268639087677 epsilon 0.6951343038652089
26-Feb-25 09:38:37 - agent.DQN.DQN - INFO - episode 6 step 195 reward tensor([-1]) loss 0.6902806758880615 epsilon 0.6951343038652089
26-Feb-25 09:38:37 - agent.DQN.DQN - INFO - episode 6 step 196 reward tensor([-1]) loss 0.5954424142837524 epsilon 0.6951343038652089
26-Feb-25 09:38:37 - agent.DQN.DQN - INFO - episode 6 step 197 reward tensor([-1]) loss 0.7061179876327515 epsilon 0.6951343038652089
26-Feb-25 09:38:37 - agent.DQN.DQN - INFO - episode 6 step 198 reward tensor([-1]) loss 0.6298205852508545 epsilon 0.6951343038652089
26-Feb-25 09:38:37 - agent.DQN.DQN - INFO - episode 6 step 199 reward tensor([-1]) loss 0.4643268585205078 epsilon 0.6951343038652089
26-Feb-25 09:38:37 - agent.DQN.DQN - INFO - episode 6 step 200 reward tensor([-1]) loss 0.8955391645431519 epsilon 0.6951343038652089
26-Feb-25 09:38:37 - agent.DQN.DQN - INFO - episode 6 step 201 reward tensor([-1]) loss 0.7444654107093811 epsilon 0.6951343038652089
26-Feb-25 09:38:37 - agent.DQN.DQN - INFO - episode 6 step 202 reward tensor([-1]) loss 0.8471866250038147 epsilon 0.6951343038652089
26-Feb-25 09:38:37 - agent.DQN.DQN - INFO - episode 6 step 203 reward tensor([-1]) loss 0.6416511535644531 epsilon 0.6951343038652089
26-Feb-25 09:38:37 - agent.DQN.DQN - INFO - episode 6 step 204 reward tensor([-1]) loss 0.525270402431488 epsilon 0.6951343038652089
26-Feb-25 09:38:37 - agent.DQN.DQN - INFO - episode 6 step 205 reward tensor([-1]) loss 0.722048282623291 epsilon 0.6951343038652089
26-Feb-25 09:38:37 - agent.DQN.DQN - INFO - episode 6 step 206 reward tensor([-1]) loss 0.607417106628418 epsilon 0.6951343038652089
26-Feb-25 09:38:37 - agent.DQN.DQN - INFO - episode 6 step 207 reward tensor([-1]) loss 0.4384145438671112 epsilon 0.6951343038652089
26-Feb-25 09:38:37 - agent.DQN.DQN - INFO - episode 6 step 208 reward tensor([-1]) loss 0.6937286257743835 epsilon 0.6951343038652089
26-Feb-25 09:38:37 - agent.DQN.DQN - INFO - episode 6 step 209 reward tensor([-1]) loss 0.5569342970848083 epsilon 0.6951343038652089
26-Feb-25 09:38:37 - agent.DQN.DQN - INFO - episode 6 step 210 reward tensor([-1]) loss 0.6980297565460205 epsilon 0.6951343038652089
26-Feb-25 09:38:37 - agent.DQN.DQN - INFO - episode 6 step 211 reward tensor([-1]) loss 0.6416576504707336 epsilon 0.6951343038652089
26-Feb-25 09:38:37 - agent.DQN.DQN - INFO - episode 6 step 212 reward tensor([-1]) loss 0.5759270787239075 epsilon 0.6951343038652089
26-Feb-25 09:38:37 - agent.DQN.DQN - INFO - episode 6 step 213 reward tensor([-1]) loss 0.9765007495880127 epsilon 0.6951343038652089
26-Feb-25 09:38:37 - agent.DQN.DQN - INFO - episode 6 step 214 reward tensor([-1]) loss 0.3999820053577423 epsilon 0.6951343038652089
26-Feb-25 09:38:37 - agent.DQN.DQN - INFO - episode 6 step 215 reward tensor([-1]) loss 0.4283772110939026 epsilon 0.6951343038652089
26-Feb-25 09:38:37 - agent.DQN.DQN - INFO - episode 6 step 216 reward tensor([-1]) loss 0.525467038154602 epsilon 0.6951343038652089
26-Feb-25 09:38:37 - agent.DQN.DQN - INFO - episode 6 step 217 reward tensor([-1]) loss 0.5658474564552307 epsilon 0.6951343038652089
26-Feb-25 09:38:37 - agent.DQN.DQN - INFO - episode 6 step 218 reward tensor([-1]) loss 0.5473847389221191 epsilon 0.6951343038652089
26-Feb-25 09:38:37 - agent.DQN.DQN - INFO - episode 6 step 219 reward tensor([-1]) loss 0.6874808073043823 epsilon 0.6951343038652089
26-Feb-25 09:38:37 - agent.DQN.DQN - INFO - episode 6 step 220 reward tensor([-1]) loss 0.5841937065124512 epsilon 0.6951343038652089
26-Feb-25 09:38:37 - agent.DQN.DQN - INFO - episode 6 step 221 reward tensor([-1]) loss 0.4841049313545227 epsilon 0.6951343038652089
26-Feb-25 09:38:37 - agent.DQN.DQN - INFO - episode 6 step 222 reward tensor([-1]) loss 0.6151644587516785 epsilon 0.6951343038652089
26-Feb-25 09:38:37 - agent.DQN.DQN - INFO - episode 6 step 223 reward tensor([-1]) loss 0.4424480199813843 epsilon 0.6951343038652089
26-Feb-25 09:38:37 - agent.DQN.DQN - INFO - episode 6 step 224 reward tensor([-1]) loss 0.3494128882884979 epsilon 0.6951343038652089
26-Feb-25 09:38:37 - agent.DQN.DQN - INFO - episode 6 step 225 reward tensor([-1]) loss 0.3275524973869324 epsilon 0.6951343038652089
26-Feb-25 09:38:37 - agent.DQN.DQN - INFO - episode 6 step 226 reward tensor([-1]) loss 0.7878415584564209 epsilon 0.6951343038652089
26-Feb-25 09:38:37 - agent.DQN.DQN - INFO - episode 6 step 227 reward tensor([-1]) loss 0.41386130452156067 epsilon 0.6951343038652089
26-Feb-25 09:38:37 - agent.DQN.DQN - INFO - episode 6 step 228 reward tensor([-1]) loss 0.48791739344596863 epsilon 0.6951343038652089
26-Feb-25 09:38:37 - agent.DQN.DQN - INFO - episode 6 step 229 reward tensor([-1]) loss 0.5000602602958679 epsilon 0.6951343038652089
26-Feb-25 09:38:37 - agent.DQN.DQN - INFO - episode 6 step 230 reward tensor([-1]) loss 0.6258701086044312 epsilon 0.6951343038652089
26-Feb-25 09:38:37 - agent.DQN.DQN - INFO - episode 6 step 231 reward tensor([-1]) loss 0.5189835429191589 epsilon 0.6951343038652089
26-Feb-25 09:38:37 - agent.DQN.DQN - INFO - episode 6 step 232 reward tensor([-1]) loss 0.6087250709533691 epsilon 0.6951343038652089
26-Feb-25 09:38:37 - agent.DQN.DQN - INFO - episode 6 step 233 reward tensor([-1]) loss 0.45323771238327026 epsilon 0.6951343038652089
26-Feb-25 09:38:37 - agent.DQN.DQN - INFO - episode 6 step 234 reward tensor([-1]) loss 0.706598162651062 epsilon 0.6951343038652089
26-Feb-25 09:38:37 - agent.DQN.DQN - INFO - episode 6 step 235 reward tensor([-1]) loss 0.32393836975097656 epsilon 0.6951343038652089
26-Feb-25 09:38:37 - agent.DQN.DQN - INFO - episode 6 step 236 reward tensor([-1]) loss 0.4570760428905487 epsilon 0.6951343038652089
26-Feb-25 09:38:37 - agent.DQN.DQN - INFO - episode 6 step 237 reward tensor([-1]) loss 0.5638433694839478 epsilon 0.6951343038652089
26-Feb-25 09:38:37 - agent.DQN.DQN - INFO - episode 6 step 238 reward tensor([-1]) loss 0.4875568151473999 epsilon 0.6951343038652089
26-Feb-25 09:38:37 - agent.DQN.DQN - INFO - episode 6 step 239 reward tensor([-1]) loss 0.41443753242492676 epsilon 0.6951343038652089
26-Feb-25 09:38:37 - agent.DQN.DQN - INFO - episode 6 step 240 reward tensor([-1]) loss 0.6148199439048767 epsilon 0.6951343038652089
26-Feb-25 09:38:37 - agent.DQN.DQN - INFO - episode 6 step 241 reward tensor([-1]) loss 0.5365282297134399 epsilon 0.6951343038652089
26-Feb-25 09:38:37 - agent.DQN.DQN - INFO - episode 6 step 242 reward tensor([-1]) loss 0.43261826038360596 epsilon 0.6951343038652089
26-Feb-25 09:38:37 - agent.DQN.DQN - INFO - episode 6 step 243 reward tensor([-1]) loss 0.5808957815170288 epsilon 0.6951343038652089
26-Feb-25 09:38:37 - agent.DQN.DQN - INFO - episode 6 step 244 reward tensor([-1]) loss 0.4242059588432312 epsilon 0.6951343038652089
26-Feb-25 09:38:37 - agent.DQN.DQN - INFO - episode 6 step 245 reward tensor([-1]) loss 0.5034638047218323 epsilon 0.6951343038652089
26-Feb-25 09:38:38 - agent.DQN.DQN - INFO - episode 6 step 246 reward tensor([-1]) loss 0.37187618017196655 epsilon 0.6951343038652089
26-Feb-25 09:38:38 - agent.DQN.DQN - INFO - episode 6 step 247 reward tensor([-1]) loss 0.4260696768760681 epsilon 0.6951343038652089
26-Feb-25 09:38:38 - agent.DQN.DQN - INFO - episode 6 step 248 reward tensor([-1]) loss 0.3673539459705353 epsilon 0.6951343038652089
26-Feb-25 09:38:38 - agent.DQN.DQN - INFO - episode 6 step 249 reward tensor([-1]) loss 0.4272226095199585 epsilon 0.6951343038652089
26-Feb-25 09:38:38 - agent.DQN.DQN - INFO - episode 6 step 250 reward tensor([-1]) loss 0.43364405632019043 epsilon 0.6951343038652089
26-Feb-25 09:38:38 - agent.DQN.DQN - INFO - episode 6 step 251 reward tensor([-1]) loss 0.6306602954864502 epsilon 0.6951343038652089
26-Feb-25 09:38:38 - agent.DQN.DQN - INFO - episode 6 step 252 reward tensor([-1]) loss 0.4616934359073639 epsilon 0.6951343038652089
26-Feb-25 09:38:38 - agent.DQN.DQN - INFO - episode 6 step 253 reward tensor([-1]) loss 0.5440810322761536 epsilon 0.6951343038652089
26-Feb-25 09:38:38 - agent.DQN.DQN - INFO - episode 6 step 254 reward tensor([-1]) loss 0.3505123257637024 epsilon 0.6951343038652089
26-Feb-25 09:38:38 - agent.DQN.DQN - INFO - episode 6 step 255 reward tensor([-1]) loss 0.3451214134693146 epsilon 0.6951343038652089
26-Feb-25 09:38:38 - agent.DQN.DQN - INFO - episode 6 step 256 reward tensor([-1]) loss 0.372872531414032 epsilon 0.6951343038652089
26-Feb-25 09:38:38 - agent.DQN.DQN - INFO - episode 6 step 257 reward tensor([-1]) loss 0.41501522064208984 epsilon 0.6951343038652089
26-Feb-25 09:38:38 - agent.DQN.DQN - INFO - episode 6 step 258 reward tensor([-1]) loss 0.36925357580184937 epsilon 0.6951343038652089
26-Feb-25 09:38:38 - agent.DQN.DQN - INFO - episode 6 step 259 reward tensor([-1]) loss 0.38564395904541016 epsilon 0.6951343038652089
26-Feb-25 09:38:38 - agent.DQN.DQN - INFO - episode 6 step 260 reward tensor([-1]) loss 0.3896678686141968 epsilon 0.6951343038652089
26-Feb-25 09:38:38 - agent.DQN.DQN - INFO - episode 6 step 261 reward tensor([-1]) loss 0.5003129243850708 epsilon 0.6951343038652089
26-Feb-25 09:38:38 - agent.DQN.DQN - INFO - episode 6 step 262 reward tensor([-1]) loss 0.4197567105293274 epsilon 0.6951343038652089
26-Feb-25 09:38:38 - agent.DQN.DQN - INFO - episode 6 step 263 reward tensor([-1]) loss 0.3215692639350891 epsilon 0.6951343038652089
26-Feb-25 09:38:38 - agent.DQN.DQN - INFO - episode 6 step 264 reward tensor([-1]) loss 0.40569889545440674 epsilon 0.6951343038652089
26-Feb-25 09:38:38 - agent.DQN.DQN - INFO - episode 6 step 265 reward tensor([-1]) loss 0.4493288993835449 epsilon 0.6951343038652089
26-Feb-25 09:38:38 - agent.DQN.DQN - INFO - episode 6 step 266 reward tensor([-1]) loss 0.33400869369506836 epsilon 0.6951343038652089
26-Feb-25 09:38:38 - agent.DQN.DQN - INFO - episode 6 step 267 reward tensor([-1]) loss 0.34192949533462524 epsilon 0.6951343038652089
26-Feb-25 09:38:38 - agent.DQN.DQN - INFO - episode 6 step 268 reward tensor([-1]) loss 0.40072348713874817 epsilon 0.6951343038652089
26-Feb-25 09:38:38 - agent.DQN.DQN - INFO - episode 6 step 269 reward tensor([-1]) loss 0.3767079710960388 epsilon 0.6951343038652089
26-Feb-25 09:38:38 - agent.DQN.DQN - INFO - episode 6 step 270 reward tensor([-1]) loss 0.3678249716758728 epsilon 0.6951343038652089
26-Feb-25 09:38:38 - agent.DQN.DQN - INFO - episode 6 step 271 reward tensor([-1]) loss 0.4659961462020874 epsilon 0.6951343038652089
26-Feb-25 09:38:38 - agent.DQN.DQN - INFO - episode 6 step 272 reward tensor([-1]) loss 0.5037488341331482 epsilon 0.6951343038652089
26-Feb-25 09:38:38 - agent.DQN.DQN - INFO - episode 6 step 273 reward tensor([-1]) loss 0.4034000635147095 epsilon 0.6951343038652089
26-Feb-25 09:38:38 - agent.DQN.DQN - INFO - episode 6 step 274 reward tensor([-1]) loss 0.407585471868515 epsilon 0.6951343038652089
26-Feb-25 09:38:38 - agent.DQN.DQN - INFO - episode 6 step 275 reward tensor([-1]) loss 0.7689545154571533 epsilon 0.6951343038652089
26-Feb-25 09:38:38 - agent.DQN.DQN - INFO - episode 6 step 276 reward tensor([-1]) loss 0.44436198472976685 epsilon 0.6951343038652089
26-Feb-25 09:38:38 - agent.DQN.DQN - INFO - episode 6 step 277 reward tensor([-1]) loss 0.40587493777275085 epsilon 0.6951343038652089
26-Feb-25 09:38:38 - agent.DQN.DQN - INFO - episode 6 step 278 reward tensor([-1]) loss 0.3908228278160095 epsilon 0.6951343038652089
26-Feb-25 09:38:38 - agent.DQN.DQN - INFO - episode 6 step 279 reward tensor([-1]) loss 0.32779479026794434 epsilon 0.6951343038652089
26-Feb-25 09:38:38 - agent.DQN.DQN - INFO - episode 6 step 280 reward tensor([-1]) loss 0.4336121082305908 epsilon 0.6951343038652089
26-Feb-25 09:38:38 - agent.DQN.DQN - INFO - episode 6 step 281 reward tensor([-1]) loss 0.32863983511924744 epsilon 0.6951343038652089
26-Feb-25 09:38:38 - agent.DQN.DQN - INFO - episode 6 step 282 reward tensor([-1]) loss 0.34961891174316406 epsilon 0.6951343038652089
26-Feb-25 09:38:38 - agent.DQN.DQN - INFO - episode 6 step 283 reward tensor([-1]) loss 0.37129542231559753 epsilon 0.6951343038652089
26-Feb-25 09:38:38 - agent.DQN.DQN - INFO - episode 6 step 284 reward tensor([-1]) loss 0.2635014057159424 epsilon 0.6951343038652089
26-Feb-25 09:38:38 - agent.DQN.DQN - INFO - episode 6 step 285 reward tensor([-1]) loss 0.4314999282360077 epsilon 0.6951343038652089
26-Feb-25 09:38:38 - agent.DQN.DQN - INFO - episode 6 step 286 reward tensor([-1]) loss 0.34517544507980347 epsilon 0.6951343038652089
26-Feb-25 09:38:38 - agent.DQN.DQN - INFO - episode 6 step 287 reward tensor([-1]) loss 0.3157671391963959 epsilon 0.6951343038652089
26-Feb-25 09:38:38 - agent.DQN.DQN - INFO - episode 6 step 288 reward tensor([-1]) loss 0.5125979781150818 epsilon 0.6951343038652089
26-Feb-25 09:38:38 - agent.DQN.DQN - INFO - episode 6 step 289 reward tensor([-1]) loss 0.39913687109947205 epsilon 0.6951343038652089
26-Feb-25 09:38:38 - agent.DQN.DQN - INFO - episode 6 step 290 reward tensor([-1]) loss 0.5873594284057617 epsilon 0.6951343038652089
26-Feb-25 09:38:38 - agent.DQN.DQN - INFO - episode 6 step 291 reward tensor([-1]) loss 0.3190176486968994 epsilon 0.6951343038652089
26-Feb-25 09:38:38 - agent.DQN.DQN - INFO - episode 6 step 292 reward tensor([-1]) loss 0.4043317139148712 epsilon 0.6951343038652089
26-Feb-25 09:38:38 - agent.DQN.DQN - INFO - episode 6 step 293 reward tensor([-1]) loss 0.3612697720527649 epsilon 0.6951343038652089
26-Feb-25 09:38:38 - agent.DQN.DQN - INFO - episode 6 step 294 reward tensor([-1]) loss 0.9079223871231079 epsilon 0.6951343038652089
26-Feb-25 09:38:38 - agent.DQN.DQN - INFO - episode 6 step 295 reward tensor([-1]) loss 0.359028160572052 epsilon 0.6951343038652089
26-Feb-25 09:38:38 - agent.DQN.DQN - INFO - episode 6 step 296 reward tensor([-1]) loss 0.38339030742645264 epsilon 0.6951343038652089
26-Feb-25 09:38:38 - agent.DQN.DQN - INFO - episode 6 step 297 reward tensor([-1]) loss 0.40071314573287964 epsilon 0.6951343038652089
26-Feb-25 09:38:38 - agent.DQN.DQN - INFO - episode 6 step 298 reward tensor([-1]) loss 0.3706795573234558 epsilon 0.6951343038652089
26-Feb-25 09:38:38 - agent.DQN.DQN - INFO - episode 6 step 299 reward tensor([-1]) loss 0.33290696144104004 epsilon 0.6951343038652089
26-Feb-25 09:38:38 - agent.DQN.DQN - INFO - episode 6 step 300 reward tensor([-1]) loss 0.6442574858665466 epsilon 0.6951343038652089
26-Feb-25 09:38:38 - agent.DQN.DQN - INFO - episode 6 step 301 reward tensor([-1]) loss 0.35145094990730286 epsilon 0.6951343038652089
26-Feb-25 09:38:38 - agent.DQN.DQN - INFO - episode 7 step 0 reward tensor([-1]) loss 0.2795936167240143 epsilon 0.6725424389895897
26-Feb-25 09:38:38 - agent.DQN.DQN - INFO - episode 7 step 1 reward tensor([-1]) loss 0.3088868260383606 epsilon 0.6725424389895897
26-Feb-25 09:38:38 - agent.DQN.DQN - INFO - episode 7 step 2 reward tensor([-1]) loss 0.4043189585208893 epsilon 0.6725424389895897
26-Feb-25 09:38:38 - agent.DQN.DQN - INFO - episode 7 step 3 reward tensor([-1]) loss 0.31212934851646423 epsilon 0.6725424389895897
26-Feb-25 09:38:38 - agent.DQN.DQN - INFO - episode 7 step 4 reward tensor([-1]) loss 0.3547522723674774 epsilon 0.6725424389895897
26-Feb-25 09:38:38 - agent.DQN.DQN - INFO - episode 7 step 5 reward tensor([-1]) loss 0.34580379724502563 epsilon 0.6725424389895897
26-Feb-25 09:38:38 - agent.DQN.DQN - INFO - episode 7 step 6 reward tensor([-1]) loss 0.2881297767162323 epsilon 0.6725424389895897
26-Feb-25 09:38:38 - agent.DQN.DQN - INFO - episode 7 step 7 reward tensor([-1]) loss 0.28369855880737305 epsilon 0.6725424389895897
26-Feb-25 09:38:38 - agent.DQN.DQN - INFO - episode 7 step 8 reward tensor([-1]) loss 0.3712189197540283 epsilon 0.6725424389895897
26-Feb-25 09:38:38 - agent.DQN.DQN - INFO - episode 7 step 9 reward tensor([-1]) loss 1.2401785850524902 epsilon 0.6725424389895897
26-Feb-25 09:38:38 - agent.DQN.DQN - INFO - episode 7 step 10 reward tensor([-1]) loss 0.2994574010372162 epsilon 0.6725424389895897
26-Feb-25 09:38:38 - agent.DQN.DQN - INFO - episode 7 step 11 reward tensor([-1]) loss 0.341726154088974 epsilon 0.6725424389895897
26-Feb-25 09:38:38 - agent.DQN.DQN - INFO - episode 7 step 12 reward tensor([-1]) loss 0.2782822251319885 epsilon 0.6725424389895897
26-Feb-25 09:38:38 - agent.DQN.DQN - INFO - episode 7 step 13 reward tensor([-1]) loss 0.3502175807952881 epsilon 0.6725424389895897
26-Feb-25 09:38:38 - agent.DQN.DQN - INFO - episode 7 step 14 reward tensor([-1]) loss 0.29473239183425903 epsilon 0.6725424389895897
26-Feb-25 09:38:38 - agent.DQN.DQN - INFO - episode 7 step 15 reward tensor([-1]) loss 0.5690552592277527 epsilon 0.6725424389895897
26-Feb-25 09:38:38 - agent.DQN.DQN - INFO - episode 7 step 16 reward tensor([-1]) loss 0.7810505032539368 epsilon 0.6725424389895897
26-Feb-25 09:38:39 - agent.DQN.DQN - INFO - episode 7 step 17 reward tensor([-1]) loss 0.3286927342414856 epsilon 0.6725424389895897
26-Feb-25 09:38:39 - agent.DQN.DQN - INFO - episode 7 step 18 reward tensor([-1]) loss 0.4734240770339966 epsilon 0.6725424389895897
26-Feb-25 09:38:39 - agent.DQN.DQN - INFO - episode 7 step 19 reward tensor([-1]) loss 1.0236963033676147 epsilon 0.6725424389895897
26-Feb-25 09:38:39 - agent.DQN.DQN - INFO - episode 7 step 20 reward tensor([-1]) loss 0.3641199469566345 epsilon 0.6725424389895897
26-Feb-25 09:38:39 - agent.DQN.DQN - INFO - episode 7 step 21 reward tensor([-1]) loss 0.34304046630859375 epsilon 0.6725424389895897
26-Feb-25 09:38:39 - agent.DQN.DQN - INFO - episode 7 step 22 reward tensor([-1]) loss 0.41373535990715027 epsilon 0.6725424389895897
26-Feb-25 09:38:39 - agent.DQN.DQN - INFO - episode 7 step 23 reward tensor([-1]) loss 0.39222246408462524 epsilon 0.6725424389895897
26-Feb-25 09:38:39 - agent.DQN.DQN - INFO - episode 7 step 24 reward tensor([-1]) loss 0.3714889883995056 epsilon 0.6725424389895897
26-Feb-25 09:38:39 - agent.DQN.DQN - INFO - episode 7 step 25 reward tensor([-1]) loss 0.3696900010108948 epsilon 0.6725424389895897
26-Feb-25 09:38:39 - agent.DQN.DQN - INFO - episode 7 step 26 reward tensor([-1]) loss 0.42225831747055054 epsilon 0.6725424389895897
26-Feb-25 09:38:39 - agent.DQN.DQN - INFO - episode 7 step 27 reward tensor([-1]) loss 0.3721277713775635 epsilon 0.6725424389895897
26-Feb-25 09:38:39 - agent.DQN.DQN - INFO - episode 7 step 28 reward tensor([-1]) loss 0.3416743874549866 epsilon 0.6725424389895897
26-Feb-25 09:38:39 - agent.DQN.DQN - INFO - episode 7 step 29 reward tensor([-1]) loss 0.39497968554496765 epsilon 0.6725424389895897
26-Feb-25 09:38:39 - agent.DQN.DQN - INFO - episode 7 step 30 reward tensor([-1]) loss 0.34877270460128784 epsilon 0.6725424389895897
26-Feb-25 09:38:39 - agent.DQN.DQN - INFO - episode 7 step 31 reward tensor([-1]) loss 0.3281393051147461 epsilon 0.6725424389895897
26-Feb-25 09:38:39 - agent.DQN.DQN - INFO - episode 7 step 32 reward tensor([-1]) loss 0.30862075090408325 epsilon 0.6725424389895897
26-Feb-25 09:38:39 - agent.DQN.DQN - INFO - episode 7 step 33 reward tensor([-1]) loss 0.38963669538497925 epsilon 0.6725424389895897
26-Feb-25 09:38:39 - agent.DQN.DQN - INFO - episode 7 step 34 reward tensor([-1]) loss 0.4550570249557495 epsilon 0.6725424389895897
26-Feb-25 09:38:39 - agent.DQN.DQN - INFO - episode 7 step 35 reward tensor([-1]) loss 0.2963498532772064 epsilon 0.6725424389895897
26-Feb-25 09:38:39 - agent.DQN.DQN - INFO - episode 7 step 36 reward tensor([-1]) loss 0.3854611814022064 epsilon 0.6725424389895897
26-Feb-25 09:38:39 - agent.DQN.DQN - INFO - episode 7 step 37 reward tensor([-1]) loss 0.6345552206039429 epsilon 0.6725424389895897
26-Feb-25 09:38:39 - agent.DQN.DQN - INFO - episode 7 step 38 reward tensor([-1]) loss 0.32388073205947876 epsilon 0.6725424389895897
26-Feb-25 09:38:39 - agent.DQN.DQN - INFO - episode 7 step 39 reward tensor([-1]) loss 0.261379599571228 epsilon 0.6725424389895897
26-Feb-25 09:38:39 - agent.DQN.DQN - INFO - episode 7 step 40 reward tensor([-1]) loss 0.28218480944633484 epsilon 0.6725424389895897
26-Feb-25 09:38:39 - agent.DQN.DQN - INFO - episode 7 step 41 reward tensor([-1]) loss 0.3954138159751892 epsilon 0.6725424389895897
26-Feb-25 09:38:39 - agent.DQN.DQN - INFO - episode 7 step 42 reward tensor([-1]) loss 0.33479204773902893 epsilon 0.6725424389895897
26-Feb-25 09:38:39 - agent.DQN.DQN - INFO - episode 7 step 43 reward tensor([-1]) loss 0.3357364237308502 epsilon 0.6725424389895897
26-Feb-25 09:38:39 - agent.DQN.DQN - INFO - episode 7 step 44 reward tensor([-1]) loss 0.3045673370361328 epsilon 0.6725424389895897
26-Feb-25 09:38:39 - agent.DQN.DQN - INFO - episode 7 step 45 reward tensor([-1]) loss 0.34342238306999207 epsilon 0.6725424389895897
26-Feb-25 09:38:39 - agent.DQN.DQN - INFO - episode 7 step 46 reward tensor([-1]) loss 0.30092135071754456 epsilon 0.6725424389895897
26-Feb-25 09:38:39 - agent.DQN.DQN - INFO - episode 7 step 47 reward tensor([-1]) loss 0.2401275932788849 epsilon 0.6725424389895897
26-Feb-25 09:38:39 - agent.DQN.DQN - INFO - episode 7 step 48 reward tensor([-1]) loss 0.29531142115592957 epsilon 0.6725424389895897
26-Feb-25 09:38:39 - agent.DQN.DQN - INFO - episode 7 step 49 reward tensor([-1]) loss 0.37691497802734375 epsilon 0.6725424389895897
26-Feb-25 09:38:39 - agent.DQN.DQN - INFO - episode 7 step 50 reward tensor([-1]) loss 0.3977178931236267 epsilon 0.6725424389895897
26-Feb-25 09:38:39 - agent.DQN.DQN - INFO - episode 7 step 51 reward tensor([-1]) loss 0.3497920036315918 epsilon 0.6725424389895897
26-Feb-25 09:38:39 - agent.DQN.DQN - INFO - episode 7 step 52 reward tensor([-1]) loss 0.34302717447280884 epsilon 0.6725424389895897
26-Feb-25 09:38:39 - agent.DQN.DQN - INFO - episode 7 step 53 reward tensor([-1]) loss 0.2909066379070282 epsilon 0.6725424389895897
26-Feb-25 09:38:39 - agent.DQN.DQN - INFO - episode 7 step 54 reward tensor([-1]) loss 0.2673489451408386 epsilon 0.6725424389895897
26-Feb-25 09:38:39 - agent.DQN.DQN - INFO - episode 7 step 55 reward tensor([-1]) loss 0.3843385577201843 epsilon 0.6725424389895897
26-Feb-25 09:38:39 - agent.DQN.DQN - INFO - episode 7 step 56 reward tensor([-1]) loss 0.7728506326675415 epsilon 0.6725424389895897
26-Feb-25 09:38:39 - agent.DQN.DQN - INFO - episode 7 step 57 reward tensor([-1]) loss 0.303994357585907 epsilon 0.6725424389895897
26-Feb-25 09:38:39 - agent.DQN.DQN - INFO - episode 7 step 58 reward tensor([-1]) loss 0.2837672531604767 epsilon 0.6725424389895897
26-Feb-25 09:38:39 - agent.DQN.DQN - INFO - episode 7 step 59 reward tensor([-1]) loss 0.3347935676574707 epsilon 0.6725424389895897
26-Feb-25 09:38:39 - agent.DQN.DQN - INFO - episode 7 step 60 reward tensor([-1]) loss 0.34537601470947266 epsilon 0.6725424389895897
26-Feb-25 09:38:39 - agent.DQN.DQN - INFO - episode 7 step 61 reward tensor([-1]) loss 0.3787074387073517 epsilon 0.6725424389895897
26-Feb-25 09:38:39 - agent.DQN.DQN - INFO - episode 7 step 62 reward tensor([-1]) loss 0.45692506432533264 epsilon 0.6725424389895897
26-Feb-25 09:38:39 - agent.DQN.DQN - INFO - episode 7 step 63 reward tensor([-1]) loss 0.3100907802581787 epsilon 0.6725424389895897
26-Feb-25 09:38:39 - agent.DQN.DQN - INFO - episode 7 step 64 reward tensor([-1]) loss 0.7190542817115784 epsilon 0.6725424389895897
26-Feb-25 09:38:39 - agent.DQN.DQN - INFO - episode 7 step 65 reward tensor([-1]) loss 0.42817285656929016 epsilon 0.6725424389895897
26-Feb-25 09:38:39 - agent.DQN.DQN - INFO - episode 7 step 66 reward tensor([-1]) loss 0.28508615493774414 epsilon 0.6725424389895897
26-Feb-25 09:38:39 - agent.DQN.DQN - INFO - episode 7 step 67 reward tensor([-1]) loss 0.3803459107875824 epsilon 0.6725424389895897
26-Feb-25 09:38:39 - agent.DQN.DQN - INFO - episode 7 step 68 reward tensor([-1]) loss 0.39595043659210205 epsilon 0.6725424389895897
26-Feb-25 09:38:39 - agent.DQN.DQN - INFO - episode 7 step 69 reward tensor([-1]) loss 0.42797762155532837 epsilon 0.6725424389895897
26-Feb-25 09:38:39 - agent.DQN.DQN - INFO - episode 7 step 70 reward tensor([-1]) loss 0.631564736366272 epsilon 0.6725424389895897
26-Feb-25 09:38:39 - agent.DQN.DQN - INFO - episode 7 step 71 reward tensor([-1]) loss 0.41135847568511963 epsilon 0.6725424389895897
26-Feb-25 09:38:39 - agent.DQN.DQN - INFO - episode 7 step 72 reward tensor([-1]) loss 0.34599947929382324 epsilon 0.6725424389895897
26-Feb-25 09:38:39 - agent.DQN.DQN - INFO - episode 7 step 73 reward tensor([-1]) loss 0.28711771965026855 epsilon 0.6725424389895897
26-Feb-25 09:38:39 - agent.DQN.DQN - INFO - episode 7 step 74 reward tensor([-1]) loss 0.358890175819397 epsilon 0.6725424389895897
26-Feb-25 09:38:39 - agent.DQN.DQN - INFO - episode 7 step 75 reward tensor([-1]) loss 0.3490549623966217 epsilon 0.6725424389895897
26-Feb-25 09:38:39 - agent.DQN.DQN - INFO - episode 7 step 76 reward tensor([-1]) loss 0.4345785677433014 epsilon 0.6725424389895897
26-Feb-25 09:38:39 - agent.DQN.DQN - INFO - episode 7 step 77 reward tensor([-1]) loss 0.5925621390342712 epsilon 0.6725424389895897
26-Feb-25 09:38:39 - agent.DQN.DQN - INFO - episode 7 step 78 reward tensor([-1]) loss 0.3495108485221863 epsilon 0.6725424389895897
26-Feb-25 09:38:39 - agent.DQN.DQN - INFO - episode 7 step 79 reward tensor([-1]) loss 0.3345828950405121 epsilon 0.6725424389895897
26-Feb-25 09:38:39 - agent.DQN.DQN - INFO - episode 7 step 80 reward tensor([-1]) loss 0.5993741154670715 epsilon 0.6725424389895897
26-Feb-25 09:38:39 - agent.DQN.DQN - INFO - episode 7 step 81 reward tensor([-1]) loss 0.3785334527492523 epsilon 0.6725424389895897
26-Feb-25 09:38:39 - agent.DQN.DQN - INFO - episode 7 step 82 reward tensor([-1]) loss 0.34212788939476013 epsilon 0.6725424389895897
26-Feb-25 09:38:39 - agent.DQN.DQN - INFO - episode 7 step 83 reward tensor([-1]) loss 0.32632166147232056 epsilon 0.6725424389895897
26-Feb-25 09:38:39 - agent.DQN.DQN - INFO - episode 7 step 84 reward tensor([-1]) loss 0.36093375086784363 epsilon 0.6725424389895897
26-Feb-25 09:38:39 - agent.DQN.DQN - INFO - episode 7 step 85 reward tensor([-1]) loss 0.3293682336807251 epsilon 0.6725424389895897
26-Feb-25 09:38:39 - agent.DQN.DQN - INFO - episode 7 step 86 reward tensor([-1]) loss 0.2958507239818573 epsilon 0.6725424389895897
26-Feb-25 09:38:39 - agent.DQN.DQN - INFO - episode 7 step 87 reward tensor([-1]) loss 0.29681840538978577 epsilon 0.6725424389895897
26-Feb-25 09:38:39 - agent.DQN.DQN - INFO - episode 7 step 88 reward tensor([-1]) loss 0.2748788595199585 epsilon 0.6725424389895897
26-Feb-25 09:38:39 - agent.DQN.DQN - INFO - episode 7 step 89 reward tensor([-1]) loss 0.3564661741256714 epsilon 0.6725424389895897
26-Feb-25 09:38:39 - agent.DQN.DQN - INFO - episode 7 step 90 reward tensor([-1]) loss 0.6202018857002258 epsilon 0.6725424389895897
26-Feb-25 09:38:39 - agent.DQN.DQN - INFO - episode 7 step 91 reward tensor([-1]) loss 0.390843003988266 epsilon 0.6725424389895897
26-Feb-25 09:38:39 - agent.DQN.DQN - INFO - episode 7 step 92 reward tensor([-1]) loss 0.3984484374523163 epsilon 0.6725424389895897
26-Feb-25 09:38:39 - agent.DQN.DQN - INFO - episode 7 step 93 reward tensor([-1]) loss 0.35372698307037354 epsilon 0.6725424389895897
26-Feb-25 09:38:39 - agent.DQN.DQN - INFO - episode 7 step 94 reward tensor([-1]) loss 0.36205747723579407 epsilon 0.6725424389895897
26-Feb-25 09:38:39 - agent.DQN.DQN - INFO - episode 7 step 95 reward tensor([-1]) loss 0.29674768447875977 epsilon 0.6725424389895897
26-Feb-25 09:38:39 - agent.DQN.DQN - INFO - episode 7 step 96 reward tensor([-1]) loss 0.3022790253162384 epsilon 0.6725424389895897
26-Feb-25 09:38:39 - agent.DQN.DQN - INFO - episode 7 step 97 reward tensor([-1]) loss 0.2859664857387543 epsilon 0.6725424389895897
26-Feb-25 09:38:40 - agent.DQN.DQN - INFO - episode 7 step 98 reward tensor([-1]) loss 0.3176218271255493 epsilon 0.6725424389895897
26-Feb-25 09:38:40 - agent.DQN.DQN - INFO - episode 7 step 99 reward tensor([-1]) loss 0.2904161512851715 epsilon 0.6725424389895897
26-Feb-25 09:38:40 - agent.DQN.DQN - INFO - episode 7 step 100 reward tensor([-1]) loss 0.310075581073761 epsilon 0.6725424389895897
26-Feb-25 09:38:40 - agent.DQN.DQN - INFO - episode 7 step 101 reward tensor([-1]) loss 0.37138116359710693 epsilon 0.6725424389895897
26-Feb-25 09:38:40 - agent.DQN.DQN - INFO - episode 7 step 102 reward tensor([-1]) loss 0.37617403268814087 epsilon 0.6725424389895897
26-Feb-25 09:38:40 - agent.DQN.DQN - INFO - episode 7 step 103 reward tensor([-1]) loss 0.31375837326049805 epsilon 0.6725424389895897
26-Feb-25 09:38:40 - agent.DQN.DQN - INFO - episode 7 step 104 reward tensor([-1]) loss 0.5170287489891052 epsilon 0.6725424389895897
26-Feb-25 09:38:40 - agent.DQN.DQN - INFO - episode 7 step 105 reward tensor([-1]) loss 0.3442438840866089 epsilon 0.6725424389895897
26-Feb-25 09:38:40 - agent.DQN.DQN - INFO - episode 7 step 106 reward tensor([-1]) loss 0.356965571641922 epsilon 0.6725424389895897
26-Feb-25 09:38:40 - agent.DQN.DQN - INFO - episode 7 step 107 reward tensor([-1]) loss 0.28094181418418884 epsilon 0.6725424389895897
26-Feb-25 09:38:40 - agent.DQN.DQN - INFO - episode 7 step 108 reward tensor([-1]) loss 0.29213470220565796 epsilon 0.6725424389895897
26-Feb-25 09:38:40 - agent.DQN.DQN - INFO - episode 7 step 109 reward tensor([-1]) loss 0.3365405797958374 epsilon 0.6725424389895897
26-Feb-25 09:38:40 - agent.DQN.DQN - INFO - episode 7 step 110 reward tensor([-1]) loss 0.36565613746643066 epsilon 0.6725424389895897
26-Feb-25 09:38:40 - agent.DQN.DQN - INFO - episode 7 step 111 reward tensor([-1]) loss 0.35674047470092773 epsilon 0.6725424389895897
26-Feb-25 09:38:40 - agent.DQN.DQN - INFO - episode 7 step 112 reward tensor([-1]) loss 0.35806187987327576 epsilon 0.6725424389895897
26-Feb-25 09:38:40 - agent.DQN.DQN - INFO - episode 7 step 113 reward tensor([-1]) loss 0.33970770239830017 epsilon 0.6725424389895897
26-Feb-25 09:38:40 - agent.DQN.DQN - INFO - episode 7 step 114 reward tensor([-1]) loss 0.35807475447654724 epsilon 0.6725424389895897
26-Feb-25 09:38:40 - agent.DQN.DQN - INFO - episode 7 step 115 reward tensor([-1]) loss 0.3570188283920288 epsilon 0.6725424389895897
26-Feb-25 09:38:40 - agent.DQN.DQN - INFO - episode 7 step 116 reward tensor([-1]) loss 0.2588416635990143 epsilon 0.6725424389895897
26-Feb-25 09:38:40 - agent.DQN.DQN - INFO - episode 7 step 117 reward tensor([-1]) loss 0.24425731599330902 epsilon 0.6725424389895897
26-Feb-25 09:38:40 - agent.DQN.DQN - INFO - episode 7 step 118 reward tensor([-1]) loss 0.3218805491924286 epsilon 0.6725424389895897
26-Feb-25 09:38:40 - agent.DQN.DQN - INFO - episode 7 step 119 reward tensor([-1]) loss 0.28910741209983826 epsilon 0.6725424389895897
26-Feb-25 09:38:40 - agent.DQN.DQN - INFO - episode 7 step 120 reward tensor([-1]) loss 0.2678053081035614 epsilon 0.6725424389895897
26-Feb-25 09:38:40 - agent.DQN.DQN - INFO - episode 7 step 121 reward tensor([-1]) loss 0.34376010298728943 epsilon 0.6725424389895897
26-Feb-25 09:38:40 - agent.DQN.DQN - INFO - episode 7 step 122 reward tensor([-1]) loss 0.5781136155128479 epsilon 0.6725424389895897
26-Feb-25 09:38:40 - agent.DQN.DQN - INFO - episode 7 step 123 reward tensor([-1]) loss 0.3253297209739685 epsilon 0.6725424389895897
26-Feb-25 09:38:40 - agent.DQN.DQN - INFO - episode 7 step 124 reward tensor([-1]) loss 0.32432377338409424 epsilon 0.6725424389895897
26-Feb-25 09:38:40 - agent.DQN.DQN - INFO - episode 7 step 125 reward tensor([-1]) loss 0.31424853205680847 epsilon 0.6725424389895897
26-Feb-25 09:38:40 - agent.DQN.DQN - INFO - episode 7 step 126 reward tensor([-1]) loss 0.29923564195632935 epsilon 0.6725424389895897
26-Feb-25 09:38:40 - agent.DQN.DQN - INFO - episode 7 step 127 reward tensor([-1]) loss 0.5754809379577637 epsilon 0.6725424389895897
26-Feb-25 09:38:40 - agent.DQN.DQN - INFO - episode 7 step 128 reward tensor([-1]) loss 0.37048715353012085 epsilon 0.6725424389895897
26-Feb-25 09:38:40 - agent.DQN.DQN - INFO - episode 7 step 129 reward tensor([-1]) loss 0.6704072952270508 epsilon 0.6725424389895897
26-Feb-25 09:38:40 - agent.DQN.DQN - INFO - episode 7 step 130 reward tensor([-1]) loss 0.5383861064910889 epsilon 0.6725424389895897
26-Feb-25 09:38:40 - agent.DQN.DQN - INFO - episode 7 step 131 reward tensor([-1]) loss 0.30691826343536377 epsilon 0.6725424389895897
26-Feb-25 09:38:40 - agent.DQN.DQN - INFO - episode 7 step 132 reward tensor([-1]) loss 0.3399879038333893 epsilon 0.6725424389895897
26-Feb-25 09:38:40 - agent.DQN.DQN - INFO - episode 7 step 133 reward tensor([-1]) loss 0.3433532118797302 epsilon 0.6725424389895897
26-Feb-25 09:38:40 - agent.DQN.DQN - INFO - episode 7 step 134 reward tensor([-1]) loss 0.4289596378803253 epsilon 0.6725424389895897
26-Feb-25 09:38:40 - agent.DQN.DQN - INFO - episode 7 step 135 reward tensor([-1]) loss 0.24707865715026855 epsilon 0.6725424389895897
26-Feb-25 09:38:40 - agent.DQN.DQN - INFO - episode 7 step 136 reward tensor([-1]) loss 0.28832533955574036 epsilon 0.6725424389895897
26-Feb-25 09:38:40 - agent.DQN.DQN - INFO - episode 7 step 137 reward tensor([-1]) loss 0.4763355255126953 epsilon 0.6725424389895897
26-Feb-25 09:38:40 - agent.DQN.DQN - INFO - episode 7 step 138 reward tensor([-1]) loss 0.29581260681152344 epsilon 0.6725424389895897
26-Feb-25 09:38:40 - agent.DQN.DQN - INFO - episode 7 step 139 reward tensor([-1]) loss 0.2857583463191986 epsilon 0.6725424389895897
26-Feb-25 09:38:40 - agent.DQN.DQN - INFO - episode 7 step 140 reward tensor([-1]) loss 0.2551628649234772 epsilon 0.6725424389895897
26-Feb-25 09:38:40 - agent.DQN.DQN - INFO - episode 7 step 141 reward tensor([-1]) loss 0.3171194791793823 epsilon 0.6725424389895897
26-Feb-25 09:38:40 - agent.DQN.DQN - INFO - episode 7 step 142 reward tensor([-1]) loss 0.37155330181121826 epsilon 0.6725424389895897
26-Feb-25 09:38:40 - agent.DQN.DQN - INFO - episode 7 step 143 reward tensor([-1]) loss 0.28417712450027466 epsilon 0.6725424389895897
26-Feb-25 09:38:40 - agent.DQN.DQN - INFO - episode 7 step 144 reward tensor([-1]) loss 0.28419649600982666 epsilon 0.6725424389895897
26-Feb-25 09:38:40 - agent.DQN.DQN - INFO - episode 7 step 145 reward tensor([-1]) loss 0.33158403635025024 epsilon 0.6725424389895897
26-Feb-25 09:38:40 - agent.DQN.DQN - INFO - episode 7 step 146 reward tensor([-1]) loss 0.30962109565734863 epsilon 0.6725424389895897
26-Feb-25 09:38:40 - agent.DQN.DQN - INFO - episode 7 step 147 reward tensor([-1]) loss 0.28775376081466675 epsilon 0.6725424389895897
26-Feb-25 09:38:40 - agent.DQN.DQN - INFO - episode 7 step 148 reward tensor([-1]) loss 0.3253997266292572 epsilon 0.6725424389895897
26-Feb-25 09:38:40 - agent.DQN.DQN - INFO - episode 7 step 149 reward tensor([-1]) loss 0.30170220136642456 epsilon 0.6725424389895897
26-Feb-25 09:38:40 - agent.DQN.DQN - INFO - episode 7 step 150 reward tensor([-1]) loss 0.29275333881378174 epsilon 0.6725424389895897
26-Feb-25 09:38:40 - agent.DQN.DQN - INFO - episode 7 step 151 reward tensor([-1]) loss 0.261062353849411 epsilon 0.6725424389895897
26-Feb-25 09:38:40 - agent.DQN.DQN - INFO - episode 7 step 152 reward tensor([-1]) loss 0.6600359082221985 epsilon 0.6725424389895897
26-Feb-25 09:38:40 - agent.DQN.DQN - INFO - episode 7 step 153 reward tensor([-1]) loss 0.2507800757884979 epsilon 0.6725424389895897
26-Feb-25 09:38:40 - agent.DQN.DQN - INFO - episode 7 step 154 reward tensor([-1]) loss 0.24726903438568115 epsilon 0.6725424389895897
26-Feb-25 09:38:40 - agent.DQN.DQN - INFO - episode 7 step 155 reward tensor([-1]) loss 0.28522229194641113 epsilon 0.6725424389895897
26-Feb-25 09:38:40 - agent.DQN.DQN - INFO - episode 7 step 156 reward tensor([-1]) loss 0.2898750305175781 epsilon 0.6725424389895897
26-Feb-25 09:38:40 - agent.DQN.DQN - INFO - episode 7 step 157 reward tensor([-1]) loss 0.333103209733963 epsilon 0.6725424389895897
26-Feb-25 09:38:40 - agent.DQN.DQN - INFO - episode 7 step 158 reward tensor([-1]) loss 0.3139650225639343 epsilon 0.6725424389895897
26-Feb-25 09:38:40 - agent.DQN.DQN - INFO - episode 7 step 159 reward tensor([-1]) loss 0.3363253176212311 epsilon 0.6725424389895897
26-Feb-25 09:38:40 - agent.DQN.DQN - INFO - episode 7 step 160 reward tensor([-1]) loss 0.30097848176956177 epsilon 0.6725424389895897
26-Feb-25 09:38:40 - agent.DQN.DQN - INFO - episode 7 step 161 reward tensor([-1]) loss 0.34866270422935486 epsilon 0.6725424389895897
26-Feb-25 09:38:40 - agent.DQN.DQN - INFO - episode 7 step 162 reward tensor([-1]) loss 0.5974763631820679 epsilon 0.6725424389895897
26-Feb-25 09:38:40 - agent.DQN.DQN - INFO - episode 7 step 163 reward tensor([-1]) loss 0.26234206557273865 epsilon 0.6725424389895897
26-Feb-25 09:38:40 - agent.DQN.DQN - INFO - episode 7 step 164 reward tensor([-1]) loss 0.3195830285549164 epsilon 0.6725424389895897
26-Feb-25 09:38:40 - agent.DQN.DQN - INFO - episode 7 step 165 reward tensor([-1]) loss 0.27294832468032837 epsilon 0.6725424389895897
26-Feb-25 09:38:40 - agent.DQN.DQN - INFO - episode 7 step 166 reward tensor([-1]) loss 0.2578088641166687 epsilon 0.6725424389895897
26-Feb-25 09:38:40 - agent.DQN.DQN - INFO - episode 7 step 167 reward tensor([-1]) loss 0.25566086173057556 epsilon 0.6725424389895897
26-Feb-25 09:38:40 - agent.DQN.DQN - INFO - episode 7 step 168 reward tensor([-1]) loss 0.24596033990383148 epsilon 0.6725424389895897
26-Feb-25 09:38:40 - agent.DQN.DQN - INFO - episode 7 step 169 reward tensor([-1]) loss 0.47402748465538025 epsilon 0.6725424389895897
26-Feb-25 09:38:40 - agent.DQN.DQN - INFO - episode 7 step 170 reward tensor([-1]) loss 0.33283644914627075 epsilon 0.6725424389895897
26-Feb-25 09:38:40 - agent.DQN.DQN - INFO - episode 7 step 171 reward tensor([-1]) loss 0.3032315671443939 epsilon 0.6725424389895897
26-Feb-25 09:38:40 - agent.DQN.DQN - INFO - episode 7 step 172 reward tensor([-1]) loss 0.342122882604599 epsilon 0.6725424389895897
26-Feb-25 09:38:40 - agent.DQN.DQN - INFO - episode 7 step 173 reward tensor([-1]) loss 0.2688114047050476 epsilon 0.6725424389895897
26-Feb-25 09:38:40 - agent.DQN.DQN - INFO - episode 7 step 174 reward tensor([-1]) loss 0.25931912660598755 epsilon 0.6725424389895897
26-Feb-25 09:38:40 - agent.DQN.DQN - INFO - episode 7 step 175 reward tensor([-1]) loss 0.29070165753364563 epsilon 0.6725424389895897
26-Feb-25 09:38:40 - agent.DQN.DQN - INFO - episode 7 step 176 reward tensor([-1]) loss 0.3439218997955322 epsilon 0.6725424389895897
26-Feb-25 09:38:40 - agent.DQN.DQN - INFO - episode 7 step 177 reward tensor([-1]) loss 0.2835255265235901 epsilon 0.6725424389895897
26-Feb-25 09:38:40 - agent.DQN.DQN - INFO - episode 7 step 178 reward tensor([-1]) loss 0.42051345109939575 epsilon 0.6725424389895897
26-Feb-25 09:38:41 - agent.DQN.DQN - INFO - episode 7 step 179 reward tensor([-1]) loss 0.23879510164260864 epsilon 0.6725424389895897
26-Feb-25 09:38:41 - agent.DQN.DQN - INFO - episode 7 step 180 reward tensor([-1]) loss 0.2458605021238327 epsilon 0.6725424389895897
26-Feb-25 09:38:41 - agent.DQN.DQN - INFO - episode 7 step 181 reward tensor([-1]) loss 0.3086692690849304 epsilon 0.6725424389895897
26-Feb-25 09:38:41 - agent.DQN.DQN - INFO - episode 7 step 182 reward tensor([-1]) loss 0.25570565462112427 epsilon 0.6725424389895897
26-Feb-25 09:38:41 - agent.DQN.DQN - INFO - episode 7 step 183 reward tensor([-1]) loss 0.3002348840236664 epsilon 0.6725424389895897
26-Feb-25 09:38:41 - agent.DQN.DQN - INFO - episode 7 step 184 reward tensor([-1]) loss 0.3719933331012726 epsilon 0.6725424389895897
26-Feb-25 09:38:41 - agent.DQN.DQN - INFO - episode 7 step 185 reward tensor([-1]) loss 0.45152127742767334 epsilon 0.6725424389895897
26-Feb-25 09:38:41 - agent.DQN.DQN - INFO - episode 7 step 186 reward tensor([-1]) loss 0.31977227330207825 epsilon 0.6725424389895897
26-Feb-25 09:38:41 - agent.DQN.DQN - INFO - episode 7 step 187 reward tensor([-1]) loss 0.2432423233985901 epsilon 0.6725424389895897
26-Feb-25 09:38:41 - agent.DQN.DQN - INFO - episode 7 step 188 reward tensor([-1]) loss 0.256267786026001 epsilon 0.6725424389895897
26-Feb-25 09:38:41 - agent.DQN.DQN - INFO - episode 7 step 189 reward tensor([-1]) loss 0.24407903850078583 epsilon 0.6725424389895897
26-Feb-25 09:38:41 - agent.DQN.DQN - INFO - episode 7 step 190 reward tensor([-1]) loss 0.3136553466320038 epsilon 0.6725424389895897
26-Feb-25 09:38:41 - agent.DQN.DQN - INFO - episode 7 step 191 reward tensor([-1]) loss 0.25140708684921265 epsilon 0.6725424389895897
26-Feb-25 09:38:41 - agent.DQN.DQN - INFO - episode 7 step 192 reward tensor([-1]) loss 0.2884429395198822 epsilon 0.6725424389895897
26-Feb-25 09:38:41 - agent.DQN.DQN - INFO - episode 7 step 193 reward tensor([-1]) loss 0.6152650117874146 epsilon 0.6725424389895897
26-Feb-25 09:38:41 - agent.DQN.DQN - INFO - episode 7 step 194 reward tensor([-1]) loss 0.3320194184780121 epsilon 0.6725424389895897
26-Feb-25 09:38:41 - agent.DQN.DQN - INFO - episode 7 step 195 reward tensor([-1]) loss 0.2945750057697296 epsilon 0.6725424389895897
26-Feb-25 09:38:41 - agent.DQN.DQN - INFO - episode 7 step 196 reward tensor([-1]) loss 0.39072924852371216 epsilon 0.6725424389895897
26-Feb-25 09:38:41 - agent.DQN.DQN - INFO - episode 7 step 197 reward tensor([-1]) loss 0.2595038414001465 epsilon 0.6725424389895897
26-Feb-25 09:38:41 - agent.DQN.DQN - INFO - episode 7 step 198 reward tensor([-1]) loss 0.3487287163734436 epsilon 0.6725424389895897
26-Feb-25 09:38:41 - agent.DQN.DQN - INFO - episode 7 step 199 reward tensor([-1]) loss 0.4373866319656372 epsilon 0.6725424389895897
26-Feb-25 09:38:41 - agent.DQN.DQN - INFO - episode 7 step 200 reward tensor([-1]) loss 0.3263079822063446 epsilon 0.6725424389895897
26-Feb-25 09:38:41 - agent.DQN.DQN - INFO - episode 7 step 201 reward tensor([-1]) loss 0.33890998363494873 epsilon 0.6725424389895897
26-Feb-25 09:38:41 - agent.DQN.DQN - INFO - episode 7 step 202 reward tensor([-1]) loss 0.3158791661262512 epsilon 0.6725424389895897
26-Feb-25 09:38:41 - agent.DQN.DQN - INFO - episode 7 step 203 reward tensor([-1]) loss 0.3154589831829071 epsilon 0.6725424389895897
26-Feb-25 09:38:41 - agent.DQN.DQN - INFO - episode 7 step 204 reward tensor([-1]) loss 0.291252076625824 epsilon 0.6725424389895897
26-Feb-25 09:38:41 - agent.DQN.DQN - INFO - episode 7 step 205 reward tensor([-1]) loss 0.43396463990211487 epsilon 0.6725424389895897
26-Feb-25 09:38:41 - agent.DQN.DQN - INFO - episode 7 step 206 reward tensor([-1]) loss 0.29370594024658203 epsilon 0.6725424389895897
26-Feb-25 09:38:41 - agent.DQN.DQN - INFO - episode 7 step 207 reward tensor([-1]) loss 0.29177677631378174 epsilon 0.6725424389895897
26-Feb-25 09:38:41 - agent.DQN.DQN - INFO - episode 7 step 208 reward tensor([-1]) loss 0.26780757308006287 epsilon 0.6725424389895897
26-Feb-25 09:38:41 - agent.DQN.DQN - INFO - episode 7 step 209 reward tensor([-1]) loss 0.35609740018844604 epsilon 0.6725424389895897
26-Feb-25 09:38:41 - agent.DQN.DQN - INFO - episode 7 step 210 reward tensor([-1]) loss 0.27595221996307373 epsilon 0.6725424389895897
26-Feb-25 09:38:41 - agent.DQN.DQN - INFO - episode 7 step 211 reward tensor([-1]) loss 0.253273606300354 epsilon 0.6725424389895897
26-Feb-25 09:38:41 - agent.DQN.DQN - INFO - episode 7 step 212 reward tensor([-1]) loss 0.3773800730705261 epsilon 0.6725424389895897
26-Feb-25 09:38:41 - agent.DQN.DQN - INFO - episode 7 step 213 reward tensor([-1]) loss 0.4345620274543762 epsilon 0.6725424389895897
26-Feb-25 09:38:41 - agent.DQN.DQN - INFO - episode 7 step 214 reward tensor([-1]) loss 0.3159372806549072 epsilon 0.6725424389895897
26-Feb-25 09:38:41 - agent.DQN.DQN - INFO - episode 7 step 215 reward tensor([-1]) loss 0.4414628744125366 epsilon 0.6725424389895897
26-Feb-25 09:38:41 - agent.DQN.DQN - INFO - episode 7 step 216 reward tensor([-1]) loss 0.32879823446273804 epsilon 0.6725424389895897
26-Feb-25 09:38:41 - agent.DQN.DQN - INFO - episode 7 step 217 reward tensor([-1]) loss 0.32357466220855713 epsilon 0.6725424389895897
26-Feb-25 09:38:41 - agent.DQN.DQN - INFO - episode 7 step 218 reward tensor([-1]) loss 0.2567213475704193 epsilon 0.6725424389895897
26-Feb-25 09:38:41 - agent.DQN.DQN - INFO - episode 7 step 219 reward tensor([-1]) loss 0.37587252259254456 epsilon 0.6725424389895897
26-Feb-25 09:38:41 - agent.DQN.DQN - INFO - episode 7 step 220 reward tensor([-1]) loss 0.30299684405326843 epsilon 0.6725424389895897
26-Feb-25 09:38:41 - agent.DQN.DQN - INFO - episode 7 step 221 reward tensor([-1]) loss 0.27378806471824646 epsilon 0.6725424389895897
26-Feb-25 09:38:41 - agent.DQN.DQN - INFO - episode 7 step 222 reward tensor([-1]) loss 0.3362525999546051 epsilon 0.6725424389895897
26-Feb-25 09:38:41 - agent.DQN.DQN - INFO - episode 7 step 223 reward tensor([-1]) loss 0.3876503109931946 epsilon 0.6725424389895897
26-Feb-25 09:38:41 - agent.DQN.DQN - INFO - episode 7 step 224 reward tensor([-1]) loss 0.6131017208099365 epsilon 0.6725424389895897
26-Feb-25 09:38:41 - agent.DQN.DQN - INFO - episode 7 step 225 reward tensor([-1]) loss 0.3220769762992859 epsilon 0.6725424389895897
26-Feb-25 09:38:41 - agent.DQN.DQN - INFO - episode 7 step 226 reward tensor([-1]) loss 0.25570422410964966 epsilon 0.6725424389895897
26-Feb-25 09:38:41 - agent.DQN.DQN - INFO - episode 7 step 227 reward tensor([-1]) loss 0.2722017168998718 epsilon 0.6725424389895897
26-Feb-25 09:38:41 - agent.DQN.DQN - INFO - episode 7 step 228 reward tensor([-1]) loss 0.26755523681640625 epsilon 0.6725424389895897
26-Feb-25 09:38:41 - agent.DQN.DQN - INFO - episode 7 step 229 reward tensor([-1]) loss 0.3148452937602997 epsilon 0.6725424389895897
26-Feb-25 09:38:41 - agent.DQN.DQN - INFO - episode 7 step 230 reward tensor([-1]) loss 0.3958848714828491 epsilon 0.6725424389895897
26-Feb-25 09:38:41 - agent.DQN.DQN - INFO - episode 7 step 231 reward tensor([-1]) loss 0.30492016673088074 epsilon 0.6725424389895897
26-Feb-25 09:38:41 - agent.DQN.DQN - INFO - episode 7 step 232 reward tensor([-1]) loss 0.3239843547344208 epsilon 0.6725424389895897
26-Feb-25 09:38:41 - agent.DQN.DQN - INFO - episode 7 step 233 reward tensor([-1]) loss 0.35956060886383057 epsilon 0.6725424389895897
26-Feb-25 09:38:41 - agent.DQN.DQN - INFO - episode 7 step 234 reward tensor([-1]) loss 0.2795497179031372 epsilon 0.6725424389895897
26-Feb-25 09:38:41 - agent.DQN.DQN - INFO - episode 7 step 235 reward tensor([-1]) loss 0.29172617197036743 epsilon 0.6725424389895897
26-Feb-25 09:38:41 - agent.DQN.DQN - INFO - episode 7 step 236 reward tensor([-1]) loss 0.6377483606338501 epsilon 0.6725424389895897
26-Feb-25 09:38:41 - agent.DQN.DQN - INFO - episode 7 step 237 reward tensor([-1]) loss 0.43296703696250916 epsilon 0.6725424389895897
26-Feb-25 09:38:41 - agent.DQN.DQN - INFO - episode 7 step 238 reward tensor([-1]) loss 0.379503458738327 epsilon 0.6725424389895897
26-Feb-25 09:38:41 - agent.DQN.DQN - INFO - episode 7 step 239 reward tensor([-1]) loss 0.2887227237224579 epsilon 0.6725424389895897
26-Feb-25 09:38:41 - agent.DQN.DQN - INFO - episode 7 step 240 reward tensor([-1]) loss 0.2647944986820221 epsilon 0.6725424389895897
26-Feb-25 09:38:41 - agent.DQN.DQN - INFO - episode 7 step 241 reward tensor([-1]) loss 0.39363405108451843 epsilon 0.6725424389895897
26-Feb-25 09:38:41 - agent.DQN.DQN - INFO - episode 7 step 242 reward tensor([-1]) loss 0.23664583265781403 epsilon 0.6725424389895897
26-Feb-25 09:38:41 - agent.DQN.DQN - INFO - episode 7 step 243 reward tensor([-1]) loss 0.40427348017692566 epsilon 0.6725424389895897
26-Feb-25 09:38:41 - agent.DQN.DQN - INFO - episode 7 step 244 reward tensor([-1]) loss 0.22104904055595398 epsilon 0.6725424389895897
26-Feb-25 09:38:41 - agent.DQN.DQN - INFO - episode 7 step 245 reward tensor([-1]) loss 0.31536465883255005 epsilon 0.6725424389895897
26-Feb-25 09:38:41 - agent.DQN.DQN - INFO - episode 7 step 246 reward tensor([-1]) loss 0.3440350294113159 epsilon 0.6725424389895897
26-Feb-25 09:38:41 - agent.DQN.DQN - INFO - episode 7 step 247 reward tensor([-1]) loss 0.3273812532424927 epsilon 0.6725424389895897
26-Feb-25 09:38:41 - agent.DQN.DQN - INFO - episode 7 step 248 reward tensor([-1]) loss 0.24144822359085083 epsilon 0.6725424389895897
26-Feb-25 09:38:41 - agent.DQN.DQN - INFO - episode 7 step 249 reward tensor([-1]) loss 0.5478610992431641 epsilon 0.6725424389895897
26-Feb-25 09:38:41 - agent.DQN.DQN - INFO - episode 7 step 250 reward tensor([-1]) loss 0.29850879311561584 epsilon 0.6725424389895897
26-Feb-25 09:38:41 - agent.DQN.DQN - INFO - episode 7 step 251 reward tensor([-1]) loss 0.2673845589160919 epsilon 0.6725424389895897
26-Feb-25 09:38:41 - agent.DQN.DQN - INFO - episode 7 step 252 reward tensor([-1]) loss 0.3177874982357025 epsilon 0.6725424389895897
26-Feb-25 09:38:41 - agent.DQN.DQN - INFO - episode 7 step 253 reward tensor([-1]) loss 0.30607032775878906 epsilon 0.6725424389895897
26-Feb-25 09:38:41 - agent.DQN.DQN - INFO - episode 7 step 254 reward tensor([-1]) loss 0.3035091757774353 epsilon 0.6725424389895897
26-Feb-25 09:38:41 - agent.DQN.DQN - INFO - episode 7 step 255 reward tensor([-1]) loss 0.515553891658783 epsilon 0.6725424389895897
26-Feb-25 09:38:41 - agent.DQN.DQN - INFO - episode 7 step 256 reward tensor([-1]) loss 0.3845575749874115 epsilon 0.6725424389895897
26-Feb-25 09:38:42 - agent.DQN.DQN - INFO - episode 7 step 257 reward tensor([-1]) loss 0.3718952238559723 epsilon 0.6725424389895897
26-Feb-25 09:38:42 - agent.DQN.DQN - INFO - episode 7 step 258 reward tensor([-1]) loss 0.294193834066391 epsilon 0.6725424389895897
26-Feb-25 09:38:42 - agent.DQN.DQN - INFO - episode 7 step 259 reward tensor([-1]) loss 0.3819051682949066 epsilon 0.6725424389895897
26-Feb-25 09:38:42 - agent.DQN.DQN - INFO - episode 7 step 260 reward tensor([-1]) loss 0.3121068775653839 epsilon 0.6725424389895897
26-Feb-25 09:38:42 - agent.DQN.DQN - INFO - episode 7 step 261 reward tensor([-1]) loss 0.36290407180786133 epsilon 0.6725424389895897
26-Feb-25 09:38:42 - agent.DQN.DQN - INFO - episode 7 step 262 reward tensor([-1]) loss 0.31990256905555725 epsilon 0.6725424389895897
26-Feb-25 09:38:42 - agent.DQN.DQN - INFO - episode 7 step 263 reward tensor([-1]) loss 0.2936418950557709 epsilon 0.6725424389895897
26-Feb-25 09:38:42 - agent.DQN.DQN - INFO - episode 7 step 264 reward tensor([-1]) loss 0.31555384397506714 epsilon 0.6725424389895897
26-Feb-25 09:38:42 - agent.DQN.DQN - INFO - episode 7 step 265 reward tensor([-1]) loss 0.3978789448738098 epsilon 0.6725424389895897
26-Feb-25 09:38:42 - agent.DQN.DQN - INFO - episode 7 step 266 reward tensor([-1]) loss 0.40467336773872375 epsilon 0.6725424389895897
26-Feb-25 09:38:42 - agent.DQN.DQN - INFO - episode 7 step 267 reward tensor([-1]) loss 0.34146296977996826 epsilon 0.6725424389895897
26-Feb-25 09:38:42 - agent.DQN.DQN - INFO - episode 7 step 268 reward tensor([-1]) loss 0.6007945537567139 epsilon 0.6725424389895897
26-Feb-25 09:38:42 - agent.DQN.DQN - INFO - episode 7 step 269 reward tensor([-1]) loss 0.3252452313899994 epsilon 0.6725424389895897
26-Feb-25 09:38:42 - agent.DQN.DQN - INFO - episode 7 step 270 reward tensor([-1]) loss 0.40623530745506287 epsilon 0.6725424389895897
26-Feb-25 09:38:42 - agent.DQN.DQN - INFO - episode 7 step 271 reward tensor([-1]) loss 0.4198923707008362 epsilon 0.6725424389895897
26-Feb-25 09:38:42 - agent.DQN.DQN - INFO - episode 7 step 272 reward tensor([-1]) loss 0.5924107432365417 epsilon 0.6725424389895897
26-Feb-25 09:38:42 - agent.DQN.DQN - INFO - episode 7 step 273 reward tensor([-1]) loss 0.310663640499115 epsilon 0.6725424389895897
26-Feb-25 09:38:42 - agent.DQN.DQN - INFO - episode 7 step 274 reward tensor([-1]) loss 0.32017582654953003 epsilon 0.6725424389895897
26-Feb-25 09:38:42 - agent.DQN.DQN - INFO - episode 7 step 275 reward tensor([-1]) loss 0.35626718401908875 epsilon 0.6725424389895897
26-Feb-25 09:38:42 - agent.DQN.DQN - INFO - episode 7 step 276 reward tensor([-1]) loss 0.3272346556186676 epsilon 0.6725424389895897
26-Feb-25 09:38:42 - agent.DQN.DQN - INFO - episode 7 step 277 reward tensor([-1]) loss 0.6042616963386536 epsilon 0.6725424389895897
26-Feb-25 09:38:42 - agent.DQN.DQN - INFO - episode 7 step 278 reward tensor([-1]) loss 0.31019723415374756 epsilon 0.6725424389895897
26-Feb-25 09:38:42 - agent.DQN.DQN - INFO - episode 7 step 279 reward tensor([-1]) loss 0.4201776683330536 epsilon 0.6725424389895897
26-Feb-25 09:38:42 - agent.DQN.DQN - INFO - episode 7 step 280 reward tensor([-1]) loss 0.39998534321784973 epsilon 0.6725424389895897
26-Feb-25 09:38:42 - agent.DQN.DQN - INFO - episode 7 step 281 reward tensor([-1]) loss 0.33238184452056885 epsilon 0.6725424389895897
26-Feb-25 09:38:42 - agent.DQN.DQN - INFO - episode 7 step 282 reward tensor([-1]) loss 0.3142738342285156 epsilon 0.6725424389895897
26-Feb-25 09:38:42 - agent.DQN.DQN - INFO - episode 7 step 283 reward tensor([-1]) loss 0.3047860860824585 epsilon 0.6725424389895897
26-Feb-25 09:38:42 - agent.DQN.DQN - INFO - episode 7 step 284 reward tensor([-1]) loss 0.37413468956947327 epsilon 0.6725424389895897
26-Feb-25 09:38:42 - agent.DQN.DQN - INFO - episode 7 step 285 reward tensor([-1]) loss 0.27678096294403076 epsilon 0.6725424389895897
26-Feb-25 09:38:42 - agent.DQN.DQN - INFO - episode 7 step 286 reward tensor([-1]) loss 0.5361559987068176 epsilon 0.6725424389895897
26-Feb-25 09:38:42 - agent.DQN.DQN - INFO - episode 7 step 287 reward tensor([-1]) loss 0.34525254368782043 epsilon 0.6725424389895897
26-Feb-25 09:38:42 - agent.DQN.DQN - INFO - episode 7 step 288 reward tensor([-1]) loss 0.3471167981624603 epsilon 0.6725424389895897
26-Feb-25 09:38:42 - agent.DQN.DQN - INFO - episode 7 step 289 reward tensor([-1]) loss 0.38622453808784485 epsilon 0.6725424389895897
26-Feb-25 09:38:42 - agent.DQN.DQN - INFO - episode 7 step 290 reward tensor([-1]) loss 0.3708657920360565 epsilon 0.6725424389895897
26-Feb-25 09:38:42 - agent.DQN.DQN - INFO - episode 7 step 291 reward tensor([-1]) loss 0.35944893956184387 epsilon 0.6725424389895897
26-Feb-25 09:38:42 - agent.DQN.DQN - INFO - episode 7 step 292 reward tensor([-1]) loss 0.5047435760498047 epsilon 0.6725424389895897
26-Feb-25 09:38:42 - agent.DQN.DQN - INFO - episode 7 step 293 reward tensor([-1]) loss 0.432594895362854 epsilon 0.6725424389895897
26-Feb-25 09:38:42 - agent.DQN.DQN - INFO - episode 7 step 294 reward tensor([-1]) loss 0.41113704442977905 epsilon 0.6725424389895897
26-Feb-25 09:38:42 - agent.DQN.DQN - INFO - episode 7 step 295 reward tensor([-1]) loss 0.42363324761390686 epsilon 0.6725424389895897
26-Feb-25 09:38:42 - agent.DQN.DQN - INFO - episode 7 step 296 reward tensor([-1]) loss 0.29320603609085083 epsilon 0.6725424389895897
26-Feb-25 09:38:42 - agent.DQN.DQN - INFO - episode 7 step 297 reward tensor([-1]) loss 0.37745198607444763 epsilon 0.6725424389895897
26-Feb-25 09:38:42 - agent.DQN.DQN - INFO - episode 7 step 298 reward tensor([-1]) loss 0.4538344740867615 epsilon 0.6725424389895897
26-Feb-25 09:38:42 - agent.DQN.DQN - INFO - episode 7 step 299 reward tensor([-1]) loss 0.36391332745552063 epsilon 0.6725424389895897
26-Feb-25 09:38:42 - agent.DQN.DQN - INFO - episode 7 step 300 reward tensor([-1]) loss 0.35018280148506165 epsilon 0.6725424389895897
26-Feb-25 09:38:42 - agent.DQN.DQN - INFO - episode 7 step 301 reward tensor([-1]) loss 0.44208306074142456 epsilon 0.6725424389895897
26-Feb-25 09:38:42 - agent.DQN.DQN - INFO - episode 8 step 0 reward tensor([-1]) loss 0.2767655551433563 epsilon 0.650684809722428
26-Feb-25 09:38:42 - agent.DQN.DQN - INFO - episode 8 step 1 reward tensor([-1]) loss 0.39695584774017334 epsilon 0.650684809722428
26-Feb-25 09:38:42 - agent.DQN.DQN - INFO - episode 8 step 2 reward tensor([-1]) loss 0.3385813236236572 epsilon 0.650684809722428
26-Feb-25 09:38:42 - agent.DQN.DQN - INFO - episode 8 step 3 reward tensor([-1]) loss 0.33077216148376465 epsilon 0.650684809722428
26-Feb-25 09:38:42 - agent.DQN.DQN - INFO - episode 8 step 4 reward tensor([-1]) loss 0.32672563195228577 epsilon 0.650684809722428
26-Feb-25 09:38:42 - agent.DQN.DQN - INFO - episode 8 step 5 reward tensor([-1]) loss 0.363913893699646 epsilon 0.650684809722428
26-Feb-25 09:38:42 - agent.DQN.DQN - INFO - episode 8 step 6 reward tensor([-1]) loss 0.4208412170410156 epsilon 0.650684809722428
26-Feb-25 09:38:42 - agent.DQN.DQN - INFO - episode 8 step 7 reward tensor([-1]) loss 0.40236350893974304 epsilon 0.650684809722428
26-Feb-25 09:38:42 - agent.DQN.DQN - INFO - episode 8 step 8 reward tensor([-1]) loss 0.5618003606796265 epsilon 0.650684809722428
26-Feb-25 09:38:42 - agent.DQN.DQN - INFO - episode 8 step 9 reward tensor([-1]) loss 0.3120107650756836 epsilon 0.650684809722428
26-Feb-25 09:38:42 - agent.DQN.DQN - INFO - episode 8 step 10 reward tensor([-1]) loss 0.4028344452381134 epsilon 0.650684809722428
26-Feb-25 09:38:42 - agent.DQN.DQN - INFO - episode 8 step 11 reward tensor([-1]) loss 0.3216589093208313 epsilon 0.650684809722428
26-Feb-25 09:38:42 - agent.DQN.DQN - INFO - episode 8 step 12 reward tensor([-1]) loss 0.26492926478385925 epsilon 0.650684809722428
26-Feb-25 09:38:42 - agent.DQN.DQN - INFO - episode 8 step 13 reward tensor([-1]) loss 0.35735177993774414 epsilon 0.650684809722428
26-Feb-25 09:38:42 - agent.DQN.DQN - INFO - episode 8 step 14 reward tensor([-1]) loss 0.35661712288856506 epsilon 0.650684809722428
26-Feb-25 09:38:42 - agent.DQN.DQN - INFO - episode 8 step 15 reward tensor([-1]) loss 0.3266444206237793 epsilon 0.650684809722428
26-Feb-25 09:38:42 - agent.DQN.DQN - INFO - episode 8 step 16 reward tensor([-1]) loss 0.4114043116569519 epsilon 0.650684809722428
26-Feb-25 09:38:42 - agent.DQN.DQN - INFO - episode 8 step 17 reward tensor([-1]) loss 0.2908517122268677 epsilon 0.650684809722428
26-Feb-25 09:38:42 - agent.DQN.DQN - INFO - episode 8 step 18 reward tensor([-1]) loss 0.35130730271339417 epsilon 0.650684809722428
26-Feb-25 09:38:42 - agent.DQN.DQN - INFO - episode 8 step 19 reward tensor([-1]) loss 0.31941699981689453 epsilon 0.650684809722428
26-Feb-25 09:38:42 - agent.DQN.DQN - INFO - episode 8 step 20 reward tensor([-1]) loss 0.33548223972320557 epsilon 0.650684809722428
26-Feb-25 09:38:42 - agent.DQN.DQN - INFO - episode 8 step 21 reward tensor([-1]) loss 0.3359619677066803 epsilon 0.650684809722428
26-Feb-25 09:38:42 - agent.DQN.DQN - INFO - episode 8 step 22 reward tensor([-1]) loss 0.38002443313598633 epsilon 0.650684809722428
26-Feb-25 09:38:42 - agent.DQN.DQN - INFO - episode 8 step 23 reward tensor([-1]) loss 0.4916638433933258 epsilon 0.650684809722428
26-Feb-25 09:38:42 - agent.DQN.DQN - INFO - episode 8 step 24 reward tensor([-1]) loss 0.25207796692848206 epsilon 0.650684809722428
26-Feb-25 09:38:43 - agent.DQN.DQN - INFO - episode 8 step 25 reward tensor([-1]) loss 0.4972619116306305 epsilon 0.650684809722428
26-Feb-25 09:38:43 - agent.DQN.DQN - INFO - episode 8 step 26 reward tensor([-1]) loss 0.3927357494831085 epsilon 0.650684809722428
26-Feb-25 09:38:43 - agent.DQN.DQN - INFO - episode 8 step 27 reward tensor([-1]) loss 0.427926242351532 epsilon 0.650684809722428
26-Feb-25 09:38:43 - agent.DQN.DQN - INFO - episode 8 step 28 reward tensor([-1]) loss 0.35191255807876587 epsilon 0.650684809722428
26-Feb-25 09:38:43 - agent.DQN.DQN - INFO - episode 8 step 29 reward tensor([-1]) loss 0.3857819437980652 epsilon 0.650684809722428
26-Feb-25 09:38:43 - agent.DQN.DQN - INFO - episode 8 step 30 reward tensor([-1]) loss 0.49917277693748474 epsilon 0.650684809722428
26-Feb-25 09:38:43 - agent.DQN.DQN - INFO - episode 8 step 31 reward tensor([-1]) loss 0.3712077736854553 epsilon 0.650684809722428
26-Feb-25 09:38:43 - agent.DQN.DQN - INFO - episode 8 step 32 reward tensor([-1]) loss 0.3583606481552124 epsilon 0.650684809722428
26-Feb-25 09:38:43 - agent.DQN.DQN - INFO - episode 8 step 33 reward tensor([-1]) loss 0.3341751992702484 epsilon 0.650684809722428
26-Feb-25 09:38:43 - agent.DQN.DQN - INFO - episode 8 step 34 reward tensor([-1]) loss 0.4883773624897003 epsilon 0.650684809722428
26-Feb-25 09:38:43 - agent.DQN.DQN - INFO - episode 8 step 35 reward tensor([-1]) loss 0.5917952060699463 epsilon 0.650684809722428
26-Feb-25 09:38:43 - agent.DQN.DQN - INFO - episode 8 step 36 reward tensor([-1]) loss 0.29616275429725647 epsilon 0.650684809722428
26-Feb-25 09:38:43 - agent.DQN.DQN - INFO - episode 8 step 37 reward tensor([-1]) loss 0.31200167536735535 epsilon 0.650684809722428
26-Feb-25 09:38:43 - agent.DQN.DQN - INFO - episode 8 step 38 reward tensor([-1]) loss 0.28017503023147583 epsilon 0.650684809722428
26-Feb-25 09:38:43 - agent.DQN.DQN - INFO - episode 8 step 39 reward tensor([-1]) loss 0.3697231709957123 epsilon 0.650684809722428
26-Feb-25 09:38:43 - agent.DQN.DQN - INFO - episode 8 step 40 reward tensor([-1]) loss 0.31347188353538513 epsilon 0.650684809722428
26-Feb-25 09:38:43 - agent.DQN.DQN - INFO - episode 8 step 41 reward tensor([-1]) loss 0.27931031584739685 epsilon 0.650684809722428
26-Feb-25 09:38:43 - agent.DQN.DQN - INFO - episode 8 step 42 reward tensor([-1]) loss 0.3129752576351166 epsilon 0.650684809722428
26-Feb-25 09:38:43 - agent.DQN.DQN - INFO - episode 8 step 43 reward tensor([-1]) loss 0.31369006633758545 epsilon 0.650684809722428
26-Feb-25 09:38:43 - agent.DQN.DQN - INFO - episode 8 step 44 reward tensor([-1]) loss 0.25608304142951965 epsilon 0.650684809722428
26-Feb-25 09:38:43 - agent.DQN.DQN - INFO - episode 8 step 45 reward tensor([-1]) loss 0.35748937726020813 epsilon 0.650684809722428
26-Feb-25 09:38:43 - agent.DQN.DQN - INFO - episode 8 step 46 reward tensor([-1]) loss 0.2912600040435791 epsilon 0.650684809722428
26-Feb-25 09:38:43 - agent.DQN.DQN - INFO - episode 8 step 47 reward tensor([-1]) loss 0.3593652546405792 epsilon 0.650684809722428
26-Feb-25 09:38:43 - agent.DQN.DQN - INFO - episode 8 step 48 reward tensor([-1]) loss 0.4858786165714264 epsilon 0.650684809722428
26-Feb-25 09:38:43 - agent.DQN.DQN - INFO - episode 8 step 49 reward tensor([-1]) loss 0.35025879740715027 epsilon 0.650684809722428
26-Feb-25 09:38:43 - agent.DQN.DQN - INFO - episode 8 step 50 reward tensor([-1]) loss 0.3329378664493561 epsilon 0.650684809722428
26-Feb-25 09:38:43 - agent.DQN.DQN - INFO - episode 8 step 51 reward tensor([-1]) loss 0.3417801558971405 epsilon 0.650684809722428
26-Feb-25 09:38:43 - agent.DQN.DQN - INFO - episode 8 step 52 reward tensor([-1]) loss 0.32270023226737976 epsilon 0.650684809722428
26-Feb-25 09:38:43 - agent.DQN.DQN - INFO - episode 8 step 53 reward tensor([-1]) loss 0.2921125292778015 epsilon 0.650684809722428
26-Feb-25 09:38:43 - agent.DQN.DQN - INFO - episode 8 step 54 reward tensor([-1]) loss 0.5097588896751404 epsilon 0.650684809722428
26-Feb-25 09:38:43 - agent.DQN.DQN - INFO - episode 8 step 55 reward tensor([-1]) loss 0.5625452399253845 epsilon 0.650684809722428
26-Feb-25 09:38:43 - agent.DQN.DQN - INFO - episode 8 step 56 reward tensor([-1]) loss 0.4112173318862915 epsilon 0.650684809722428
26-Feb-25 09:38:43 - agent.DQN.DQN - INFO - episode 8 step 57 reward tensor([-1]) loss 0.3149483799934387 epsilon 0.650684809722428
26-Feb-25 09:38:43 - agent.DQN.DQN - INFO - episode 8 step 58 reward tensor([-1]) loss 0.27290013432502747 epsilon 0.650684809722428
26-Feb-25 09:38:43 - agent.DQN.DQN - INFO - episode 8 step 59 reward tensor([-1]) loss 0.29621902108192444 epsilon 0.650684809722428
26-Feb-25 09:38:43 - agent.DQN.DQN - INFO - episode 8 step 60 reward tensor([-1]) loss 0.5903089642524719 epsilon 0.650684809722428
26-Feb-25 09:38:43 - agent.DQN.DQN - INFO - episode 8 step 61 reward tensor([-1]) loss 0.4894145727157593 epsilon 0.650684809722428
26-Feb-25 09:38:43 - agent.DQN.DQN - INFO - episode 8 step 62 reward tensor([-1]) loss 0.4586310088634491 epsilon 0.650684809722428
26-Feb-25 09:38:43 - agent.DQN.DQN - INFO - episode 8 step 63 reward tensor([-1]) loss 0.2770792543888092 epsilon 0.650684809722428
26-Feb-25 09:38:43 - agent.DQN.DQN - INFO - episode 8 step 64 reward tensor([-1]) loss 0.23803921043872833 epsilon 0.650684809722428
26-Feb-25 09:38:43 - agent.DQN.DQN - INFO - episode 8 step 65 reward tensor([-1]) loss 0.32307323813438416 epsilon 0.650684809722428
26-Feb-25 09:38:43 - agent.DQN.DQN - INFO - episode 8 step 66 reward tensor([-1]) loss 0.32059964537620544 epsilon 0.650684809722428
26-Feb-25 09:38:43 - agent.DQN.DQN - INFO - episode 8 step 67 reward tensor([-1]) loss 0.2718944549560547 epsilon 0.650684809722428
26-Feb-25 09:38:43 - agent.DQN.DQN - INFO - episode 8 step 68 reward tensor([-1]) loss 0.311320424079895 epsilon 0.650684809722428
26-Feb-25 09:38:43 - agent.DQN.DQN - INFO - episode 8 step 69 reward tensor([-1]) loss 0.3001871109008789 epsilon 0.650684809722428
26-Feb-25 09:38:43 - agent.DQN.DQN - INFO - episode 8 step 70 reward tensor([-1]) loss 0.4205889403820038 epsilon 0.650684809722428
26-Feb-25 09:38:43 - agent.DQN.DQN - INFO - episode 8 step 71 reward tensor([-1]) loss 0.3041462302207947 epsilon 0.650684809722428
26-Feb-25 09:38:43 - agent.DQN.DQN - INFO - episode 8 step 72 reward tensor([-1]) loss 0.32297027111053467 epsilon 0.650684809722428
26-Feb-25 09:38:43 - agent.DQN.DQN - INFO - episode 8 step 73 reward tensor([-1]) loss 0.4058364927768707 epsilon 0.650684809722428
26-Feb-25 09:38:43 - agent.DQN.DQN - INFO - episode 8 step 74 reward tensor([-1]) loss 0.32800933718681335 epsilon 0.650684809722428
26-Feb-25 09:38:43 - agent.DQN.DQN - INFO - episode 8 step 75 reward tensor([-1]) loss 0.35284268856048584 epsilon 0.650684809722428
26-Feb-25 09:38:43 - agent.DQN.DQN - INFO - episode 8 step 76 reward tensor([-1]) loss 0.32703104615211487 epsilon 0.650684809722428
26-Feb-25 09:38:43 - agent.DQN.DQN - INFO - episode 8 step 77 reward tensor([-1]) loss 0.3413911461830139 epsilon 0.650684809722428
26-Feb-25 09:38:43 - agent.DQN.DQN - INFO - episode 8 step 78 reward tensor([-1]) loss 0.35790929198265076 epsilon 0.650684809722428
26-Feb-25 09:38:43 - agent.DQN.DQN - INFO - episode 8 step 79 reward tensor([-1]) loss 0.3453705310821533 epsilon 0.650684809722428
26-Feb-25 09:38:43 - agent.DQN.DQN - INFO - episode 8 step 80 reward tensor([-1]) loss 0.378996878862381 epsilon 0.650684809722428
26-Feb-25 09:38:43 - agent.DQN.DQN - INFO - episode 8 step 81 reward tensor([-1]) loss 0.33288198709487915 epsilon 0.650684809722428
26-Feb-25 09:38:43 - agent.DQN.DQN - INFO - episode 8 step 82 reward tensor([-1]) loss 0.3076484799385071 epsilon 0.650684809722428
26-Feb-25 09:38:43 - agent.DQN.DQN - INFO - episode 8 step 83 reward tensor([-1]) loss 0.3276475965976715 epsilon 0.650684809722428
26-Feb-25 09:38:43 - agent.DQN.DQN - INFO - episode 8 step 84 reward tensor([-1]) loss 0.35730573534965515 epsilon 0.650684809722428
26-Feb-25 09:38:43 - agent.DQN.DQN - INFO - episode 8 step 85 reward tensor([-1]) loss 0.2766531705856323 epsilon 0.650684809722428
26-Feb-25 09:38:43 - agent.DQN.DQN - INFO - episode 8 step 86 reward tensor([-1]) loss 0.3210581839084625 epsilon 0.650684809722428
26-Feb-25 09:38:43 - agent.DQN.DQN - INFO - episode 8 step 87 reward tensor([-1]) loss 0.2718021869659424 epsilon 0.650684809722428
26-Feb-25 09:38:43 - agent.DQN.DQN - INFO - episode 8 step 88 reward tensor([-1]) loss 0.6326154470443726 epsilon 0.650684809722428
26-Feb-25 09:38:43 - agent.DQN.DQN - INFO - episode 8 step 89 reward tensor([-1]) loss 0.4112109839916229 epsilon 0.650684809722428
26-Feb-25 09:38:43 - agent.DQN.DQN - INFO - episode 8 step 90 reward tensor([-1]) loss 0.3983936905860901 epsilon 0.650684809722428
26-Feb-25 09:38:43 - agent.DQN.DQN - INFO - episode 8 step 91 reward tensor([-1]) loss 0.28205302357673645 epsilon 0.650684809722428
26-Feb-25 09:38:43 - agent.DQN.DQN - INFO - episode 8 step 92 reward tensor([-1]) loss 0.28706902265548706 epsilon 0.650684809722428
26-Feb-25 09:38:43 - agent.DQN.DQN - INFO - episode 8 step 93 reward tensor([-1]) loss 0.26576754450798035 epsilon 0.650684809722428
26-Feb-25 09:38:43 - agent.DQN.DQN - INFO - episode 8 step 94 reward tensor([-1]) loss 0.2759970426559448 epsilon 0.650684809722428
26-Feb-25 09:38:43 - agent.DQN.DQN - INFO - episode 8 step 95 reward tensor([-1]) loss 0.2755624055862427 epsilon 0.650684809722428
26-Feb-25 09:38:43 - agent.DQN.DQN - INFO - episode 8 step 96 reward tensor([-1]) loss 0.2864605188369751 epsilon 0.650684809722428
26-Feb-25 09:38:43 - agent.DQN.DQN - INFO - episode 8 step 97 reward tensor([-1]) loss 0.33006390929222107 epsilon 0.650684809722428
26-Feb-25 09:38:43 - agent.DQN.DQN - INFO - episode 8 step 98 reward tensor([-1]) loss 0.45889347791671753 epsilon 0.650684809722428
26-Feb-25 09:38:43 - agent.DQN.DQN - INFO - episode 8 step 99 reward tensor([-1]) loss 0.28700727224349976 epsilon 0.650684809722428
26-Feb-25 09:38:43 - agent.DQN.DQN - INFO - episode 8 step 100 reward tensor([-1]) loss 0.3145446479320526 epsilon 0.650684809722428
26-Feb-25 09:38:43 - agent.DQN.DQN - INFO - episode 8 step 101 reward tensor([-1]) loss 0.3361491858959198 epsilon 0.650684809722428
26-Feb-25 09:38:43 - agent.DQN.DQN - INFO - episode 8 step 102 reward tensor([-1]) loss 0.3125576674938202 epsilon 0.650684809722428
26-Feb-25 09:38:43 - agent.DQN.DQN - INFO - episode 8 step 103 reward tensor([-1]) loss 0.24618954956531525 epsilon 0.650684809722428
26-Feb-25 09:38:43 - agent.DQN.DQN - INFO - episode 8 step 104 reward tensor([-1]) loss 0.3611495792865753 epsilon 0.650684809722428
26-Feb-25 09:38:43 - agent.DQN.DQN - INFO - episode 8 step 105 reward tensor([-1]) loss 0.2838558256626129 epsilon 0.650684809722428
26-Feb-25 09:38:43 - agent.DQN.DQN - INFO - episode 8 step 106 reward tensor([-1]) loss 0.3350467085838318 epsilon 0.650684809722428
26-Feb-25 09:38:44 - agent.DQN.DQN - INFO - episode 8 step 107 reward tensor([-1]) loss 0.3275895416736603 epsilon 0.650684809722428
26-Feb-25 09:38:44 - agent.DQN.DQN - INFO - episode 8 step 108 reward tensor([-1]) loss 0.33358070254325867 epsilon 0.650684809722428
26-Feb-25 09:38:44 - agent.DQN.DQN - INFO - episode 8 step 109 reward tensor([-1]) loss 0.33778852224349976 epsilon 0.650684809722428
26-Feb-25 09:38:44 - agent.DQN.DQN - INFO - episode 8 step 110 reward tensor([-1]) loss 0.35292959213256836 epsilon 0.650684809722428
26-Feb-25 09:38:44 - agent.DQN.DQN - INFO - episode 8 step 111 reward tensor([-1]) loss 0.38795268535614014 epsilon 0.650684809722428
26-Feb-25 09:38:44 - agent.DQN.DQN - INFO - episode 8 step 112 reward tensor([-1]) loss 0.5305426716804504 epsilon 0.650684809722428
26-Feb-25 09:38:44 - agent.DQN.DQN - INFO - episode 8 step 113 reward tensor([-1]) loss 0.259565144777298 epsilon 0.650684809722428
26-Feb-25 09:38:44 - agent.DQN.DQN - INFO - episode 8 step 114 reward tensor([-1]) loss 0.526193380355835 epsilon 0.650684809722428
26-Feb-25 09:38:44 - agent.DQN.DQN - INFO - episode 8 step 115 reward tensor([-1]) loss 0.23057293891906738 epsilon 0.650684809722428
26-Feb-25 09:38:44 - agent.DQN.DQN - INFO - episode 8 step 116 reward tensor([-1]) loss 0.3691096305847168 epsilon 0.650684809722428
26-Feb-25 09:38:44 - agent.DQN.DQN - INFO - episode 8 step 117 reward tensor([-1]) loss 0.2583981156349182 epsilon 0.650684809722428
26-Feb-25 09:38:44 - agent.DQN.DQN - INFO - episode 8 step 118 reward tensor([-1]) loss 0.3134690523147583 epsilon 0.650684809722428
26-Feb-25 09:38:44 - agent.DQN.DQN - INFO - episode 8 step 119 reward tensor([-1]) loss 0.38820698857307434 epsilon 0.650684809722428
26-Feb-25 09:38:44 - agent.DQN.DQN - INFO - episode 8 step 120 reward tensor([-1]) loss 0.2732774019241333 epsilon 0.650684809722428
26-Feb-25 09:38:44 - agent.DQN.DQN - INFO - episode 8 step 121 reward tensor([-1]) loss 0.2761476933956146 epsilon 0.650684809722428
26-Feb-25 09:38:44 - agent.DQN.DQN - INFO - episode 8 step 122 reward tensor([-1]) loss 0.3239966034889221 epsilon 0.650684809722428
26-Feb-25 09:38:44 - agent.DQN.DQN - INFO - episode 8 step 123 reward tensor([-1]) loss 0.3020370304584503 epsilon 0.650684809722428
26-Feb-25 09:38:44 - agent.DQN.DQN - INFO - episode 8 step 124 reward tensor([-1]) loss 0.349348783493042 epsilon 0.650684809722428
26-Feb-25 09:38:44 - agent.DQN.DQN - INFO - episode 8 step 125 reward tensor([-1]) loss 0.5101767778396606 epsilon 0.650684809722428
26-Feb-25 09:38:44 - agent.DQN.DQN - INFO - episode 8 step 126 reward tensor([-1]) loss 0.33320075273513794 epsilon 0.650684809722428
26-Feb-25 09:38:44 - agent.DQN.DQN - INFO - episode 8 step 127 reward tensor([-1]) loss 0.5012608170509338 epsilon 0.650684809722428
26-Feb-25 09:38:44 - agent.DQN.DQN - INFO - episode 8 step 128 reward tensor([-1]) loss 0.2983671724796295 epsilon 0.650684809722428
26-Feb-25 09:38:44 - agent.DQN.DQN - INFO - episode 8 step 129 reward tensor([-1]) loss 0.28389620780944824 epsilon 0.650684809722428
26-Feb-25 09:38:44 - agent.DQN.DQN - INFO - episode 8 step 130 reward tensor([-1]) loss 0.3500896990299225 epsilon 0.650684809722428
26-Feb-25 09:38:44 - agent.DQN.DQN - INFO - episode 8 step 131 reward tensor([-1]) loss 0.269478976726532 epsilon 0.650684809722428
26-Feb-25 09:38:44 - agent.DQN.DQN - INFO - episode 8 step 132 reward tensor([-1]) loss 0.2681209146976471 epsilon 0.650684809722428
26-Feb-25 09:38:44 - agent.DQN.DQN - INFO - episode 8 step 133 reward tensor([-1]) loss 0.2814229428768158 epsilon 0.650684809722428
26-Feb-25 09:38:44 - agent.DQN.DQN - INFO - episode 8 step 134 reward tensor([-1]) loss 0.2769928574562073 epsilon 0.650684809722428
26-Feb-25 09:38:44 - agent.DQN.DQN - INFO - episode 8 step 135 reward tensor([-1]) loss 0.3298698663711548 epsilon 0.650684809722428
26-Feb-25 09:38:44 - agent.DQN.DQN - INFO - episode 8 step 136 reward tensor([-1]) loss 0.313364177942276 epsilon 0.650684809722428
26-Feb-25 09:38:44 - agent.DQN.DQN - INFO - episode 8 step 137 reward tensor([-1]) loss 0.4012588560581207 epsilon 0.650684809722428
26-Feb-25 09:38:44 - agent.DQN.DQN - INFO - episode 8 step 138 reward tensor([-1]) loss 0.37520015239715576 epsilon 0.650684809722428
26-Feb-25 09:38:44 - agent.DQN.DQN - INFO - episode 8 step 139 reward tensor([-1]) loss 0.37658780813217163 epsilon 0.650684809722428
26-Feb-25 09:38:44 - agent.DQN.DQN - INFO - episode 8 step 140 reward tensor([-1]) loss 0.3162083327770233 epsilon 0.650684809722428
26-Feb-25 09:38:44 - agent.DQN.DQN - INFO - episode 8 step 141 reward tensor([-1]) loss 0.34281980991363525 epsilon 0.650684809722428
26-Feb-25 09:38:44 - agent.DQN.DQN - INFO - episode 8 step 142 reward tensor([-1]) loss 0.3694377839565277 epsilon 0.650684809722428
26-Feb-25 09:38:44 - agent.DQN.DQN - INFO - episode 8 step 143 reward tensor([-1]) loss 0.23723706603050232 epsilon 0.650684809722428
26-Feb-25 09:38:44 - agent.DQN.DQN - INFO - episode 8 step 144 reward tensor([-1]) loss 0.30194512009620667 epsilon 0.650684809722428
26-Feb-25 09:38:44 - agent.DQN.DQN - INFO - episode 8 step 145 reward tensor([-1]) loss 0.3748246431350708 epsilon 0.650684809722428
26-Feb-25 09:38:44 - agent.DQN.DQN - INFO - episode 8 step 146 reward tensor([-1]) loss 0.3161323666572571 epsilon 0.650684809722428
26-Feb-25 09:38:44 - agent.DQN.DQN - INFO - episode 8 step 147 reward tensor([-1]) loss 0.30434495210647583 epsilon 0.650684809722428
26-Feb-25 09:38:44 - agent.DQN.DQN - INFO - episode 8 step 148 reward tensor([-1]) loss 0.3386988341808319 epsilon 0.650684809722428
26-Feb-25 09:38:44 - agent.DQN.DQN - INFO - episode 8 step 149 reward tensor([-1]) loss 0.3410826027393341 epsilon 0.650684809722428
26-Feb-25 09:38:44 - agent.DQN.DQN - INFO - episode 8 step 150 reward tensor([-1]) loss 0.33729469776153564 epsilon 0.650684809722428
26-Feb-25 09:38:44 - agent.DQN.DQN - INFO - episode 8 step 151 reward tensor([-1]) loss 0.29437240958213806 epsilon 0.650684809722428
26-Feb-25 09:38:44 - agent.DQN.DQN - INFO - episode 8 step 152 reward tensor([-1]) loss 0.2588975429534912 epsilon 0.650684809722428
26-Feb-25 09:38:44 - agent.DQN.DQN - INFO - episode 8 step 153 reward tensor([-1]) loss 0.5103921890258789 epsilon 0.650684809722428
26-Feb-25 09:38:44 - agent.DQN.DQN - INFO - episode 8 step 154 reward tensor([-1]) loss 0.27214017510414124 epsilon 0.650684809722428
26-Feb-25 09:38:44 - agent.DQN.DQN - INFO - episode 8 step 155 reward tensor([-1]) loss 0.32013314962387085 epsilon 0.650684809722428
26-Feb-25 09:38:44 - agent.DQN.DQN - INFO - episode 8 step 156 reward tensor([-1]) loss 0.47401851415634155 epsilon 0.650684809722428
26-Feb-25 09:38:44 - agent.DQN.DQN - INFO - episode 8 step 157 reward tensor([-1]) loss 0.27261674404144287 epsilon 0.650684809722428
26-Feb-25 09:38:44 - agent.DQN.DQN - INFO - episode 8 step 158 reward tensor([-1]) loss 0.31612274050712585 epsilon 0.650684809722428
26-Feb-25 09:38:44 - agent.DQN.DQN - INFO - episode 8 step 159 reward tensor([-1]) loss 0.3112422227859497 epsilon 0.650684809722428
26-Feb-25 09:38:44 - agent.DQN.DQN - INFO - episode 8 step 160 reward tensor([-1]) loss 0.27389106154441833 epsilon 0.650684809722428
26-Feb-25 09:38:44 - agent.DQN.DQN - INFO - episode 8 step 161 reward tensor([-1]) loss 0.3470837473869324 epsilon 0.650684809722428
26-Feb-25 09:38:44 - agent.DQN.DQN - INFO - episode 8 step 162 reward tensor([-1]) loss 0.3804166615009308 epsilon 0.650684809722428
26-Feb-25 09:38:44 - agent.DQN.DQN - INFO - episode 8 step 163 reward tensor([-1]) loss 0.33983802795410156 epsilon 0.650684809722428
26-Feb-25 09:38:44 - agent.DQN.DQN - INFO - episode 8 step 164 reward tensor([-1]) loss 0.3030047118663788 epsilon 0.650684809722428
26-Feb-25 09:38:44 - agent.DQN.DQN - INFO - episode 8 step 165 reward tensor([-1]) loss 0.3444911241531372 epsilon 0.650684809722428
26-Feb-25 09:38:44 - agent.DQN.DQN - INFO - episode 8 step 166 reward tensor([-1]) loss 0.34464794397354126 epsilon 0.650684809722428
26-Feb-25 09:38:44 - agent.DQN.DQN - INFO - episode 8 step 167 reward tensor([-1]) loss 0.3594340980052948 epsilon 0.650684809722428
26-Feb-25 09:38:44 - agent.DQN.DQN - INFO - episode 8 step 168 reward tensor([-1]) loss 0.41596853733062744 epsilon 0.650684809722428
26-Feb-25 09:38:44 - agent.DQN.DQN - INFO - episode 8 step 169 reward tensor([-1]) loss 0.28292590379714966 epsilon 0.650684809722428
26-Feb-25 09:38:44 - agent.DQN.DQN - INFO - episode 8 step 170 reward tensor([-1]) loss 0.3376549184322357 epsilon 0.650684809722428
26-Feb-25 09:38:44 - agent.DQN.DQN - INFO - episode 8 step 171 reward tensor([-1]) loss 0.32950279116630554 epsilon 0.650684809722428
26-Feb-25 09:38:44 - agent.DQN.DQN - INFO - episode 8 step 172 reward tensor([-1]) loss 0.2541148066520691 epsilon 0.650684809722428
26-Feb-25 09:38:44 - agent.DQN.DQN - INFO - episode 8 step 173 reward tensor([-1]) loss 0.2966412305831909 epsilon 0.650684809722428
26-Feb-25 09:38:44 - agent.DQN.DQN - INFO - episode 8 step 174 reward tensor([-1]) loss 0.36378970742225647 epsilon 0.650684809722428
26-Feb-25 09:38:44 - agent.DQN.DQN - INFO - episode 8 step 175 reward tensor([-1]) loss 0.35155048966407776 epsilon 0.650684809722428
26-Feb-25 09:38:44 - agent.DQN.DQN - INFO - episode 8 step 176 reward tensor([-1]) loss 0.27087873220443726 epsilon 0.650684809722428
26-Feb-25 09:38:44 - agent.DQN.DQN - INFO - episode 8 step 177 reward tensor([-1]) loss 0.30566373467445374 epsilon 0.650684809722428
26-Feb-25 09:38:44 - agent.DQN.DQN - INFO - episode 8 step 178 reward tensor([-1]) loss 0.29702502489089966 epsilon 0.650684809722428
26-Feb-25 09:38:44 - agent.DQN.DQN - INFO - episode 8 step 179 reward tensor([-1]) loss 0.3716336190700531 epsilon 0.650684809722428
26-Feb-25 09:38:44 - agent.DQN.DQN - INFO - episode 8 step 180 reward tensor([-1]) loss 0.3413662612438202 epsilon 0.650684809722428
26-Feb-25 09:38:44 - agent.DQN.DQN - INFO - episode 8 step 181 reward tensor([-1]) loss 0.36024191975593567 epsilon 0.650684809722428
26-Feb-25 09:38:44 - agent.DQN.DQN - INFO - episode 8 step 182 reward tensor([-1]) loss 0.30653589963912964 epsilon 0.650684809722428
26-Feb-25 09:38:44 - agent.DQN.DQN - INFO - episode 8 step 183 reward tensor([-1]) loss 0.5225171446800232 epsilon 0.650684809722428
26-Feb-25 09:38:44 - agent.DQN.DQN - INFO - episode 8 step 184 reward tensor([-1]) loss 0.2813023030757904 epsilon 0.650684809722428
26-Feb-25 09:38:44 - agent.DQN.DQN - INFO - episode 8 step 185 reward tensor([-1]) loss 0.39022621512413025 epsilon 0.650684809722428
26-Feb-25 09:38:44 - agent.DQN.DQN - INFO - episode 8 step 186 reward tensor([-1]) loss 0.3821001648902893 epsilon 0.650684809722428
26-Feb-25 09:38:44 - agent.DQN.DQN - INFO - episode 8 step 187 reward tensor([-1]) loss 0.3299214839935303 epsilon 0.650684809722428
26-Feb-25 09:38:44 - agent.DQN.DQN - INFO - episode 8 step 188 reward tensor([-1]) loss 0.3448425531387329 epsilon 0.650684809722428
26-Feb-25 09:38:45 - agent.DQN.DQN - INFO - episode 8 step 189 reward tensor([-1]) loss 0.31483492255210876 epsilon 0.650684809722428
26-Feb-25 09:38:45 - agent.DQN.DQN - INFO - episode 8 step 190 reward tensor([-1]) loss 0.2952515482902527 epsilon 0.650684809722428
26-Feb-25 09:38:45 - agent.DQN.DQN - INFO - episode 8 step 191 reward tensor([-1]) loss 0.3233078718185425 epsilon 0.650684809722428
26-Feb-25 09:38:45 - agent.DQN.DQN - INFO - episode 8 step 192 reward tensor([-1]) loss 0.25302654504776 epsilon 0.650684809722428
26-Feb-25 09:38:45 - agent.DQN.DQN - INFO - episode 8 step 193 reward tensor([-1]) loss 0.3035743832588196 epsilon 0.650684809722428
26-Feb-25 09:38:45 - agent.DQN.DQN - INFO - episode 8 step 194 reward tensor([-1]) loss 0.29640284180641174 epsilon 0.650684809722428
26-Feb-25 09:38:45 - agent.DQN.DQN - INFO - episode 8 step 195 reward tensor([-1]) loss 0.3324102461338043 epsilon 0.650684809722428
26-Feb-25 09:38:45 - agent.DQN.DQN - INFO - episode 8 step 196 reward tensor([-1]) loss 0.39881885051727295 epsilon 0.650684809722428
26-Feb-25 09:38:45 - agent.DQN.DQN - INFO - episode 8 step 197 reward tensor([-1]) loss 0.3307122588157654 epsilon 0.650684809722428
26-Feb-25 09:38:45 - agent.DQN.DQN - INFO - episode 8 step 198 reward tensor([-1]) loss 0.31334611773490906 epsilon 0.650684809722428
26-Feb-25 09:38:45 - agent.DQN.DQN - INFO - episode 8 step 199 reward tensor([-1]) loss 0.3979569375514984 epsilon 0.650684809722428
26-Feb-25 09:38:45 - agent.DQN.DQN - INFO - episode 8 step 200 reward tensor([-1]) loss 0.29468539357185364 epsilon 0.650684809722428
26-Feb-25 09:38:45 - agent.DQN.DQN - INFO - episode 8 step 201 reward tensor([-1]) loss 0.3149518370628357 epsilon 0.650684809722428
26-Feb-25 09:38:45 - agent.DQN.DQN - INFO - episode 8 step 202 reward tensor([-1]) loss 0.31215426325798035 epsilon 0.650684809722428
26-Feb-25 09:38:45 - agent.DQN.DQN - INFO - episode 8 step 203 reward tensor([-1]) loss 0.3689616918563843 epsilon 0.650684809722428
26-Feb-25 09:38:45 - agent.DQN.DQN - INFO - episode 8 step 204 reward tensor([-1]) loss 0.2600594162940979 epsilon 0.650684809722428
26-Feb-25 09:38:45 - agent.DQN.DQN - INFO - episode 8 step 205 reward tensor([-1]) loss 0.3063233494758606 epsilon 0.650684809722428
26-Feb-25 09:38:45 - agent.DQN.DQN - INFO - episode 8 step 206 reward tensor([-1]) loss 0.2976381182670593 epsilon 0.650684809722428
26-Feb-25 09:38:45 - agent.DQN.DQN - INFO - episode 8 step 207 reward tensor([-1]) loss 0.35178717970848083 epsilon 0.650684809722428
26-Feb-25 09:38:45 - agent.DQN.DQN - INFO - episode 8 step 208 reward tensor([-1]) loss 0.3315194547176361 epsilon 0.650684809722428
26-Feb-25 09:38:45 - agent.DQN.DQN - INFO - episode 8 step 209 reward tensor([-1]) loss 0.3555944263935089 epsilon 0.650684809722428
26-Feb-25 09:38:45 - agent.DQN.DQN - INFO - episode 8 step 210 reward tensor([-1]) loss 0.3182254731655121 epsilon 0.650684809722428
26-Feb-25 09:38:45 - agent.DQN.DQN - INFO - episode 8 step 211 reward tensor([-1]) loss 0.31068021059036255 epsilon 0.650684809722428
26-Feb-25 09:38:45 - agent.DQN.DQN - INFO - episode 8 step 212 reward tensor([-1]) loss 0.2839321792125702 epsilon 0.650684809722428
26-Feb-25 09:38:45 - agent.DQN.DQN - INFO - episode 8 step 213 reward tensor([-1]) loss 0.4192027747631073 epsilon 0.650684809722428
26-Feb-25 09:38:45 - agent.DQN.DQN - INFO - episode 8 step 214 reward tensor([-1]) loss 0.2757279872894287 epsilon 0.650684809722428
26-Feb-25 09:38:45 - agent.DQN.DQN - INFO - episode 8 step 215 reward tensor([-1]) loss 0.3129886984825134 epsilon 0.650684809722428
26-Feb-25 09:38:45 - agent.DQN.DQN - INFO - episode 8 step 216 reward tensor([-1]) loss 0.20604082942008972 epsilon 0.650684809722428
26-Feb-25 09:38:45 - agent.DQN.DQN - INFO - episode 8 step 217 reward tensor([-1]) loss 0.3421728312969208 epsilon 0.650684809722428
26-Feb-25 09:38:45 - agent.DQN.DQN - INFO - episode 8 step 218 reward tensor([-1]) loss 0.33716511726379395 epsilon 0.650684809722428
26-Feb-25 09:38:45 - agent.DQN.DQN - INFO - episode 8 step 219 reward tensor([-1]) loss 0.360929399728775 epsilon 0.650684809722428
26-Feb-25 09:38:45 - agent.DQN.DQN - INFO - episode 8 step 220 reward tensor([-1]) loss 0.28651827573776245 epsilon 0.650684809722428
26-Feb-25 09:38:45 - agent.DQN.DQN - INFO - episode 8 step 221 reward tensor([-1]) loss 0.2686375677585602 epsilon 0.650684809722428
26-Feb-25 09:38:45 - agent.DQN.DQN - INFO - episode 8 step 222 reward tensor([-1]) loss 0.3346947133541107 epsilon 0.650684809722428
26-Feb-25 09:38:45 - agent.DQN.DQN - INFO - episode 8 step 223 reward tensor([-1]) loss 0.386316180229187 epsilon 0.650684809722428
26-Feb-25 09:38:45 - agent.DQN.DQN - INFO - episode 8 step 224 reward tensor([-1]) loss 0.30569982528686523 epsilon 0.650684809722428
26-Feb-25 09:38:45 - agent.DQN.DQN - INFO - episode 8 step 225 reward tensor([-1]) loss 0.242457777261734 epsilon 0.650684809722428
26-Feb-25 09:38:45 - agent.DQN.DQN - INFO - episode 8 step 226 reward tensor([-1]) loss 0.6844778060913086 epsilon 0.650684809722428
26-Feb-25 09:38:45 - agent.DQN.DQN - INFO - episode 8 step 227 reward tensor([-1]) loss 0.4647083580493927 epsilon 0.650684809722428
26-Feb-25 09:38:45 - agent.DQN.DQN - INFO - episode 8 step 228 reward tensor([-1]) loss 0.4701730012893677 epsilon 0.650684809722428
26-Feb-25 09:38:45 - agent.DQN.DQN - INFO - episode 8 step 229 reward tensor([-1]) loss 0.6810791492462158 epsilon 0.650684809722428
26-Feb-25 09:38:45 - agent.DQN.DQN - INFO - episode 8 step 230 reward tensor([-1]) loss 0.3147878050804138 epsilon 0.650684809722428
26-Feb-25 09:38:45 - agent.DQN.DQN - INFO - episode 8 step 231 reward tensor([-1]) loss 0.48878878355026245 epsilon 0.650684809722428
26-Feb-25 09:38:45 - agent.DQN.DQN - INFO - episode 8 step 232 reward tensor([-1]) loss 0.3831237554550171 epsilon 0.650684809722428
26-Feb-25 09:38:45 - agent.DQN.DQN - INFO - episode 8 step 233 reward tensor([-1]) loss 0.3567848205566406 epsilon 0.650684809722428
26-Feb-25 09:38:45 - agent.DQN.DQN - INFO - episode 8 step 234 reward tensor([-1]) loss 0.41436803340911865 epsilon 0.650684809722428
26-Feb-25 09:38:45 - agent.DQN.DQN - INFO - episode 8 step 235 reward tensor([-1]) loss 0.33404821157455444 epsilon 0.650684809722428
26-Feb-25 09:38:45 - agent.DQN.DQN - INFO - episode 8 step 236 reward tensor([-1]) loss 0.3167000412940979 epsilon 0.650684809722428
26-Feb-25 09:38:45 - agent.DQN.DQN - INFO - episode 8 step 237 reward tensor([-1]) loss 0.33799976110458374 epsilon 0.650684809722428
26-Feb-25 09:38:45 - agent.DQN.DQN - INFO - episode 8 step 238 reward tensor([-1]) loss 0.4352366328239441 epsilon 0.650684809722428
26-Feb-25 09:38:45 - agent.DQN.DQN - INFO - episode 8 step 239 reward tensor([-1]) loss 0.3943398594856262 epsilon 0.650684809722428
26-Feb-25 09:38:45 - agent.DQN.DQN - INFO - episode 8 step 240 reward tensor([-1]) loss 0.31528955698013306 epsilon 0.650684809722428
26-Feb-25 09:38:45 - agent.DQN.DQN - INFO - episode 8 step 241 reward tensor([-1]) loss 0.41607239842414856 epsilon 0.650684809722428
26-Feb-25 09:38:45 - agent.DQN.DQN - INFO - episode 8 step 242 reward tensor([-1]) loss 0.39459604024887085 epsilon 0.650684809722428
26-Feb-25 09:38:45 - agent.DQN.DQN - INFO - episode 8 step 243 reward tensor([-1]) loss 0.4046395719051361 epsilon 0.650684809722428
26-Feb-25 09:38:45 - agent.DQN.DQN - INFO - episode 8 step 244 reward tensor([-1]) loss 0.30979618430137634 epsilon 0.650684809722428
26-Feb-25 09:38:45 - agent.DQN.DQN - INFO - episode 8 step 245 reward tensor([-1]) loss 0.531304657459259 epsilon 0.650684809722428
26-Feb-25 09:38:45 - agent.DQN.DQN - INFO - episode 8 step 246 reward tensor([-1]) loss 0.33672788739204407 epsilon 0.650684809722428
26-Feb-25 09:38:45 - agent.DQN.DQN - INFO - episode 8 step 247 reward tensor([-1]) loss 0.3344033658504486 epsilon 0.650684809722428
26-Feb-25 09:38:45 - agent.DQN.DQN - INFO - episode 8 step 248 reward tensor([-1]) loss 0.4825816750526428 epsilon 0.650684809722428
26-Feb-25 09:38:45 - agent.DQN.DQN - INFO - episode 8 step 249 reward tensor([-1]) loss 0.43366557359695435 epsilon 0.650684809722428
26-Feb-25 09:38:45 - agent.DQN.DQN - INFO - episode 8 step 250 reward tensor([-1]) loss 0.423644095659256 epsilon 0.650684809722428
26-Feb-25 09:38:45 - agent.DQN.DQN - INFO - episode 8 step 251 reward tensor([-1]) loss 0.3178672194480896 epsilon 0.650684809722428
26-Feb-25 09:38:45 - agent.DQN.DQN - INFO - episode 8 step 252 reward tensor([-1]) loss 0.3820095658302307 epsilon 0.650684809722428
26-Feb-25 09:38:45 - agent.DQN.DQN - INFO - episode 8 step 253 reward tensor([-1]) loss 0.34861689805984497 epsilon 0.650684809722428
26-Feb-25 09:38:45 - agent.DQN.DQN - INFO - episode 8 step 254 reward tensor([-1]) loss 0.3603157103061676 epsilon 0.650684809722428
26-Feb-25 09:38:45 - agent.DQN.DQN - INFO - episode 8 step 255 reward tensor([-1]) loss 0.2811483144760132 epsilon 0.650684809722428
26-Feb-25 09:38:45 - agent.DQN.DQN - INFO - episode 8 step 256 reward tensor([-1]) loss 0.4649388790130615 epsilon 0.650684809722428
26-Feb-25 09:38:45 - agent.DQN.DQN - INFO - episode 8 step 257 reward tensor([-1]) loss 0.37304842472076416 epsilon 0.650684809722428
26-Feb-25 09:38:45 - agent.DQN.DQN - INFO - episode 8 step 258 reward tensor([-1]) loss 0.36200931668281555 epsilon 0.650684809722428
26-Feb-25 09:38:45 - agent.DQN.DQN - INFO - episode 8 step 259 reward tensor([-1]) loss 0.30960607528686523 epsilon 0.650684809722428
26-Feb-25 09:38:45 - agent.DQN.DQN - INFO - episode 8 step 260 reward tensor([-1]) loss 0.38620609045028687 epsilon 0.650684809722428
26-Feb-25 09:38:45 - agent.DQN.DQN - INFO - episode 8 step 261 reward tensor([-1]) loss 0.3376879096031189 epsilon 0.650684809722428
26-Feb-25 09:38:46 - agent.DQN.DQN - INFO - episode 8 step 262 reward tensor([-1]) loss 0.2768683433532715 epsilon 0.650684809722428
26-Feb-25 09:38:46 - agent.DQN.DQN - INFO - episode 8 step 263 reward tensor([-1]) loss 0.34888190031051636 epsilon 0.650684809722428
26-Feb-25 09:38:46 - agent.DQN.DQN - INFO - episode 8 step 264 reward tensor([-1]) loss 0.4820724129676819 epsilon 0.650684809722428
26-Feb-25 09:38:46 - agent.DQN.DQN - INFO - episode 8 step 265 reward tensor([-1]) loss 0.3688340187072754 epsilon 0.650684809722428
26-Feb-25 09:38:46 - agent.DQN.DQN - INFO - episode 8 step 266 reward tensor([-1]) loss 0.47155094146728516 epsilon 0.650684809722428
26-Feb-25 09:38:46 - agent.DQN.DQN - INFO - episode 8 step 267 reward tensor([-1]) loss 0.36939820647239685 epsilon 0.650684809722428
26-Feb-25 09:38:46 - agent.DQN.DQN - INFO - episode 8 step 268 reward tensor([-1]) loss 0.4804894030094147 epsilon 0.650684809722428
26-Feb-25 09:38:46 - agent.DQN.DQN - INFO - episode 8 step 269 reward tensor([-1]) loss 0.34069231152534485 epsilon 0.650684809722428
26-Feb-25 09:38:46 - agent.DQN.DQN - INFO - episode 8 step 270 reward tensor([-1]) loss 0.27418869733810425 epsilon 0.650684809722428
26-Feb-25 09:38:46 - agent.DQN.DQN - INFO - episode 8 step 271 reward tensor([-1]) loss 0.32327526807785034 epsilon 0.650684809722428
26-Feb-25 09:38:46 - agent.DQN.DQN - INFO - episode 8 step 272 reward tensor([-1]) loss 0.3979474604129791 epsilon 0.650684809722428
26-Feb-25 09:38:46 - agent.DQN.DQN - INFO - episode 8 step 273 reward tensor([-1]) loss 0.37257108092308044 epsilon 0.650684809722428
26-Feb-25 09:38:46 - agent.DQN.DQN - INFO - episode 8 step 274 reward tensor([-1]) loss 0.3711516261100769 epsilon 0.650684809722428
26-Feb-25 09:38:46 - agent.DQN.DQN - INFO - episode 8 step 275 reward tensor([-1]) loss 0.5118892192840576 epsilon 0.650684809722428
26-Feb-25 09:38:46 - agent.DQN.DQN - INFO - episode 8 step 276 reward tensor([-1]) loss 0.27967754006385803 epsilon 0.650684809722428
26-Feb-25 09:38:46 - agent.DQN.DQN - INFO - episode 8 step 277 reward tensor([-1]) loss 0.33299845457077026 epsilon 0.650684809722428
26-Feb-25 09:38:46 - agent.DQN.DQN - INFO - episode 8 step 278 reward tensor([-1]) loss 0.2886161208152771 epsilon 0.650684809722428
26-Feb-25 09:38:46 - agent.DQN.DQN - INFO - episode 8 step 279 reward tensor([-1]) loss 0.3408953547477722 epsilon 0.650684809722428
26-Feb-25 09:38:46 - agent.DQN.DQN - INFO - episode 8 step 280 reward tensor([-1]) loss 0.3023204207420349 epsilon 0.650684809722428
26-Feb-25 09:38:46 - agent.DQN.DQN - INFO - episode 8 step 281 reward tensor([-1]) loss 0.2682153582572937 epsilon 0.650684809722428
26-Feb-25 09:38:46 - agent.DQN.DQN - INFO - episode 8 step 282 reward tensor([-1]) loss 0.41460368037223816 epsilon 0.650684809722428
26-Feb-25 09:38:46 - agent.DQN.DQN - INFO - episode 8 step 283 reward tensor([-1]) loss 0.44822433590888977 epsilon 0.650684809722428
26-Feb-25 09:38:46 - agent.DQN.DQN - INFO - episode 8 step 284 reward tensor([-1]) loss 0.3274008631706238 epsilon 0.650684809722428
26-Feb-25 09:38:46 - agent.DQN.DQN - INFO - episode 8 step 285 reward tensor([-1]) loss 0.28025463223457336 epsilon 0.650684809722428
26-Feb-25 09:38:46 - agent.DQN.DQN - INFO - episode 8 step 286 reward tensor([-1]) loss 0.283692866563797 epsilon 0.650684809722428
26-Feb-25 09:38:46 - agent.DQN.DQN - INFO - episode 8 step 287 reward tensor([-1]) loss 0.31138473749160767 epsilon 0.650684809722428
26-Feb-25 09:38:46 - agent.DQN.DQN - INFO - episode 8 step 288 reward tensor([-1]) loss 0.4581378102302551 epsilon 0.650684809722428
26-Feb-25 09:38:46 - agent.DQN.DQN - INFO - episode 8 step 289 reward tensor([-1]) loss 0.46986842155456543 epsilon 0.650684809722428
26-Feb-25 09:38:46 - agent.DQN.DQN - INFO - episode 8 step 290 reward tensor([-1]) loss 0.2998144030570984 epsilon 0.650684809722428
26-Feb-25 09:38:46 - agent.DQN.DQN - INFO - episode 8 step 291 reward tensor([-1]) loss 0.39583709836006165 epsilon 0.650684809722428
26-Feb-25 09:38:46 - agent.DQN.DQN - INFO - episode 8 step 292 reward tensor([-1]) loss 0.2830112874507904 epsilon 0.650684809722428
26-Feb-25 09:38:46 - agent.DQN.DQN - INFO - episode 8 step 293 reward tensor([-1]) loss 0.29015210270881653 epsilon 0.650684809722428
26-Feb-25 09:38:46 - agent.DQN.DQN - INFO - episode 8 step 294 reward tensor([-1]) loss 0.39949434995651245 epsilon 0.650684809722428
26-Feb-25 09:38:46 - agent.DQN.DQN - INFO - episode 8 step 295 reward tensor([-1]) loss 0.2633601129055023 epsilon 0.650684809722428
26-Feb-25 09:38:46 - agent.DQN.DQN - INFO - episode 8 step 296 reward tensor([-1]) loss 0.33431634306907654 epsilon 0.650684809722428
26-Feb-25 09:38:46 - agent.DQN.DQN - INFO - episode 8 step 297 reward tensor([-1]) loss 0.24223865568637848 epsilon 0.650684809722428
26-Feb-25 09:38:46 - agent.DQN.DQN - INFO - episode 8 step 298 reward tensor([-1]) loss 0.30296871066093445 epsilon 0.650684809722428
26-Feb-25 09:38:46 - agent.DQN.DQN - INFO - episode 8 step 299 reward tensor([-1]) loss 0.2779654562473297 epsilon 0.650684809722428
26-Feb-25 09:38:46 - agent.DQN.DQN - INFO - episode 8 step 300 reward tensor([-1]) loss 0.3134784996509552 epsilon 0.650684809722428
26-Feb-25 09:38:46 - agent.DQN.DQN - INFO - episode 8 step 301 reward tensor([-1]) loss 0.2573883831501007 epsilon 0.650684809722428
26-Feb-25 09:38:46 - agent.DQN.DQN - INFO - episode 9 step 0 reward tensor([-1]) loss 0.33228936791419983 epsilon 0.6295375534064491
26-Feb-25 09:38:46 - agent.DQN.DQN - INFO - episode 9 step 1 reward tensor([-1]) loss 0.2579634189605713 epsilon 0.6295375534064491
26-Feb-25 09:38:46 - agent.DQN.DQN - INFO - episode 9 step 2 reward tensor([-1]) loss 0.31870678067207336 epsilon 0.6295375534064491
26-Feb-25 09:38:46 - agent.DQN.DQN - INFO - episode 9 step 3 reward tensor([-1]) loss 0.2849573791027069 epsilon 0.6295375534064491
26-Feb-25 09:38:46 - agent.DQN.DQN - INFO - episode 9 step 4 reward tensor([-1]) loss 0.2702837884426117 epsilon 0.6295375534064491
26-Feb-25 09:38:46 - agent.DQN.DQN - INFO - episode 9 step 5 reward tensor([-1]) loss 0.29846417903900146 epsilon 0.6295375534064491
26-Feb-25 09:38:46 - agent.DQN.DQN - INFO - episode 9 step 6 reward tensor([-1]) loss 0.2714504897594452 epsilon 0.6295375534064491
26-Feb-25 09:38:46 - agent.DQN.DQN - INFO - episode 9 step 7 reward tensor([-1]) loss 0.2016884982585907 epsilon 0.6295375534064491
26-Feb-25 09:38:46 - agent.DQN.DQN - INFO - episode 9 step 8 reward tensor([-1]) loss 0.23552414774894714 epsilon 0.6295375534064491
26-Feb-25 09:38:46 - agent.DQN.DQN - INFO - episode 9 step 9 reward tensor([-1]) loss 0.42738261818885803 epsilon 0.6295375534064491
26-Feb-25 09:38:46 - agent.DQN.DQN - INFO - episode 9 step 10 reward tensor([-1]) loss 0.271411269903183 epsilon 0.6295375534064491
26-Feb-25 09:38:46 - agent.DQN.DQN - INFO - episode 9 step 11 reward tensor([-1]) loss 0.22496703267097473 epsilon 0.6295375534064491
26-Feb-25 09:38:46 - agent.DQN.DQN - INFO - episode 9 step 12 reward tensor([-1]) loss 0.2561507821083069 epsilon 0.6295375534064491
26-Feb-25 09:38:46 - agent.DQN.DQN - INFO - episode 9 step 13 reward tensor([-1]) loss 0.2723791003227234 epsilon 0.6295375534064491
26-Feb-25 09:38:46 - agent.DQN.DQN - INFO - episode 9 step 14 reward tensor([-1]) loss 0.2852531671524048 epsilon 0.6295375534064491
26-Feb-25 09:38:46 - agent.DQN.DQN - INFO - episode 9 step 15 reward tensor([-1]) loss 0.29143908619880676 epsilon 0.6295375534064491
26-Feb-25 09:38:46 - agent.DQN.DQN - INFO - episode 9 step 16 reward tensor([-1]) loss 0.28276827931404114 epsilon 0.6295375534064491
26-Feb-25 09:38:46 - agent.DQN.DQN - INFO - episode 9 step 17 reward tensor([-1]) loss 0.3353847861289978 epsilon 0.6295375534064491
26-Feb-25 09:38:46 - agent.DQN.DQN - INFO - episode 9 step 18 reward tensor([-1]) loss 0.28589537739753723 epsilon 0.6295375534064491
26-Feb-25 09:38:46 - agent.DQN.DQN - INFO - episode 9 step 19 reward tensor([-1]) loss 0.2993450164794922 epsilon 0.6295375534064491
26-Feb-25 09:38:46 - agent.DQN.DQN - INFO - episode 9 step 20 reward tensor([-1]) loss 0.26061439514160156 epsilon 0.6295375534064491
26-Feb-25 09:38:46 - agent.DQN.DQN - INFO - episode 9 step 21 reward tensor([-1]) loss 0.2767718732357025 epsilon 0.6295375534064491
26-Feb-25 09:38:46 - agent.DQN.DQN - INFO - episode 9 step 22 reward tensor([-1]) loss 0.27269646525382996 epsilon 0.6295375534064491
26-Feb-25 09:38:46 - agent.DQN.DQN - INFO - episode 9 step 23 reward tensor([-1]) loss 0.2790713906288147 epsilon 0.6295375534064491
26-Feb-25 09:38:46 - agent.DQN.DQN - INFO - episode 9 step 24 reward tensor([-1]) loss 0.24297219514846802 epsilon 0.6295375534064491
26-Feb-25 09:38:46 - agent.DQN.DQN - INFO - episode 9 step 25 reward tensor([-1]) loss 0.2957445979118347 epsilon 0.6295375534064491
26-Feb-25 09:38:46 - agent.DQN.DQN - INFO - episode 9 step 26 reward tensor([-1]) loss 0.2579687535762787 epsilon 0.6295375534064491
26-Feb-25 09:38:46 - agent.DQN.DQN - INFO - episode 9 step 27 reward tensor([-1]) loss 0.259473979473114 epsilon 0.6295375534064491
26-Feb-25 09:38:46 - agent.DQN.DQN - INFO - episode 9 step 28 reward tensor([-1]) loss 0.2502005398273468 epsilon 0.6295375534064491
26-Feb-25 09:38:46 - agent.DQN.DQN - INFO - episode 9 step 29 reward tensor([-1]) loss 0.28086239099502563 epsilon 0.6295375534064491
26-Feb-25 09:38:46 - agent.DQN.DQN - INFO - episode 9 step 30 reward tensor([-1]) loss 0.2564699947834015 epsilon 0.6295375534064491
26-Feb-25 09:38:46 - agent.DQN.DQN - INFO - episode 9 step 31 reward tensor([-1]) loss 0.3022010326385498 epsilon 0.6295375534064491
26-Feb-25 09:38:46 - agent.DQN.DQN - INFO - episode 9 step 32 reward tensor([-1]) loss 0.28262385725975037 epsilon 0.6295375534064491
26-Feb-25 09:38:46 - agent.DQN.DQN - INFO - episode 9 step 33 reward tensor([-1]) loss 0.2571554183959961 epsilon 0.6295375534064491
26-Feb-25 09:38:46 - agent.DQN.DQN - INFO - episode 9 step 34 reward tensor([-1]) loss 0.30951765179634094 epsilon 0.6295375534064491
26-Feb-25 09:38:46 - agent.DQN.DQN - INFO - episode 9 step 35 reward tensor([-1]) loss 0.29925885796546936 epsilon 0.6295375534064491
26-Feb-25 09:38:46 - agent.DQN.DQN - INFO - episode 9 step 36 reward tensor([-1]) loss 0.2680075168609619 epsilon 0.6295375534064491
26-Feb-25 09:38:46 - agent.DQN.DQN - INFO - episode 9 step 37 reward tensor([-1]) loss 0.29798904061317444 epsilon 0.6295375534064491
26-Feb-25 09:38:46 - agent.DQN.DQN - INFO - episode 9 step 38 reward tensor([-1]) loss 0.22591164708137512 epsilon 0.6295375534064491
26-Feb-25 09:38:47 - agent.DQN.DQN - INFO - episode 9 step 39 reward tensor([-1]) loss 0.24628937244415283 epsilon 0.6295375534064491
26-Feb-25 09:38:47 - agent.DQN.DQN - INFO - episode 9 step 40 reward tensor([-1]) loss 0.29531288146972656 epsilon 0.6295375534064491
26-Feb-25 09:38:47 - agent.DQN.DQN - INFO - episode 9 step 41 reward tensor([-1]) loss 0.2902783751487732 epsilon 0.6295375534064491
26-Feb-25 09:38:47 - agent.DQN.DQN - INFO - episode 9 step 42 reward tensor([-1]) loss 0.22506111860275269 epsilon 0.6295375534064491
26-Feb-25 09:38:47 - agent.DQN.DQN - INFO - episode 9 step 43 reward tensor([-1]) loss 0.2750014066696167 epsilon 0.6295375534064491
26-Feb-25 09:38:47 - agent.DQN.DQN - INFO - episode 9 step 44 reward tensor([-1]) loss 0.4901883602142334 epsilon 0.6295375534064491
26-Feb-25 09:38:47 - agent.DQN.DQN - INFO - episode 9 step 45 reward tensor([-1]) loss 0.29787373542785645 epsilon 0.6295375534064491
26-Feb-25 09:38:47 - agent.DQN.DQN - INFO - episode 9 step 46 reward tensor([-1]) loss 0.30649077892303467 epsilon 0.6295375534064491
26-Feb-25 09:38:47 - agent.DQN.DQN - INFO - episode 9 step 47 reward tensor([-1]) loss 0.4418191909790039 epsilon 0.6295375534064491
26-Feb-25 09:38:47 - agent.DQN.DQN - INFO - episode 9 step 48 reward tensor([-1]) loss 0.24928772449493408 epsilon 0.6295375534064491
26-Feb-25 09:38:47 - agent.DQN.DQN - INFO - episode 9 step 49 reward tensor([-1]) loss 0.23523366451263428 epsilon 0.6295375534064491
26-Feb-25 09:38:47 - agent.DQN.DQN - INFO - episode 9 step 50 reward tensor([-1]) loss 0.25370103120803833 epsilon 0.6295375534064491
26-Feb-25 09:38:47 - agent.DQN.DQN - INFO - episode 9 step 51 reward tensor([-1]) loss 0.28012266755104065 epsilon 0.6295375534064491
26-Feb-25 09:38:47 - agent.DQN.DQN - INFO - episode 9 step 52 reward tensor([-1]) loss 0.3405724763870239 epsilon 0.6295375534064491
26-Feb-25 09:38:47 - agent.DQN.DQN - INFO - episode 9 step 53 reward tensor([-1]) loss 0.289131224155426 epsilon 0.6295375534064491
26-Feb-25 09:38:47 - agent.DQN.DQN - INFO - episode 9 step 54 reward tensor([-1]) loss 0.3143552541732788 epsilon 0.6295375534064491
26-Feb-25 09:38:47 - agent.DQN.DQN - INFO - episode 9 step 55 reward tensor([-1]) loss 0.223244309425354 epsilon 0.6295375534064491
26-Feb-25 09:38:47 - agent.DQN.DQN - INFO - episode 9 step 56 reward tensor([-1]) loss 0.3911449909210205 epsilon 0.6295375534064491
26-Feb-25 09:38:47 - agent.DQN.DQN - INFO - episode 9 step 57 reward tensor([-1]) loss 0.27836430072784424 epsilon 0.6295375534064491
26-Feb-25 09:38:47 - agent.DQN.DQN - INFO - episode 9 step 58 reward tensor([-1]) loss 0.22293701767921448 epsilon 0.6295375534064491
26-Feb-25 09:38:47 - agent.DQN.DQN - INFO - episode 9 step 59 reward tensor([-1]) loss 0.2553183436393738 epsilon 0.6295375534064491
26-Feb-25 09:38:47 - agent.DQN.DQN - INFO - episode 9 step 60 reward tensor([-1]) loss 0.30324244499206543 epsilon 0.6295375534064491
26-Feb-25 09:38:47 - agent.DQN.DQN - INFO - episode 9 step 61 reward tensor([-1]) loss 0.2558715343475342 epsilon 0.6295375534064491
26-Feb-25 09:38:47 - agent.DQN.DQN - INFO - episode 9 step 62 reward tensor([-1]) loss 0.23591741919517517 epsilon 0.6295375534064491
26-Feb-25 09:38:47 - agent.DQN.DQN - INFO - episode 9 step 63 reward tensor([-1]) loss 0.227614164352417 epsilon 0.6295375534064491
26-Feb-25 09:38:47 - agent.DQN.DQN - INFO - episode 9 step 64 reward tensor([-1]) loss 0.26818519830703735 epsilon 0.6295375534064491
26-Feb-25 09:38:47 - agent.DQN.DQN - INFO - episode 9 step 65 reward tensor([-1]) loss 0.25604021549224854 epsilon 0.6295375534064491
26-Feb-25 09:38:47 - agent.DQN.DQN - INFO - episode 9 step 66 reward tensor([-1]) loss 0.28589126467704773 epsilon 0.6295375534064491
26-Feb-25 09:38:47 - agent.DQN.DQN - INFO - episode 9 step 67 reward tensor([-1]) loss 0.26211825013160706 epsilon 0.6295375534064491
26-Feb-25 09:38:47 - agent.DQN.DQN - INFO - episode 9 step 68 reward tensor([-1]) loss 0.26473742723464966 epsilon 0.6295375534064491
26-Feb-25 09:38:47 - agent.DQN.DQN - INFO - episode 9 step 69 reward tensor([-1]) loss 0.2429162710905075 epsilon 0.6295375534064491
26-Feb-25 09:38:47 - agent.DQN.DQN - INFO - episode 9 step 70 reward tensor([-1]) loss 0.29513639211654663 epsilon 0.6295375534064491
26-Feb-25 09:38:47 - agent.DQN.DQN - INFO - episode 9 step 71 reward tensor([-1]) loss 0.28666046261787415 epsilon 0.6295375534064491
26-Feb-25 09:38:47 - agent.DQN.DQN - INFO - episode 9 step 72 reward tensor([-1]) loss 0.24391591548919678 epsilon 0.6295375534064491
26-Feb-25 09:38:47 - agent.DQN.DQN - INFO - episode 9 step 73 reward tensor([-1]) loss 0.28307366371154785 epsilon 0.6295375534064491
26-Feb-25 09:38:47 - agent.DQN.DQN - INFO - episode 9 step 74 reward tensor([-1]) loss 0.45168206095695496 epsilon 0.6295375534064491
26-Feb-25 09:38:47 - agent.DQN.DQN - INFO - episode 9 step 75 reward tensor([-1]) loss 0.3956446945667267 epsilon 0.6295375534064491
26-Feb-25 09:38:47 - agent.DQN.DQN - INFO - episode 9 step 76 reward tensor([-1]) loss 0.3086920380592346 epsilon 0.6295375534064491
26-Feb-25 09:38:47 - agent.DQN.DQN - INFO - episode 9 step 77 reward tensor([-1]) loss 0.25916770100593567 epsilon 0.6295375534064491
26-Feb-25 09:38:47 - agent.DQN.DQN - INFO - episode 9 step 78 reward tensor([-1]) loss 0.30262231826782227 epsilon 0.6295375534064491
26-Feb-25 09:38:47 - agent.DQN.DQN - INFO - episode 9 step 79 reward tensor([-1]) loss 0.2960188686847687 epsilon 0.6295375534064491
26-Feb-25 09:38:47 - agent.DQN.DQN - INFO - episode 9 step 80 reward tensor([-1]) loss 0.34777432680130005 epsilon 0.6295375534064491
26-Feb-25 09:38:47 - agent.DQN.DQN - INFO - episode 9 step 81 reward tensor([-1]) loss 0.26106753945350647 epsilon 0.6295375534064491
26-Feb-25 09:38:47 - agent.DQN.DQN - INFO - episode 9 step 82 reward tensor([-1]) loss 0.2596580982208252 epsilon 0.6295375534064491
26-Feb-25 09:38:47 - agent.DQN.DQN - INFO - episode 9 step 83 reward tensor([-1]) loss 0.2723865509033203 epsilon 0.6295375534064491
26-Feb-25 09:38:47 - agent.DQN.DQN - INFO - episode 9 step 84 reward tensor([-1]) loss 0.29692399501800537 epsilon 0.6295375534064491
26-Feb-25 09:38:47 - agent.DQN.DQN - INFO - episode 9 step 85 reward tensor([-1]) loss 0.31234970688819885 epsilon 0.6295375534064491
26-Feb-25 09:38:47 - agent.DQN.DQN - INFO - episode 9 step 86 reward tensor([-1]) loss 0.39886265993118286 epsilon 0.6295375534064491
26-Feb-25 09:38:47 - agent.DQN.DQN - INFO - episode 9 step 87 reward tensor([-1]) loss 0.32417404651641846 epsilon 0.6295375534064491
26-Feb-25 09:38:47 - agent.DQN.DQN - INFO - episode 9 step 88 reward tensor([-1]) loss 0.278723806142807 epsilon 0.6295375534064491
26-Feb-25 09:38:47 - agent.DQN.DQN - INFO - episode 9 step 89 reward tensor([-1]) loss 0.2903374433517456 epsilon 0.6295375534064491
26-Feb-25 09:38:47 - agent.DQN.DQN - INFO - episode 9 step 90 reward tensor([-1]) loss 0.2538079023361206 epsilon 0.6295375534064491
26-Feb-25 09:38:47 - agent.DQN.DQN - INFO - episode 9 step 91 reward tensor([-1]) loss 0.2659910023212433 epsilon 0.6295375534064491
26-Feb-25 09:38:47 - agent.DQN.DQN - INFO - episode 9 step 92 reward tensor([-1]) loss 0.2674398720264435 epsilon 0.6295375534064491
26-Feb-25 09:38:47 - agent.DQN.DQN - INFO - episode 9 step 93 reward tensor([-1]) loss 0.23298944532871246 epsilon 0.6295375534064491
26-Feb-25 09:38:47 - agent.DQN.DQN - INFO - episode 9 step 94 reward tensor([-1]) loss 0.3015584647655487 epsilon 0.6295375534064491
26-Feb-25 09:38:47 - agent.DQN.DQN - INFO - episode 9 step 95 reward tensor([-1]) loss 0.21053914725780487 epsilon 0.6295375534064491
26-Feb-25 09:38:47 - agent.DQN.DQN - INFO - episode 9 step 96 reward tensor([-1]) loss 0.2176767736673355 epsilon 0.6295375534064491
26-Feb-25 09:38:47 - agent.DQN.DQN - INFO - episode 9 step 97 reward tensor([-1]) loss 0.4715700149536133 epsilon 0.6295375534064491
26-Feb-25 09:38:47 - agent.DQN.DQN - INFO - episode 9 step 98 reward tensor([-1]) loss 0.2349611520767212 epsilon 0.6295375534064491
26-Feb-25 09:38:47 - agent.DQN.DQN - INFO - episode 9 step 99 reward tensor([-1]) loss 0.30339086055755615 epsilon 0.6295375534064491
26-Feb-25 09:38:47 - agent.DQN.DQN - INFO - episode 9 step 100 reward tensor([-1]) loss 0.24352812767028809 epsilon 0.6295375534064491
26-Feb-25 09:38:47 - agent.DQN.DQN - INFO - episode 9 step 101 reward tensor([-1]) loss 0.21129240095615387 epsilon 0.6295375534064491
26-Feb-25 09:38:47 - agent.DQN.DQN - INFO - episode 9 step 102 reward tensor([-1]) loss 0.22698208689689636 epsilon 0.6295375534064491
26-Feb-25 09:38:47 - agent.DQN.DQN - INFO - episode 9 step 103 reward tensor([-1]) loss 0.27274566888809204 epsilon 0.6295375534064491
26-Feb-25 09:38:47 - agent.DQN.DQN - INFO - episode 9 step 104 reward tensor([-1]) loss 0.26966530084609985 epsilon 0.6295375534064491
26-Feb-25 09:38:47 - agent.DQN.DQN - INFO - episode 9 step 105 reward tensor([-1]) loss 0.2783142030239105 epsilon 0.6295375534064491
26-Feb-25 09:38:47 - agent.DQN.DQN - INFO - episode 9 step 106 reward tensor([-1]) loss 0.37630414962768555 epsilon 0.6295375534064491
26-Feb-25 09:38:47 - agent.DQN.DQN - INFO - episode 9 step 107 reward tensor([-1]) loss 0.2544049620628357 epsilon 0.6295375534064491
26-Feb-25 09:38:47 - agent.DQN.DQN - INFO - episode 9 step 108 reward tensor([-1]) loss 0.22589737176895142 epsilon 0.6295375534064491
26-Feb-25 09:38:47 - agent.DQN.DQN - INFO - episode 9 step 109 reward tensor([-1]) loss 0.2942945659160614 epsilon 0.6295375534064491
26-Feb-25 09:38:47 - agent.DQN.DQN - INFO - episode 9 step 110 reward tensor([-1]) loss 0.46966469287872314 epsilon 0.6295375534064491
26-Feb-25 09:38:48 - agent.DQN.DQN - INFO - episode 9 step 111 reward tensor([-1]) loss 0.33935490250587463 epsilon 0.6295375534064491
26-Feb-25 09:38:48 - agent.DQN.DQN - INFO - episode 9 step 112 reward tensor([-1]) loss 0.2673666179180145 epsilon 0.6295375534064491
26-Feb-25 09:38:48 - agent.DQN.DQN - INFO - episode 9 step 113 reward tensor([-1]) loss 0.2800711691379547 epsilon 0.6295375534064491
26-Feb-25 09:38:48 - agent.DQN.DQN - INFO - episode 9 step 114 reward tensor([-1]) loss 0.20571407675743103 epsilon 0.6295375534064491
26-Feb-25 09:38:48 - agent.DQN.DQN - INFO - episode 9 step 115 reward tensor([-1]) loss 0.44321614503860474 epsilon 0.6295375534064491
26-Feb-25 09:38:48 - agent.DQN.DQN - INFO - episode 9 step 116 reward tensor([-1]) loss 0.3808097541332245 epsilon 0.6295375534064491
26-Feb-25 09:38:48 - agent.DQN.DQN - INFO - episode 9 step 117 reward tensor([-1]) loss 0.2746295928955078 epsilon 0.6295375534064491
26-Feb-25 09:38:48 - agent.DQN.DQN - INFO - episode 9 step 118 reward tensor([-1]) loss 0.3348642587661743 epsilon 0.6295375534064491
26-Feb-25 09:38:48 - agent.DQN.DQN - INFO - episode 9 step 119 reward tensor([-1]) loss 0.34168878197669983 epsilon 0.6295375534064491
26-Feb-25 09:38:48 - agent.DQN.DQN - INFO - episode 9 step 120 reward tensor([-1]) loss 0.26724863052368164 epsilon 0.6295375534064491
26-Feb-25 09:38:48 - agent.DQN.DQN - INFO - episode 9 step 121 reward tensor([-1]) loss 0.24515469372272491 epsilon 0.6295375534064491
26-Feb-25 09:38:48 - agent.DQN.DQN - INFO - episode 9 step 122 reward tensor([-1]) loss 0.291668564081192 epsilon 0.6295375534064491
26-Feb-25 09:38:48 - agent.DQN.DQN - INFO - episode 9 step 123 reward tensor([-1]) loss 0.2421410232782364 epsilon 0.6295375534064491
26-Feb-25 09:38:48 - agent.DQN.DQN - INFO - episode 9 step 124 reward tensor([-1]) loss 0.28458350896835327 epsilon 0.6295375534064491
26-Feb-25 09:38:48 - agent.DQN.DQN - INFO - episode 9 step 125 reward tensor([-1]) loss 0.23587028682231903 epsilon 0.6295375534064491
26-Feb-25 09:38:48 - agent.DQN.DQN - INFO - episode 9 step 126 reward tensor([-1]) loss 0.28241950273513794 epsilon 0.6295375534064491
26-Feb-25 09:38:48 - agent.DQN.DQN - INFO - episode 9 step 127 reward tensor([-1]) loss 0.31187695264816284 epsilon 0.6295375534064491
26-Feb-25 09:38:48 - agent.DQN.DQN - INFO - episode 9 step 128 reward tensor([-1]) loss 0.2503712475299835 epsilon 0.6295375534064491
26-Feb-25 09:38:48 - agent.DQN.DQN - INFO - episode 9 step 129 reward tensor([-1]) loss 0.22924208641052246 epsilon 0.6295375534064491
26-Feb-25 09:38:48 - agent.DQN.DQN - INFO - episode 9 step 130 reward tensor([-1]) loss 0.28686612844467163 epsilon 0.6295375534064491
26-Feb-25 09:38:48 - agent.DQN.DQN - INFO - episode 9 step 131 reward tensor([-1]) loss 0.2127256691455841 epsilon 0.6295375534064491
26-Feb-25 09:38:48 - agent.DQN.DQN - INFO - episode 9 step 132 reward tensor([-1]) loss 0.21874088048934937 epsilon 0.6295375534064491
26-Feb-25 09:38:48 - agent.DQN.DQN - INFO - episode 9 step 133 reward tensor([-1]) loss 0.25786447525024414 epsilon 0.6295375534064491
26-Feb-25 09:38:48 - agent.DQN.DQN - INFO - episode 9 step 134 reward tensor([-1]) loss 0.25900188088417053 epsilon 0.6295375534064491
26-Feb-25 09:38:48 - agent.DQN.DQN - INFO - episode 9 step 135 reward tensor([-1]) loss 0.3138444125652313 epsilon 0.6295375534064491
26-Feb-25 09:38:48 - agent.DQN.DQN - INFO - episode 9 step 136 reward tensor([-1]) loss 0.295197069644928 epsilon 0.6295375534064491
26-Feb-25 09:38:48 - agent.DQN.DQN - INFO - episode 9 step 137 reward tensor([-1]) loss 0.3121736943721771 epsilon 0.6295375534064491
26-Feb-25 09:38:48 - agent.DQN.DQN - INFO - episode 9 step 138 reward tensor([-1]) loss 0.31459105014801025 epsilon 0.6295375534064491
26-Feb-25 09:38:48 - agent.DQN.DQN - INFO - episode 9 step 139 reward tensor([-1]) loss 0.27530941367149353 epsilon 0.6295375534064491
26-Feb-25 09:38:48 - agent.DQN.DQN - INFO - episode 9 step 140 reward tensor([-1]) loss 0.2602273225784302 epsilon 0.6295375534064491
26-Feb-25 09:38:48 - agent.DQN.DQN - INFO - episode 9 step 141 reward tensor([-1]) loss 0.3766477108001709 epsilon 0.6295375534064491
26-Feb-25 09:38:48 - agent.DQN.DQN - INFO - episode 9 step 142 reward tensor([-1]) loss 0.44951489567756653 epsilon 0.6295375534064491
26-Feb-25 09:38:48 - agent.DQN.DQN - INFO - episode 9 step 143 reward tensor([-1]) loss 0.3302059471607208 epsilon 0.6295375534064491
26-Feb-25 09:38:48 - agent.DQN.DQN - INFO - episode 9 step 144 reward tensor([-1]) loss 0.2513448894023895 epsilon 0.6295375534064491
26-Feb-25 09:38:48 - agent.DQN.DQN - INFO - episode 9 step 145 reward tensor([-1]) loss 0.300658643245697 epsilon 0.6295375534064491
26-Feb-25 09:38:48 - agent.DQN.DQN - INFO - episode 9 step 146 reward tensor([-1]) loss 0.2689153850078583 epsilon 0.6295375534064491
26-Feb-25 09:38:48 - agent.DQN.DQN - INFO - episode 9 step 147 reward tensor([-1]) loss 0.2847956418991089 epsilon 0.6295375534064491
26-Feb-25 09:38:48 - agent.DQN.DQN - INFO - episode 9 step 148 reward tensor([-1]) loss 0.2563389241695404 epsilon 0.6295375534064491
26-Feb-25 09:38:48 - agent.DQN.DQN - INFO - episode 9 step 149 reward tensor([-1]) loss 0.20372578501701355 epsilon 0.6295375534064491
26-Feb-25 09:38:48 - agent.DQN.DQN - INFO - episode 9 step 150 reward tensor([-1]) loss 0.2283279299736023 epsilon 0.6295375534064491
26-Feb-25 09:38:48 - agent.DQN.DQN - INFO - episode 9 step 151 reward tensor([-1]) loss 0.23771274089813232 epsilon 0.6295375534064491
26-Feb-25 09:38:48 - agent.DQN.DQN - INFO - episode 9 step 152 reward tensor([-1]) loss 0.26721423864364624 epsilon 0.6295375534064491
26-Feb-25 09:38:48 - agent.DQN.DQN - INFO - episode 9 step 153 reward tensor([-1]) loss 0.25313207507133484 epsilon 0.6295375534064491
26-Feb-25 09:38:48 - agent.DQN.DQN - INFO - episode 9 step 154 reward tensor([-1]) loss 0.2910825312137604 epsilon 0.6295375534064491
26-Feb-25 09:38:48 - agent.DQN.DQN - INFO - episode 9 step 155 reward tensor([-1]) loss 0.22014716267585754 epsilon 0.6295375534064491
26-Feb-25 09:38:48 - agent.DQN.DQN - INFO - episode 9 step 156 reward tensor([-1]) loss 0.2610703706741333 epsilon 0.6295375534064491
26-Feb-25 09:38:48 - agent.DQN.DQN - INFO - episode 9 step 157 reward tensor([-1]) loss 0.26650840044021606 epsilon 0.6295375534064491
26-Feb-25 09:38:48 - agent.DQN.DQN - INFO - episode 9 step 158 reward tensor([-1]) loss 0.2233268916606903 epsilon 0.6295375534064491
26-Feb-25 09:38:48 - agent.DQN.DQN - INFO - episode 9 step 159 reward tensor([-1]) loss 0.22418826818466187 epsilon 0.6295375534064491
26-Feb-25 09:38:48 - agent.DQN.DQN - INFO - episode 9 step 160 reward tensor([-1]) loss 0.2299155443906784 epsilon 0.6295375534064491
26-Feb-25 09:38:48 - agent.DQN.DQN - INFO - episode 9 step 161 reward tensor([-1]) loss 0.21993489563465118 epsilon 0.6295375534064491
26-Feb-25 09:38:48 - agent.DQN.DQN - INFO - episode 9 step 162 reward tensor([-1]) loss 0.2275252491235733 epsilon 0.6295375534064491
26-Feb-25 09:38:48 - agent.DQN.DQN - INFO - episode 9 step 163 reward tensor([-1]) loss 0.2858656346797943 epsilon 0.6295375534064491
26-Feb-25 09:38:48 - agent.DQN.DQN - INFO - episode 9 step 164 reward tensor([-1]) loss 0.24301818013191223 epsilon 0.6295375534064491
26-Feb-25 09:38:48 - agent.DQN.DQN - INFO - episode 9 step 165 reward tensor([-1]) loss 0.3666944205760956 epsilon 0.6295375534064491
26-Feb-25 09:38:48 - agent.DQN.DQN - INFO - episode 9 step 166 reward tensor([-1]) loss 0.40733423829078674 epsilon 0.6295375534064491
26-Feb-25 09:38:48 - agent.DQN.DQN - INFO - episode 9 step 167 reward tensor([-1]) loss 0.2834862172603607 epsilon 0.6295375534064491
26-Feb-25 09:38:48 - agent.DQN.DQN - INFO - episode 9 step 168 reward tensor([-1]) loss 0.24026313424110413 epsilon 0.6295375534064491
26-Feb-25 09:38:48 - agent.DQN.DQN - INFO - episode 9 step 169 reward tensor([-1]) loss 0.39301353693008423 epsilon 0.6295375534064491
26-Feb-25 09:38:48 - agent.DQN.DQN - INFO - episode 9 step 170 reward tensor([-1]) loss 0.23222343623638153 epsilon 0.6295375534064491
26-Feb-25 09:38:48 - agent.DQN.DQN - INFO - episode 9 step 171 reward tensor([-1]) loss 0.40755924582481384 epsilon 0.6295375534064491
26-Feb-25 09:38:48 - agent.DQN.DQN - INFO - episode 9 step 172 reward tensor([-1]) loss 0.42266711592674255 epsilon 0.6295375534064491
26-Feb-25 09:38:48 - agent.DQN.DQN - INFO - episode 9 step 173 reward tensor([-1]) loss 0.299394428730011 epsilon 0.6295375534064491
26-Feb-25 09:38:48 - agent.DQN.DQN - INFO - episode 9 step 174 reward tensor([-1]) loss 0.2930932939052582 epsilon 0.6295375534064491
26-Feb-25 09:38:48 - agent.DQN.DQN - INFO - episode 9 step 175 reward tensor([-1]) loss 0.3260088860988617 epsilon 0.6295375534064491
26-Feb-25 09:38:48 - agent.DQN.DQN - INFO - episode 9 step 176 reward tensor([-1]) loss 0.28110262751579285 epsilon 0.6295375534064491
26-Feb-25 09:38:48 - agent.DQN.DQN - INFO - episode 9 step 177 reward tensor([-1]) loss 0.3306623101234436 epsilon 0.6295375534064491
26-Feb-25 09:38:48 - agent.DQN.DQN - INFO - episode 9 step 178 reward tensor([-1]) loss 0.2796279489994049 epsilon 0.6295375534064491
26-Feb-25 09:38:48 - agent.DQN.DQN - INFO - episode 9 step 179 reward tensor([-1]) loss 0.2399858683347702 epsilon 0.6295375534064491
26-Feb-25 09:38:48 - agent.DQN.DQN - INFO - episode 9 step 180 reward tensor([-1]) loss 0.3066464066505432 epsilon 0.6295375534064491
26-Feb-25 09:38:48 - agent.DQN.DQN - INFO - episode 9 step 181 reward tensor([-1]) loss 0.29089564085006714 epsilon 0.6295375534064491
26-Feb-25 09:38:48 - agent.DQN.DQN - INFO - episode 9 step 182 reward tensor([-1]) loss 0.2573317587375641 epsilon 0.6295375534064491
26-Feb-25 09:38:49 - agent.DQN.DQN - INFO - episode 9 step 183 reward tensor([-1]) loss 0.3690040111541748 epsilon 0.6295375534064491
26-Feb-25 09:38:49 - agent.DQN.DQN - INFO - episode 9 step 184 reward tensor([-1]) loss 0.3971114754676819 epsilon 0.6295375534064491
26-Feb-25 09:38:49 - agent.DQN.DQN - INFO - episode 9 step 185 reward tensor([-1]) loss 0.19264370203018188 epsilon 0.6295375534064491
26-Feb-25 09:38:49 - agent.DQN.DQN - INFO - episode 9 step 186 reward tensor([-1]) loss 0.3596567213535309 epsilon 0.6295375534064491
26-Feb-25 09:38:49 - agent.DQN.DQN - INFO - episode 9 step 187 reward tensor([-1]) loss 0.2616438567638397 epsilon 0.6295375534064491
26-Feb-25 09:38:49 - agent.DQN.DQN - INFO - episode 9 step 188 reward tensor([-1]) loss 0.28503942489624023 epsilon 0.6295375534064491
26-Feb-25 09:38:49 - agent.DQN.DQN - INFO - episode 9 step 189 reward tensor([-1]) loss 0.2803112864494324 epsilon 0.6295375534064491
26-Feb-25 09:38:49 - agent.DQN.DQN - INFO - episode 9 step 190 reward tensor([-1]) loss 0.25055578351020813 epsilon 0.6295375534064491
26-Feb-25 09:38:49 - agent.DQN.DQN - INFO - episode 9 step 191 reward tensor([-1]) loss 0.22421827912330627 epsilon 0.6295375534064491
26-Feb-25 09:38:49 - agent.DQN.DQN - INFO - episode 9 step 192 reward tensor([-1]) loss 0.23737135529518127 epsilon 0.6295375534064491
26-Feb-25 09:38:49 - agent.DQN.DQN - INFO - episode 9 step 193 reward tensor([-1]) loss 0.22274184226989746 epsilon 0.6295375534064491
26-Feb-25 09:38:49 - agent.DQN.DQN - INFO - episode 9 step 194 reward tensor([-1]) loss 0.257139652967453 epsilon 0.6295375534064491
26-Feb-25 09:38:49 - agent.DQN.DQN - INFO - episode 9 step 195 reward tensor([-1]) loss 0.22436143457889557 epsilon 0.6295375534064491
26-Feb-25 09:38:49 - agent.DQN.DQN - INFO - episode 9 step 196 reward tensor([-1]) loss 0.30765876173973083 epsilon 0.6295375534064491
26-Feb-25 09:38:49 - agent.DQN.DQN - INFO - episode 9 step 197 reward tensor([-1]) loss 0.29489848017692566 epsilon 0.6295375534064491
26-Feb-25 09:38:49 - agent.DQN.DQN - INFO - episode 9 step 198 reward tensor([-1]) loss 0.27091825008392334 epsilon 0.6295375534064491
26-Feb-25 09:38:49 - agent.DQN.DQN - INFO - episode 9 step 199 reward tensor([-1]) loss 0.43264341354370117 epsilon 0.6295375534064491
26-Feb-25 09:38:49 - agent.DQN.DQN - INFO - episode 9 step 200 reward tensor([-1]) loss 0.2559395134449005 epsilon 0.6295375534064491
26-Feb-25 09:38:49 - agent.DQN.DQN - INFO - episode 9 step 201 reward tensor([-1]) loss 0.26261869072914124 epsilon 0.6295375534064491
26-Feb-25 09:38:49 - agent.DQN.DQN - INFO - episode 9 step 202 reward tensor([-1]) loss 0.22924013435840607 epsilon 0.6295375534064491
26-Feb-25 09:38:49 - agent.DQN.DQN - INFO - episode 9 step 203 reward tensor([-1]) loss 0.33440113067626953 epsilon 0.6295375534064491
26-Feb-25 09:38:49 - agent.DQN.DQN - INFO - episode 9 step 204 reward tensor([-1]) loss 0.256625235080719 epsilon 0.6295375534064491
26-Feb-25 09:38:49 - agent.DQN.DQN - INFO - episode 9 step 205 reward tensor([-1]) loss 0.2533963918685913 epsilon 0.6295375534064491
26-Feb-25 09:38:49 - agent.DQN.DQN - INFO - episode 9 step 206 reward tensor([-1]) loss 0.250660240650177 epsilon 0.6295375534064491
26-Feb-25 09:38:49 - agent.DQN.DQN - INFO - episode 9 step 207 reward tensor([-1]) loss 0.2674124240875244 epsilon 0.6295375534064491
26-Feb-25 09:38:49 - agent.DQN.DQN - INFO - episode 9 step 208 reward tensor([-1]) loss 0.25027385354042053 epsilon 0.6295375534064491
26-Feb-25 09:38:49 - agent.DQN.DQN - INFO - episode 9 step 209 reward tensor([-1]) loss 0.4247806966304779 epsilon 0.6295375534064491
26-Feb-25 09:38:49 - agent.DQN.DQN - INFO - episode 9 step 210 reward tensor([-1]) loss 0.2776397168636322 epsilon 0.6295375534064491
26-Feb-25 09:38:49 - agent.DQN.DQN - INFO - episode 9 step 211 reward tensor([-1]) loss 0.2684243321418762 epsilon 0.6295375534064491
26-Feb-25 09:38:49 - agent.DQN.DQN - INFO - episode 9 step 212 reward tensor([-1]) loss 0.26906490325927734 epsilon 0.6295375534064491
26-Feb-25 09:38:49 - agent.DQN.DQN - INFO - episode 9 step 213 reward tensor([-1]) loss 0.30770739912986755 epsilon 0.6295375534064491
26-Feb-25 09:38:49 - agent.DQN.DQN - INFO - episode 9 step 214 reward tensor([-1]) loss 0.2744593620300293 epsilon 0.6295375534064491
26-Feb-25 09:38:49 - agent.DQN.DQN - INFO - episode 9 step 215 reward tensor([-1]) loss 0.29017385840415955 epsilon 0.6295375534064491
26-Feb-25 09:38:49 - agent.DQN.DQN - INFO - episode 9 step 216 reward tensor([-1]) loss 0.314680814743042 epsilon 0.6295375534064491
26-Feb-25 09:38:49 - agent.DQN.DQN - INFO - episode 9 step 217 reward tensor([-1]) loss 0.2644898593425751 epsilon 0.6295375534064491
26-Feb-25 09:38:49 - agent.DQN.DQN - INFO - episode 9 step 218 reward tensor([-1]) loss 0.32356134057044983 epsilon 0.6295375534064491
26-Feb-25 09:38:49 - agent.DQN.DQN - INFO - episode 9 step 219 reward tensor([-1]) loss 0.2188294380903244 epsilon 0.6295375534064491
26-Feb-25 09:38:49 - agent.DQN.DQN - INFO - episode 9 step 220 reward tensor([-1]) loss 0.2336447387933731 epsilon 0.6295375534064491
26-Feb-25 09:38:49 - agent.DQN.DQN - INFO - episode 9 step 221 reward tensor([-1]) loss 0.29487571120262146 epsilon 0.6295375534064491
26-Feb-25 09:38:49 - agent.DQN.DQN - INFO - episode 9 step 222 reward tensor([-1]) loss 0.2623293399810791 epsilon 0.6295375534064491
26-Feb-25 09:38:49 - agent.DQN.DQN - INFO - episode 9 step 223 reward tensor([-1]) loss 0.22694535553455353 epsilon 0.6295375534064491
26-Feb-25 09:38:49 - agent.DQN.DQN - INFO - episode 9 step 224 reward tensor([-1]) loss 0.20942175388336182 epsilon 0.6295375534064491
26-Feb-25 09:38:49 - agent.DQN.DQN - INFO - episode 9 step 225 reward tensor([-1]) loss 0.3742457628250122 epsilon 0.6295375534064491
26-Feb-25 09:38:49 - agent.DQN.DQN - INFO - episode 9 step 226 reward tensor([-1]) loss 0.23613224923610687 epsilon 0.6295375534064491
26-Feb-25 09:38:49 - agent.DQN.DQN - INFO - episode 9 step 227 reward tensor([-1]) loss 0.23612049221992493 epsilon 0.6295375534064491
26-Feb-25 09:38:49 - agent.DQN.DQN - INFO - episode 9 step 228 reward tensor([-1]) loss 0.2677213251590729 epsilon 0.6295375534064491
26-Feb-25 09:38:49 - agent.DQN.DQN - INFO - episode 9 step 229 reward tensor([-1]) loss 0.2540976107120514 epsilon 0.6295375534064491
26-Feb-25 09:38:49 - agent.DQN.DQN - INFO - episode 9 step 230 reward tensor([-1]) loss 0.2081165909767151 epsilon 0.6295375534064491
26-Feb-25 09:38:49 - agent.DQN.DQN - INFO - episode 9 step 231 reward tensor([-1]) loss 0.21047905087471008 epsilon 0.6295375534064491
26-Feb-25 09:38:49 - agent.DQN.DQN - INFO - episode 9 step 232 reward tensor([-1]) loss 0.24065762758255005 epsilon 0.6295375534064491
26-Feb-25 09:38:49 - agent.DQN.DQN - INFO - episode 9 step 233 reward tensor([-1]) loss 0.26047855615615845 epsilon 0.6295375534064491
26-Feb-25 09:38:49 - agent.DQN.DQN - INFO - episode 9 step 234 reward tensor([-1]) loss 0.2346854954957962 epsilon 0.6295375534064491
26-Feb-25 09:38:49 - agent.DQN.DQN - INFO - episode 9 step 235 reward tensor([-1]) loss 0.3038659691810608 epsilon 0.6295375534064491
26-Feb-25 09:38:49 - agent.DQN.DQN - INFO - episode 9 step 236 reward tensor([-1]) loss 0.23028869926929474 epsilon 0.6295375534064491
26-Feb-25 09:38:49 - agent.DQN.DQN - INFO - episode 9 step 237 reward tensor([-1]) loss 0.3004150986671448 epsilon 0.6295375534064491
26-Feb-25 09:38:49 - agent.DQN.DQN - INFO - episode 9 step 238 reward tensor([-1]) loss 0.3343226909637451 epsilon 0.6295375534064491
26-Feb-25 09:38:49 - agent.DQN.DQN - INFO - episode 9 step 239 reward tensor([-1]) loss 0.218403160572052 epsilon 0.6295375534064491
26-Feb-25 09:38:49 - agent.DQN.DQN - INFO - episode 9 step 240 reward tensor([-1]) loss 0.21062573790550232 epsilon 0.6295375534064491
26-Feb-25 09:38:49 - agent.DQN.DQN - INFO - episode 9 step 241 reward tensor([-1]) loss 0.4100162386894226 epsilon 0.6295375534064491
26-Feb-25 09:38:49 - agent.DQN.DQN - INFO - episode 9 step 242 reward tensor([-1]) loss 0.32197389006614685 epsilon 0.6295375534064491
26-Feb-25 09:38:49 - agent.DQN.DQN - INFO - episode 9 step 243 reward tensor([-1]) loss 0.27278149127960205 epsilon 0.6295375534064491
26-Feb-25 09:38:49 - agent.DQN.DQN - INFO - episode 9 step 244 reward tensor([-1]) loss 0.24653494358062744 epsilon 0.6295375534064491
26-Feb-25 09:38:49 - agent.DQN.DQN - INFO - episode 9 step 245 reward tensor([-1]) loss 0.25346142053604126 epsilon 0.6295375534064491
26-Feb-25 09:38:49 - agent.DQN.DQN - INFO - episode 9 step 246 reward tensor([-1]) loss 0.3774080276489258 epsilon 0.6295375534064491
26-Feb-25 09:38:49 - agent.DQN.DQN - INFO - episode 9 step 247 reward tensor([-1]) loss 0.3005322813987732 epsilon 0.6295375534064491
26-Feb-25 09:38:49 - agent.DQN.DQN - INFO - episode 9 step 248 reward tensor([-1]) loss 0.27899959683418274 epsilon 0.6295375534064491
26-Feb-25 09:38:49 - agent.DQN.DQN - INFO - episode 9 step 249 reward tensor([-1]) loss 0.23006346821784973 epsilon 0.6295375534064491
26-Feb-25 09:38:49 - agent.DQN.DQN - INFO - episode 9 step 250 reward tensor([-1]) loss 0.29091793298721313 epsilon 0.6295375534064491
26-Feb-25 09:38:49 - agent.DQN.DQN - INFO - episode 9 step 251 reward tensor([-1]) loss 0.2727556526660919 epsilon 0.6295375534064491
26-Feb-25 09:38:49 - agent.DQN.DQN - INFO - episode 9 step 252 reward tensor([-1]) loss 0.22457441687583923 epsilon 0.6295375534064491
26-Feb-25 09:38:49 - agent.DQN.DQN - INFO - episode 9 step 253 reward tensor([-1]) loss 0.26937031745910645 epsilon 0.6295375534064491
26-Feb-25 09:38:49 - agent.DQN.DQN - INFO - episode 9 step 254 reward tensor([-1]) loss 0.23745661973953247 epsilon 0.6295375534064491
26-Feb-25 09:38:49 - agent.DQN.DQN - INFO - episode 9 step 255 reward tensor([-1]) loss 0.36346086859703064 epsilon 0.6295375534064491
26-Feb-25 09:38:49 - agent.DQN.DQN - INFO - episode 9 step 256 reward tensor([-1]) loss 0.2584347724914551 epsilon 0.6295375534064491
26-Feb-25 09:38:49 - agent.DQN.DQN - INFO - episode 9 step 257 reward tensor([-1]) loss 0.2983405888080597 epsilon 0.6295375534064491
26-Feb-25 09:38:49 - agent.DQN.DQN - INFO - episode 9 step 258 reward tensor([-1]) loss 0.2821023166179657 epsilon 0.6295375534064491
26-Feb-25 09:38:49 - agent.DQN.DQN - INFO - episode 9 step 259 reward tensor([-1]) loss 0.2723630964756012 epsilon 0.6295375534064491
26-Feb-25 09:38:49 - agent.DQN.DQN - INFO - episode 9 step 260 reward tensor([-1]) loss 0.2684437334537506 epsilon 0.6295375534064491
26-Feb-25 09:38:49 - agent.DQN.DQN - INFO - episode 9 step 261 reward tensor([-1]) loss 0.2973402440547943 epsilon 0.6295375534064491
26-Feb-25 09:38:49 - agent.DQN.DQN - INFO - episode 9 step 262 reward tensor([-1]) loss 0.27261707186698914 epsilon 0.6295375534064491
26-Feb-25 09:38:49 - agent.DQN.DQN - INFO - episode 9 step 263 reward tensor([-1]) loss 0.23728609085083008 epsilon 0.6295375534064491
26-Feb-25 09:38:49 - agent.DQN.DQN - INFO - episode 9 step 264 reward tensor([-1]) loss 0.2735403776168823 epsilon 0.6295375534064491
26-Feb-25 09:38:50 - agent.DQN.DQN - INFO - episode 9 step 265 reward tensor([-1]) loss 0.29622071981430054 epsilon 0.6295375534064491
26-Feb-25 09:38:50 - agent.DQN.DQN - INFO - episode 9 step 266 reward tensor([-1]) loss 0.3321452736854553 epsilon 0.6295375534064491
26-Feb-25 09:38:50 - agent.DQN.DQN - INFO - episode 9 step 267 reward tensor([-1]) loss 0.28414297103881836 epsilon 0.6295375534064491
26-Feb-25 09:38:50 - agent.DQN.DQN - INFO - episode 9 step 268 reward tensor([-1]) loss 0.2534269690513611 epsilon 0.6295375534064491
26-Feb-25 09:38:50 - agent.DQN.DQN - INFO - episode 9 step 269 reward tensor([-1]) loss 0.2995378077030182 epsilon 0.6295375534064491
26-Feb-25 09:38:50 - agent.DQN.DQN - INFO - episode 9 step 270 reward tensor([-1]) loss 0.231418177485466 epsilon 0.6295375534064491
26-Feb-25 09:38:50 - agent.DQN.DQN - INFO - episode 9 step 271 reward tensor([-1]) loss 0.28118810057640076 epsilon 0.6295375534064491
26-Feb-25 09:38:50 - agent.DQN.DQN - INFO - episode 9 step 272 reward tensor([-1]) loss 0.32231605052948 epsilon 0.6295375534064491
26-Feb-25 09:38:50 - agent.DQN.DQN - INFO - episode 9 step 273 reward tensor([-1]) loss 0.30577167868614197 epsilon 0.6295375534064491
26-Feb-25 09:38:50 - agent.DQN.DQN - INFO - episode 9 step 274 reward tensor([-1]) loss 0.4349227547645569 epsilon 0.6295375534064491
26-Feb-25 09:38:50 - agent.DQN.DQN - INFO - episode 9 step 275 reward tensor([-1]) loss 0.2535906136035919 epsilon 0.6295375534064491
26-Feb-25 09:38:50 - agent.DQN.DQN - INFO - episode 9 step 276 reward tensor([-1]) loss 0.26238059997558594 epsilon 0.6295375534064491
26-Feb-25 09:38:50 - agent.DQN.DQN - INFO - episode 9 step 277 reward tensor([-1]) loss 0.2611502408981323 epsilon 0.6295375534064491
26-Feb-25 09:38:50 - agent.DQN.DQN - INFO - episode 9 step 278 reward tensor([-1]) loss 0.3045107424259186 epsilon 0.6295375534064491
26-Feb-25 09:38:50 - agent.DQN.DQN - INFO - episode 9 step 279 reward tensor([-1]) loss 0.3147486746311188 epsilon 0.6295375534064491
26-Feb-25 09:38:50 - agent.DQN.DQN - INFO - episode 9 step 280 reward tensor([-1]) loss 0.2741767168045044 epsilon 0.6295375534064491
26-Feb-25 09:38:50 - agent.DQN.DQN - INFO - episode 9 step 281 reward tensor([-1]) loss 0.2675810158252716 epsilon 0.6295375534064491
26-Feb-25 09:38:50 - agent.DQN.DQN - INFO - episode 9 step 282 reward tensor([-1]) loss 0.230447918176651 epsilon 0.6295375534064491
26-Feb-25 09:38:50 - agent.DQN.DQN - INFO - episode 9 step 283 reward tensor([-1]) loss 0.25973302125930786 epsilon 0.6295375534064491
26-Feb-25 09:38:50 - agent.DQN.DQN - INFO - episode 9 step 284 reward tensor([-1]) loss 0.20966976881027222 epsilon 0.6295375534064491
26-Feb-25 09:38:50 - agent.DQN.DQN - INFO - episode 9 step 285 reward tensor([-1]) loss 0.2790343761444092 epsilon 0.6295375534064491
26-Feb-25 09:38:50 - agent.DQN.DQN - INFO - episode 9 step 286 reward tensor([-1]) loss 0.26669707894325256 epsilon 0.6295375534064491
26-Feb-25 09:38:50 - agent.DQN.DQN - INFO - episode 9 step 287 reward tensor([-1]) loss 0.2850334048271179 epsilon 0.6295375534064491
26-Feb-25 09:38:50 - agent.DQN.DQN - INFO - episode 9 step 288 reward tensor([-1]) loss 0.3079150319099426 epsilon 0.6295375534064491
26-Feb-25 09:38:50 - agent.DQN.DQN - INFO - episode 9 step 289 reward tensor([-1]) loss 0.2566383183002472 epsilon 0.6295375534064491
26-Feb-25 09:38:50 - agent.DQN.DQN - INFO - episode 9 step 290 reward tensor([-1]) loss 0.25430387258529663 epsilon 0.6295375534064491
26-Feb-25 09:38:50 - agent.DQN.DQN - INFO - episode 9 step 291 reward tensor([-1]) loss 0.3785184323787689 epsilon 0.6295375534064491
26-Feb-25 09:38:50 - agent.DQN.DQN - INFO - episode 9 step 292 reward tensor([-1]) loss 0.29339200258255005 epsilon 0.6295375534064491
26-Feb-25 09:38:50 - agent.DQN.DQN - INFO - episode 9 step 293 reward tensor([-1]) loss 0.2624502182006836 epsilon 0.6295375534064491
26-Feb-25 09:38:50 - agent.DQN.DQN - INFO - episode 9 step 294 reward tensor([-1]) loss 0.2534880042076111 epsilon 0.6295375534064491
26-Feb-25 09:38:50 - agent.DQN.DQN - INFO - episode 9 step 295 reward tensor([-1]) loss 0.30051350593566895 epsilon 0.6295375534064491
26-Feb-25 09:38:50 - agent.DQN.DQN - INFO - episode 9 step 296 reward tensor([-1]) loss 0.22805255651474 epsilon 0.6295375534064491
26-Feb-25 09:38:50 - agent.DQN.DQN - INFO - episode 9 step 297 reward tensor([-1]) loss 0.28220006823539734 epsilon 0.6295375534064491
26-Feb-25 09:38:50 - agent.DQN.DQN - INFO - episode 9 step 298 reward tensor([-1]) loss 0.23830083012580872 epsilon 0.6295375534064491
26-Feb-25 09:38:50 - agent.DQN.DQN - INFO - episode 9 step 299 reward tensor([-1]) loss 0.2580491900444031 epsilon 0.6295375534064491
26-Feb-25 09:38:50 - agent.DQN.DQN - INFO - episode 9 step 300 reward tensor([-1]) loss 0.31839650869369507 epsilon 0.6295375534064491
26-Feb-25 09:38:50 - agent.DQN.DQN - INFO - episode 9 step 301 reward tensor([-1]) loss 0.23799744248390198 epsilon 0.6295375534064491
26-Feb-25 09:38:50 - __main__ - INFO - Training finished for epoch 1, training time: 34.10 seconds
26-Feb-25 09:38:50 - __main__ - INFO - Starting epoch 2
26-Feb-25 09:38:50 - agent.DQN.DQN - INFO - QNetwork initialized with 10 observations and 9 actions
26-Feb-25 09:38:50 - agent.DQN.DQN - INFO - QNetwork initialized with 10 observations and 9 actions
26-Feb-25 09:38:50 - __main__ - INFO - Q-Networks initialized and synchronized
26-Feb-25 09:38:50 - __main__ - INFO - Optimizer, LR scheduler, and loss function initialized
26-Feb-25 09:38:50 - __main__ - INFO - Epsilon-greedy strategy initialized
26-Feb-25 09:38:50 - __main__ - INFO - Replay buffer initialized
26-Feb-25 09:38:50 - __main__ - INFO - Training DQN2 agent
26-Feb-25 09:38:50 - agent.DQN.DQN - INFO - episode 1 step 128 reward tensor([-1]) loss 209.4514617919922 epsilon 0.82
26-Feb-25 09:38:50 - agent.DQN.DQN - INFO - episode 1 step 129 reward tensor([-1]) loss 162.94566345214844 epsilon 0.82
26-Feb-25 09:38:50 - agent.DQN.DQN - INFO - episode 1 step 130 reward tensor([-1]) loss 111.51884460449219 epsilon 0.82
26-Feb-25 09:38:50 - agent.DQN.DQN - INFO - episode 1 step 131 reward tensor([-1]) loss 87.75967407226562 epsilon 0.82
26-Feb-25 09:38:50 - agent.DQN.DQN - INFO - episode 1 step 132 reward tensor([-1]) loss 69.0633544921875 epsilon 0.82
26-Feb-25 09:38:50 - agent.DQN.DQN - INFO - episode 1 step 133 reward tensor([-1]) loss 37.23672866821289 epsilon 0.82
26-Feb-25 09:38:50 - agent.DQN.DQN - INFO - episode 1 step 134 reward tensor([-1]) loss 22.482585906982422 epsilon 0.82
26-Feb-25 09:38:50 - agent.DQN.DQN - INFO - episode 1 step 135 reward tensor([-1]) loss 30.56700897216797 epsilon 0.82
26-Feb-25 09:38:50 - agent.DQN.DQN - INFO - episode 1 step 136 reward tensor([-1]) loss 47.86079406738281 epsilon 0.82
26-Feb-25 09:38:50 - agent.DQN.DQN - INFO - episode 1 step 137 reward tensor([-1]) loss 46.36296844482422 epsilon 0.82
26-Feb-25 09:38:50 - agent.DQN.DQN - INFO - episode 1 step 138 reward tensor([-1]) loss 29.08060073852539 epsilon 0.82
26-Feb-25 09:38:50 - agent.DQN.DQN - INFO - episode 1 step 139 reward tensor([-1]) loss 14.739938735961914 epsilon 0.82
26-Feb-25 09:38:50 - agent.DQN.DQN - INFO - episode 1 step 140 reward tensor([-1]) loss 11.396484375 epsilon 0.82
26-Feb-25 09:38:50 - agent.DQN.DQN - INFO - episode 1 step 141 reward tensor([-1]) loss 12.193687438964844 epsilon 0.82
26-Feb-25 09:38:50 - agent.DQN.DQN - INFO - episode 1 step 142 reward tensor([-1]) loss 14.63541030883789 epsilon 0.82
26-Feb-25 09:38:50 - agent.DQN.DQN - INFO - episode 1 step 143 reward tensor([-1]) loss 17.561017990112305 epsilon 0.82
26-Feb-25 09:38:50 - agent.DQN.DQN - INFO - episode 1 step 144 reward tensor([-1]) loss 14.910455703735352 epsilon 0.82
26-Feb-25 09:38:50 - agent.DQN.DQN - INFO - episode 1 step 145 reward tensor([-1]) loss 15.03090763092041 epsilon 0.82
26-Feb-25 09:38:50 - agent.DQN.DQN - INFO - episode 1 step 146 reward tensor([-1]) loss 10.713855743408203 epsilon 0.82
26-Feb-25 09:38:50 - agent.DQN.DQN - INFO - episode 1 step 147 reward tensor([-1]) loss 6.748654365539551 epsilon 0.82
26-Feb-25 09:38:50 - agent.DQN.DQN - INFO - episode 1 step 148 reward tensor([-1]) loss 3.6785237789154053 epsilon 0.82
26-Feb-25 09:38:50 - agent.DQN.DQN - INFO - episode 1 step 149 reward tensor([-1]) loss 3.3966760635375977 epsilon 0.82
26-Feb-25 09:38:50 - agent.DQN.DQN - INFO - episode 1 step 150 reward tensor([-1]) loss 4.473130702972412 epsilon 0.82
26-Feb-25 09:38:50 - agent.DQN.DQN - INFO - episode 1 step 151 reward tensor([-1]) loss 5.277454853057861 epsilon 0.82
26-Feb-25 09:38:50 - agent.DQN.DQN - INFO - episode 1 step 152 reward tensor([-1]) loss 5.19580078125 epsilon 0.82
26-Feb-25 09:38:51 - agent.DQN.DQN - INFO - episode 1 step 153 reward tensor([-1]) loss 5.482289791107178 epsilon 0.82
26-Feb-25 09:38:51 - agent.DQN.DQN - INFO - episode 1 step 154 reward tensor([-1]) loss 4.264084815979004 epsilon 0.82
26-Feb-25 09:38:51 - agent.DQN.DQN - INFO - episode 1 step 155 reward tensor([-1]) loss 3.8508148193359375 epsilon 0.82
26-Feb-25 09:38:51 - agent.DQN.DQN - INFO - episode 1 step 156 reward tensor([-1]) loss 2.683969497680664 epsilon 0.82
26-Feb-25 09:38:51 - agent.DQN.DQN - INFO - episode 1 step 157 reward tensor([-1]) loss 3.9403040409088135 epsilon 0.82
26-Feb-25 09:38:51 - agent.DQN.DQN - INFO - episode 1 step 158 reward tensor([-1]) loss 3.6338307857513428 epsilon 0.82
26-Feb-25 09:38:51 - agent.DQN.DQN - INFO - episode 1 step 159 reward tensor([-1]) loss 3.568312883377075 epsilon 0.82
26-Feb-25 09:38:51 - agent.DQN.DQN - INFO - episode 1 step 160 reward tensor([-1]) loss 3.9680862426757812 epsilon 0.82
26-Feb-25 09:38:51 - agent.DQN.DQN - INFO - episode 1 step 161 reward tensor([-1]) loss 2.480966091156006 epsilon 0.82
26-Feb-25 09:38:51 - agent.DQN.DQN - INFO - episode 1 step 162 reward tensor([-1]) loss 2.137484550476074 epsilon 0.82
26-Feb-25 09:38:51 - agent.DQN.DQN - INFO - episode 1 step 163 reward tensor([-1]) loss 1.726609468460083 epsilon 0.82
26-Feb-25 09:38:51 - agent.DQN.DQN - INFO - episode 1 step 164 reward tensor([-1]) loss 1.4869221448898315 epsilon 0.82
26-Feb-25 09:38:51 - agent.DQN.DQN - INFO - episode 1 step 165 reward tensor([-1]) loss 1.5142511129379272 epsilon 0.82
26-Feb-25 09:38:51 - agent.DQN.DQN - INFO - episode 1 step 166 reward tensor([-1]) loss 1.3204877376556396 epsilon 0.82
26-Feb-25 09:38:51 - agent.DQN.DQN - INFO - episode 1 step 167 reward tensor([-1]) loss 1.4001011848449707 epsilon 0.82
26-Feb-25 09:38:51 - agent.DQN.DQN - INFO - episode 1 step 168 reward tensor([-1]) loss 1.0991288423538208 epsilon 0.82
26-Feb-25 09:38:51 - agent.DQN.DQN - INFO - episode 1 step 169 reward tensor([-1]) loss 1.0669262409210205 epsilon 0.82
26-Feb-25 09:38:51 - agent.DQN.DQN - INFO - episode 1 step 170 reward tensor([-1]) loss 1.0376359224319458 epsilon 0.82
26-Feb-25 09:38:51 - agent.DQN.DQN - INFO - episode 1 step 171 reward tensor([-1]) loss 1.0797759294509888 epsilon 0.82
26-Feb-25 09:38:51 - agent.DQN.DQN - INFO - episode 1 step 172 reward tensor([-1]) loss 0.961014986038208 epsilon 0.82
26-Feb-25 09:38:51 - agent.DQN.DQN - INFO - episode 1 step 173 reward tensor([-1]) loss 0.9008327126502991 epsilon 0.82
26-Feb-25 09:38:51 - agent.DQN.DQN - INFO - episode 1 step 174 reward tensor([-1]) loss 0.7516428828239441 epsilon 0.82
26-Feb-25 09:38:51 - agent.DQN.DQN - INFO - episode 1 step 175 reward tensor([-1]) loss 0.6622233390808105 epsilon 0.82
26-Feb-25 09:38:51 - agent.DQN.DQN - INFO - episode 1 step 176 reward tensor([-1]) loss 0.5493071675300598 epsilon 0.82
26-Feb-25 09:38:51 - agent.DQN.DQN - INFO - episode 1 step 177 reward tensor([-1]) loss 0.3726905882358551 epsilon 0.82
26-Feb-25 09:38:51 - agent.DQN.DQN - INFO - episode 1 step 178 reward tensor([-1]) loss 0.4216187596321106 epsilon 0.82
26-Feb-25 09:38:51 - agent.DQN.DQN - INFO - episode 1 step 179 reward tensor([-1]) loss 0.45516693592071533 epsilon 0.82
26-Feb-25 09:38:51 - agent.DQN.DQN - INFO - episode 1 step 180 reward tensor([-1]) loss 0.5700757503509521 epsilon 0.82
26-Feb-25 09:38:51 - agent.DQN.DQN - INFO - episode 1 step 181 reward tensor([-1]) loss 5.628649711608887 epsilon 0.82
26-Feb-25 09:38:51 - agent.DQN.DQN - INFO - episode 1 step 182 reward tensor([-1]) loss 3.6894309520721436 epsilon 0.82
26-Feb-25 09:38:51 - agent.DQN.DQN - INFO - episode 1 step 183 reward tensor([-1]) loss 1.9398257732391357 epsilon 0.82
26-Feb-25 09:38:51 - agent.DQN.DQN - INFO - episode 1 step 184 reward tensor([-1]) loss 0.8692747354507446 epsilon 0.82
26-Feb-25 09:38:51 - agent.DQN.DQN - INFO - episode 1 step 185 reward tensor([-1]) loss 0.6257680654525757 epsilon 0.82
26-Feb-25 09:38:51 - agent.DQN.DQN - INFO - episode 1 step 186 reward tensor([-1]) loss 0.9863622188568115 epsilon 0.82
26-Feb-25 09:38:51 - agent.DQN.DQN - INFO - episode 1 step 187 reward tensor([-1]) loss 1.9511524438858032 epsilon 0.82
26-Feb-25 09:38:51 - agent.DQN.DQN - INFO - episode 1 step 188 reward tensor([-1]) loss 1.9829847812652588 epsilon 0.82
26-Feb-25 09:38:51 - agent.DQN.DQN - INFO - episode 1 step 189 reward tensor([-1]) loss 2.0792453289031982 epsilon 0.82
26-Feb-25 09:38:51 - agent.DQN.DQN - INFO - episode 1 step 190 reward tensor([-1]) loss 1.4188950061798096 epsilon 0.82
26-Feb-25 09:38:51 - agent.DQN.DQN - INFO - episode 1 step 191 reward tensor([-1]) loss 1.1177020072937012 epsilon 0.82
26-Feb-25 09:38:51 - agent.DQN.DQN - INFO - episode 1 step 192 reward tensor([-1]) loss 0.5364968776702881 epsilon 0.82
26-Feb-25 09:38:51 - agent.DQN.DQN - INFO - episode 1 step 193 reward tensor([-1]) loss 0.522480845451355 epsilon 0.82
26-Feb-25 09:38:51 - agent.DQN.DQN - INFO - episode 1 step 194 reward tensor([-1]) loss 0.4048599898815155 epsilon 0.82
26-Feb-25 09:38:51 - agent.DQN.DQN - INFO - episode 1 step 195 reward tensor([-1]) loss 0.5666091442108154 epsilon 0.82
26-Feb-25 09:38:51 - agent.DQN.DQN - INFO - episode 1 step 196 reward tensor([-1]) loss 0.6740227341651917 epsilon 0.82
26-Feb-25 09:38:51 - agent.DQN.DQN - INFO - episode 1 step 197 reward tensor([-1]) loss 0.9223855137825012 epsilon 0.82
26-Feb-25 09:38:51 - agent.DQN.DQN - INFO - episode 1 step 198 reward tensor([-1]) loss 0.7787854671478271 epsilon 0.82
26-Feb-25 09:38:51 - agent.DQN.DQN - INFO - episode 1 step 199 reward tensor([-1]) loss 0.7013235688209534 epsilon 0.82
26-Feb-25 09:38:51 - agent.DQN.DQN - INFO - episode 1 step 200 reward tensor([-1]) loss 0.4553922116756439 epsilon 0.82
26-Feb-25 09:38:51 - agent.DQN.DQN - INFO - episode 1 step 201 reward tensor([-1]) loss 0.40948477387428284 epsilon 0.82
26-Feb-25 09:38:51 - agent.DQN.DQN - INFO - episode 1 step 202 reward tensor([-1]) loss 0.2820068895816803 epsilon 0.82
26-Feb-25 09:38:51 - agent.DQN.DQN - INFO - episode 1 step 203 reward tensor([-1]) loss 0.38087183237075806 epsilon 0.82
26-Feb-25 09:38:51 - agent.DQN.DQN - INFO - episode 1 step 204 reward tensor([-1]) loss 0.4269017279148102 epsilon 0.82
26-Feb-25 09:38:51 - agent.DQN.DQN - INFO - episode 1 step 205 reward tensor([-1]) loss 0.7193284034729004 epsilon 0.82
26-Feb-25 09:38:51 - agent.DQN.DQN - INFO - episode 1 step 206 reward tensor([-1]) loss 0.7667577862739563 epsilon 0.82
26-Feb-25 09:38:51 - agent.DQN.DQN - INFO - episode 1 step 207 reward tensor([-1]) loss 0.6681925058364868 epsilon 0.82
26-Feb-25 09:38:51 - agent.DQN.DQN - INFO - episode 1 step 208 reward tensor([-1]) loss 0.7396472692489624 epsilon 0.82
26-Feb-25 09:38:51 - agent.DQN.DQN - INFO - episode 1 step 209 reward tensor([-1]) loss 0.3309173285961151 epsilon 0.82
26-Feb-25 09:38:51 - agent.DQN.DQN - INFO - episode 1 step 210 reward tensor([-1]) loss 0.6276574730873108 epsilon 0.82
26-Feb-25 09:38:51 - agent.DQN.DQN - INFO - episode 1 step 211 reward tensor([-1]) loss 6.269482612609863 epsilon 0.82
26-Feb-25 09:38:51 - agent.DQN.DQN - INFO - episode 1 step 212 reward tensor([-1]) loss 6.108490467071533 epsilon 0.82
26-Feb-25 09:38:51 - agent.DQN.DQN - INFO - episode 1 step 213 reward tensor([-1]) loss 4.957814693450928 epsilon 0.82
26-Feb-25 09:38:51 - agent.DQN.DQN - INFO - episode 1 step 214 reward tensor([-1]) loss 3.769751787185669 epsilon 0.82
26-Feb-25 09:38:51 - agent.DQN.DQN - INFO - episode 1 step 215 reward tensor([-1]) loss 2.3564627170562744 epsilon 0.82
26-Feb-25 09:38:51 - agent.DQN.DQN - INFO - episode 1 step 216 reward tensor([-1]) loss 1.381338119506836 epsilon 0.82
26-Feb-25 09:38:51 - agent.DQN.DQN - INFO - episode 1 step 217 reward tensor([-1]) loss 0.9783671498298645 epsilon 0.82
26-Feb-25 09:38:51 - agent.DQN.DQN - INFO - episode 1 step 218 reward tensor([-1]) loss 1.0948909521102905 epsilon 0.82
26-Feb-25 09:38:51 - agent.DQN.DQN - INFO - episode 1 step 219 reward tensor([-1]) loss 1.305680751800537 epsilon 0.82
26-Feb-25 09:38:51 - agent.DQN.DQN - INFO - episode 1 step 220 reward tensor([-1]) loss 1.7572256326675415 epsilon 0.82
26-Feb-25 09:38:51 - agent.DQN.DQN - INFO - episode 1 step 221 reward tensor([-1]) loss 1.8238790035247803 epsilon 0.82
26-Feb-25 09:38:51 - agent.DQN.DQN - INFO - episode 1 step 222 reward tensor([-1]) loss 2.680912494659424 epsilon 0.82
26-Feb-25 09:38:51 - agent.DQN.DQN - INFO - episode 1 step 223 reward tensor([-1]) loss 2.13147234916687 epsilon 0.82
26-Feb-25 09:38:51 - agent.DQN.DQN - INFO - episode 1 step 224 reward tensor([-1]) loss 2.569049835205078 epsilon 0.82
26-Feb-25 09:38:51 - agent.DQN.DQN - INFO - episode 1 step 225 reward tensor([-1]) loss 2.404127597808838 epsilon 0.82
26-Feb-25 09:38:51 - agent.DQN.DQN - INFO - episode 1 step 226 reward tensor([-1]) loss 1.7357561588287354 epsilon 0.82
26-Feb-25 09:38:51 - agent.DQN.DQN - INFO - episode 1 step 227 reward tensor([-1]) loss 2.2792677879333496 epsilon 0.82
26-Feb-25 09:38:51 - agent.DQN.DQN - INFO - episode 1 step 228 reward tensor([-1]) loss 1.6616394519805908 epsilon 0.82
26-Feb-25 09:38:51 - agent.DQN.DQN - INFO - episode 1 step 229 reward tensor([-1]) loss 1.4488321542739868 epsilon 0.82
26-Feb-25 09:38:51 - agent.DQN.DQN - INFO - episode 1 step 230 reward tensor([-1]) loss 1.3626431226730347 epsilon 0.82
26-Feb-25 09:38:51 - agent.DQN.DQN - INFO - episode 1 step 231 reward tensor([-1]) loss 1.5452204942703247 epsilon 0.82
26-Feb-25 09:38:51 - agent.DQN.DQN - INFO - episode 1 step 232 reward tensor([-1]) loss 1.6591740846633911 epsilon 0.82
26-Feb-25 09:38:51 - agent.DQN.DQN - INFO - episode 1 step 233 reward tensor([-1]) loss 2.037551164627075 epsilon 0.82
26-Feb-25 09:38:51 - agent.DQN.DQN - INFO - episode 1 step 234 reward tensor([-1]) loss 1.6070528030395508 epsilon 0.82
26-Feb-25 09:38:51 - agent.DQN.DQN - INFO - episode 1 step 235 reward tensor([-1]) loss 1.9425106048583984 epsilon 0.82
26-Feb-25 09:38:51 - agent.DQN.DQN - INFO - episode 1 step 236 reward tensor([-1]) loss 1.0439969301223755 epsilon 0.82
26-Feb-25 09:38:51 - agent.DQN.DQN - INFO - episode 1 step 237 reward tensor([-1]) loss 1.8304026126861572 epsilon 0.82
26-Feb-25 09:38:51 - agent.DQN.DQN - INFO - episode 1 step 238 reward tensor([-1]) loss 1.946685552597046 epsilon 0.82
26-Feb-25 09:38:51 - agent.DQN.DQN - INFO - episode 1 step 239 reward tensor([-1]) loss 1.6117175817489624 epsilon 0.82
26-Feb-25 09:38:51 - agent.DQN.DQN - INFO - episode 1 step 240 reward tensor([-1]) loss 1.4071235656738281 epsilon 0.82
26-Feb-25 09:38:52 - agent.DQN.DQN - INFO - episode 1 step 241 reward tensor([-1]) loss 3.821347713470459 epsilon 0.82
26-Feb-25 09:38:52 - agent.DQN.DQN - INFO - episode 1 step 242 reward tensor([-1]) loss 3.7391903400421143 epsilon 0.82
26-Feb-25 09:38:52 - agent.DQN.DQN - INFO - episode 1 step 243 reward tensor([-1]) loss 3.513859272003174 epsilon 0.82
26-Feb-25 09:38:52 - agent.DQN.DQN - INFO - episode 1 step 244 reward tensor([-1]) loss 2.908097267150879 epsilon 0.82
26-Feb-25 09:38:52 - agent.DQN.DQN - INFO - episode 1 step 245 reward tensor([-1]) loss 2.7440481185913086 epsilon 0.82
26-Feb-25 09:38:52 - agent.DQN.DQN - INFO - episode 1 step 246 reward tensor([-1]) loss 2.389695882797241 epsilon 0.82
26-Feb-25 09:38:52 - agent.DQN.DQN - INFO - episode 1 step 247 reward tensor([-1]) loss 2.029263973236084 epsilon 0.82
26-Feb-25 09:38:52 - agent.DQN.DQN - INFO - episode 1 step 248 reward tensor([-1]) loss 1.6739059686660767 epsilon 0.82
26-Feb-25 09:38:52 - agent.DQN.DQN - INFO - episode 1 step 249 reward tensor([-1]) loss 1.5642187595367432 epsilon 0.82
26-Feb-25 09:38:52 - agent.DQN.DQN - INFO - episode 1 step 250 reward tensor([-1]) loss 1.7413750886917114 epsilon 0.82
26-Feb-25 09:38:52 - agent.DQN.DQN - INFO - episode 1 step 251 reward tensor([-1]) loss 1.3965377807617188 epsilon 0.82
26-Feb-25 09:38:52 - agent.DQN.DQN - INFO - episode 1 step 252 reward tensor([-1]) loss 1.3190410137176514 epsilon 0.82
26-Feb-25 09:38:52 - agent.DQN.DQN - INFO - episode 1 step 253 reward tensor([-1]) loss 1.8489055633544922 epsilon 0.82
26-Feb-25 09:38:52 - agent.DQN.DQN - INFO - episode 1 step 254 reward tensor([-1]) loss 1.2291512489318848 epsilon 0.82
26-Feb-25 09:38:52 - agent.DQN.DQN - INFO - episode 1 step 255 reward tensor([-1]) loss 1.4476803541183472 epsilon 0.82
26-Feb-25 09:38:52 - agent.DQN.DQN - INFO - episode 1 step 256 reward tensor([-1]) loss 2.1978538036346436 epsilon 0.82
26-Feb-25 09:38:52 - agent.DQN.DQN - INFO - episode 1 step 257 reward tensor([-1]) loss 1.8045523166656494 epsilon 0.82
26-Feb-25 09:38:52 - agent.DQN.DQN - INFO - episode 1 step 258 reward tensor([-1]) loss 1.9131730794906616 epsilon 0.82
26-Feb-25 09:38:52 - agent.DQN.DQN - INFO - episode 1 step 259 reward tensor([-1]) loss 1.6927506923675537 epsilon 0.82
26-Feb-25 09:38:52 - agent.DQN.DQN - INFO - episode 1 step 260 reward tensor([-1]) loss 1.1715830564498901 epsilon 0.82
26-Feb-25 09:38:52 - agent.DQN.DQN - INFO - episode 1 step 261 reward tensor([-1]) loss 1.740740180015564 epsilon 0.82
26-Feb-25 09:38:52 - agent.DQN.DQN - INFO - episode 1 step 262 reward tensor([-1]) loss 1.4455218315124512 epsilon 0.82
26-Feb-25 09:38:52 - agent.DQN.DQN - INFO - episode 1 step 263 reward tensor([-1]) loss 1.0310728549957275 epsilon 0.82
26-Feb-25 09:38:52 - agent.DQN.DQN - INFO - episode 1 step 264 reward tensor([-1]) loss 0.8576091527938843 epsilon 0.82
26-Feb-25 09:38:52 - agent.DQN.DQN - INFO - episode 1 step 265 reward tensor([-1]) loss 0.9009140729904175 epsilon 0.82
26-Feb-25 09:38:52 - agent.DQN.DQN - INFO - episode 1 step 266 reward tensor([-1]) loss 1.245721459388733 epsilon 0.82
26-Feb-25 09:38:52 - agent.DQN.DQN - INFO - episode 1 step 267 reward tensor([-1]) loss 1.045444130897522 epsilon 0.82
26-Feb-25 09:38:52 - agent.DQN.DQN - INFO - episode 1 step 268 reward tensor([-1]) loss 1.0704591274261475 epsilon 0.82
26-Feb-25 09:38:52 - agent.DQN.DQN - INFO - episode 1 step 269 reward tensor([-1]) loss 1.0301127433776855 epsilon 0.82
26-Feb-25 09:38:52 - agent.DQN.DQN - INFO - episode 1 step 270 reward tensor([-1]) loss 0.9093337059020996 epsilon 0.82
26-Feb-25 09:38:52 - agent.DQN.DQN - INFO - episode 1 step 271 reward tensor([-1]) loss 5.022924900054932 epsilon 0.82
26-Feb-25 09:38:52 - agent.DQN.DQN - INFO - episode 1 step 272 reward tensor([-1]) loss 4.757664680480957 epsilon 0.82
26-Feb-25 09:38:52 - agent.DQN.DQN - INFO - episode 1 step 273 reward tensor([-1]) loss 4.139948844909668 epsilon 0.82
26-Feb-25 09:38:52 - agent.DQN.DQN - INFO - episode 1 step 274 reward tensor([-1]) loss 3.5015082359313965 epsilon 0.82
26-Feb-25 09:38:52 - agent.DQN.DQN - INFO - episode 1 step 275 reward tensor([-1]) loss 3.34375 epsilon 0.82
26-Feb-25 09:38:52 - agent.DQN.DQN - INFO - episode 1 step 276 reward tensor([-1]) loss 2.615168571472168 epsilon 0.82
26-Feb-25 09:38:52 - agent.DQN.DQN - INFO - episode 1 step 277 reward tensor([-1]) loss 2.105539321899414 epsilon 0.82
26-Feb-25 09:38:52 - agent.DQN.DQN - INFO - episode 1 step 278 reward tensor([-1]) loss 1.4741617441177368 epsilon 0.82
26-Feb-25 09:38:52 - agent.DQN.DQN - INFO - episode 1 step 279 reward tensor([-1]) loss 1.1726815700531006 epsilon 0.82
26-Feb-25 09:38:52 - agent.DQN.DQN - INFO - episode 1 step 280 reward tensor([-1]) loss 1.0068684816360474 epsilon 0.82
26-Feb-25 09:38:52 - agent.DQN.DQN - INFO - episode 1 step 281 reward tensor([-1]) loss 0.7440809011459351 epsilon 0.82
26-Feb-25 09:38:52 - agent.DQN.DQN - INFO - episode 1 step 282 reward tensor([-1]) loss 0.718585193157196 epsilon 0.82
26-Feb-25 09:38:52 - agent.DQN.DQN - INFO - episode 1 step 283 reward tensor([-1]) loss 0.9567323923110962 epsilon 0.82
26-Feb-25 09:38:52 - agent.DQN.DQN - INFO - episode 1 step 284 reward tensor([-1]) loss 1.166552186012268 epsilon 0.82
26-Feb-25 09:38:52 - agent.DQN.DQN - INFO - episode 1 step 285 reward tensor([-1]) loss 1.3365484476089478 epsilon 0.82
26-Feb-25 09:38:52 - agent.DQN.DQN - INFO - episode 1 step 286 reward tensor([-1]) loss 1.0631824731826782 epsilon 0.82
26-Feb-25 09:38:52 - agent.DQN.DQN - INFO - episode 1 step 287 reward tensor([-1]) loss 1.3541914224624634 epsilon 0.82
26-Feb-25 09:38:52 - agent.DQN.DQN - INFO - episode 1 step 288 reward tensor([-1]) loss 0.9868714809417725 epsilon 0.82
26-Feb-25 09:38:52 - agent.DQN.DQN - INFO - episode 1 step 289 reward tensor([-1]) loss 1.1920316219329834 epsilon 0.82
26-Feb-25 09:38:52 - agent.DQN.DQN - INFO - episode 1 step 290 reward tensor([-1]) loss 1.1462115049362183 epsilon 0.82
26-Feb-25 09:38:52 - agent.DQN.DQN - INFO - episode 1 step 291 reward tensor([-1]) loss 0.9505031108856201 epsilon 0.82
26-Feb-25 09:38:52 - agent.DQN.DQN - INFO - episode 1 step 292 reward tensor([-1]) loss 1.0409069061279297 epsilon 0.82
26-Feb-25 09:38:52 - agent.DQN.DQN - INFO - episode 1 step 293 reward tensor([-1]) loss 0.9187873601913452 epsilon 0.82
26-Feb-25 09:38:52 - agent.DQN.DQN - INFO - episode 1 step 294 reward tensor([-1]) loss 0.6543262600898743 epsilon 0.82
26-Feb-25 09:38:52 - agent.DQN.DQN - INFO - episode 1 step 295 reward tensor([-1]) loss 0.681057333946228 epsilon 0.82
26-Feb-25 09:38:52 - agent.DQN.DQN - INFO - episode 1 step 296 reward tensor([-1]) loss 0.623892068862915 epsilon 0.82
26-Feb-25 09:38:52 - agent.DQN.DQN - INFO - episode 1 step 297 reward tensor([-1]) loss 0.6337718963623047 epsilon 0.82
26-Feb-25 09:38:52 - agent.DQN.DQN - INFO - episode 1 step 298 reward tensor([-1]) loss 0.5558106303215027 epsilon 0.82
26-Feb-25 09:38:52 - agent.DQN.DQN - INFO - episode 1 step 299 reward tensor([-1]) loss 0.5787513256072998 epsilon 0.82
26-Feb-25 09:38:52 - agent.DQN.DQN - INFO - episode 1 step 300 reward tensor([-1]) loss 0.5027613043785095 epsilon 0.82
26-Feb-25 09:38:52 - agent.DQN.DQN - INFO - episode 1 step 301 reward tensor([-1]) loss 5.640999794006348 epsilon 0.82
26-Feb-25 09:38:52 - agent.DQN.DQN - INFO - episode 2 step 0 reward tensor([-1]) loss 28.02974510192871 epsilon 0.79335
26-Feb-25 09:38:52 - agent.DQN.DQN - INFO - episode 2 step 1 reward tensor([-1]) loss 5.015209674835205 epsilon 0.79335
26-Feb-25 09:38:52 - agent.DQN.DQN - INFO - episode 2 step 2 reward tensor([-1]) loss 3.9733080863952637 epsilon 0.79335
26-Feb-25 09:38:52 - agent.DQN.DQN - INFO - episode 2 step 3 reward tensor([-1]) loss 23.095645904541016 epsilon 0.79335
26-Feb-25 09:38:52 - agent.DQN.DQN - INFO - episode 2 step 4 reward tensor([-1]) loss 2.4067742824554443 epsilon 0.79335
26-Feb-25 09:38:52 - agent.DQN.DQN - INFO - episode 2 step 5 reward tensor([-1]) loss 1.4188029766082764 epsilon 0.79335
26-Feb-25 09:38:52 - agent.DQN.DQN - INFO - episode 2 step 6 reward tensor([-1]) loss 1.1235004663467407 epsilon 0.79335
26-Feb-25 09:38:52 - agent.DQN.DQN - INFO - episode 2 step 7 reward tensor([-1]) loss 0.6989580988883972 epsilon 0.79335
26-Feb-25 09:38:52 - agent.DQN.DQN - INFO - episode 2 step 8 reward tensor([-1]) loss 0.7779480218887329 epsilon 0.79335
26-Feb-25 09:38:52 - agent.DQN.DQN - INFO - episode 2 step 9 reward tensor([-1]) loss 0.9519845247268677 epsilon 0.79335
26-Feb-25 09:38:52 - agent.DQN.DQN - INFO - episode 2 step 10 reward tensor([-1]) loss 15.783053398132324 epsilon 0.79335
26-Feb-25 09:38:52 - agent.DQN.DQN - INFO - episode 2 step 11 reward tensor([-1]) loss 1.529917597770691 epsilon 0.79335
26-Feb-25 09:38:53 - agent.DQN.DQN - INFO - episode 2 step 12 reward tensor([-1]) loss 15.352461814880371 epsilon 0.79335
26-Feb-25 09:38:53 - agent.DQN.DQN - INFO - episode 2 step 13 reward tensor([-1]) loss 15.451664924621582 epsilon 0.79335
26-Feb-25 09:38:53 - agent.DQN.DQN - INFO - episode 2 step 14 reward tensor([-1]) loss 3.1029715538024902 epsilon 0.79335
26-Feb-25 09:38:53 - agent.DQN.DQN - INFO - episode 2 step 15 reward tensor([100]) loss 15.870684623718262 epsilon 0.79335
26-Feb-25 09:38:53 - agent.DQN.DQN - INFO - episode 3 step 0 reward tensor([-1]) loss 90.77619171142578 epsilon 0.767566125
26-Feb-25 09:38:53 - agent.DQN.DQN - INFO - episode 3 step 1 reward tensor([-1]) loss 3.620349407196045 epsilon 0.767566125
26-Feb-25 09:38:53 - agent.DQN.DQN - INFO - episode 3 step 2 reward tensor([-1]) loss 78.75067901611328 epsilon 0.767566125
26-Feb-25 09:38:53 - agent.DQN.DQN - INFO - episode 3 step 3 reward tensor([-1]) loss 3.449429512023926 epsilon 0.767566125
26-Feb-25 09:38:53 - agent.DQN.DQN - INFO - episode 3 step 4 reward tensor([-1]) loss 77.9132080078125 epsilon 0.767566125
26-Feb-25 09:38:53 - agent.DQN.DQN - INFO - episode 3 step 5 reward tensor([-1]) loss 77.05867767333984 epsilon 0.767566125
26-Feb-25 09:38:53 - agent.DQN.DQN - INFO - episode 3 step 6 reward tensor([-1]) loss 14.856804847717285 epsilon 0.767566125
26-Feb-25 09:38:53 - agent.DQN.DQN - INFO - episode 3 step 7 reward tensor([-1]) loss 89.78312683105469 epsilon 0.767566125
26-Feb-25 09:38:53 - agent.DQN.DQN - INFO - episode 3 step 8 reward tensor([-1]) loss 14.969955444335938 epsilon 0.767566125
26-Feb-25 09:38:53 - agent.DQN.DQN - INFO - episode 3 step 9 reward tensor([-1]) loss 89.6231689453125 epsilon 0.767566125
26-Feb-25 09:38:53 - agent.DQN.DQN - INFO - episode 3 step 10 reward tensor([-1]) loss 75.69847106933594 epsilon 0.767566125
26-Feb-25 09:38:53 - agent.DQN.DQN - INFO - episode 3 step 11 reward tensor([-1]) loss 14.545007705688477 epsilon 0.767566125
26-Feb-25 09:38:53 - agent.DQN.DQN - INFO - episode 3 step 12 reward tensor([-1]) loss 14.756244659423828 epsilon 0.767566125
26-Feb-25 09:38:53 - agent.DQN.DQN - INFO - episode 3 step 13 reward tensor([-1]) loss 16.584735870361328 epsilon 0.767566125
26-Feb-25 09:38:53 - agent.DQN.DQN - INFO - episode 3 step 14 reward tensor([-1]) loss 16.82716941833496 epsilon 0.767566125
26-Feb-25 09:38:53 - agent.DQN.DQN - INFO - episode 3 step 15 reward tensor([-1]) loss 77.69384002685547 epsilon 0.767566125
26-Feb-25 09:38:53 - agent.DQN.DQN - INFO - episode 3 step 16 reward tensor([-1]) loss 15.549138069152832 epsilon 0.767566125
26-Feb-25 09:38:53 - agent.DQN.DQN - INFO - episode 3 step 17 reward tensor([-1]) loss 77.4784927368164 epsilon 0.767566125
26-Feb-25 09:38:53 - agent.DQN.DQN - INFO - episode 3 step 18 reward tensor([-1]) loss 75.62043762207031 epsilon 0.767566125
26-Feb-25 09:38:53 - agent.DQN.DQN - INFO - episode 3 step 19 reward tensor([-1]) loss 2.3529934883117676 epsilon 0.767566125
26-Feb-25 09:38:53 - agent.DQN.DQN - INFO - episode 3 step 20 reward tensor([-1]) loss 85.73118591308594 epsilon 0.767566125
26-Feb-25 09:38:53 - agent.DQN.DQN - INFO - episode 3 step 21 reward tensor([-1]) loss 12.318525314331055 epsilon 0.767566125
26-Feb-25 09:38:53 - agent.DQN.DQN - INFO - episode 3 step 22 reward tensor([-1]) loss 12.204655647277832 epsilon 0.767566125
26-Feb-25 09:38:53 - agent.DQN.DQN - INFO - episode 3 step 23 reward tensor([-1]) loss 74.07608795166016 epsilon 0.767566125
26-Feb-25 09:38:53 - agent.DQN.DQN - INFO - episode 3 step 24 reward tensor([-1]) loss 1.3756541013717651 epsilon 0.767566125
26-Feb-25 09:38:53 - agent.DQN.DQN - INFO - episode 3 step 25 reward tensor([-1]) loss 1.7209948301315308 epsilon 0.767566125
26-Feb-25 09:38:53 - agent.DQN.DQN - INFO - episode 3 step 26 reward tensor([-1]) loss 84.16096496582031 epsilon 0.767566125
26-Feb-25 09:38:53 - agent.DQN.DQN - INFO - episode 3 step 27 reward tensor([-1]) loss 12.145292282104492 epsilon 0.767566125
26-Feb-25 09:38:53 - agent.DQN.DQN - INFO - episode 3 step 28 reward tensor([-1]) loss 2.1825356483459473 epsilon 0.767566125
26-Feb-25 09:38:53 - agent.DQN.DQN - INFO - episode 3 step 29 reward tensor([-1]) loss 1.8281296491622925 epsilon 0.767566125
26-Feb-25 09:38:53 - agent.DQN.DQN - INFO - episode 3 step 30 reward tensor([-1]) loss 73.6866683959961 epsilon 0.767566125
26-Feb-25 09:38:53 - agent.DQN.DQN - INFO - episode 3 step 31 reward tensor([-1]) loss 1.6349656581878662 epsilon 0.767566125
26-Feb-25 09:38:53 - agent.DQN.DQN - INFO - episode 3 step 32 reward tensor([-1]) loss 12.531246185302734 epsilon 0.767566125
26-Feb-25 09:38:53 - agent.DQN.DQN - INFO - episode 3 step 33 reward tensor([-1]) loss 12.840777397155762 epsilon 0.767566125
26-Feb-25 09:38:53 - agent.DQN.DQN - INFO - episode 3 step 34 reward tensor([-1]) loss 72.59445190429688 epsilon 0.767566125
26-Feb-25 09:38:53 - agent.DQN.DQN - INFO - episode 3 step 35 reward tensor([-1]) loss 83.24567413330078 epsilon 0.767566125
26-Feb-25 09:38:53 - agent.DQN.DQN - INFO - episode 3 step 36 reward tensor([-1]) loss 71.86145782470703 epsilon 0.767566125
26-Feb-25 09:38:53 - agent.DQN.DQN - INFO - episode 3 step 37 reward tensor([-1]) loss 0.7152565121650696 epsilon 0.767566125
26-Feb-25 09:38:53 - agent.DQN.DQN - INFO - episode 3 step 38 reward tensor([-1]) loss 1.011220097541809 epsilon 0.767566125
26-Feb-25 09:38:53 - agent.DQN.DQN - INFO - episode 3 step 39 reward tensor([-1]) loss 0.9335435628890991 epsilon 0.767566125
26-Feb-25 09:38:53 - agent.DQN.DQN - INFO - episode 3 step 40 reward tensor([-1]) loss 0.7772769331932068 epsilon 0.767566125
26-Feb-25 09:38:53 - agent.DQN.DQN - INFO - episode 3 step 41 reward tensor([-1]) loss 11.887090682983398 epsilon 0.767566125
26-Feb-25 09:38:53 - agent.DQN.DQN - INFO - episode 3 step 42 reward tensor([-1]) loss 0.6248334646224976 epsilon 0.767566125
26-Feb-25 09:38:53 - agent.DQN.DQN - INFO - episode 3 step 43 reward tensor([-1]) loss 14.125202178955078 epsilon 0.767566125
26-Feb-25 09:38:53 - agent.DQN.DQN - INFO - episode 3 step 44 reward tensor([-1]) loss 3.294365882873535 epsilon 0.767566125
26-Feb-25 09:38:53 - agent.DQN.DQN - INFO - episode 3 step 45 reward tensor([-1]) loss 72.80492401123047 epsilon 0.767566125
26-Feb-25 09:38:53 - agent.DQN.DQN - INFO - episode 3 step 46 reward tensor([-1]) loss 72.61454010009766 epsilon 0.767566125
26-Feb-25 09:38:53 - agent.DQN.DQN - INFO - episode 3 step 47 reward tensor([-1]) loss 2.3824801445007324 epsilon 0.767566125
26-Feb-25 09:38:53 - agent.DQN.DQN - INFO - episode 3 step 48 reward tensor([-1]) loss 81.85538482666016 epsilon 0.767566125
26-Feb-25 09:38:53 - agent.DQN.DQN - INFO - episode 3 step 49 reward tensor([-1]) loss 71.41413879394531 epsilon 0.767566125
26-Feb-25 09:38:53 - agent.DQN.DQN - INFO - episode 3 step 50 reward tensor([-1]) loss 81.00310516357422 epsilon 0.767566125
26-Feb-25 09:38:53 - agent.DQN.DQN - INFO - episode 3 step 51 reward tensor([-1]) loss 1.0313365459442139 epsilon 0.767566125
26-Feb-25 09:38:53 - agent.DQN.DQN - INFO - episode 3 step 52 reward tensor([-1]) loss 10.234615325927734 epsilon 0.767566125
26-Feb-25 09:38:53 - agent.DQN.DQN - INFO - episode 3 step 53 reward tensor([-1]) loss 1.1269136667251587 epsilon 0.767566125
26-Feb-25 09:38:53 - agent.DQN.DQN - INFO - episode 3 step 54 reward tensor([-1]) loss 1.4625229835510254 epsilon 0.767566125
26-Feb-25 09:38:53 - agent.DQN.DQN - INFO - episode 3 step 55 reward tensor([-1]) loss 70.25682067871094 epsilon 0.767566125
26-Feb-25 09:38:53 - agent.DQN.DQN - INFO - episode 3 step 56 reward tensor([-1]) loss 70.38436889648438 epsilon 0.767566125
26-Feb-25 09:38:53 - agent.DQN.DQN - INFO - episode 3 step 57 reward tensor([-1]) loss 69.99877166748047 epsilon 0.767566125
26-Feb-25 09:38:53 - agent.DQN.DQN - INFO - episode 3 step 58 reward tensor([-1]) loss 1.3171089887619019 epsilon 0.767566125
26-Feb-25 09:38:53 - agent.DQN.DQN - INFO - episode 3 step 59 reward tensor([-1]) loss 69.8171157836914 epsilon 0.767566125
26-Feb-25 09:38:53 - agent.DQN.DQN - INFO - episode 3 step 60 reward tensor([-1]) loss 1.1713042259216309 epsilon 0.767566125
26-Feb-25 09:38:53 - agent.DQN.DQN - INFO - episode 3 step 61 reward tensor([-1]) loss 1.3982279300689697 epsilon 0.767566125
26-Feb-25 09:38:53 - agent.DQN.DQN - INFO - episode 3 step 62 reward tensor([-1]) loss 79.30018615722656 epsilon 0.767566125
26-Feb-25 09:38:53 - agent.DQN.DQN - INFO - episode 3 step 63 reward tensor([-1]) loss 10.853086471557617 epsilon 0.767566125
26-Feb-25 09:38:53 - agent.DQN.DQN - INFO - episode 3 step 64 reward tensor([-1]) loss 1.1630308628082275 epsilon 0.767566125
26-Feb-25 09:38:53 - agent.DQN.DQN - INFO - episode 3 step 65 reward tensor([-1]) loss 69.35342407226562 epsilon 0.767566125
26-Feb-25 09:38:53 - agent.DQN.DQN - INFO - episode 3 step 66 reward tensor([-1]) loss 69.09054565429688 epsilon 0.767566125
26-Feb-25 09:38:53 - agent.DQN.DQN - INFO - episode 3 step 67 reward tensor([-1]) loss 1.3279047012329102 epsilon 0.767566125
26-Feb-25 09:38:53 - agent.DQN.DQN - INFO - episode 3 step 68 reward tensor([-1]) loss 10.585695266723633 epsilon 0.767566125
26-Feb-25 09:38:53 - agent.DQN.DQN - INFO - episode 3 step 69 reward tensor([-1]) loss 68.30131530761719 epsilon 0.767566125
26-Feb-25 09:38:53 - agent.DQN.DQN - INFO - episode 3 step 70 reward tensor([-1]) loss 1.2946124076843262 epsilon 0.767566125
26-Feb-25 09:38:53 - agent.DQN.DQN - INFO - episode 3 step 71 reward tensor([-1]) loss 0.9612054228782654 epsilon 0.767566125
26-Feb-25 09:38:53 - agent.DQN.DQN - INFO - episode 3 step 72 reward tensor([-1]) loss 68.31532287597656 epsilon 0.767566125
26-Feb-25 09:38:53 - agent.DQN.DQN - INFO - episode 3 step 73 reward tensor([-1]) loss 13.302711486816406 epsilon 0.767566125
26-Feb-25 09:38:53 - agent.DQN.DQN - INFO - episode 3 step 74 reward tensor([-1]) loss 13.077166557312012 epsilon 0.767566125
26-Feb-25 09:38:53 - agent.DQN.DQN - INFO - episode 3 step 75 reward tensor([-1]) loss 3.853296995162964 epsilon 0.767566125
26-Feb-25 09:38:53 - agent.DQN.DQN - INFO - episode 3 step 76 reward tensor([-1]) loss 11.551868438720703 epsilon 0.767566125
26-Feb-25 09:38:53 - agent.DQN.DQN - INFO - episode 3 step 77 reward tensor([-1]) loss 10.577192306518555 epsilon 0.767566125
26-Feb-25 09:38:53 - agent.DQN.DQN - INFO - episode 3 step 78 reward tensor([-1]) loss 76.56039428710938 epsilon 0.767566125
26-Feb-25 09:38:54 - agent.DQN.DQN - INFO - episode 3 step 79 reward tensor([-1]) loss 2.18454909324646 epsilon 0.767566125
26-Feb-25 09:38:54 - agent.DQN.DQN - INFO - episode 3 step 80 reward tensor([-1]) loss 75.57453918457031 epsilon 0.767566125
26-Feb-25 09:38:54 - agent.DQN.DQN - INFO - episode 3 step 81 reward tensor([-1]) loss 68.93173217773438 epsilon 0.767566125
26-Feb-25 09:38:54 - agent.DQN.DQN - INFO - episode 3 step 82 reward tensor([-1]) loss 2.1414761543273926 epsilon 0.767566125
26-Feb-25 09:38:54 - agent.DQN.DQN - INFO - episode 3 step 83 reward tensor([-1]) loss 69.11212158203125 epsilon 0.767566125
26-Feb-25 09:38:54 - agent.DQN.DQN - INFO - episode 3 step 84 reward tensor([-1]) loss 1.8957464694976807 epsilon 0.767566125
26-Feb-25 09:38:54 - agent.DQN.DQN - INFO - episode 3 step 85 reward tensor([-1]) loss 68.79169464111328 epsilon 0.767566125
26-Feb-25 09:38:54 - agent.DQN.DQN - INFO - episode 3 step 86 reward tensor([-1]) loss 68.22168731689453 epsilon 0.767566125
26-Feb-25 09:38:54 - agent.DQN.DQN - INFO - episode 3 step 87 reward tensor([-1]) loss 2.9896864891052246 epsilon 0.767566125
26-Feb-25 09:38:54 - agent.DQN.DQN - INFO - episode 3 step 88 reward tensor([-1]) loss 8.044337272644043 epsilon 0.767566125
26-Feb-25 09:38:54 - agent.DQN.DQN - INFO - episode 3 step 89 reward tensor([-1]) loss 2.203618288040161 epsilon 0.767566125
26-Feb-25 09:38:54 - agent.DQN.DQN - INFO - episode 3 step 90 reward tensor([-1]) loss 2.127884864807129 epsilon 0.767566125
26-Feb-25 09:38:54 - agent.DQN.DQN - INFO - episode 3 step 91 reward tensor([-1]) loss 2.5930962562561035 epsilon 0.767566125
26-Feb-25 09:38:54 - agent.DQN.DQN - INFO - episode 3 step 92 reward tensor([-1]) loss 74.99529266357422 epsilon 0.767566125
26-Feb-25 09:38:54 - agent.DQN.DQN - INFO - episode 3 step 93 reward tensor([-1]) loss 9.281060218811035 epsilon 0.767566125
26-Feb-25 09:38:54 - agent.DQN.DQN - INFO - episode 3 step 94 reward tensor([-1]) loss 1.6693464517593384 epsilon 0.767566125
26-Feb-25 09:38:54 - agent.DQN.DQN - INFO - episode 3 step 95 reward tensor([-1]) loss 75.1435775756836 epsilon 0.767566125
26-Feb-25 09:38:54 - agent.DQN.DQN - INFO - episode 3 step 96 reward tensor([-1]) loss 1.3122332096099854 epsilon 0.767566125
26-Feb-25 09:38:54 - agent.DQN.DQN - INFO - episode 3 step 97 reward tensor([-1]) loss 8.81714153289795 epsilon 0.767566125
26-Feb-25 09:38:54 - agent.DQN.DQN - INFO - episode 3 step 98 reward tensor([-1]) loss 0.9987816214561462 epsilon 0.767566125
26-Feb-25 09:38:54 - agent.DQN.DQN - INFO - episode 3 step 99 reward tensor([-1]) loss 66.17235565185547 epsilon 0.767566125
26-Feb-25 09:38:54 - agent.DQN.DQN - INFO - episode 3 step 100 reward tensor([-1]) loss 65.94032287597656 epsilon 0.767566125
26-Feb-25 09:38:54 - agent.DQN.DQN - INFO - episode 3 step 101 reward tensor([-1]) loss 1.0277762413024902 epsilon 0.767566125
26-Feb-25 09:38:54 - agent.DQN.DQN - INFO - episode 3 step 102 reward tensor([-1]) loss 1.2309503555297852 epsilon 0.767566125
26-Feb-25 09:38:54 - agent.DQN.DQN - INFO - episode 3 step 103 reward tensor([-1]) loss 10.462376594543457 epsilon 0.767566125
26-Feb-25 09:38:54 - agent.DQN.DQN - INFO - episode 3 step 104 reward tensor([-1]) loss 67.35722351074219 epsilon 0.767566125
26-Feb-25 09:38:54 - agent.DQN.DQN - INFO - episode 3 step 105 reward tensor([-1]) loss 2.684019088745117 epsilon 0.767566125
26-Feb-25 09:38:54 - agent.DQN.DQN - INFO - episode 3 step 106 reward tensor([-1]) loss 66.66678619384766 epsilon 0.767566125
26-Feb-25 09:38:54 - agent.DQN.DQN - INFO - episode 3 step 107 reward tensor([-1]) loss 66.95932006835938 epsilon 0.767566125
26-Feb-25 09:38:54 - agent.DQN.DQN - INFO - episode 3 step 108 reward tensor([-1]) loss 8.992254257202148 epsilon 0.767566125
26-Feb-25 09:38:54 - agent.DQN.DQN - INFO - episode 3 step 109 reward tensor([-1]) loss 8.617807388305664 epsilon 0.767566125
26-Feb-25 09:38:54 - agent.DQN.DQN - INFO - episode 3 step 110 reward tensor([-1]) loss 72.53472900390625 epsilon 0.767566125
26-Feb-25 09:38:54 - agent.DQN.DQN - INFO - episode 3 step 111 reward tensor([-1]) loss 65.86444854736328 epsilon 0.767566125
26-Feb-25 09:38:54 - agent.DQN.DQN - INFO - episode 3 step 112 reward tensor([-1]) loss 65.23026275634766 epsilon 0.767566125
26-Feb-25 09:38:54 - agent.DQN.DQN - INFO - episode 3 step 113 reward tensor([-1]) loss 6.523327827453613 epsilon 0.767566125
26-Feb-25 09:38:54 - agent.DQN.DQN - INFO - episode 3 step 114 reward tensor([-1]) loss 2.616086483001709 epsilon 0.767566125
26-Feb-25 09:38:54 - agent.DQN.DQN - INFO - episode 3 step 115 reward tensor([-1]) loss 2.171689987182617 epsilon 0.767566125
26-Feb-25 09:38:54 - agent.DQN.DQN - INFO - episode 3 step 116 reward tensor([-1]) loss 2.032470226287842 epsilon 0.767566125
26-Feb-25 09:38:54 - agent.DQN.DQN - INFO - episode 3 step 117 reward tensor([-1]) loss 1.7796987295150757 epsilon 0.767566125
26-Feb-25 09:38:54 - agent.DQN.DQN - INFO - episode 3 step 118 reward tensor([-1]) loss 2.0749850273132324 epsilon 0.767566125
26-Feb-25 09:38:54 - agent.DQN.DQN - INFO - episode 3 step 119 reward tensor([-1]) loss 1.16154146194458 epsilon 0.767566125
26-Feb-25 09:38:54 - agent.DQN.DQN - INFO - episode 3 step 120 reward tensor([-1]) loss 1.1886200904846191 epsilon 0.767566125
26-Feb-25 09:38:54 - agent.DQN.DQN - INFO - episode 3 step 121 reward tensor([-1]) loss 0.9123961925506592 epsilon 0.767566125
26-Feb-25 09:38:54 - agent.DQN.DQN - INFO - episode 3 step 122 reward tensor([-1]) loss 12.599875450134277 epsilon 0.767566125
26-Feb-25 09:38:54 - agent.DQN.DQN - INFO - episode 3 step 123 reward tensor([-1]) loss 3.3323373794555664 epsilon 0.767566125
26-Feb-25 09:38:54 - agent.DQN.DQN - INFO - episode 3 step 124 reward tensor([-1]) loss 3.233416795730591 epsilon 0.767566125
26-Feb-25 09:38:54 - agent.DQN.DQN - INFO - episode 3 step 125 reward tensor([-1]) loss 63.8902702331543 epsilon 0.767566125
26-Feb-25 09:38:54 - agent.DQN.DQN - INFO - episode 3 step 126 reward tensor([-1]) loss 70.8285140991211 epsilon 0.767566125
26-Feb-25 09:38:54 - agent.DQN.DQN - INFO - episode 3 step 127 reward tensor([-1]) loss 2.574864625930786 epsilon 0.767566125
26-Feb-25 09:38:54 - agent.DQN.DQN - INFO - episode 3 step 128 reward tensor([-1]) loss 68.94769287109375 epsilon 0.767566125
26-Feb-25 09:38:54 - agent.DQN.DQN - INFO - episode 3 step 129 reward tensor([-1]) loss 71.6241455078125 epsilon 0.767566125
26-Feb-25 09:38:54 - agent.DQN.DQN - INFO - episode 3 step 130 reward tensor([-1]) loss 5.43715763092041 epsilon 0.767566125
26-Feb-25 09:38:54 - agent.DQN.DQN - INFO - episode 3 step 131 reward tensor([-1]) loss 7.743516445159912 epsilon 0.767566125
26-Feb-25 09:38:54 - agent.DQN.DQN - INFO - episode 3 step 132 reward tensor([-1]) loss 64.2706527709961 epsilon 0.767566125
26-Feb-25 09:38:54 - agent.DQN.DQN - INFO - episode 3 step 133 reward tensor([-1]) loss 65.49302673339844 epsilon 0.767566125
26-Feb-25 09:38:54 - agent.DQN.DQN - INFO - episode 3 step 134 reward tensor([-1]) loss 3.602959394454956 epsilon 0.767566125
26-Feb-25 09:38:54 - agent.DQN.DQN - INFO - episode 3 step 135 reward tensor([-1]) loss 3.002594470977783 epsilon 0.767566125
26-Feb-25 09:38:54 - agent.DQN.DQN - INFO - episode 3 step 136 reward tensor([-1]) loss 8.981633186340332 epsilon 0.767566125
26-Feb-25 09:38:54 - agent.DQN.DQN - INFO - episode 3 step 137 reward tensor([-1]) loss 4.162732124328613 epsilon 0.767566125
26-Feb-25 09:38:54 - agent.DQN.DQN - INFO - episode 3 step 138 reward tensor([-1]) loss 64.87716674804688 epsilon 0.767566125
26-Feb-25 09:38:54 - agent.DQN.DQN - INFO - episode 3 step 139 reward tensor([-1]) loss 7.573160648345947 epsilon 0.767566125
26-Feb-25 09:38:54 - agent.DQN.DQN - INFO - episode 3 step 140 reward tensor([-1]) loss 69.64808654785156 epsilon 0.767566125
26-Feb-25 09:38:54 - agent.DQN.DQN - INFO - episode 3 step 141 reward tensor([-1]) loss 63.42045593261719 epsilon 0.767566125
26-Feb-25 09:38:54 - agent.DQN.DQN - INFO - episode 3 step 142 reward tensor([-1]) loss 68.05007934570312 epsilon 0.767566125
26-Feb-25 09:38:54 - agent.DQN.DQN - INFO - episode 3 step 143 reward tensor([-1]) loss 1.67014479637146 epsilon 0.767566125
26-Feb-25 09:38:54 - agent.DQN.DQN - INFO - episode 3 step 144 reward tensor([-1]) loss 64.36514282226562 epsilon 0.767566125
26-Feb-25 09:38:54 - agent.DQN.DQN - INFO - episode 3 step 145 reward tensor([-1]) loss 62.97996139526367 epsilon 0.767566125
26-Feb-25 09:38:54 - agent.DQN.DQN - INFO - episode 3 step 146 reward tensor([-1]) loss 2.3447139263153076 epsilon 0.767566125
26-Feb-25 09:38:54 - agent.DQN.DQN - INFO - episode 3 step 147 reward tensor([-1]) loss 1.12120521068573 epsilon 0.767566125
26-Feb-25 09:38:54 - agent.DQN.DQN - INFO - episode 3 step 148 reward tensor([-1]) loss 6.0089521408081055 epsilon 0.767566125
26-Feb-25 09:38:54 - agent.DQN.DQN - INFO - episode 3 step 149 reward tensor([-1]) loss 5.806197643280029 epsilon 0.767566125
26-Feb-25 09:38:54 - agent.DQN.DQN - INFO - episode 3 step 150 reward tensor([-1]) loss 62.6982307434082 epsilon 0.767566125
26-Feb-25 09:38:54 - agent.DQN.DQN - INFO - episode 3 step 151 reward tensor([-1]) loss 1.6497286558151245 epsilon 0.767566125
26-Feb-25 09:38:54 - agent.DQN.DQN - INFO - episode 3 step 152 reward tensor([-1]) loss 1.7448973655700684 epsilon 0.767566125
26-Feb-25 09:38:54 - agent.DQN.DQN - INFO - episode 3 step 153 reward tensor([-1]) loss 65.89991760253906 epsilon 0.767566125
26-Feb-25 09:38:54 - agent.DQN.DQN - INFO - episode 3 step 154 reward tensor([-1]) loss 62.81206130981445 epsilon 0.767566125
26-Feb-25 09:38:54 - agent.DQN.DQN - INFO - episode 3 step 155 reward tensor([-1]) loss 62.199241638183594 epsilon 0.767566125
26-Feb-25 09:38:54 - agent.DQN.DQN - INFO - episode 3 step 156 reward tensor([-1]) loss 6.056701183319092 epsilon 0.767566125
26-Feb-25 09:38:54 - agent.DQN.DQN - INFO - episode 3 step 157 reward tensor([-1]) loss 5.995034217834473 epsilon 0.767566125
26-Feb-25 09:38:55 - agent.DQN.DQN - INFO - episode 3 step 158 reward tensor([-1]) loss 62.5149040222168 epsilon 0.767566125
26-Feb-25 09:38:55 - agent.DQN.DQN - INFO - episode 3 step 159 reward tensor([-1]) loss 5.707529067993164 epsilon 0.767566125
26-Feb-25 09:38:55 - agent.DQN.DQN - INFO - episode 3 step 160 reward tensor([-1]) loss 1.3874437808990479 epsilon 0.767566125
26-Feb-25 09:38:55 - agent.DQN.DQN - INFO - episode 3 step 161 reward tensor([-1]) loss 7.335633754730225 epsilon 0.767566125
26-Feb-25 09:38:55 - agent.DQN.DQN - INFO - episode 3 step 162 reward tensor([-1]) loss 1.5499001741409302 epsilon 0.767566125
26-Feb-25 09:38:55 - agent.DQN.DQN - INFO - episode 3 step 163 reward tensor([-1]) loss 3.061216115951538 epsilon 0.767566125
26-Feb-25 09:38:55 - agent.DQN.DQN - INFO - episode 3 step 164 reward tensor([-1]) loss 7.038957118988037 epsilon 0.767566125
26-Feb-25 09:38:55 - agent.DQN.DQN - INFO - episode 3 step 165 reward tensor([-1]) loss 63.04894256591797 epsilon 0.767566125
26-Feb-25 09:38:55 - agent.DQN.DQN - INFO - episode 3 step 166 reward tensor([-1]) loss 2.825542449951172 epsilon 0.767566125
26-Feb-25 09:38:55 - agent.DQN.DQN - INFO - episode 3 step 167 reward tensor([-1]) loss 66.32797241210938 epsilon 0.767566125
26-Feb-25 09:38:55 - agent.DQN.DQN - INFO - episode 3 step 168 reward tensor([-1]) loss 62.79739761352539 epsilon 0.767566125
26-Feb-25 09:38:55 - agent.DQN.DQN - INFO - episode 3 step 169 reward tensor([-1]) loss 1.6542471647262573 epsilon 0.767566125
26-Feb-25 09:38:55 - agent.DQN.DQN - INFO - episode 3 step 170 reward tensor([-1]) loss 7.303821086883545 epsilon 0.767566125
26-Feb-25 09:38:55 - agent.DQN.DQN - INFO - episode 3 step 171 reward tensor([-1]) loss 66.02281951904297 epsilon 0.767566125
26-Feb-25 09:38:55 - agent.DQN.DQN - INFO - episode 3 step 172 reward tensor([-1]) loss 2.458501100540161 epsilon 0.767566125
26-Feb-25 09:38:55 - agent.DQN.DQN - INFO - episode 3 step 173 reward tensor([-1]) loss 1.0621037483215332 epsilon 0.767566125
26-Feb-25 09:38:55 - agent.DQN.DQN - INFO - episode 3 step 174 reward tensor([-1]) loss 1.718364953994751 epsilon 0.767566125
26-Feb-25 09:38:55 - agent.DQN.DQN - INFO - episode 3 step 175 reward tensor([-1]) loss 61.03985595703125 epsilon 0.767566125
26-Feb-25 09:38:55 - agent.DQN.DQN - INFO - episode 3 step 176 reward tensor([-1]) loss 62.0919189453125 epsilon 0.767566125
26-Feb-25 09:38:55 - agent.DQN.DQN - INFO - episode 3 step 177 reward tensor([-1]) loss 1.8356220722198486 epsilon 0.767566125
26-Feb-25 09:38:55 - agent.DQN.DQN - INFO - episode 3 step 178 reward tensor([-1]) loss 1.9592947959899902 epsilon 0.767566125
26-Feb-25 09:38:55 - agent.DQN.DQN - INFO - episode 3 step 179 reward tensor([-1]) loss 1.0130687952041626 epsilon 0.767566125
26-Feb-25 09:38:55 - agent.DQN.DQN - INFO - episode 3 step 180 reward tensor([-1]) loss 2.0676658153533936 epsilon 0.767566125
26-Feb-25 09:38:55 - agent.DQN.DQN - INFO - episode 3 step 181 reward tensor([-1]) loss 2.0446157455444336 epsilon 0.767566125
26-Feb-25 09:38:55 - agent.DQN.DQN - INFO - episode 3 step 182 reward tensor([-1]) loss 2.0505568981170654 epsilon 0.767566125
26-Feb-25 09:38:55 - agent.DQN.DQN - INFO - episode 3 step 183 reward tensor([-1]) loss 5.164676189422607 epsilon 0.767566125
26-Feb-25 09:38:55 - agent.DQN.DQN - INFO - episode 3 step 184 reward tensor([-1]) loss 2.7905728816986084 epsilon 0.767566125
26-Feb-25 09:38:55 - agent.DQN.DQN - INFO - episode 3 step 185 reward tensor([-1]) loss 5.69097900390625 epsilon 0.767566125
26-Feb-25 09:38:55 - agent.DQN.DQN - INFO - episode 3 step 186 reward tensor([-1]) loss 2.4805593490600586 epsilon 0.767566125
26-Feb-25 09:38:55 - agent.DQN.DQN - INFO - episode 3 step 187 reward tensor([-1]) loss 1.895449161529541 epsilon 0.767566125
26-Feb-25 09:38:55 - agent.DQN.DQN - INFO - episode 3 step 188 reward tensor([-1]) loss 2.687077522277832 epsilon 0.767566125
26-Feb-25 09:38:55 - agent.DQN.DQN - INFO - episode 3 step 189 reward tensor([-1]) loss 1.8899524211883545 epsilon 0.767566125
26-Feb-25 09:38:55 - agent.DQN.DQN - INFO - episode 3 step 190 reward tensor([-1]) loss 1.8784162998199463 epsilon 0.767566125
26-Feb-25 09:38:55 - agent.DQN.DQN - INFO - episode 3 step 191 reward tensor([-1]) loss 3.369408369064331 epsilon 0.767566125
26-Feb-25 09:38:55 - agent.DQN.DQN - INFO - episode 3 step 192 reward tensor([-1]) loss 3.015929698944092 epsilon 0.767566125
26-Feb-25 09:38:55 - agent.DQN.DQN - INFO - episode 3 step 193 reward tensor([-1]) loss 3.5393972396850586 epsilon 0.767566125
26-Feb-25 09:38:55 - agent.DQN.DQN - INFO - episode 3 step 194 reward tensor([-1]) loss 3.0722925662994385 epsilon 0.767566125
26-Feb-25 09:38:55 - agent.DQN.DQN - INFO - episode 3 step 195 reward tensor([-1]) loss 8.092144012451172 epsilon 0.767566125
26-Feb-25 09:38:55 - agent.DQN.DQN - INFO - episode 3 step 196 reward tensor([-1]) loss 3.1979939937591553 epsilon 0.767566125
26-Feb-25 09:38:55 - agent.DQN.DQN - INFO - episode 3 step 197 reward tensor([-1]) loss 2.734417200088501 epsilon 0.767566125
26-Feb-25 09:38:55 - agent.DQN.DQN - INFO - episode 3 step 198 reward tensor([-1]) loss 2.8939924240112305 epsilon 0.767566125
26-Feb-25 09:38:55 - agent.DQN.DQN - INFO - episode 3 step 199 reward tensor([-1]) loss 3.3411383628845215 epsilon 0.767566125
26-Feb-25 09:38:55 - agent.DQN.DQN - INFO - episode 3 step 200 reward tensor([-1]) loss 3.2264626026153564 epsilon 0.767566125
26-Feb-25 09:38:55 - agent.DQN.DQN - INFO - episode 3 step 201 reward tensor([-1]) loss 2.8537440299987793 epsilon 0.767566125
26-Feb-25 09:38:55 - agent.DQN.DQN - INFO - episode 3 step 202 reward tensor([-1]) loss 2.955740451812744 epsilon 0.767566125
26-Feb-25 09:38:55 - agent.DQN.DQN - INFO - episode 3 step 203 reward tensor([-1]) loss 4.211332321166992 epsilon 0.767566125
26-Feb-25 09:38:55 - agent.DQN.DQN - INFO - episode 3 step 204 reward tensor([-1]) loss 4.84526252746582 epsilon 0.767566125
26-Feb-25 09:38:55 - agent.DQN.DQN - INFO - episode 3 step 205 reward tensor([-1]) loss 64.28762817382812 epsilon 0.767566125
26-Feb-25 09:38:55 - agent.DQN.DQN - INFO - episode 3 step 206 reward tensor([-1]) loss 1.8460919857025146 epsilon 0.767566125
26-Feb-25 09:38:55 - agent.DQN.DQN - INFO - episode 3 step 207 reward tensor([-1]) loss 2.7576279640197754 epsilon 0.767566125
26-Feb-25 09:38:55 - agent.DQN.DQN - INFO - episode 3 step 208 reward tensor([-1]) loss 4.862968921661377 epsilon 0.767566125
26-Feb-25 09:38:55 - agent.DQN.DQN - INFO - episode 3 step 209 reward tensor([-1]) loss 1.6354087591171265 epsilon 0.767566125
26-Feb-25 09:38:55 - agent.DQN.DQN - INFO - episode 3 step 210 reward tensor([-1]) loss 2.4602839946746826 epsilon 0.767566125
26-Feb-25 09:38:55 - agent.DQN.DQN - INFO - episode 3 step 211 reward tensor([-1]) loss 63.149959564208984 epsilon 0.767566125
26-Feb-25 09:38:55 - agent.DQN.DQN - INFO - episode 3 step 212 reward tensor([-1]) loss 1.6337844133377075 epsilon 0.767566125
26-Feb-25 09:38:55 - agent.DQN.DQN - INFO - episode 3 step 213 reward tensor([-1]) loss 3.0734715461730957 epsilon 0.767566125
26-Feb-25 09:38:55 - agent.DQN.DQN - INFO - episode 3 step 214 reward tensor([-1]) loss 3.81296968460083 epsilon 0.767566125
26-Feb-25 09:38:55 - agent.DQN.DQN - INFO - episode 3 step 215 reward tensor([-1]) loss 4.910219192504883 epsilon 0.767566125
26-Feb-25 09:38:55 - agent.DQN.DQN - INFO - episode 3 step 216 reward tensor([-1]) loss 2.6132571697235107 epsilon 0.767566125
26-Feb-25 09:38:55 - agent.DQN.DQN - INFO - episode 3 step 217 reward tensor([-1]) loss 3.1846275329589844 epsilon 0.767566125
26-Feb-25 09:38:55 - agent.DQN.DQN - INFO - episode 3 step 218 reward tensor([-1]) loss 4.268256187438965 epsilon 0.767566125
26-Feb-25 09:38:55 - agent.DQN.DQN - INFO - episode 3 step 219 reward tensor([-1]) loss 2.702228307723999 epsilon 0.767566125
26-Feb-25 09:38:55 - agent.DQN.DQN - INFO - episode 3 step 220 reward tensor([-1]) loss 60.5952262878418 epsilon 0.767566125
26-Feb-25 09:38:55 - agent.DQN.DQN - INFO - episode 3 step 221 reward tensor([-1]) loss 3.4976632595062256 epsilon 0.767566125
26-Feb-25 09:38:55 - agent.DQN.DQN - INFO - episode 3 step 222 reward tensor([-1]) loss 63.989234924316406 epsilon 0.767566125
26-Feb-25 09:38:55 - agent.DQN.DQN - INFO - episode 3 step 223 reward tensor([-1]) loss 63.53151321411133 epsilon 0.767566125
26-Feb-25 09:38:55 - agent.DQN.DQN - INFO - episode 3 step 224 reward tensor([-1]) loss 3.787905693054199 epsilon 0.767566125
26-Feb-25 09:38:55 - agent.DQN.DQN - INFO - episode 3 step 225 reward tensor([-1]) loss 5.746819972991943 epsilon 0.767566125
26-Feb-25 09:38:55 - agent.DQN.DQN - INFO - episode 3 step 226 reward tensor([-1]) loss 2.520051956176758 epsilon 0.767566125
26-Feb-25 09:38:55 - agent.DQN.DQN - INFO - episode 3 step 227 reward tensor([-1]) loss 2.6612963676452637 epsilon 0.767566125
26-Feb-25 09:38:55 - agent.DQN.DQN - INFO - episode 3 step 228 reward tensor([-1]) loss 1.8365063667297363 epsilon 0.767566125
26-Feb-25 09:38:55 - agent.DQN.DQN - INFO - episode 3 step 229 reward tensor([-1]) loss 59.77715301513672 epsilon 0.767566125
26-Feb-25 09:38:55 - agent.DQN.DQN - INFO - episode 3 step 230 reward tensor([-1]) loss 1.9662635326385498 epsilon 0.767566125
26-Feb-25 09:38:55 - agent.DQN.DQN - INFO - episode 3 step 231 reward tensor([-1]) loss 59.88951873779297 epsilon 0.767566125
26-Feb-25 09:38:55 - agent.DQN.DQN - INFO - episode 3 step 232 reward tensor([-1]) loss 1.7748990058898926 epsilon 0.767566125
26-Feb-25 09:38:55 - agent.DQN.DQN - INFO - episode 3 step 233 reward tensor([-1]) loss 59.920597076416016 epsilon 0.767566125
26-Feb-25 09:38:55 - agent.DQN.DQN - INFO - episode 3 step 234 reward tensor([-1]) loss 2.043114423751831 epsilon 0.767566125
26-Feb-25 09:38:55 - agent.DQN.DQN - INFO - episode 3 step 235 reward tensor([-1]) loss 1.7347253561019897 epsilon 0.767566125
26-Feb-25 09:38:55 - agent.DQN.DQN - INFO - episode 3 step 236 reward tensor([-1]) loss 1.6544783115386963 epsilon 0.767566125
26-Feb-25 09:38:56 - agent.DQN.DQN - INFO - episode 3 step 237 reward tensor([-1]) loss 1.175659418106079 epsilon 0.767566125
26-Feb-25 09:38:56 - agent.DQN.DQN - INFO - episode 3 step 238 reward tensor([-1]) loss 1.985792636871338 epsilon 0.767566125
26-Feb-25 09:38:56 - agent.DQN.DQN - INFO - episode 3 step 239 reward tensor([-1]) loss 60.618534088134766 epsilon 0.767566125
26-Feb-25 09:38:56 - agent.DQN.DQN - INFO - episode 3 step 240 reward tensor([-1]) loss 1.1455413103103638 epsilon 0.767566125
26-Feb-25 09:38:56 - agent.DQN.DQN - INFO - episode 3 step 241 reward tensor([-1]) loss 60.1872673034668 epsilon 0.767566125
26-Feb-25 09:38:56 - agent.DQN.DQN - INFO - episode 3 step 242 reward tensor([-1]) loss 1.475409984588623 epsilon 0.767566125
26-Feb-25 09:38:56 - agent.DQN.DQN - INFO - episode 3 step 243 reward tensor([-1]) loss 3.367358684539795 epsilon 0.767566125
26-Feb-25 09:38:56 - agent.DQN.DQN - INFO - episode 3 step 244 reward tensor([-1]) loss 58.37449645996094 epsilon 0.767566125
26-Feb-25 09:38:56 - agent.DQN.DQN - INFO - episode 3 step 245 reward tensor([-1]) loss 61.25583267211914 epsilon 0.767566125
26-Feb-25 09:38:56 - agent.DQN.DQN - INFO - episode 3 step 246 reward tensor([-1]) loss 1.6944091320037842 epsilon 0.767566125
26-Feb-25 09:38:56 - agent.DQN.DQN - INFO - episode 3 step 247 reward tensor([-1]) loss 2.5911736488342285 epsilon 0.767566125
26-Feb-25 09:38:56 - agent.DQN.DQN - INFO - episode 3 step 248 reward tensor([-1]) loss 2.554046392440796 epsilon 0.767566125
26-Feb-25 09:38:56 - agent.DQN.DQN - INFO - episode 3 step 249 reward tensor([-1]) loss 58.28956604003906 epsilon 0.767566125
26-Feb-25 09:38:56 - agent.DQN.DQN - INFO - episode 3 step 250 reward tensor([-1]) loss 2.4089958667755127 epsilon 0.767566125
26-Feb-25 09:38:56 - agent.DQN.DQN - INFO - episode 3 step 251 reward tensor([-1]) loss 1.6137901544570923 epsilon 0.767566125
26-Feb-25 09:38:56 - agent.DQN.DQN - INFO - episode 3 step 252 reward tensor([-1]) loss 1.3636493682861328 epsilon 0.767566125
26-Feb-25 09:38:56 - agent.DQN.DQN - INFO - episode 3 step 253 reward tensor([-1]) loss 6.2780375480651855 epsilon 0.767566125
26-Feb-25 09:38:56 - agent.DQN.DQN - INFO - episode 3 step 254 reward tensor([-1]) loss 3.456458806991577 epsilon 0.767566125
26-Feb-25 09:38:56 - agent.DQN.DQN - INFO - episode 3 step 255 reward tensor([-1]) loss 4.546409606933594 epsilon 0.767566125
26-Feb-25 09:38:56 - agent.DQN.DQN - INFO - episode 3 step 256 reward tensor([-1]) loss 3.2815144062042236 epsilon 0.767566125
26-Feb-25 09:38:56 - agent.DQN.DQN - INFO - episode 3 step 257 reward tensor([-1]) loss 3.750795841217041 epsilon 0.767566125
26-Feb-25 09:38:56 - agent.DQN.DQN - INFO - episode 3 step 258 reward tensor([-1]) loss 58.91194152832031 epsilon 0.767566125
26-Feb-25 09:38:56 - agent.DQN.DQN - INFO - episode 3 step 259 reward tensor([-1]) loss 1.7909226417541504 epsilon 0.767566125
26-Feb-25 09:38:56 - agent.DQN.DQN - INFO - episode 3 step 260 reward tensor([-1]) loss 58.71335220336914 epsilon 0.767566125
26-Feb-25 09:38:56 - agent.DQN.DQN - INFO - episode 3 step 261 reward tensor([-1]) loss 1.3839763402938843 epsilon 0.767566125
26-Feb-25 09:38:56 - agent.DQN.DQN - INFO - episode 3 step 262 reward tensor([-1]) loss 4.425583362579346 epsilon 0.767566125
26-Feb-25 09:38:56 - agent.DQN.DQN - INFO - episode 3 step 263 reward tensor([-1]) loss 2.7532601356506348 epsilon 0.767566125
26-Feb-25 09:38:56 - agent.DQN.DQN - INFO - episode 3 step 264 reward tensor([-1]) loss 2.4171175956726074 epsilon 0.767566125
26-Feb-25 09:38:56 - agent.DQN.DQN - INFO - episode 3 step 265 reward tensor([-1]) loss 58.26530838012695 epsilon 0.767566125
26-Feb-25 09:38:56 - agent.DQN.DQN - INFO - episode 3 step 266 reward tensor([-1]) loss 1.7857990264892578 epsilon 0.767566125
26-Feb-25 09:38:56 - agent.DQN.DQN - INFO - episode 3 step 267 reward tensor([-1]) loss 3.8333115577697754 epsilon 0.767566125
26-Feb-25 09:38:56 - agent.DQN.DQN - INFO - episode 3 step 268 reward tensor([-1]) loss 1.8837974071502686 epsilon 0.767566125
26-Feb-25 09:38:56 - agent.DQN.DQN - INFO - episode 3 step 269 reward tensor([-1]) loss 4.550387382507324 epsilon 0.767566125
26-Feb-25 09:38:56 - agent.DQN.DQN - INFO - episode 3 step 270 reward tensor([-1]) loss 1.6604909896850586 epsilon 0.767566125
26-Feb-25 09:38:56 - agent.DQN.DQN - INFO - episode 3 step 271 reward tensor([-1]) loss 1.0873850584030151 epsilon 0.767566125
26-Feb-25 09:38:56 - agent.DQN.DQN - INFO - episode 3 step 272 reward tensor([-1]) loss 1.9051610231399536 epsilon 0.767566125
26-Feb-25 09:38:56 - agent.DQN.DQN - INFO - episode 3 step 273 reward tensor([-1]) loss 1.8558952808380127 epsilon 0.767566125
26-Feb-25 09:38:56 - agent.DQN.DQN - INFO - episode 3 step 274 reward tensor([-1]) loss 3.003645420074463 epsilon 0.767566125
26-Feb-25 09:38:56 - agent.DQN.DQN - INFO - episode 3 step 275 reward tensor([-1]) loss 1.8098505735397339 epsilon 0.767566125
26-Feb-25 09:38:56 - agent.DQN.DQN - INFO - episode 3 step 276 reward tensor([-1]) loss 58.84931564331055 epsilon 0.767566125
26-Feb-25 09:38:56 - agent.DQN.DQN - INFO - episode 3 step 277 reward tensor([-1]) loss 1.0073964595794678 epsilon 0.767566125
26-Feb-25 09:38:56 - agent.DQN.DQN - INFO - episode 3 step 278 reward tensor([-1]) loss 1.9109246730804443 epsilon 0.767566125
26-Feb-25 09:38:56 - agent.DQN.DQN - INFO - episode 3 step 279 reward tensor([-1]) loss 58.42063522338867 epsilon 0.767566125
26-Feb-25 09:38:56 - agent.DQN.DQN - INFO - episode 3 step 280 reward tensor([-1]) loss 57.20747375488281 epsilon 0.767566125
26-Feb-25 09:38:56 - agent.DQN.DQN - INFO - episode 3 step 281 reward tensor([-1]) loss 2.3969812393188477 epsilon 0.767566125
26-Feb-25 09:38:56 - agent.DQN.DQN - INFO - episode 3 step 282 reward tensor([-1]) loss 0.8997008800506592 epsilon 0.767566125
26-Feb-25 09:38:56 - agent.DQN.DQN - INFO - episode 3 step 283 reward tensor([-1]) loss 62.5635986328125 epsilon 0.767566125
26-Feb-25 09:38:56 - agent.DQN.DQN - INFO - episode 3 step 284 reward tensor([-1]) loss 4.734900951385498 epsilon 0.767566125
26-Feb-25 09:38:56 - agent.DQN.DQN - INFO - episode 3 step 285 reward tensor([-1]) loss 4.197788238525391 epsilon 0.767566125
26-Feb-25 09:38:56 - agent.DQN.DQN - INFO - episode 3 step 286 reward tensor([-1]) loss 2.7964799404144287 epsilon 0.767566125
26-Feb-25 09:38:56 - agent.DQN.DQN - INFO - episode 3 step 287 reward tensor([-1]) loss 57.56913375854492 epsilon 0.767566125
26-Feb-25 09:38:56 - agent.DQN.DQN - INFO - episode 3 step 288 reward tensor([-1]) loss 1.702070713043213 epsilon 0.767566125
26-Feb-25 09:38:56 - agent.DQN.DQN - INFO - episode 3 step 289 reward tensor([-1]) loss 1.5854853391647339 epsilon 0.767566125
26-Feb-25 09:38:56 - agent.DQN.DQN - INFO - episode 3 step 290 reward tensor([-1]) loss 1.7586456537246704 epsilon 0.767566125
26-Feb-25 09:38:56 - agent.DQN.DQN - INFO - episode 3 step 291 reward tensor([-1]) loss 4.353886604309082 epsilon 0.767566125
26-Feb-25 09:38:56 - agent.DQN.DQN - INFO - episode 3 step 292 reward tensor([-1]) loss 1.129210352897644 epsilon 0.767566125
26-Feb-25 09:38:56 - agent.DQN.DQN - INFO - episode 3 step 293 reward tensor([-1]) loss 1.1523487567901611 epsilon 0.767566125
26-Feb-25 09:38:56 - agent.DQN.DQN - INFO - episode 3 step 294 reward tensor([-1]) loss 57.24567794799805 epsilon 0.767566125
26-Feb-25 09:38:56 - agent.DQN.DQN - INFO - episode 3 step 295 reward tensor([-1]) loss 1.9690897464752197 epsilon 0.767566125
26-Feb-25 09:38:56 - agent.DQN.DQN - INFO - episode 3 step 296 reward tensor([-1]) loss 4.135149002075195 epsilon 0.767566125
26-Feb-25 09:38:56 - agent.DQN.DQN - INFO - episode 3 step 297 reward tensor([-1]) loss 1.5760234594345093 epsilon 0.767566125
26-Feb-25 09:38:56 - agent.DQN.DQN - INFO - episode 3 step 298 reward tensor([-1]) loss 1.05715811252594 epsilon 0.767566125
26-Feb-25 09:38:56 - agent.DQN.DQN - INFO - episode 3 step 299 reward tensor([-1]) loss 1.743775486946106 epsilon 0.767566125
26-Feb-25 09:38:56 - agent.DQN.DQN - INFO - episode 3 step 300 reward tensor([-1]) loss 57.16166305541992 epsilon 0.767566125
26-Feb-25 09:38:56 - agent.DQN.DQN - INFO - episode 3 step 301 reward tensor([-1]) loss 13.908442497253418 epsilon 0.767566125
26-Feb-25 09:38:56 - agent.DQN.DQN - INFO - episode 4 step 0 reward tensor([-1]) loss 56.352970123291016 epsilon 0.7426202259375
26-Feb-25 09:38:56 - agent.DQN.DQN - INFO - episode 4 step 1 reward tensor([-1]) loss 3.906320810317993 epsilon 0.7426202259375
26-Feb-25 09:38:56 - agent.DQN.DQN - INFO - episode 4 step 2 reward tensor([-1]) loss 1.928257703781128 epsilon 0.7426202259375
26-Feb-25 09:38:56 - agent.DQN.DQN - INFO - episode 4 step 3 reward tensor([-1]) loss 1.501682162284851 epsilon 0.7426202259375
26-Feb-25 09:38:56 - agent.DQN.DQN - INFO - episode 4 step 4 reward tensor([-1]) loss 57.139564514160156 epsilon 0.7426202259375
26-Feb-25 09:38:56 - agent.DQN.DQN - INFO - episode 4 step 5 reward tensor([-1]) loss 3.6624794006347656 epsilon 0.7426202259375
26-Feb-25 09:38:56 - agent.DQN.DQN - INFO - episode 4 step 6 reward tensor([-1]) loss 56.438663482666016 epsilon 0.7426202259375
26-Feb-25 09:38:56 - agent.DQN.DQN - INFO - episode 4 step 7 reward tensor([-1]) loss 1.1603602170944214 epsilon 0.7426202259375
26-Feb-25 09:38:56 - agent.DQN.DQN - INFO - episode 4 step 8 reward tensor([-1]) loss 16.1299991607666 epsilon 0.7426202259375
26-Feb-25 09:38:56 - agent.DQN.DQN - INFO - episode 4 step 9 reward tensor([-1]) loss 67.94174194335938 epsilon 0.7426202259375
26-Feb-25 09:38:56 - agent.DQN.DQN - INFO - episode 4 step 10 reward tensor([-1]) loss 13.58096694946289 epsilon 0.7426202259375
26-Feb-25 09:38:56 - agent.DQN.DQN - INFO - episode 4 step 11 reward tensor([-1]) loss 7.271675109863281 epsilon 0.7426202259375
26-Feb-25 09:38:56 - agent.DQN.DQN - INFO - episode 4 step 12 reward tensor([-1]) loss 4.159764766693115 epsilon 0.7426202259375
26-Feb-25 09:38:56 - agent.DQN.DQN - INFO - episode 4 step 13 reward tensor([-1]) loss 66.52852630615234 epsilon 0.7426202259375
26-Feb-25 09:38:56 - agent.DQN.DQN - INFO - episode 4 step 14 reward tensor([-1]) loss 3.474994659423828 epsilon 0.7426202259375
26-Feb-25 09:38:56 - agent.DQN.DQN - INFO - episode 4 step 15 reward tensor([-1]) loss 10.646710395812988 epsilon 0.7426202259375
26-Feb-25 09:38:56 - agent.DQN.DQN - INFO - episode 4 step 16 reward tensor([-1]) loss 57.8256721496582 epsilon 0.7426202259375
26-Feb-25 09:38:56 - agent.DQN.DQN - INFO - episode 4 step 17 reward tensor([-1]) loss 3.6023967266082764 epsilon 0.7426202259375
26-Feb-25 09:38:56 - agent.DQN.DQN - INFO - episode 4 step 18 reward tensor([-1]) loss 57.599918365478516 epsilon 0.7426202259375
26-Feb-25 09:38:56 - agent.DQN.DQN - INFO - episode 4 step 19 reward tensor([-1]) loss 3.3274612426757812 epsilon 0.7426202259375
26-Feb-25 09:38:56 - agent.DQN.DQN - INFO - episode 4 step 20 reward tensor([-1]) loss 3.023642063140869 epsilon 0.7426202259375
26-Feb-25 09:38:56 - agent.DQN.DQN - INFO - episode 4 step 21 reward tensor([-1]) loss 2.0893235206604004 epsilon 0.7426202259375
26-Feb-25 09:38:56 - agent.DQN.DQN - INFO - episode 4 step 22 reward tensor([-1]) loss 2.771317481994629 epsilon 0.7426202259375
26-Feb-25 09:38:57 - agent.DQN.DQN - INFO - episode 4 step 23 reward tensor([-1]) loss 2.216317892074585 epsilon 0.7426202259375
26-Feb-25 09:38:57 - agent.DQN.DQN - INFO - episode 4 step 24 reward tensor([-1]) loss 11.217753410339355 epsilon 0.7426202259375
26-Feb-25 09:38:57 - agent.DQN.DQN - INFO - episode 4 step 25 reward tensor([-1]) loss 1.9490543603897095 epsilon 0.7426202259375
26-Feb-25 09:38:57 - agent.DQN.DQN - INFO - episode 4 step 26 reward tensor([-1]) loss 10.744709014892578 epsilon 0.7426202259375
26-Feb-25 09:38:57 - agent.DQN.DQN - INFO - episode 4 step 27 reward tensor([-1]) loss 55.660186767578125 epsilon 0.7426202259375
26-Feb-25 09:38:57 - agent.DQN.DQN - INFO - episode 4 step 28 reward tensor([-1]) loss 1.1426464319229126 epsilon 0.7426202259375
26-Feb-25 09:38:57 - agent.DQN.DQN - INFO - episode 4 step 29 reward tensor([-1]) loss 2.0341100692749023 epsilon 0.7426202259375
26-Feb-25 09:38:57 - agent.DQN.DQN - INFO - episode 4 step 30 reward tensor([-1]) loss 10.805944442749023 epsilon 0.7426202259375
26-Feb-25 09:38:57 - agent.DQN.DQN - INFO - episode 4 step 31 reward tensor([-1]) loss 66.51485443115234 epsilon 0.7426202259375
26-Feb-25 09:38:57 - agent.DQN.DQN - INFO - episode 4 step 32 reward tensor([-1]) loss 1.054541826248169 epsilon 0.7426202259375
26-Feb-25 09:38:57 - agent.DQN.DQN - INFO - episode 4 step 33 reward tensor([-1]) loss 2.4929614067077637 epsilon 0.7426202259375
26-Feb-25 09:38:57 - agent.DQN.DQN - INFO - episode 4 step 34 reward tensor([-1]) loss 2.6689977645874023 epsilon 0.7426202259375
26-Feb-25 09:38:57 - agent.DQN.DQN - INFO - episode 4 step 35 reward tensor([-1]) loss 9.995619773864746 epsilon 0.7426202259375
26-Feb-25 09:38:57 - agent.DQN.DQN - INFO - episode 4 step 36 reward tensor([-1]) loss 1.8766343593597412 epsilon 0.7426202259375
26-Feb-25 09:38:57 - agent.DQN.DQN - INFO - episode 4 step 37 reward tensor([-1]) loss 9.38628101348877 epsilon 0.7426202259375
26-Feb-25 09:38:57 - agent.DQN.DQN - INFO - episode 4 step 38 reward tensor([-1]) loss 10.304895401000977 epsilon 0.7426202259375
26-Feb-25 09:38:57 - agent.DQN.DQN - INFO - episode 4 step 39 reward tensor([-1]) loss 56.40961456298828 epsilon 0.7426202259375
26-Feb-25 09:38:57 - agent.DQN.DQN - INFO - episode 4 step 40 reward tensor([-1]) loss 3.728663206100464 epsilon 0.7426202259375
26-Feb-25 09:38:57 - agent.DQN.DQN - INFO - episode 4 step 41 reward tensor([-1]) loss 3.647221326828003 epsilon 0.7426202259375
26-Feb-25 09:38:57 - agent.DQN.DQN - INFO - episode 4 step 42 reward tensor([-1]) loss 3.095418691635132 epsilon 0.7426202259375
26-Feb-25 09:38:57 - agent.DQN.DQN - INFO - episode 4 step 43 reward tensor([-1]) loss 3.082223892211914 epsilon 0.7426202259375
26-Feb-25 09:38:57 - agent.DQN.DQN - INFO - episode 4 step 44 reward tensor([-1]) loss 11.086195945739746 epsilon 0.7426202259375
26-Feb-25 09:38:57 - agent.DQN.DQN - INFO - episode 4 step 45 reward tensor([-1]) loss 10.194672584533691 epsilon 0.7426202259375
26-Feb-25 09:38:57 - agent.DQN.DQN - INFO - episode 4 step 46 reward tensor([-1]) loss 3.1559360027313232 epsilon 0.7426202259375
26-Feb-25 09:38:57 - agent.DQN.DQN - INFO - episode 4 step 47 reward tensor([-1]) loss 4.158566951751709 epsilon 0.7426202259375
26-Feb-25 09:38:57 - agent.DQN.DQN - INFO - episode 4 step 48 reward tensor([-1]) loss 2.408376932144165 epsilon 0.7426202259375
26-Feb-25 09:38:57 - agent.DQN.DQN - INFO - episode 4 step 49 reward tensor([-1]) loss 65.42572021484375 epsilon 0.7426202259375
26-Feb-25 09:38:57 - agent.DQN.DQN - INFO - episode 4 step 50 reward tensor([-1]) loss 3.878481149673462 epsilon 0.7426202259375
26-Feb-25 09:38:57 - agent.DQN.DQN - INFO - episode 4 step 51 reward tensor([-1]) loss 57.64199447631836 epsilon 0.7426202259375
26-Feb-25 09:38:57 - agent.DQN.DQN - INFO - episode 4 step 52 reward tensor([-1]) loss 2.226175546646118 epsilon 0.7426202259375
26-Feb-25 09:38:57 - agent.DQN.DQN - INFO - episode 4 step 53 reward tensor([-1]) loss 3.3757882118225098 epsilon 0.7426202259375
26-Feb-25 09:38:57 - agent.DQN.DQN - INFO - episode 4 step 54 reward tensor([-1]) loss 3.194209098815918 epsilon 0.7426202259375
26-Feb-25 09:38:57 - agent.DQN.DQN - INFO - episode 4 step 55 reward tensor([-1]) loss 11.44329833984375 epsilon 0.7426202259375
26-Feb-25 09:38:57 - agent.DQN.DQN - INFO - episode 4 step 56 reward tensor([-1]) loss 5.809382438659668 epsilon 0.7426202259375
26-Feb-25 09:38:57 - agent.DQN.DQN - INFO - episode 4 step 57 reward tensor([-1]) loss 4.414004325866699 epsilon 0.7426202259375
26-Feb-25 09:38:57 - agent.DQN.DQN - INFO - episode 4 step 58 reward tensor([-1]) loss 5.748158931732178 epsilon 0.7426202259375
26-Feb-25 09:38:57 - agent.DQN.DQN - INFO - episode 4 step 59 reward tensor([-1]) loss 11.095769882202148 epsilon 0.7426202259375
26-Feb-25 09:38:57 - agent.DQN.DQN - INFO - episode 4 step 60 reward tensor([-1]) loss 5.571072101593018 epsilon 0.7426202259375
26-Feb-25 09:38:57 - agent.DQN.DQN - INFO - episode 4 step 61 reward tensor([-1]) loss 57.769187927246094 epsilon 0.7426202259375
26-Feb-25 09:38:57 - agent.DQN.DQN - INFO - episode 4 step 62 reward tensor([-1]) loss 6.493006706237793 epsilon 0.7426202259375
26-Feb-25 09:38:57 - agent.DQN.DQN - INFO - episode 4 step 63 reward tensor([-1]) loss 6.909561634063721 epsilon 0.7426202259375
26-Feb-25 09:38:57 - agent.DQN.DQN - INFO - episode 4 step 64 reward tensor([-1]) loss 8.665136337280273 epsilon 0.7426202259375
26-Feb-25 09:38:57 - agent.DQN.DQN - INFO - episode 4 step 65 reward tensor([-1]) loss 58.955650329589844 epsilon 0.7426202259375
26-Feb-25 09:38:57 - agent.DQN.DQN - INFO - episode 4 step 66 reward tensor([-1]) loss 1.5165996551513672 epsilon 0.7426202259375
26-Feb-25 09:38:57 - agent.DQN.DQN - INFO - episode 4 step 67 reward tensor([-1]) loss 4.041970252990723 epsilon 0.7426202259375
26-Feb-25 09:38:57 - agent.DQN.DQN - INFO - episode 4 step 68 reward tensor([-1]) loss 3.1480398178100586 epsilon 0.7426202259375
26-Feb-25 09:38:57 - agent.DQN.DQN - INFO - episode 4 step 69 reward tensor([-1]) loss 14.428229331970215 epsilon 0.7426202259375
26-Feb-25 09:38:57 - agent.DQN.DQN - INFO - episode 4 step 70 reward tensor([-1]) loss 15.152145385742188 epsilon 0.7426202259375
26-Feb-25 09:38:57 - agent.DQN.DQN - INFO - episode 4 step 71 reward tensor([-1]) loss 8.117570877075195 epsilon 0.7426202259375
26-Feb-25 09:38:57 - agent.DQN.DQN - INFO - episode 4 step 72 reward tensor([-1]) loss 63.66252136230469 epsilon 0.7426202259375
26-Feb-25 09:38:57 - agent.DQN.DQN - INFO - episode 4 step 73 reward tensor([-1]) loss 9.9993257522583 epsilon 0.7426202259375
26-Feb-25 09:38:57 - agent.DQN.DQN - INFO - episode 4 step 74 reward tensor([-1]) loss 4.877825736999512 epsilon 0.7426202259375
26-Feb-25 09:38:57 - agent.DQN.DQN - INFO - episode 4 step 75 reward tensor([-1]) loss 8.937928199768066 epsilon 0.7426202259375
26-Feb-25 09:38:57 - agent.DQN.DQN - INFO - episode 4 step 76 reward tensor([-1]) loss 9.89931869506836 epsilon 0.7426202259375
26-Feb-25 09:38:57 - agent.DQN.DQN - INFO - episode 4 step 77 reward tensor([-1]) loss 2.9237284660339355 epsilon 0.7426202259375
26-Feb-25 09:38:57 - agent.DQN.DQN - INFO - episode 4 step 78 reward tensor([-1]) loss 6.381289958953857 epsilon 0.7426202259375
26-Feb-25 09:38:57 - agent.DQN.DQN - INFO - episode 4 step 79 reward tensor([-1]) loss 8.36903190612793 epsilon 0.7426202259375
26-Feb-25 09:38:57 - agent.DQN.DQN - INFO - episode 4 step 80 reward tensor([-1]) loss 6.498983383178711 epsilon 0.7426202259375
26-Feb-25 09:38:57 - agent.DQN.DQN - INFO - episode 4 step 81 reward tensor([-1]) loss 13.36365032196045 epsilon 0.7426202259375
26-Feb-25 09:38:57 - agent.DQN.DQN - INFO - episode 4 step 82 reward tensor([-1]) loss 11.629470825195312 epsilon 0.7426202259375
26-Feb-25 09:38:57 - agent.DQN.DQN - INFO - episode 4 step 83 reward tensor([-1]) loss 11.301679611206055 epsilon 0.7426202259375
26-Feb-25 09:38:57 - agent.DQN.DQN - INFO - episode 4 step 84 reward tensor([-1]) loss 3.432908296585083 epsilon 0.7426202259375
26-Feb-25 09:38:57 - agent.DQN.DQN - INFO - episode 4 step 85 reward tensor([-1]) loss 7.922834396362305 epsilon 0.7426202259375
26-Feb-25 09:38:57 - agent.DQN.DQN - INFO - episode 4 step 86 reward tensor([-1]) loss 63.23793411254883 epsilon 0.7426202259375
26-Feb-25 09:38:57 - agent.DQN.DQN - INFO - episode 4 step 87 reward tensor([-1]) loss 14.468944549560547 epsilon 0.7426202259375
26-Feb-25 09:38:57 - agent.DQN.DQN - INFO - episode 4 step 88 reward tensor([-1]) loss 9.542962074279785 epsilon 0.7426202259375
26-Feb-25 09:38:57 - agent.DQN.DQN - INFO - episode 4 step 89 reward tensor([-1]) loss 62.27827453613281 epsilon 0.7426202259375
26-Feb-25 09:38:57 - agent.DQN.DQN - INFO - episode 4 step 90 reward tensor([-1]) loss 9.922520637512207 epsilon 0.7426202259375
26-Feb-25 09:38:57 - agent.DQN.DQN - INFO - episode 4 step 91 reward tensor([-1]) loss 10.181585311889648 epsilon 0.7426202259375
26-Feb-25 09:38:57 - agent.DQN.DQN - INFO - episode 4 step 92 reward tensor([-1]) loss 4.503839492797852 epsilon 0.7426202259375
26-Feb-25 09:38:57 - agent.DQN.DQN - INFO - episode 4 step 93 reward tensor([-1]) loss 8.000101089477539 epsilon 0.7426202259375
26-Feb-25 09:38:57 - agent.DQN.DQN - INFO - episode 4 step 94 reward tensor([-1]) loss 5.5355143547058105 epsilon 0.7426202259375
26-Feb-25 09:38:57 - agent.DQN.DQN - INFO - episode 4 step 95 reward tensor([-1]) loss 7.677326679229736 epsilon 0.7426202259375
26-Feb-25 09:38:57 - agent.DQN.DQN - INFO - episode 4 step 96 reward tensor([-1]) loss 3.1551663875579834 epsilon 0.7426202259375
26-Feb-25 09:38:57 - agent.DQN.DQN - INFO - episode 4 step 97 reward tensor([-1]) loss 6.4991254806518555 epsilon 0.7426202259375
26-Feb-25 09:38:57 - agent.DQN.DQN - INFO - episode 4 step 98 reward tensor([-1]) loss 59.30614471435547 epsilon 0.7426202259375
26-Feb-25 09:38:57 - agent.DQN.DQN - INFO - episode 4 step 99 reward tensor([-1]) loss 6.7864813804626465 epsilon 0.7426202259375
26-Feb-25 09:38:57 - agent.DQN.DQN - INFO - episode 4 step 100 reward tensor([-1]) loss 12.620294570922852 epsilon 0.7426202259375
26-Feb-25 09:38:57 - agent.DQN.DQN - INFO - episode 4 step 101 reward tensor([-1]) loss 14.068056106567383 epsilon 0.7426202259375
26-Feb-25 09:38:57 - agent.DQN.DQN - INFO - episode 4 step 102 reward tensor([-1]) loss 8.937828063964844 epsilon 0.7426202259375
26-Feb-25 09:38:57 - agent.DQN.DQN - INFO - episode 4 step 103 reward tensor([-1]) loss 9.657444953918457 epsilon 0.7426202259375
26-Feb-25 09:38:57 - agent.DQN.DQN - INFO - episode 4 step 104 reward tensor([-1]) loss 61.211875915527344 epsilon 0.7426202259375
26-Feb-25 09:38:57 - agent.DQN.DQN - INFO - episode 4 step 105 reward tensor([-1]) loss 9.448612213134766 epsilon 0.7426202259375
26-Feb-25 09:38:57 - agent.DQN.DQN - INFO - episode 4 step 106 reward tensor([-1]) loss 2.2678256034851074 epsilon 0.7426202259375
26-Feb-25 09:38:58 - agent.DQN.DQN - INFO - episode 4 step 107 reward tensor([-1]) loss 11.722713470458984 epsilon 0.7426202259375
26-Feb-25 09:38:58 - agent.DQN.DQN - INFO - episode 4 step 108 reward tensor([-1]) loss 8.943984031677246 epsilon 0.7426202259375
26-Feb-25 09:38:58 - agent.DQN.DQN - INFO - episode 4 step 109 reward tensor([-1]) loss 8.345057487487793 epsilon 0.7426202259375
26-Feb-25 09:38:58 - agent.DQN.DQN - INFO - episode 4 step 110 reward tensor([-1]) loss 13.649595260620117 epsilon 0.7426202259375
26-Feb-25 09:38:58 - agent.DQN.DQN - INFO - episode 4 step 111 reward tensor([-1]) loss 4.609005928039551 epsilon 0.7426202259375
26-Feb-25 09:38:58 - agent.DQN.DQN - INFO - episode 4 step 112 reward tensor([-1]) loss 10.822234153747559 epsilon 0.7426202259375
26-Feb-25 09:38:58 - agent.DQN.DQN - INFO - episode 4 step 113 reward tensor([-1]) loss 11.424556732177734 epsilon 0.7426202259375
26-Feb-25 09:38:58 - agent.DQN.DQN - INFO - episode 4 step 114 reward tensor([-1]) loss 12.440308570861816 epsilon 0.7426202259375
26-Feb-25 09:38:58 - agent.DQN.DQN - INFO - episode 4 step 115 reward tensor([-1]) loss 12.003087997436523 epsilon 0.7426202259375
26-Feb-25 09:38:58 - agent.DQN.DQN - INFO - episode 4 step 116 reward tensor([-1]) loss 5.123596668243408 epsilon 0.7426202259375
26-Feb-25 09:38:58 - agent.DQN.DQN - INFO - episode 4 step 117 reward tensor([-1]) loss 5.2462477684021 epsilon 0.7426202259375
26-Feb-25 09:38:58 - agent.DQN.DQN - INFO - episode 4 step 118 reward tensor([-1]) loss 8.012727737426758 epsilon 0.7426202259375
26-Feb-25 09:38:58 - agent.DQN.DQN - INFO - episode 4 step 119 reward tensor([-1]) loss 6.37034797668457 epsilon 0.7426202259375
26-Feb-25 09:38:58 - agent.DQN.DQN - INFO - episode 4 step 120 reward tensor([-1]) loss 7.987439155578613 epsilon 0.7426202259375
26-Feb-25 09:38:58 - agent.DQN.DQN - INFO - episode 4 step 121 reward tensor([-1]) loss 6.631851673126221 epsilon 0.7426202259375
26-Feb-25 09:38:58 - agent.DQN.DQN - INFO - episode 4 step 122 reward tensor([-1]) loss 6.0952630043029785 epsilon 0.7426202259375
26-Feb-25 09:38:58 - agent.DQN.DQN - INFO - episode 4 step 123 reward tensor([-1]) loss 5.128401279449463 epsilon 0.7426202259375
26-Feb-25 09:38:58 - agent.DQN.DQN - INFO - episode 4 step 124 reward tensor([-1]) loss 8.400629997253418 epsilon 0.7426202259375
26-Feb-25 09:38:58 - agent.DQN.DQN - INFO - episode 4 step 125 reward tensor([-1]) loss 5.642686367034912 epsilon 0.7426202259375
26-Feb-25 09:38:58 - agent.DQN.DQN - INFO - episode 4 step 126 reward tensor([-1]) loss 65.97423553466797 epsilon 0.7426202259375
26-Feb-25 09:38:58 - agent.DQN.DQN - INFO - episode 4 step 127 reward tensor([-1]) loss 4.86334753036499 epsilon 0.7426202259375
26-Feb-25 09:38:58 - agent.DQN.DQN - INFO - episode 4 step 128 reward tensor([-1]) loss 10.28233528137207 epsilon 0.7426202259375
26-Feb-25 09:38:58 - agent.DQN.DQN - INFO - episode 4 step 129 reward tensor([-1]) loss 4.1080546379089355 epsilon 0.7426202259375
26-Feb-25 09:38:58 - agent.DQN.DQN - INFO - episode 4 step 130 reward tensor([-1]) loss 3.9305739402770996 epsilon 0.7426202259375
26-Feb-25 09:38:58 - agent.DQN.DQN - INFO - episode 4 step 131 reward tensor([-1]) loss 6.256293296813965 epsilon 0.7426202259375
26-Feb-25 09:38:58 - agent.DQN.DQN - INFO - episode 4 step 132 reward tensor([-1]) loss 59.126678466796875 epsilon 0.7426202259375
26-Feb-25 09:38:58 - agent.DQN.DQN - INFO - episode 4 step 133 reward tensor([-1]) loss 4.409348011016846 epsilon 0.7426202259375
26-Feb-25 09:38:58 - agent.DQN.DQN - INFO - episode 4 step 134 reward tensor([-1]) loss 60.26069259643555 epsilon 0.7426202259375
26-Feb-25 09:38:58 - agent.DQN.DQN - INFO - episode 4 step 135 reward tensor([-1]) loss 58.76247787475586 epsilon 0.7426202259375
26-Feb-25 09:38:58 - agent.DQN.DQN - INFO - episode 4 step 136 reward tensor([-1]) loss 8.256784439086914 epsilon 0.7426202259375
26-Feb-25 09:38:58 - agent.DQN.DQN - INFO - episode 4 step 137 reward tensor([-1]) loss 59.43518829345703 epsilon 0.7426202259375
26-Feb-25 09:38:58 - agent.DQN.DQN - INFO - episode 4 step 138 reward tensor([-1]) loss 59.012725830078125 epsilon 0.7426202259375
26-Feb-25 09:38:58 - agent.DQN.DQN - INFO - episode 4 step 139 reward tensor([-1]) loss 4.307082653045654 epsilon 0.7426202259375
26-Feb-25 09:38:58 - agent.DQN.DQN - INFO - episode 4 step 140 reward tensor([-1]) loss 61.652870178222656 epsilon 0.7426202259375
26-Feb-25 09:38:58 - agent.DQN.DQN - INFO - episode 4 step 141 reward tensor([-1]) loss 3.6198551654815674 epsilon 0.7426202259375
26-Feb-25 09:38:58 - agent.DQN.DQN - INFO - episode 4 step 142 reward tensor([-1]) loss 5.716698169708252 epsilon 0.7426202259375
26-Feb-25 09:38:58 - agent.DQN.DQN - INFO - episode 4 step 143 reward tensor([-1]) loss 8.977206230163574 epsilon 0.7426202259375
26-Feb-25 09:38:58 - agent.DQN.DQN - INFO - episode 4 step 144 reward tensor([-1]) loss 5.709729194641113 epsilon 0.7426202259375
26-Feb-25 09:38:58 - agent.DQN.DQN - INFO - episode 4 step 145 reward tensor([-1]) loss 12.61959457397461 epsilon 0.7426202259375
26-Feb-25 09:38:58 - agent.DQN.DQN - INFO - episode 4 step 146 reward tensor([-1]) loss 2.3309166431427 epsilon 0.7426202259375
26-Feb-25 09:38:58 - agent.DQN.DQN - INFO - episode 4 step 147 reward tensor([-1]) loss 6.4492011070251465 epsilon 0.7426202259375
26-Feb-25 09:38:58 - agent.DQN.DQN - INFO - episode 4 step 148 reward tensor([-1]) loss 6.751765727996826 epsilon 0.7426202259375
26-Feb-25 09:38:58 - agent.DQN.DQN - INFO - episode 4 step 149 reward tensor([-1]) loss 5.0464935302734375 epsilon 0.7426202259375
26-Feb-25 09:38:58 - agent.DQN.DQN - INFO - episode 4 step 150 reward tensor([-1]) loss 8.615798950195312 epsilon 0.7426202259375
26-Feb-25 09:38:58 - agent.DQN.DQN - INFO - episode 4 step 151 reward tensor([-1]) loss 56.29798126220703 epsilon 0.7426202259375
26-Feb-25 09:38:58 - agent.DQN.DQN - INFO - episode 4 step 152 reward tensor([-1]) loss 8.881449699401855 epsilon 0.7426202259375
26-Feb-25 09:38:58 - agent.DQN.DQN - INFO - episode 4 step 153 reward tensor([-1]) loss 4.450687408447266 epsilon 0.7426202259375
26-Feb-25 09:38:58 - agent.DQN.DQN - INFO - episode 4 step 154 reward tensor([-1]) loss 9.271116256713867 epsilon 0.7426202259375
26-Feb-25 09:38:58 - agent.DQN.DQN - INFO - episode 4 step 155 reward tensor([-1]) loss 4.442901611328125 epsilon 0.7426202259375
26-Feb-25 09:38:58 - agent.DQN.DQN - INFO - episode 4 step 156 reward tensor([-1]) loss 8.349775314331055 epsilon 0.7426202259375
26-Feb-25 09:38:58 - agent.DQN.DQN - INFO - episode 4 step 157 reward tensor([-1]) loss 3.0304973125457764 epsilon 0.7426202259375
26-Feb-25 09:38:58 - agent.DQN.DQN - INFO - episode 4 step 158 reward tensor([-1]) loss 4.833137512207031 epsilon 0.7426202259375
26-Feb-25 09:38:58 - agent.DQN.DQN - INFO - episode 4 step 159 reward tensor([-1]) loss 5.284535884857178 epsilon 0.7426202259375
26-Feb-25 09:38:58 - agent.DQN.DQN - INFO - episode 4 step 160 reward tensor([-1]) loss 5.560439586639404 epsilon 0.7426202259375
26-Feb-25 09:38:58 - agent.DQN.DQN - INFO - episode 4 step 161 reward tensor([-1]) loss 58.42494583129883 epsilon 0.7426202259375
26-Feb-25 09:38:58 - agent.DQN.DQN - INFO - episode 4 step 162 reward tensor([-1]) loss 4.963508605957031 epsilon 0.7426202259375
26-Feb-25 09:38:58 - agent.DQN.DQN - INFO - episode 4 step 163 reward tensor([-1]) loss 5.405296325683594 epsilon 0.7426202259375
26-Feb-25 09:38:58 - agent.DQN.DQN - INFO - episode 4 step 164 reward tensor([-1]) loss 3.556642532348633 epsilon 0.7426202259375
26-Feb-25 09:38:58 - agent.DQN.DQN - INFO - episode 4 step 165 reward tensor([-1]) loss 5.565451145172119 epsilon 0.7426202259375
26-Feb-25 09:38:58 - agent.DQN.DQN - INFO - episode 4 step 166 reward tensor([-1]) loss 6.630284786224365 epsilon 0.7426202259375
26-Feb-25 09:38:58 - agent.DQN.DQN - INFO - episode 4 step 167 reward tensor([-1]) loss 4.315022945404053 epsilon 0.7426202259375
26-Feb-25 09:38:58 - agent.DQN.DQN - INFO - episode 4 step 168 reward tensor([-1]) loss 60.95713424682617 epsilon 0.7426202259375
26-Feb-25 09:38:58 - agent.DQN.DQN - INFO - episode 4 step 169 reward tensor([-1]) loss 6.14934778213501 epsilon 0.7426202259375
26-Feb-25 09:38:58 - agent.DQN.DQN - INFO - episode 4 step 170 reward tensor([-1]) loss 2.915419578552246 epsilon 0.7426202259375
26-Feb-25 09:38:58 - agent.DQN.DQN - INFO - episode 4 step 171 reward tensor([-1]) loss 56.71986770629883 epsilon 0.7426202259375
26-Feb-25 09:38:58 - agent.DQN.DQN - INFO - episode 4 step 172 reward tensor([-1]) loss 56.3505973815918 epsilon 0.7426202259375
26-Feb-25 09:38:58 - agent.DQN.DQN - INFO - episode 4 step 173 reward tensor([-1]) loss 58.28498458862305 epsilon 0.7426202259375
26-Feb-25 09:38:58 - agent.DQN.DQN - INFO - episode 4 step 174 reward tensor([-1]) loss 10.00150203704834 epsilon 0.7426202259375
26-Feb-25 09:38:58 - agent.DQN.DQN - INFO - episode 4 step 175 reward tensor([-1]) loss 2.116079330444336 epsilon 0.7426202259375
26-Feb-25 09:38:58 - agent.DQN.DQN - INFO - episode 4 step 176 reward tensor([-1]) loss 5.367231845855713 epsilon 0.7426202259375
26-Feb-25 09:38:58 - agent.DQN.DQN - INFO - episode 4 step 177 reward tensor([-1]) loss 4.393836975097656 epsilon 0.7426202259375
26-Feb-25 09:38:58 - agent.DQN.DQN - INFO - episode 4 step 178 reward tensor([-1]) loss 7.779519557952881 epsilon 0.7426202259375
26-Feb-25 09:38:58 - agent.DQN.DQN - INFO - episode 4 step 179 reward tensor([-1]) loss 55.84946060180664 epsilon 0.7426202259375
26-Feb-25 09:38:58 - agent.DQN.DQN - INFO - episode 4 step 180 reward tensor([-1]) loss 6.516862392425537 epsilon 0.7426202259375
26-Feb-25 09:38:58 - agent.DQN.DQN - INFO - episode 4 step 181 reward tensor([-1]) loss 60.161617279052734 epsilon 0.7426202259375
26-Feb-25 09:38:58 - agent.DQN.DQN - INFO - episode 4 step 182 reward tensor([-1]) loss 4.4110517501831055 epsilon 0.7426202259375
26-Feb-25 09:38:59 - agent.DQN.DQN - INFO - episode 4 step 183 reward tensor([-1]) loss 6.660501003265381 epsilon 0.7426202259375
26-Feb-25 09:38:59 - agent.DQN.DQN - INFO - episode 4 step 184 reward tensor([-1]) loss 5.556802749633789 epsilon 0.7426202259375
26-Feb-25 09:38:59 - agent.DQN.DQN - INFO - episode 4 step 185 reward tensor([-1]) loss 8.098482131958008 epsilon 0.7426202259375
26-Feb-25 09:38:59 - agent.DQN.DQN - INFO - episode 4 step 186 reward tensor([-1]) loss 8.141390800476074 epsilon 0.7426202259375
26-Feb-25 09:38:59 - agent.DQN.DQN - INFO - episode 4 step 187 reward tensor([-1]) loss 2.6953890323638916 epsilon 0.7426202259375
26-Feb-25 09:38:59 - agent.DQN.DQN - INFO - episode 4 step 188 reward tensor([-1]) loss 4.974220275878906 epsilon 0.7426202259375
26-Feb-25 09:38:59 - agent.DQN.DQN - INFO - episode 4 step 189 reward tensor([-1]) loss 9.410565376281738 epsilon 0.7426202259375
26-Feb-25 09:38:59 - agent.DQN.DQN - INFO - episode 4 step 190 reward tensor([-1]) loss 8.049627304077148 epsilon 0.7426202259375
26-Feb-25 09:38:59 - agent.DQN.DQN - INFO - episode 4 step 191 reward tensor([-1]) loss 60.05118179321289 epsilon 0.7426202259375
26-Feb-25 09:38:59 - agent.DQN.DQN - INFO - episode 4 step 192 reward tensor([-1]) loss 7.674921035766602 epsilon 0.7426202259375
26-Feb-25 09:38:59 - agent.DQN.DQN - INFO - episode 4 step 193 reward tensor([-1]) loss 6.062402725219727 epsilon 0.7426202259375
26-Feb-25 09:38:59 - agent.DQN.DQN - INFO - episode 4 step 194 reward tensor([-1]) loss 5.615412712097168 epsilon 0.7426202259375
26-Feb-25 09:38:59 - agent.DQN.DQN - INFO - episode 4 step 195 reward tensor([-1]) loss 4.394128322601318 epsilon 0.7426202259375
26-Feb-25 09:38:59 - agent.DQN.DQN - INFO - episode 4 step 196 reward tensor([-1]) loss 55.8351936340332 epsilon 0.7426202259375
26-Feb-25 09:38:59 - agent.DQN.DQN - INFO - episode 4 step 197 reward tensor([-1]) loss 56.79955291748047 epsilon 0.7426202259375
26-Feb-25 09:38:59 - agent.DQN.DQN - INFO - episode 4 step 198 reward tensor([-1]) loss 7.0300469398498535 epsilon 0.7426202259375
26-Feb-25 09:38:59 - agent.DQN.DQN - INFO - episode 4 step 199 reward tensor([-1]) loss 6.436168193817139 epsilon 0.7426202259375
26-Feb-25 09:38:59 - agent.DQN.DQN - INFO - episode 4 step 200 reward tensor([-1]) loss 4.89401388168335 epsilon 0.7426202259375
26-Feb-25 09:38:59 - agent.DQN.DQN - INFO - episode 4 step 201 reward tensor([-1]) loss 10.114109992980957 epsilon 0.7426202259375
26-Feb-25 09:38:59 - agent.DQN.DQN - INFO - episode 4 step 202 reward tensor([-1]) loss 7.070836067199707 epsilon 0.7426202259375
26-Feb-25 09:38:59 - agent.DQN.DQN - INFO - episode 4 step 203 reward tensor([-1]) loss 4.274896621704102 epsilon 0.7426202259375
26-Feb-25 09:38:59 - agent.DQN.DQN - INFO - episode 4 step 204 reward tensor([-1]) loss 55.29270553588867 epsilon 0.7426202259375
26-Feb-25 09:38:59 - agent.DQN.DQN - INFO - episode 4 step 205 reward tensor([-1]) loss 10.343110084533691 epsilon 0.7426202259375
26-Feb-25 09:38:59 - agent.DQN.DQN - INFO - episode 4 step 206 reward tensor([-1]) loss 3.6726233959198 epsilon 0.7426202259375
26-Feb-25 09:38:59 - agent.DQN.DQN - INFO - episode 4 step 207 reward tensor([-1]) loss 55.48838424682617 epsilon 0.7426202259375
26-Feb-25 09:38:59 - agent.DQN.DQN - INFO - episode 4 step 208 reward tensor([-1]) loss 7.46661376953125 epsilon 0.7426202259375
26-Feb-25 09:38:59 - agent.DQN.DQN - INFO - episode 4 step 209 reward tensor([-1]) loss 56.184574127197266 epsilon 0.7426202259375
26-Feb-25 09:38:59 - agent.DQN.DQN - INFO - episode 4 step 210 reward tensor([-1]) loss 4.824285984039307 epsilon 0.7426202259375
26-Feb-25 09:38:59 - agent.DQN.DQN - INFO - episode 4 step 211 reward tensor([-1]) loss 8.72584056854248 epsilon 0.7426202259375
26-Feb-25 09:38:59 - agent.DQN.DQN - INFO - episode 4 step 212 reward tensor([-1]) loss 61.25772476196289 epsilon 0.7426202259375
26-Feb-25 09:38:59 - agent.DQN.DQN - INFO - episode 4 step 213 reward tensor([-1]) loss 8.467836380004883 epsilon 0.7426202259375
26-Feb-25 09:38:59 - agent.DQN.DQN - INFO - episode 4 step 214 reward tensor([-1]) loss 4.475823879241943 epsilon 0.7426202259375
26-Feb-25 09:38:59 - agent.DQN.DQN - INFO - episode 4 step 215 reward tensor([-1]) loss 5.439184188842773 epsilon 0.7426202259375
26-Feb-25 09:38:59 - agent.DQN.DQN - INFO - episode 4 step 216 reward tensor([-1]) loss 4.306763172149658 epsilon 0.7426202259375
26-Feb-25 09:38:59 - agent.DQN.DQN - INFO - episode 4 step 217 reward tensor([-1]) loss 8.737103462219238 epsilon 0.7426202259375
26-Feb-25 09:38:59 - agent.DQN.DQN - INFO - episode 4 step 218 reward tensor([-1]) loss 5.391810417175293 epsilon 0.7426202259375
26-Feb-25 09:38:59 - agent.DQN.DQN - INFO - episode 4 step 219 reward tensor([-1]) loss 6.017932415008545 epsilon 0.7426202259375
26-Feb-25 09:38:59 - agent.DQN.DQN - INFO - episode 4 step 220 reward tensor([-1]) loss 55.571495056152344 epsilon 0.7426202259375
26-Feb-25 09:38:59 - agent.DQN.DQN - INFO - episode 4 step 221 reward tensor([-1]) loss 3.9444944858551025 epsilon 0.7426202259375
26-Feb-25 09:38:59 - agent.DQN.DQN - INFO - episode 4 step 222 reward tensor([-1]) loss 5.766773223876953 epsilon 0.7426202259375
26-Feb-25 09:38:59 - agent.DQN.DQN - INFO - episode 4 step 223 reward tensor([-1]) loss 5.143355369567871 epsilon 0.7426202259375
26-Feb-25 09:38:59 - agent.DQN.DQN - INFO - episode 4 step 224 reward tensor([-1]) loss 7.750150680541992 epsilon 0.7426202259375
26-Feb-25 09:38:59 - agent.DQN.DQN - INFO - episode 4 step 225 reward tensor([-1]) loss 7.648982048034668 epsilon 0.7426202259375
26-Feb-25 09:38:59 - agent.DQN.DQN - INFO - episode 4 step 226 reward tensor([-1]) loss 4.820529937744141 epsilon 0.7426202259375
26-Feb-25 09:38:59 - agent.DQN.DQN - INFO - episode 4 step 227 reward tensor([-1]) loss 5.674526691436768 epsilon 0.7426202259375
26-Feb-25 09:38:59 - agent.DQN.DQN - INFO - episode 4 step 228 reward tensor([-1]) loss 55.258731842041016 epsilon 0.7426202259375
26-Feb-25 09:38:59 - agent.DQN.DQN - INFO - episode 4 step 229 reward tensor([-1]) loss 5.513480186462402 epsilon 0.7426202259375
26-Feb-25 09:38:59 - agent.DQN.DQN - INFO - episode 4 step 230 reward tensor([-1]) loss 7.186077117919922 epsilon 0.7426202259375
26-Feb-25 09:38:59 - agent.DQN.DQN - INFO - episode 4 step 231 reward tensor([-1]) loss 54.6629524230957 epsilon 0.7426202259375
26-Feb-25 09:38:59 - agent.DQN.DQN - INFO - episode 4 step 232 reward tensor([-1]) loss 58.007362365722656 epsilon 0.7426202259375
26-Feb-25 09:38:59 - agent.DQN.DQN - INFO - episode 4 step 233 reward tensor([-1]) loss 7.38953971862793 epsilon 0.7426202259375
26-Feb-25 09:38:59 - agent.DQN.DQN - INFO - episode 4 step 234 reward tensor([-1]) loss 5.176078796386719 epsilon 0.7426202259375
26-Feb-25 09:38:59 - agent.DQN.DQN - INFO - episode 4 step 235 reward tensor([-1]) loss 8.035694122314453 epsilon 0.7426202259375
26-Feb-25 09:38:59 - agent.DQN.DQN - INFO - episode 4 step 236 reward tensor([-1]) loss 3.9897689819335938 epsilon 0.7426202259375
26-Feb-25 09:38:59 - agent.DQN.DQN - INFO - episode 4 step 237 reward tensor([-1]) loss 5.296036243438721 epsilon 0.7426202259375
26-Feb-25 09:38:59 - agent.DQN.DQN - INFO - episode 4 step 238 reward tensor([-1]) loss 54.4549674987793 epsilon 0.7426202259375
26-Feb-25 09:38:59 - agent.DQN.DQN - INFO - episode 4 step 239 reward tensor([-1]) loss 54.219730377197266 epsilon 0.7426202259375
26-Feb-25 09:38:59 - agent.DQN.DQN - INFO - episode 4 step 240 reward tensor([-1]) loss 6.6786417961120605 epsilon 0.7426202259375
26-Feb-25 09:38:59 - agent.DQN.DQN - INFO - episode 4 step 241 reward tensor([-1]) loss 8.596709251403809 epsilon 0.7426202259375
26-Feb-25 09:38:59 - agent.DQN.DQN - INFO - episode 4 step 242 reward tensor([-1]) loss 8.037353515625 epsilon 0.7426202259375
26-Feb-25 09:38:59 - agent.DQN.DQN - INFO - episode 4 step 243 reward tensor([-1]) loss 2.974334478378296 epsilon 0.7426202259375
26-Feb-25 09:38:59 - agent.DQN.DQN - INFO - episode 4 step 244 reward tensor([-1]) loss 9.139267921447754 epsilon 0.7426202259375
26-Feb-25 09:38:59 - agent.DQN.DQN - INFO - episode 4 step 245 reward tensor([-1]) loss 5.036405086517334 epsilon 0.7426202259375
26-Feb-25 09:38:59 - agent.DQN.DQN - INFO - episode 4 step 246 reward tensor([-1]) loss 54.60929870605469 epsilon 0.7426202259375
26-Feb-25 09:38:59 - agent.DQN.DQN - INFO - episode 4 step 247 reward tensor([-1]) loss 6.705148696899414 epsilon 0.7426202259375
26-Feb-25 09:38:59 - agent.DQN.DQN - INFO - episode 4 step 248 reward tensor([-1]) loss 3.4586334228515625 epsilon 0.7426202259375
26-Feb-25 09:38:59 - agent.DQN.DQN - INFO - episode 4 step 249 reward tensor([-1]) loss 4.948546886444092 epsilon 0.7426202259375
26-Feb-25 09:38:59 - agent.DQN.DQN - INFO - episode 4 step 250 reward tensor([-1]) loss 6.156461715698242 epsilon 0.7426202259375
26-Feb-25 09:38:59 - agent.DQN.DQN - INFO - episode 4 step 251 reward tensor([-1]) loss 6.064662933349609 epsilon 0.7426202259375
26-Feb-25 09:38:59 - agent.DQN.DQN - INFO - episode 4 step 252 reward tensor([-1]) loss 8.123668670654297 epsilon 0.7426202259375
26-Feb-25 09:38:59 - agent.DQN.DQN - INFO - episode 4 step 253 reward tensor([-1]) loss 9.546504974365234 epsilon 0.7426202259375
26-Feb-25 09:38:59 - agent.DQN.DQN - INFO - episode 4 step 254 reward tensor([-1]) loss 6.270724296569824 epsilon 0.7426202259375
26-Feb-25 09:38:59 - agent.DQN.DQN - INFO - episode 4 step 255 reward tensor([-1]) loss 4.301316738128662 epsilon 0.7426202259375
26-Feb-25 09:38:59 - agent.DQN.DQN - INFO - episode 4 step 256 reward tensor([-1]) loss 4.090095043182373 epsilon 0.7426202259375
26-Feb-25 09:38:59 - agent.DQN.DQN - INFO - episode 4 step 257 reward tensor([-1]) loss 4.166970252990723 epsilon 0.7426202259375
26-Feb-25 09:38:59 - agent.DQN.DQN - INFO - episode 4 step 258 reward tensor([-1]) loss 4.205164432525635 epsilon 0.7426202259375
26-Feb-25 09:39:00 - agent.DQN.DQN - INFO - episode 4 step 259 reward tensor([-1]) loss 8.27642822265625 epsilon 0.7426202259375
26-Feb-25 09:39:00 - agent.DQN.DQN - INFO - episode 4 step 260 reward tensor([-1]) loss 4.766271114349365 epsilon 0.7426202259375
26-Feb-25 09:39:00 - agent.DQN.DQN - INFO - episode 4 step 261 reward tensor([-1]) loss 4.376437187194824 epsilon 0.7426202259375
26-Feb-25 09:39:00 - agent.DQN.DQN - INFO - episode 4 step 262 reward tensor([-1]) loss 56.548282623291016 epsilon 0.7426202259375
26-Feb-25 09:39:00 - agent.DQN.DQN - INFO - episode 4 step 263 reward tensor([-1]) loss 4.498841762542725 epsilon 0.7426202259375
26-Feb-25 09:39:00 - agent.DQN.DQN - INFO - episode 4 step 264 reward tensor([-1]) loss 1.3063594102859497 epsilon 0.7426202259375
26-Feb-25 09:39:00 - agent.DQN.DQN - INFO - episode 4 step 265 reward tensor([-1]) loss 2.685483455657959 epsilon 0.7426202259375
26-Feb-25 09:39:00 - agent.DQN.DQN - INFO - episode 4 step 266 reward tensor([-1]) loss 5.811093330383301 epsilon 0.7426202259375
26-Feb-25 09:39:00 - agent.DQN.DQN - INFO - episode 4 step 267 reward tensor([-1]) loss 5.836744785308838 epsilon 0.7426202259375
26-Feb-25 09:39:00 - agent.DQN.DQN - INFO - episode 4 step 268 reward tensor([-1]) loss 53.97093963623047 epsilon 0.7426202259375
26-Feb-25 09:39:00 - agent.DQN.DQN - INFO - episode 4 step 269 reward tensor([-1]) loss 53.54712677001953 epsilon 0.7426202259375
26-Feb-25 09:39:00 - agent.DQN.DQN - INFO - episode 4 step 270 reward tensor([-1]) loss 3.8789303302764893 epsilon 0.7426202259375
26-Feb-25 09:39:00 - agent.DQN.DQN - INFO - episode 4 step 271 reward tensor([-1]) loss 6.31205940246582 epsilon 0.7426202259375
26-Feb-25 09:39:00 - agent.DQN.DQN - INFO - episode 4 step 272 reward tensor([-1]) loss 4.45239782333374 epsilon 0.7426202259375
26-Feb-25 09:39:00 - agent.DQN.DQN - INFO - episode 4 step 273 reward tensor([-1]) loss 6.166646480560303 epsilon 0.7426202259375
26-Feb-25 09:39:00 - agent.DQN.DQN - INFO - episode 4 step 274 reward tensor([-1]) loss 6.298069477081299 epsilon 0.7426202259375
26-Feb-25 09:39:00 - agent.DQN.DQN - INFO - episode 4 step 275 reward tensor([-1]) loss 5.8957133293151855 epsilon 0.7426202259375
26-Feb-25 09:39:00 - agent.DQN.DQN - INFO - episode 4 step 276 reward tensor([-1]) loss 1.5128735303878784 epsilon 0.7426202259375
26-Feb-25 09:39:00 - agent.DQN.DQN - INFO - episode 4 step 277 reward tensor([-1]) loss 7.325699806213379 epsilon 0.7426202259375
26-Feb-25 09:39:00 - agent.DQN.DQN - INFO - episode 4 step 278 reward tensor([-1]) loss 4.2170000076293945 epsilon 0.7426202259375
26-Feb-25 09:39:00 - agent.DQN.DQN - INFO - episode 4 step 279 reward tensor([-1]) loss 3.23881459236145 epsilon 0.7426202259375
26-Feb-25 09:39:00 - agent.DQN.DQN - INFO - episode 4 step 280 reward tensor([-1]) loss 4.056513786315918 epsilon 0.7426202259375
26-Feb-25 09:39:00 - agent.DQN.DQN - INFO - episode 4 step 281 reward tensor([-1]) loss 7.777835845947266 epsilon 0.7426202259375
26-Feb-25 09:39:00 - agent.DQN.DQN - INFO - episode 4 step 282 reward tensor([-1]) loss 54.48918914794922 epsilon 0.7426202259375
26-Feb-25 09:39:00 - agent.DQN.DQN - INFO - episode 4 step 283 reward tensor([-1]) loss 8.75619125366211 epsilon 0.7426202259375
26-Feb-25 09:39:00 - agent.DQN.DQN - INFO - episode 4 step 284 reward tensor([-1]) loss 7.237310886383057 epsilon 0.7426202259375
26-Feb-25 09:39:00 - agent.DQN.DQN - INFO - episode 4 step 285 reward tensor([-1]) loss 3.5632808208465576 epsilon 0.7426202259375
26-Feb-25 09:39:00 - agent.DQN.DQN - INFO - episode 4 step 286 reward tensor([-1]) loss 55.57072067260742 epsilon 0.7426202259375
26-Feb-25 09:39:00 - agent.DQN.DQN - INFO - episode 4 step 287 reward tensor([-1]) loss 4.8281731605529785 epsilon 0.7426202259375
26-Feb-25 09:39:00 - agent.DQN.DQN - INFO - episode 4 step 288 reward tensor([-1]) loss 5.974419593811035 epsilon 0.7426202259375
26-Feb-25 09:39:00 - agent.DQN.DQN - INFO - episode 4 step 289 reward tensor([-1]) loss 5.440606117248535 epsilon 0.7426202259375
26-Feb-25 09:39:00 - agent.DQN.DQN - INFO - episode 4 step 290 reward tensor([-1]) loss 7.753373622894287 epsilon 0.7426202259375
26-Feb-25 09:39:00 - agent.DQN.DQN - INFO - episode 4 step 291 reward tensor([-1]) loss 5.654163360595703 epsilon 0.7426202259375
26-Feb-25 09:39:00 - agent.DQN.DQN - INFO - episode 4 step 292 reward tensor([-1]) loss 4.305300235748291 epsilon 0.7426202259375
26-Feb-25 09:39:00 - agent.DQN.DQN - INFO - episode 4 step 293 reward tensor([-1]) loss 4.58113956451416 epsilon 0.7426202259375
26-Feb-25 09:39:00 - agent.DQN.DQN - INFO - episode 4 step 294 reward tensor([-1]) loss 3.2338457107543945 epsilon 0.7426202259375
26-Feb-25 09:39:00 - agent.DQN.DQN - INFO - episode 4 step 295 reward tensor([-1]) loss 2.4793319702148438 epsilon 0.7426202259375
26-Feb-25 09:39:00 - agent.DQN.DQN - INFO - episode 4 step 296 reward tensor([-1]) loss 3.3052315711975098 epsilon 0.7426202259375
26-Feb-25 09:39:00 - agent.DQN.DQN - INFO - episode 4 step 297 reward tensor([-1]) loss 4.219486713409424 epsilon 0.7426202259375
26-Feb-25 09:39:00 - agent.DQN.DQN - INFO - episode 4 step 298 reward tensor([-1]) loss 7.242893218994141 epsilon 0.7426202259375
26-Feb-25 09:39:00 - agent.DQN.DQN - INFO - episode 4 step 299 reward tensor([-1]) loss 53.06770706176758 epsilon 0.7426202259375
26-Feb-25 09:39:00 - agent.DQN.DQN - INFO - episode 4 step 300 reward tensor([-1]) loss 52.9863166809082 epsilon 0.7426202259375
26-Feb-25 09:39:00 - agent.DQN.DQN - INFO - episode 4 step 301 reward tensor([-1]) loss 3.6618547439575195 epsilon 0.7426202259375
26-Feb-25 09:39:00 - agent.DQN.DQN - INFO - episode 5 step 0 reward tensor([-1]) loss 5.21619176864624 epsilon 0.7184850685945312
26-Feb-25 09:39:00 - agent.DQN.DQN - INFO - episode 5 step 1 reward tensor([-1]) loss 7.537928581237793 epsilon 0.7184850685945312
26-Feb-25 09:39:00 - agent.DQN.DQN - INFO - episode 5 step 2 reward tensor([-1]) loss 51.72357177734375 epsilon 0.7184850685945312
26-Feb-25 09:39:00 - agent.DQN.DQN - INFO - episode 5 step 3 reward tensor([-1]) loss 52.34931182861328 epsilon 0.7184850685945312
26-Feb-25 09:39:00 - agent.DQN.DQN - INFO - episode 5 step 4 reward tensor([-1]) loss 3.850447177886963 epsilon 0.7184850685945312
26-Feb-25 09:39:00 - agent.DQN.DQN - INFO - episode 5 step 5 reward tensor([-1]) loss 7.241436004638672 epsilon 0.7184850685945312
26-Feb-25 09:39:00 - agent.DQN.DQN - INFO - episode 5 step 6 reward tensor([-1]) loss 5.687340259552002 epsilon 0.7184850685945312
26-Feb-25 09:39:00 - agent.DQN.DQN - INFO - episode 5 step 7 reward tensor([-1]) loss 4.21812629699707 epsilon 0.7184850685945312
26-Feb-25 09:39:00 - agent.DQN.DQN - INFO - episode 5 step 8 reward tensor([-1]) loss 6.5189690589904785 epsilon 0.7184850685945312
26-Feb-25 09:39:00 - agent.DQN.DQN - INFO - episode 5 step 9 reward tensor([-1]) loss 4.326969623565674 epsilon 0.7184850685945312
26-Feb-25 09:39:00 - agent.DQN.DQN - INFO - episode 5 step 10 reward tensor([-1]) loss 7.143826961517334 epsilon 0.7184850685945312
26-Feb-25 09:39:00 - agent.DQN.DQN - INFO - episode 5 step 11 reward tensor([-1]) loss 1.9276090860366821 epsilon 0.7184850685945312
26-Feb-25 09:39:00 - agent.DQN.DQN - INFO - episode 5 step 12 reward tensor([-1]) loss 9.15605640411377 epsilon 0.7184850685945312
26-Feb-25 09:39:00 - agent.DQN.DQN - INFO - episode 5 step 13 reward tensor([-1]) loss 3.225369453430176 epsilon 0.7184850685945312
26-Feb-25 09:39:00 - agent.DQN.DQN - INFO - episode 5 step 14 reward tensor([-1]) loss 53.67453384399414 epsilon 0.7184850685945312
26-Feb-25 09:39:00 - agent.DQN.DQN - INFO - episode 5 step 15 reward tensor([-1]) loss 2.1242988109588623 epsilon 0.7184850685945312
26-Feb-25 09:39:00 - agent.DQN.DQN - INFO - episode 5 step 16 reward tensor([-1]) loss 5.675900936126709 epsilon 0.7184850685945312
26-Feb-25 09:39:00 - agent.DQN.DQN - INFO - episode 5 step 17 reward tensor([-1]) loss 7.76812219619751 epsilon 0.7184850685945312
26-Feb-25 09:39:00 - agent.DQN.DQN - INFO - episode 5 step 18 reward tensor([-1]) loss 53.35914993286133 epsilon 0.7184850685945312
26-Feb-25 09:39:00 - agent.DQN.DQN - INFO - episode 5 step 19 reward tensor([-1]) loss 5.738427639007568 epsilon 0.7184850685945312
26-Feb-25 09:39:00 - agent.DQN.DQN - INFO - episode 5 step 20 reward tensor([-1]) loss 6.374386787414551 epsilon 0.7184850685945312
26-Feb-25 09:39:00 - agent.DQN.DQN - INFO - episode 5 step 21 reward tensor([-1]) loss 3.702479362487793 epsilon 0.7184850685945312
26-Feb-25 09:39:00 - agent.DQN.DQN - INFO - episode 5 step 22 reward tensor([-1]) loss 2.9867103099823 epsilon 0.7184850685945312
26-Feb-25 09:39:00 - agent.DQN.DQN - INFO - episode 5 step 23 reward tensor([-1]) loss 5.5479631423950195 epsilon 0.7184850685945312
26-Feb-25 09:39:00 - agent.DQN.DQN - INFO - episode 5 step 24 reward tensor([-1]) loss 4.22874116897583 epsilon 0.7184850685945312
26-Feb-25 09:39:00 - agent.DQN.DQN - INFO - episode 5 step 25 reward tensor([-1]) loss 3.7384192943573 epsilon 0.7184850685945312
26-Feb-25 09:39:00 - agent.DQN.DQN - INFO - episode 5 step 26 reward tensor([-1]) loss 6.860825061798096 epsilon 0.7184850685945312
26-Feb-25 09:39:00 - agent.DQN.DQN - INFO - episode 5 step 27 reward tensor([-1]) loss 4.503964424133301 epsilon 0.7184850685945312
26-Feb-25 09:39:00 - agent.DQN.DQN - INFO - episode 5 step 28 reward tensor([-1]) loss 5.412273406982422 epsilon 0.7184850685945312
26-Feb-25 09:39:00 - agent.DQN.DQN - INFO - episode 5 step 29 reward tensor([-1]) loss 6.23305606842041 epsilon 0.7184850685945312
26-Feb-25 09:39:00 - agent.DQN.DQN - INFO - episode 5 step 30 reward tensor([-1]) loss 9.704511642456055 epsilon 0.7184850685945312
26-Feb-25 09:39:00 - agent.DQN.DQN - INFO - episode 5 step 31 reward tensor([-1]) loss 2.489635705947876 epsilon 0.7184850685945312
26-Feb-25 09:39:00 - agent.DQN.DQN - INFO - episode 5 step 32 reward tensor([-1]) loss 3.616081714630127 epsilon 0.7184850685945312
26-Feb-25 09:39:00 - agent.DQN.DQN - INFO - episode 5 step 33 reward tensor([-1]) loss 2.743844985961914 epsilon 0.7184850685945312
26-Feb-25 09:39:00 - agent.DQN.DQN - INFO - episode 5 step 34 reward tensor([-1]) loss 53.2791748046875 epsilon 0.7184850685945312
26-Feb-25 09:39:00 - agent.DQN.DQN - INFO - episode 5 step 35 reward tensor([-1]) loss 4.7060418128967285 epsilon 0.7184850685945312
26-Feb-25 09:39:01 - agent.DQN.DQN - INFO - episode 5 step 36 reward tensor([-1]) loss 6.114879608154297 epsilon 0.7184850685945312
26-Feb-25 09:39:01 - agent.DQN.DQN - INFO - episode 5 step 37 reward tensor([-1]) loss 51.43981170654297 epsilon 0.7184850685945312
26-Feb-25 09:39:01 - agent.DQN.DQN - INFO - episode 5 step 38 reward tensor([-1]) loss 52.55758285522461 epsilon 0.7184850685945312
26-Feb-25 09:39:01 - agent.DQN.DQN - INFO - episode 5 step 39 reward tensor([-1]) loss 5.525852203369141 epsilon 0.7184850685945312
26-Feb-25 09:39:01 - agent.DQN.DQN - INFO - episode 5 step 40 reward tensor([-1]) loss 8.205836296081543 epsilon 0.7184850685945312
26-Feb-25 09:39:01 - agent.DQN.DQN - INFO - episode 5 step 41 reward tensor([-1]) loss 3.8478145599365234 epsilon 0.7184850685945312
26-Feb-25 09:39:01 - agent.DQN.DQN - INFO - episode 5 step 42 reward tensor([-1]) loss 51.81719207763672 epsilon 0.7184850685945312
26-Feb-25 09:39:01 - agent.DQN.DQN - INFO - episode 5 step 43 reward tensor([-1]) loss 3.4402971267700195 epsilon 0.7184850685945312
26-Feb-25 09:39:01 - agent.DQN.DQN - INFO - episode 5 step 44 reward tensor([-1]) loss 9.649504661560059 epsilon 0.7184850685945312
26-Feb-25 09:39:01 - agent.DQN.DQN - INFO - episode 5 step 45 reward tensor([-1]) loss 5.574584484100342 epsilon 0.7184850685945312
26-Feb-25 09:39:01 - agent.DQN.DQN - INFO - episode 5 step 46 reward tensor([-1]) loss 8.568559646606445 epsilon 0.7184850685945312
26-Feb-25 09:39:01 - agent.DQN.DQN - INFO - episode 5 step 47 reward tensor([-1]) loss 7.063808441162109 epsilon 0.7184850685945312
26-Feb-25 09:39:01 - agent.DQN.DQN - INFO - episode 5 step 48 reward tensor([-1]) loss 60.13607406616211 epsilon 0.7184850685945312
26-Feb-25 09:39:01 - agent.DQN.DQN - INFO - episode 5 step 49 reward tensor([-1]) loss 6.373225212097168 epsilon 0.7184850685945312
26-Feb-25 09:39:01 - agent.DQN.DQN - INFO - episode 5 step 50 reward tensor([-1]) loss 4.955447673797607 epsilon 0.7184850685945312
26-Feb-25 09:39:01 - agent.DQN.DQN - INFO - episode 5 step 51 reward tensor([-1]) loss 3.658931016921997 epsilon 0.7184850685945312
26-Feb-25 09:39:01 - agent.DQN.DQN - INFO - episode 5 step 52 reward tensor([-1]) loss 51.764488220214844 epsilon 0.7184850685945312
26-Feb-25 09:39:01 - agent.DQN.DQN - INFO - episode 5 step 53 reward tensor([-1]) loss 4.895112991333008 epsilon 0.7184850685945312
26-Feb-25 09:39:01 - agent.DQN.DQN - INFO - episode 5 step 54 reward tensor([-1]) loss 3.9003491401672363 epsilon 0.7184850685945312
26-Feb-25 09:39:01 - agent.DQN.DQN - INFO - episode 5 step 55 reward tensor([-1]) loss 4.463037490844727 epsilon 0.7184850685945312
26-Feb-25 09:39:01 - agent.DQN.DQN - INFO - episode 5 step 56 reward tensor([-1]) loss 3.94389271736145 epsilon 0.7184850685945312
26-Feb-25 09:39:01 - agent.DQN.DQN - INFO - episode 5 step 57 reward tensor([-1]) loss 4.116499423980713 epsilon 0.7184850685945312
26-Feb-25 09:39:01 - agent.DQN.DQN - INFO - episode 5 step 58 reward tensor([-1]) loss 3.235243797302246 epsilon 0.7184850685945312
26-Feb-25 09:39:01 - agent.DQN.DQN - INFO - episode 5 step 59 reward tensor([-1]) loss 5.434610366821289 epsilon 0.7184850685945312
26-Feb-25 09:39:01 - agent.DQN.DQN - INFO - episode 5 step 60 reward tensor([-1]) loss 2.990034341812134 epsilon 0.7184850685945312
26-Feb-25 09:39:01 - agent.DQN.DQN - INFO - episode 5 step 61 reward tensor([-1]) loss 4.207545757293701 epsilon 0.7184850685945312
26-Feb-25 09:39:01 - agent.DQN.DQN - INFO - episode 5 step 62 reward tensor([-1]) loss 51.562156677246094 epsilon 0.7184850685945312
26-Feb-25 09:39:01 - agent.DQN.DQN - INFO - episode 5 step 63 reward tensor([-1]) loss 58.29840087890625 epsilon 0.7184850685945312
26-Feb-25 09:39:01 - agent.DQN.DQN - INFO - episode 5 step 64 reward tensor([-1]) loss 4.919012546539307 epsilon 0.7184850685945312
26-Feb-25 09:39:01 - agent.DQN.DQN - INFO - episode 5 step 65 reward tensor([-1]) loss 3.457167625427246 epsilon 0.7184850685945312
26-Feb-25 09:39:01 - agent.DQN.DQN - INFO - episode 5 step 66 reward tensor([-1]) loss 5.2796783447265625 epsilon 0.7184850685945312
26-Feb-25 09:39:01 - agent.DQN.DQN - INFO - episode 5 step 67 reward tensor([-1]) loss 2.3460464477539062 epsilon 0.7184850685945312
26-Feb-25 09:39:01 - agent.DQN.DQN - INFO - episode 5 step 68 reward tensor([-1]) loss 2.967402696609497 epsilon 0.7184850685945312
26-Feb-25 09:39:01 - agent.DQN.DQN - INFO - episode 5 step 69 reward tensor([-1]) loss 10.49855899810791 epsilon 0.7184850685945312
26-Feb-25 09:39:01 - agent.DQN.DQN - INFO - episode 5 step 70 reward tensor([-1]) loss 5.844290733337402 epsilon 0.7184850685945312
26-Feb-25 09:39:01 - agent.DQN.DQN - INFO - episode 5 step 71 reward tensor([-1]) loss 6.5393571853637695 epsilon 0.7184850685945312
26-Feb-25 09:39:01 - agent.DQN.DQN - INFO - episode 5 step 72 reward tensor([-1]) loss 7.6945977210998535 epsilon 0.7184850685945312
26-Feb-25 09:39:01 - agent.DQN.DQN - INFO - episode 5 step 73 reward tensor([-1]) loss 5.112728118896484 epsilon 0.7184850685945312
26-Feb-25 09:39:01 - agent.DQN.DQN - INFO - episode 5 step 74 reward tensor([-1]) loss 6.482202529907227 epsilon 0.7184850685945312
26-Feb-25 09:39:01 - agent.DQN.DQN - INFO - episode 5 step 75 reward tensor([-1]) loss 4.594822883605957 epsilon 0.7184850685945312
26-Feb-25 09:39:01 - agent.DQN.DQN - INFO - episode 5 step 76 reward tensor([-1]) loss 51.64868927001953 epsilon 0.7184850685945312
26-Feb-25 09:39:01 - agent.DQN.DQN - INFO - episode 5 step 77 reward tensor([-1]) loss 6.0902628898620605 epsilon 0.7184850685945312
26-Feb-25 09:39:01 - agent.DQN.DQN - INFO - episode 5 step 78 reward tensor([-1]) loss 3.769366979598999 epsilon 0.7184850685945312
26-Feb-25 09:39:01 - agent.DQN.DQN - INFO - episode 5 step 79 reward tensor([-1]) loss 55.31184768676758 epsilon 0.7184850685945312
26-Feb-25 09:39:01 - agent.DQN.DQN - INFO - episode 5 step 80 reward tensor([-1]) loss 4.961276054382324 epsilon 0.7184850685945312
26-Feb-25 09:39:01 - agent.DQN.DQN - INFO - episode 5 step 81 reward tensor([-1]) loss 50.54766082763672 epsilon 0.7184850685945312
26-Feb-25 09:39:01 - agent.DQN.DQN - INFO - episode 5 step 82 reward tensor([-1]) loss 50.3721923828125 epsilon 0.7184850685945312
26-Feb-25 09:39:01 - agent.DQN.DQN - INFO - episode 5 step 83 reward tensor([-1]) loss 50.09019470214844 epsilon 0.7184850685945312
26-Feb-25 09:39:01 - agent.DQN.DQN - INFO - episode 5 step 84 reward tensor([-1]) loss 3.652813196182251 epsilon 0.7184850685945312
26-Feb-25 09:39:01 - agent.DQN.DQN - INFO - episode 5 step 85 reward tensor([-1]) loss 2.763023614883423 epsilon 0.7184850685945312
26-Feb-25 09:39:01 - agent.DQN.DQN - INFO - episode 5 step 86 reward tensor([-1]) loss 7.415686130523682 epsilon 0.7184850685945312
26-Feb-25 09:39:01 - agent.DQN.DQN - INFO - episode 5 step 87 reward tensor([-1]) loss 4.607483386993408 epsilon 0.7184850685945312
26-Feb-25 09:39:01 - agent.DQN.DQN - INFO - episode 5 step 88 reward tensor([-1]) loss 5.697805881500244 epsilon 0.7184850685945312
26-Feb-25 09:39:01 - agent.DQN.DQN - INFO - episode 5 step 89 reward tensor([-1]) loss 6.576446056365967 epsilon 0.7184850685945312
26-Feb-25 09:39:01 - agent.DQN.DQN - INFO - episode 5 step 90 reward tensor([-1]) loss 5.316269397735596 epsilon 0.7184850685945312
26-Feb-25 09:39:01 - agent.DQN.DQN - INFO - episode 5 step 91 reward tensor([-1]) loss 2.7631099224090576 epsilon 0.7184850685945312
26-Feb-25 09:39:01 - agent.DQN.DQN - INFO - episode 5 step 92 reward tensor([-1]) loss 4.078191757202148 epsilon 0.7184850685945312
26-Feb-25 09:39:01 - agent.DQN.DQN - INFO - episode 5 step 93 reward tensor([-1]) loss 6.321528911590576 epsilon 0.7184850685945312
26-Feb-25 09:39:01 - agent.DQN.DQN - INFO - episode 5 step 94 reward tensor([-1]) loss 52.06879806518555 epsilon 0.7184850685945312
26-Feb-25 09:39:01 - agent.DQN.DQN - INFO - episode 5 step 95 reward tensor([-1]) loss 3.4402918815612793 epsilon 0.7184850685945312
26-Feb-25 09:39:01 - agent.DQN.DQN - INFO - episode 5 step 96 reward tensor([-1]) loss 5.936007499694824 epsilon 0.7184850685945312
26-Feb-25 09:39:01 - agent.DQN.DQN - INFO - episode 5 step 97 reward tensor([-1]) loss 8.280571937561035 epsilon 0.7184850685945312
26-Feb-25 09:39:01 - agent.DQN.DQN - INFO - episode 5 step 98 reward tensor([-1]) loss 6.668915748596191 epsilon 0.7184850685945312
26-Feb-25 09:39:01 - agent.DQN.DQN - INFO - episode 5 step 99 reward tensor([-1]) loss 6.962031841278076 epsilon 0.7184850685945312
26-Feb-25 09:39:01 - agent.DQN.DQN - INFO - episode 5 step 100 reward tensor([-1]) loss 2.9854989051818848 epsilon 0.7184850685945312
26-Feb-25 09:39:01 - agent.DQN.DQN - INFO - episode 5 step 101 reward tensor([-1]) loss 3.723289966583252 epsilon 0.7184850685945312
26-Feb-25 09:39:01 - agent.DQN.DQN - INFO - episode 5 step 102 reward tensor([-1]) loss 2.072887659072876 epsilon 0.7184850685945312
26-Feb-25 09:39:01 - agent.DQN.DQN - INFO - episode 5 step 103 reward tensor([-1]) loss 7.329395771026611 epsilon 0.7184850685945312
26-Feb-25 09:39:01 - agent.DQN.DQN - INFO - episode 5 step 104 reward tensor([-1]) loss 2.7992167472839355 epsilon 0.7184850685945312
26-Feb-25 09:39:01 - agent.DQN.DQN - INFO - episode 5 step 105 reward tensor([-1]) loss 4.102142333984375 epsilon 0.7184850685945312
26-Feb-25 09:39:01 - agent.DQN.DQN - INFO - episode 5 step 106 reward tensor([-1]) loss 52.11433792114258 epsilon 0.7184850685945312
26-Feb-25 09:39:01 - agent.DQN.DQN - INFO - episode 5 step 107 reward tensor([-1]) loss 5.287810325622559 epsilon 0.7184850685945312
26-Feb-25 09:39:01 - agent.DQN.DQN - INFO - episode 5 step 108 reward tensor([-1]) loss 50.09724807739258 epsilon 0.7184850685945312
26-Feb-25 09:39:01 - agent.DQN.DQN - INFO - episode 5 step 109 reward tensor([-1]) loss 50.94552230834961 epsilon 0.7184850685945312
26-Feb-25 09:39:01 - agent.DQN.DQN - INFO - episode 5 step 110 reward tensor([-1]) loss 7.9393157958984375 epsilon 0.7184850685945312
26-Feb-25 09:39:01 - agent.DQN.DQN - INFO - episode 5 step 111 reward tensor([-1]) loss 5.708086013793945 epsilon 0.7184850685945312
26-Feb-25 09:39:01 - agent.DQN.DQN - INFO - episode 5 step 112 reward tensor([-1]) loss 4.434900283813477 epsilon 0.7184850685945312
26-Feb-25 09:39:01 - agent.DQN.DQN - INFO - episode 5 step 113 reward tensor([-1]) loss 50.60894775390625 epsilon 0.7184850685945312
26-Feb-25 09:39:02 - agent.DQN.DQN - INFO - episode 5 step 114 reward tensor([-1]) loss 3.7384073734283447 epsilon 0.7184850685945312
26-Feb-25 09:39:02 - agent.DQN.DQN - INFO - episode 5 step 115 reward tensor([-1]) loss 7.166267395019531 epsilon 0.7184850685945312
26-Feb-25 09:39:02 - agent.DQN.DQN - INFO - episode 5 step 116 reward tensor([-1]) loss 5.661468505859375 epsilon 0.7184850685945312
26-Feb-25 09:39:02 - agent.DQN.DQN - INFO - episode 5 step 117 reward tensor([-1]) loss 4.488724708557129 epsilon 0.7184850685945312
26-Feb-25 09:39:02 - agent.DQN.DQN - INFO - episode 5 step 118 reward tensor([-1]) loss 2.4486184120178223 epsilon 0.7184850685945312
26-Feb-25 09:39:02 - agent.DQN.DQN - INFO - episode 5 step 119 reward tensor([-1]) loss 2.9346671104431152 epsilon 0.7184850685945312
26-Feb-25 09:39:02 - agent.DQN.DQN - INFO - episode 5 step 120 reward tensor([-1]) loss 6.780740737915039 epsilon 0.7184850685945312
26-Feb-25 09:39:02 - agent.DQN.DQN - INFO - episode 5 step 121 reward tensor([-1]) loss 6.08047342300415 epsilon 0.7184850685945312
26-Feb-25 09:39:02 - agent.DQN.DQN - INFO - episode 5 step 122 reward tensor([-1]) loss 5.0585832595825195 epsilon 0.7184850685945312
26-Feb-25 09:39:02 - agent.DQN.DQN - INFO - episode 5 step 123 reward tensor([-1]) loss 5.535091876983643 epsilon 0.7184850685945312
26-Feb-25 09:39:02 - agent.DQN.DQN - INFO - episode 5 step 124 reward tensor([-1]) loss 48.70859146118164 epsilon 0.7184850685945312
26-Feb-25 09:39:02 - agent.DQN.DQN - INFO - episode 5 step 125 reward tensor([-1]) loss 3.6455078125 epsilon 0.7184850685945312
26-Feb-25 09:39:02 - agent.DQN.DQN - INFO - episode 5 step 126 reward tensor([-1]) loss 52.63862991333008 epsilon 0.7184850685945312
26-Feb-25 09:39:02 - agent.DQN.DQN - INFO - episode 5 step 127 reward tensor([-1]) loss 2.5280637741088867 epsilon 0.7184850685945312
26-Feb-25 09:39:02 - agent.DQN.DQN - INFO - episode 5 step 128 reward tensor([-1]) loss 4.766374588012695 epsilon 0.7184850685945312
26-Feb-25 09:39:02 - agent.DQN.DQN - INFO - episode 5 step 129 reward tensor([-1]) loss 6.125535011291504 epsilon 0.7184850685945312
26-Feb-25 09:39:02 - agent.DQN.DQN - INFO - episode 5 step 130 reward tensor([-1]) loss 4.1733479499816895 epsilon 0.7184850685945312
26-Feb-25 09:39:02 - agent.DQN.DQN - INFO - episode 5 step 131 reward tensor([-1]) loss 48.40342712402344 epsilon 0.7184850685945312
26-Feb-25 09:39:02 - agent.DQN.DQN - INFO - episode 5 step 132 reward tensor([-1]) loss 3.788828134536743 epsilon 0.7184850685945312
26-Feb-25 09:39:02 - agent.DQN.DQN - INFO - episode 5 step 133 reward tensor([-1]) loss 5.047065734863281 epsilon 0.7184850685945312
26-Feb-25 09:39:02 - agent.DQN.DQN - INFO - episode 5 step 134 reward tensor([-1]) loss 4.7880659103393555 epsilon 0.7184850685945312
26-Feb-25 09:39:02 - agent.DQN.DQN - INFO - episode 5 step 135 reward tensor([-1]) loss 4.496760845184326 epsilon 0.7184850685945312
26-Feb-25 09:39:02 - agent.DQN.DQN - INFO - episode 5 step 136 reward tensor([-1]) loss 9.734940528869629 epsilon 0.7184850685945312
26-Feb-25 09:39:02 - agent.DQN.DQN - INFO - episode 5 step 137 reward tensor([-1]) loss 6.513045310974121 epsilon 0.7184850685945312
26-Feb-25 09:39:02 - agent.DQN.DQN - INFO - episode 5 step 138 reward tensor([-1]) loss 47.885860443115234 epsilon 0.7184850685945312
26-Feb-25 09:39:02 - agent.DQN.DQN - INFO - episode 5 step 139 reward tensor([-1]) loss 5.500838756561279 epsilon 0.7184850685945312
26-Feb-25 09:39:02 - agent.DQN.DQN - INFO - episode 5 step 140 reward tensor([-1]) loss 4.237661361694336 epsilon 0.7184850685945312
26-Feb-25 09:39:02 - agent.DQN.DQN - INFO - episode 5 step 141 reward tensor([-1]) loss 47.346256256103516 epsilon 0.7184850685945312
26-Feb-25 09:39:02 - agent.DQN.DQN - INFO - episode 5 step 142 reward tensor([-1]) loss 5.090155601501465 epsilon 0.7184850685945312
26-Feb-25 09:39:02 - agent.DQN.DQN - INFO - episode 5 step 143 reward tensor([-1]) loss 5.990396499633789 epsilon 0.7184850685945312
26-Feb-25 09:39:02 - agent.DQN.DQN - INFO - episode 5 step 144 reward tensor([-1]) loss 5.819273948669434 epsilon 0.7184850685945312
26-Feb-25 09:39:02 - agent.DQN.DQN - INFO - episode 5 step 145 reward tensor([-1]) loss 9.421960830688477 epsilon 0.7184850685945312
26-Feb-25 09:39:02 - agent.DQN.DQN - INFO - episode 5 step 146 reward tensor([-1]) loss 6.193998336791992 epsilon 0.7184850685945312
26-Feb-25 09:39:02 - agent.DQN.DQN - INFO - episode 5 step 147 reward tensor([-1]) loss 2.5804736614227295 epsilon 0.7184850685945312
26-Feb-25 09:39:02 - agent.DQN.DQN - INFO - episode 5 step 148 reward tensor([-1]) loss 3.043860912322998 epsilon 0.7184850685945312
26-Feb-25 09:39:02 - agent.DQN.DQN - INFO - episode 5 step 149 reward tensor([-1]) loss 7.9864373207092285 epsilon 0.7184850685945312
26-Feb-25 09:39:02 - agent.DQN.DQN - INFO - episode 5 step 150 reward tensor([-1]) loss 4.075170516967773 epsilon 0.7184850685945312
26-Feb-25 09:39:02 - agent.DQN.DQN - INFO - episode 5 step 151 reward tensor([-1]) loss 49.69972229003906 epsilon 0.7184850685945312
26-Feb-25 09:39:02 - agent.DQN.DQN - INFO - episode 5 step 152 reward tensor([-1]) loss 6.6415791511535645 epsilon 0.7184850685945312
26-Feb-25 09:39:02 - agent.DQN.DQN - INFO - episode 5 step 153 reward tensor([-1]) loss 11.164670944213867 epsilon 0.7184850685945312
26-Feb-25 09:39:02 - agent.DQN.DQN - INFO - episode 5 step 154 reward tensor([-1]) loss 12.139464378356934 epsilon 0.7184850685945312
26-Feb-25 09:39:02 - agent.DQN.DQN - INFO - episode 5 step 155 reward tensor([-1]) loss 10.388935089111328 epsilon 0.7184850685945312
26-Feb-25 09:39:02 - agent.DQN.DQN - INFO - episode 5 step 156 reward tensor([-1]) loss 22.904827117919922 epsilon 0.7184850685945312
26-Feb-25 09:39:02 - agent.DQN.DQN - INFO - episode 5 step 157 reward tensor([-1]) loss 6.850701808929443 epsilon 0.7184850685945312
26-Feb-25 09:39:02 - agent.DQN.DQN - INFO - episode 5 step 158 reward tensor([-1]) loss 2.9568421840667725 epsilon 0.7184850685945312
26-Feb-25 09:39:02 - agent.DQN.DQN - INFO - episode 5 step 159 reward tensor([-1]) loss 19.296266555786133 epsilon 0.7184850685945312
26-Feb-25 09:39:02 - agent.DQN.DQN - INFO - episode 5 step 160 reward tensor([-1]) loss 11.511001586914062 epsilon 0.7184850685945312
26-Feb-25 09:39:02 - agent.DQN.DQN - INFO - episode 5 step 161 reward tensor([-1]) loss 57.18876266479492 epsilon 0.7184850685945312
26-Feb-25 09:39:02 - agent.DQN.DQN - INFO - episode 5 step 162 reward tensor([-1]) loss 24.412403106689453 epsilon 0.7184850685945312
26-Feb-25 09:39:02 - agent.DQN.DQN - INFO - episode 5 step 163 reward tensor([-1]) loss 16.410871505737305 epsilon 0.7184850685945312
26-Feb-25 09:39:02 - agent.DQN.DQN - INFO - episode 5 step 164 reward tensor([-1]) loss 9.127629280090332 epsilon 0.7184850685945312
26-Feb-25 09:39:02 - agent.DQN.DQN - INFO - episode 5 step 165 reward tensor([-1]) loss 29.44253158569336 epsilon 0.7184850685945312
26-Feb-25 09:39:02 - agent.DQN.DQN - INFO - episode 5 step 166 reward tensor([-1]) loss 3.489091157913208 epsilon 0.7184850685945312
26-Feb-25 09:39:02 - agent.DQN.DQN - INFO - episode 5 step 167 reward tensor([-1]) loss 11.804727554321289 epsilon 0.7184850685945312
26-Feb-25 09:39:02 - agent.DQN.DQN - INFO - episode 5 step 168 reward tensor([-1]) loss 15.792840957641602 epsilon 0.7184850685945312
26-Feb-25 09:39:02 - agent.DQN.DQN - INFO - episode 5 step 169 reward tensor([-1]) loss 13.163455963134766 epsilon 0.7184850685945312
26-Feb-25 09:39:02 - agent.DQN.DQN - INFO - episode 5 step 170 reward tensor([-1]) loss 15.095108985900879 epsilon 0.7184850685945312
26-Feb-25 09:39:02 - agent.DQN.DQN - INFO - episode 5 step 171 reward tensor([-1]) loss 18.94522476196289 epsilon 0.7184850685945312
26-Feb-25 09:39:02 - agent.DQN.DQN - INFO - episode 5 step 172 reward tensor([-1]) loss 7.97114896774292 epsilon 0.7184850685945312
26-Feb-25 09:39:02 - agent.DQN.DQN - INFO - episode 5 step 173 reward tensor([-1]) loss 24.96102523803711 epsilon 0.7184850685945312
26-Feb-25 09:39:02 - agent.DQN.DQN - INFO - episode 5 step 174 reward tensor([-1]) loss 17.263715744018555 epsilon 0.7184850685945312
26-Feb-25 09:39:02 - agent.DQN.DQN - INFO - episode 5 step 175 reward tensor([-1]) loss 67.34688568115234 epsilon 0.7184850685945312
26-Feb-25 09:39:02 - agent.DQN.DQN - INFO - episode 5 step 176 reward tensor([-1]) loss 8.858613967895508 epsilon 0.7184850685945312
26-Feb-25 09:39:02 - agent.DQN.DQN - INFO - episode 5 step 177 reward tensor([-1]) loss 13.22350025177002 epsilon 0.7184850685945312
26-Feb-25 09:39:02 - agent.DQN.DQN - INFO - episode 5 step 178 reward tensor([-1]) loss 5.383425712585449 epsilon 0.7184850685945312
26-Feb-25 09:39:02 - agent.DQN.DQN - INFO - episode 5 step 179 reward tensor([-1]) loss 10.909428596496582 epsilon 0.7184850685945312
26-Feb-25 09:39:02 - agent.DQN.DQN - INFO - episode 5 step 180 reward tensor([-1]) loss 21.5053653717041 epsilon 0.7184850685945312
26-Feb-25 09:39:03 - agent.DQN.DQN - INFO - episode 5 step 181 reward tensor([-1]) loss 6.878365993499756 epsilon 0.7184850685945312
26-Feb-25 09:39:03 - agent.DQN.DQN - INFO - episode 5 step 182 reward tensor([-1]) loss 12.523174285888672 epsilon 0.7184850685945312
26-Feb-25 09:39:03 - agent.DQN.DQN - INFO - episode 5 step 183 reward tensor([-1]) loss 9.122854232788086 epsilon 0.7184850685945312
26-Feb-25 09:39:03 - agent.DQN.DQN - INFO - episode 5 step 184 reward tensor([-1]) loss 10.100454330444336 epsilon 0.7184850685945312
26-Feb-25 09:39:03 - agent.DQN.DQN - INFO - episode 5 step 185 reward tensor([-1]) loss 10.257926940917969 epsilon 0.7184850685945312
26-Feb-25 09:39:03 - agent.DQN.DQN - INFO - episode 5 step 186 reward tensor([-1]) loss 12.007739067077637 epsilon 0.7184850685945312
26-Feb-25 09:39:03 - agent.DQN.DQN - INFO - episode 5 step 187 reward tensor([-1]) loss 52.00392150878906 epsilon 0.7184850685945312
26-Feb-25 09:39:03 - agent.DQN.DQN - INFO - episode 5 step 188 reward tensor([-1]) loss 9.010509490966797 epsilon 0.7184850685945312
26-Feb-25 09:39:03 - agent.DQN.DQN - INFO - episode 5 step 189 reward tensor([-1]) loss 10.965314865112305 epsilon 0.7184850685945312
26-Feb-25 09:39:03 - agent.DQN.DQN - INFO - episode 5 step 190 reward tensor([-1]) loss 5.86408805847168 epsilon 0.7184850685945312
26-Feb-25 09:39:03 - agent.DQN.DQN - INFO - episode 5 step 191 reward tensor([-1]) loss 13.984017372131348 epsilon 0.7184850685945312
26-Feb-25 09:39:03 - agent.DQN.DQN - INFO - episode 5 step 192 reward tensor([-1]) loss 15.184046745300293 epsilon 0.7184850685945312
26-Feb-25 09:39:03 - agent.DQN.DQN - INFO - episode 5 step 193 reward tensor([-1]) loss 51.98481369018555 epsilon 0.7184850685945312
26-Feb-25 09:39:03 - agent.DQN.DQN - INFO - episode 5 step 194 reward tensor([-1]) loss 3.6324098110198975 epsilon 0.7184850685945312
26-Feb-25 09:39:03 - agent.DQN.DQN - INFO - episode 5 step 195 reward tensor([-1]) loss 10.990289688110352 epsilon 0.7184850685945312
26-Feb-25 09:39:03 - agent.DQN.DQN - INFO - episode 5 step 196 reward tensor([-1]) loss 9.464323043823242 epsilon 0.7184850685945312
26-Feb-25 09:39:03 - agent.DQN.DQN - INFO - episode 5 step 197 reward tensor([-1]) loss 7.198697566986084 epsilon 0.7184850685945312
26-Feb-25 09:39:03 - agent.DQN.DQN - INFO - episode 5 step 198 reward tensor([-1]) loss 6.479135513305664 epsilon 0.7184850685945312
26-Feb-25 09:39:03 - agent.DQN.DQN - INFO - episode 5 step 199 reward tensor([-1]) loss 13.039375305175781 epsilon 0.7184850685945312
26-Feb-25 09:39:03 - agent.DQN.DQN - INFO - episode 5 step 200 reward tensor([-1]) loss 9.317173957824707 epsilon 0.7184850685945312
26-Feb-25 09:39:03 - agent.DQN.DQN - INFO - episode 5 step 201 reward tensor([-1]) loss 2.641500949859619 epsilon 0.7184850685945312
26-Feb-25 09:39:03 - agent.DQN.DQN - INFO - episode 5 step 202 reward tensor([-1]) loss 14.996232032775879 epsilon 0.7184850685945312
26-Feb-25 09:39:03 - agent.DQN.DQN - INFO - episode 5 step 203 reward tensor([-1]) loss 5.988311767578125 epsilon 0.7184850685945312
26-Feb-25 09:39:03 - agent.DQN.DQN - INFO - episode 5 step 204 reward tensor([-1]) loss 10.236754417419434 epsilon 0.7184850685945312
26-Feb-25 09:39:03 - agent.DQN.DQN - INFO - episode 5 step 205 reward tensor([-1]) loss 13.146305084228516 epsilon 0.7184850685945312
26-Feb-25 09:39:03 - agent.DQN.DQN - INFO - episode 5 step 206 reward tensor([-1]) loss 9.0224027633667 epsilon 0.7184850685945312
26-Feb-25 09:39:03 - agent.DQN.DQN - INFO - episode 5 step 207 reward tensor([-1]) loss 13.697027206420898 epsilon 0.7184850685945312
26-Feb-25 09:39:03 - agent.DQN.DQN - INFO - episode 5 step 208 reward tensor([-1]) loss 9.87340259552002 epsilon 0.7184850685945312
26-Feb-25 09:39:03 - agent.DQN.DQN - INFO - episode 5 step 209 reward tensor([-1]) loss 12.815857887268066 epsilon 0.7184850685945312
26-Feb-25 09:39:03 - agent.DQN.DQN - INFO - episode 5 step 210 reward tensor([-1]) loss 49.64958190917969 epsilon 0.7184850685945312
26-Feb-25 09:39:03 - agent.DQN.DQN - INFO - episode 5 step 211 reward tensor([-1]) loss 6.200015068054199 epsilon 0.7184850685945312
26-Feb-25 09:39:03 - agent.DQN.DQN - INFO - episode 5 step 212 reward tensor([-1]) loss 9.978769302368164 epsilon 0.7184850685945312
26-Feb-25 09:39:03 - agent.DQN.DQN - INFO - episode 5 step 213 reward tensor([-1]) loss 4.760804176330566 epsilon 0.7184850685945312
26-Feb-25 09:39:03 - agent.DQN.DQN - INFO - episode 5 step 214 reward tensor([-1]) loss 6.940855979919434 epsilon 0.7184850685945312
26-Feb-25 09:39:03 - agent.DQN.DQN - INFO - episode 5 step 215 reward tensor([-1]) loss 1.9428011178970337 epsilon 0.7184850685945312
26-Feb-25 09:39:03 - agent.DQN.DQN - INFO - episode 5 step 216 reward tensor([-1]) loss 8.339085578918457 epsilon 0.7184850685945312
26-Feb-25 09:39:03 - agent.DQN.DQN - INFO - episode 5 step 217 reward tensor([-1]) loss 7.581656455993652 epsilon 0.7184850685945312
26-Feb-25 09:39:03 - agent.DQN.DQN - INFO - episode 5 step 218 reward tensor([-1]) loss 17.607913970947266 epsilon 0.7184850685945312
26-Feb-25 09:39:03 - agent.DQN.DQN - INFO - episode 5 step 219 reward tensor([-1]) loss 9.336365699768066 epsilon 0.7184850685945312
26-Feb-25 09:39:03 - agent.DQN.DQN - INFO - episode 5 step 220 reward tensor([-1]) loss 6.2133893966674805 epsilon 0.7184850685945312
26-Feb-25 09:39:03 - agent.DQN.DQN - INFO - episode 5 step 221 reward tensor([-1]) loss 6.214363098144531 epsilon 0.7184850685945312
26-Feb-25 09:39:03 - agent.DQN.DQN - INFO - episode 5 step 222 reward tensor([-1]) loss 7.449272155761719 epsilon 0.7184850685945312
26-Feb-25 09:39:03 - agent.DQN.DQN - INFO - episode 5 step 223 reward tensor([-1]) loss 3.9956672191619873 epsilon 0.7184850685945312
26-Feb-25 09:39:03 - agent.DQN.DQN - INFO - episode 5 step 224 reward tensor([-1]) loss 2.609621286392212 epsilon 0.7184850685945312
26-Feb-25 09:39:03 - agent.DQN.DQN - INFO - episode 5 step 225 reward tensor([-1]) loss 7.341860771179199 epsilon 0.7184850685945312
26-Feb-25 09:39:03 - agent.DQN.DQN - INFO - episode 5 step 226 reward tensor([-1]) loss 8.295700073242188 epsilon 0.7184850685945312
26-Feb-25 09:39:03 - agent.DQN.DQN - INFO - episode 5 step 227 reward tensor([-1]) loss 3.747653007507324 epsilon 0.7184850685945312
26-Feb-25 09:39:03 - agent.DQN.DQN - INFO - episode 5 step 228 reward tensor([-1]) loss 12.274654388427734 epsilon 0.7184850685945312
26-Feb-25 09:39:03 - agent.DQN.DQN - INFO - episode 5 step 229 reward tensor([-1]) loss 4.439940929412842 epsilon 0.7184850685945312
26-Feb-25 09:39:03 - agent.DQN.DQN - INFO - episode 5 step 230 reward tensor([-1]) loss 10.78272533416748 epsilon 0.7184850685945312
26-Feb-25 09:39:03 - agent.DQN.DQN - INFO - episode 5 step 231 reward tensor([-1]) loss 5.092881202697754 epsilon 0.7184850685945312
26-Feb-25 09:39:03 - agent.DQN.DQN - INFO - episode 5 step 232 reward tensor([-1]) loss 1.7181450128555298 epsilon 0.7184850685945312
26-Feb-25 09:39:03 - agent.DQN.DQN - INFO - episode 5 step 233 reward tensor([-1]) loss 5.855297088623047 epsilon 0.7184850685945312
26-Feb-25 09:39:03 - agent.DQN.DQN - INFO - episode 5 step 234 reward tensor([-1]) loss 7.962184906005859 epsilon 0.7184850685945312
26-Feb-25 09:39:03 - agent.DQN.DQN - INFO - episode 5 step 235 reward tensor([-1]) loss 7.912978172302246 epsilon 0.7184850685945312
26-Feb-25 09:39:03 - agent.DQN.DQN - INFO - episode 5 step 236 reward tensor([-1]) loss 4.586732864379883 epsilon 0.7184850685945312
26-Feb-25 09:39:03 - agent.DQN.DQN - INFO - episode 5 step 237 reward tensor([-1]) loss 4.784355163574219 epsilon 0.7184850685945312
26-Feb-25 09:39:03 - agent.DQN.DQN - INFO - episode 5 step 238 reward tensor([-1]) loss 7.262539863586426 epsilon 0.7184850685945312
26-Feb-25 09:39:03 - agent.DQN.DQN - INFO - episode 5 step 239 reward tensor([-1]) loss 2.3409676551818848 epsilon 0.7184850685945312
26-Feb-25 09:39:03 - agent.DQN.DQN - INFO - episode 5 step 240 reward tensor([-1]) loss 7.687344551086426 epsilon 0.7184850685945312
26-Feb-25 09:39:03 - agent.DQN.DQN - INFO - episode 5 step 241 reward tensor([-1]) loss 8.745792388916016 epsilon 0.7184850685945312
26-Feb-25 09:39:03 - agent.DQN.DQN - INFO - episode 5 step 242 reward tensor([-1]) loss 6.373627185821533 epsilon 0.7184850685945312
26-Feb-25 09:39:03 - agent.DQN.DQN - INFO - episode 5 step 243 reward tensor([-1]) loss 2.8685004711151123 epsilon 0.7184850685945312
26-Feb-25 09:39:03 - agent.DQN.DQN - INFO - episode 5 step 244 reward tensor([-1]) loss 48.90473937988281 epsilon 0.7184850685945312
26-Feb-25 09:39:03 - agent.DQN.DQN - INFO - episode 5 step 245 reward tensor([-1]) loss 2.8534514904022217 epsilon 0.7184850685945312
26-Feb-25 09:39:03 - agent.DQN.DQN - INFO - episode 5 step 246 reward tensor([-1]) loss 48.68817138671875 epsilon 0.7184850685945312
26-Feb-25 09:39:03 - agent.DQN.DQN - INFO - episode 5 step 247 reward tensor([-1]) loss 3.866525888442993 epsilon 0.7184850685945312
26-Feb-25 09:39:03 - agent.DQN.DQN - INFO - episode 5 step 248 reward tensor([-1]) loss 2.726290702819824 epsilon 0.7184850685945312
26-Feb-25 09:39:03 - agent.DQN.DQN - INFO - episode 5 step 249 reward tensor([-1]) loss 5.994289398193359 epsilon 0.7184850685945312
26-Feb-25 09:39:03 - agent.DQN.DQN - INFO - episode 5 step 250 reward tensor([-1]) loss 4.996946811676025 epsilon 0.7184850685945312
26-Feb-25 09:39:03 - agent.DQN.DQN - INFO - episode 5 step 251 reward tensor([-1]) loss 2.7449870109558105 epsilon 0.7184850685945312
26-Feb-25 09:39:03 - agent.DQN.DQN - INFO - episode 5 step 252 reward tensor([-1]) loss 49.64476776123047 epsilon 0.7184850685945312
26-Feb-25 09:39:03 - agent.DQN.DQN - INFO - episode 5 step 253 reward tensor([-1]) loss 5.157979965209961 epsilon 0.7184850685945312
26-Feb-25 09:39:03 - agent.DQN.DQN - INFO - episode 5 step 254 reward tensor([-1]) loss 2.625732421875 epsilon 0.7184850685945312
26-Feb-25 09:39:03 - agent.DQN.DQN - INFO - episode 5 step 255 reward tensor([-1]) loss 3.0417470932006836 epsilon 0.7184850685945312
26-Feb-25 09:39:03 - agent.DQN.DQN - INFO - episode 5 step 256 reward tensor([-1]) loss 4.737162113189697 epsilon 0.7184850685945312
26-Feb-25 09:39:03 - agent.DQN.DQN - INFO - episode 5 step 257 reward tensor([-1]) loss 2.394948959350586 epsilon 0.7184850685945312
26-Feb-25 09:39:03 - agent.DQN.DQN - INFO - episode 5 step 258 reward tensor([-1]) loss 5.466949462890625 epsilon 0.7184850685945312
26-Feb-25 09:39:03 - agent.DQN.DQN - INFO - episode 5 step 259 reward tensor([-1]) loss 7.336069583892822 epsilon 0.7184850685945312
26-Feb-25 09:39:03 - agent.DQN.DQN - INFO - episode 5 step 260 reward tensor([-1]) loss 3.878964424133301 epsilon 0.7184850685945312
26-Feb-25 09:39:03 - agent.DQN.DQN - INFO - episode 5 step 261 reward tensor([-1]) loss 51.04356002807617 epsilon 0.7184850685945312
26-Feb-25 09:39:03 - agent.DQN.DQN - INFO - episode 5 step 262 reward tensor([-1]) loss 6.164816856384277 epsilon 0.7184850685945312
26-Feb-25 09:39:03 - agent.DQN.DQN - INFO - episode 5 step 263 reward tensor([-1]) loss 2.987067699432373 epsilon 0.7184850685945312
26-Feb-25 09:39:03 - agent.DQN.DQN - INFO - episode 5 step 264 reward tensor([-1]) loss 4.584404468536377 epsilon 0.7184850685945312
26-Feb-25 09:39:03 - agent.DQN.DQN - INFO - episode 5 step 265 reward tensor([-1]) loss 4.7513017654418945 epsilon 0.7184850685945312
26-Feb-25 09:39:03 - agent.DQN.DQN - INFO - episode 5 step 266 reward tensor([-1]) loss 3.831997871398926 epsilon 0.7184850685945312
26-Feb-25 09:39:03 - agent.DQN.DQN - INFO - episode 5 step 267 reward tensor([-1]) loss 4.717629432678223 epsilon 0.7184850685945312
26-Feb-25 09:39:03 - agent.DQN.DQN - INFO - episode 5 step 268 reward tensor([-1]) loss 3.514174461364746 epsilon 0.7184850685945312
26-Feb-25 09:39:03 - agent.DQN.DQN - INFO - episode 5 step 269 reward tensor([-1]) loss 3.1693246364593506 epsilon 0.7184850685945312
26-Feb-25 09:39:03 - agent.DQN.DQN - INFO - episode 5 step 270 reward tensor([-1]) loss 4.516376972198486 epsilon 0.7184850685945312
26-Feb-25 09:39:03 - agent.DQN.DQN - INFO - episode 5 step 271 reward tensor([-1]) loss 6.314703941345215 epsilon 0.7184850685945312
26-Feb-25 09:39:03 - agent.DQN.DQN - INFO - episode 5 step 272 reward tensor([-1]) loss 3.9984002113342285 epsilon 0.7184850685945312
26-Feb-25 09:39:04 - agent.DQN.DQN - INFO - episode 5 step 273 reward tensor([-1]) loss 51.13896179199219 epsilon 0.7184850685945312
26-Feb-25 09:39:04 - agent.DQN.DQN - INFO - episode 5 step 274 reward tensor([-1]) loss 5.317854881286621 epsilon 0.7184850685945312
26-Feb-25 09:39:04 - agent.DQN.DQN - INFO - episode 5 step 275 reward tensor([-1]) loss 4.3943891525268555 epsilon 0.7184850685945312
26-Feb-25 09:39:04 - agent.DQN.DQN - INFO - episode 5 step 276 reward tensor([-1]) loss 49.65480041503906 epsilon 0.7184850685945312
26-Feb-25 09:39:04 - agent.DQN.DQN - INFO - episode 5 step 277 reward tensor([-1]) loss 4.1357645988464355 epsilon 0.7184850685945312
26-Feb-25 09:39:04 - agent.DQN.DQN - INFO - episode 5 step 278 reward tensor([-1]) loss 6.150373935699463 epsilon 0.7184850685945312
26-Feb-25 09:39:04 - agent.DQN.DQN - INFO - episode 5 step 279 reward tensor([-1]) loss 4.521124839782715 epsilon 0.7184850685945312
26-Feb-25 09:39:04 - agent.DQN.DQN - INFO - episode 5 step 280 reward tensor([-1]) loss 2.7108020782470703 epsilon 0.7184850685945312
26-Feb-25 09:39:04 - agent.DQN.DQN - INFO - episode 5 step 281 reward tensor([-1]) loss 51.68037414550781 epsilon 0.7184850685945312
26-Feb-25 09:39:04 - agent.DQN.DQN - INFO - episode 5 step 282 reward tensor([-1]) loss 2.644137144088745 epsilon 0.7184850685945312
26-Feb-25 09:39:04 - agent.DQN.DQN - INFO - episode 5 step 283 reward tensor([-1]) loss 5.839122772216797 epsilon 0.7184850685945312
26-Feb-25 09:39:04 - agent.DQN.DQN - INFO - episode 5 step 284 reward tensor([-1]) loss 4.325348854064941 epsilon 0.7184850685945312
26-Feb-25 09:39:04 - agent.DQN.DQN - INFO - episode 5 step 285 reward tensor([-1]) loss 2.9414174556732178 epsilon 0.7184850685945312
26-Feb-25 09:39:04 - agent.DQN.DQN - INFO - episode 5 step 286 reward tensor([-1]) loss 3.3969058990478516 epsilon 0.7184850685945312
26-Feb-25 09:39:04 - agent.DQN.DQN - INFO - episode 5 step 287 reward tensor([-1]) loss 3.5447938442230225 epsilon 0.7184850685945312
26-Feb-25 09:39:04 - agent.DQN.DQN - INFO - episode 5 step 288 reward tensor([-1]) loss 54.22508239746094 epsilon 0.7184850685945312
26-Feb-25 09:39:04 - agent.DQN.DQN - INFO - episode 5 step 289 reward tensor([-1]) loss 2.7704293727874756 epsilon 0.7184850685945312
26-Feb-25 09:39:04 - agent.DQN.DQN - INFO - episode 5 step 290 reward tensor([-1]) loss 4.165107727050781 epsilon 0.7184850685945312
26-Feb-25 09:39:04 - agent.DQN.DQN - INFO - episode 5 step 291 reward tensor([-1]) loss 3.348163366317749 epsilon 0.7184850685945312
26-Feb-25 09:39:04 - agent.DQN.DQN - INFO - episode 5 step 292 reward tensor([-1]) loss 2.579119920730591 epsilon 0.7184850685945312
26-Feb-25 09:39:04 - agent.DQN.DQN - INFO - episode 5 step 293 reward tensor([-1]) loss 1.249818205833435 epsilon 0.7184850685945312
26-Feb-25 09:39:04 - agent.DQN.DQN - INFO - episode 5 step 294 reward tensor([-1]) loss 3.197653293609619 epsilon 0.7184850685945312
26-Feb-25 09:39:04 - agent.DQN.DQN - INFO - episode 5 step 295 reward tensor([-1]) loss 2.7683863639831543 epsilon 0.7184850685945312
26-Feb-25 09:39:04 - agent.DQN.DQN - INFO - episode 5 step 296 reward tensor([-1]) loss 3.1003894805908203 epsilon 0.7184850685945312
26-Feb-25 09:39:04 - agent.DQN.DQN - INFO - episode 5 step 297 reward tensor([-1]) loss 1.7344250679016113 epsilon 0.7184850685945312
26-Feb-25 09:39:04 - agent.DQN.DQN - INFO - episode 5 step 298 reward tensor([-1]) loss 4.088644981384277 epsilon 0.7184850685945312
26-Feb-25 09:39:04 - agent.DQN.DQN - INFO - episode 5 step 299 reward tensor([-1]) loss 2.9809956550598145 epsilon 0.7184850685945312
26-Feb-25 09:39:04 - agent.DQN.DQN - INFO - episode 5 step 300 reward tensor([-1]) loss 2.953190803527832 epsilon 0.7184850685945312
26-Feb-25 09:39:04 - agent.DQN.DQN - INFO - episode 5 step 301 reward tensor([-1]) loss 2.7615554332733154 epsilon 0.7184850685945312
26-Feb-25 09:39:04 - agent.DQN.DQN - INFO - episode 6 step 0 reward tensor([-1]) loss 3.863064765930176 epsilon 0.6951343038652089
26-Feb-25 09:39:04 - agent.DQN.DQN - INFO - episode 6 step 1 reward tensor([-1]) loss 1.8184585571289062 epsilon 0.6951343038652089
26-Feb-25 09:39:04 - agent.DQN.DQN - INFO - episode 6 step 2 reward tensor([-1]) loss 2.5899667739868164 epsilon 0.6951343038652089
26-Feb-25 09:39:04 - agent.DQN.DQN - INFO - episode 6 step 3 reward tensor([-1]) loss 4.194458484649658 epsilon 0.6951343038652089
26-Feb-25 09:39:04 - agent.DQN.DQN - INFO - episode 6 step 4 reward tensor([-1]) loss 1.4813603162765503 epsilon 0.6951343038652089
26-Feb-25 09:39:04 - agent.DQN.DQN - INFO - episode 6 step 5 reward tensor([-1]) loss 3.9731335639953613 epsilon 0.6951343038652089
26-Feb-25 09:39:04 - agent.DQN.DQN - INFO - episode 6 step 6 reward tensor([-1]) loss 1.336649775505066 epsilon 0.6951343038652089
26-Feb-25 09:39:04 - agent.DQN.DQN - INFO - episode 6 step 7 reward tensor([100]) loss 49.220943450927734 epsilon 0.6951343038652089
26-Feb-25 09:39:04 - agent.DQN.DQN - INFO - episode 7 step 0 reward tensor([-1]) loss 2.541259765625 epsilon 0.6725424389895897
26-Feb-25 09:39:04 - agent.DQN.DQN - INFO - episode 7 step 1 reward tensor([-1]) loss 2.4761953353881836 epsilon 0.6725424389895897
26-Feb-25 09:39:04 - agent.DQN.DQN - INFO - episode 7 step 2 reward tensor([-1]) loss 1.9917608499526978 epsilon 0.6725424389895897
26-Feb-25 09:39:04 - agent.DQN.DQN - INFO - episode 7 step 3 reward tensor([-1]) loss 2.0228025913238525 epsilon 0.6725424389895897
26-Feb-25 09:39:04 - agent.DQN.DQN - INFO - episode 7 step 4 reward tensor([-1]) loss 2.542545795440674 epsilon 0.6725424389895897
26-Feb-25 09:39:04 - agent.DQN.DQN - INFO - episode 7 step 5 reward tensor([-1]) loss 1.571325421333313 epsilon 0.6725424389895897
26-Feb-25 09:39:04 - agent.DQN.DQN - INFO - episode 7 step 6 reward tensor([-1]) loss 2.035762310028076 epsilon 0.6725424389895897
26-Feb-25 09:39:04 - agent.DQN.DQN - INFO - episode 7 step 7 reward tensor([-1]) loss 1.962512493133545 epsilon 0.6725424389895897
26-Feb-25 09:39:04 - agent.DQN.DQN - INFO - episode 7 step 8 reward tensor([-1]) loss 1.302198886871338 epsilon 0.6725424389895897
26-Feb-25 09:39:04 - agent.DQN.DQN - INFO - episode 7 step 9 reward tensor([-1]) loss 129.45364379882812 epsilon 0.6725424389895897
26-Feb-25 09:39:04 - agent.DQN.DQN - INFO - episode 7 step 10 reward tensor([-1]) loss 2.0856118202209473 epsilon 0.6725424389895897
26-Feb-25 09:39:04 - agent.DQN.DQN - INFO - episode 7 step 11 reward tensor([-1]) loss 1.7985562086105347 epsilon 0.6725424389895897
26-Feb-25 09:39:04 - agent.DQN.DQN - INFO - episode 7 step 12 reward tensor([-1]) loss 1.8972091674804688 epsilon 0.6725424389895897
26-Feb-25 09:39:04 - agent.DQN.DQN - INFO - episode 7 step 13 reward tensor([-1]) loss 3.5664844512939453 epsilon 0.6725424389895897
26-Feb-25 09:39:04 - agent.DQN.DQN - INFO - episode 7 step 14 reward tensor([-1]) loss 1.8227602243423462 epsilon 0.6725424389895897
26-Feb-25 09:39:04 - agent.DQN.DQN - INFO - episode 7 step 15 reward tensor([-1]) loss 0.9879225492477417 epsilon 0.6725424389895897
26-Feb-25 09:39:04 - agent.DQN.DQN - INFO - episode 7 step 16 reward tensor([-1]) loss 1.674422025680542 epsilon 0.6725424389895897
26-Feb-25 09:39:04 - agent.DQN.DQN - INFO - episode 7 step 17 reward tensor([-1]) loss 3.1987123489379883 epsilon 0.6725424389895897
26-Feb-25 09:39:04 - agent.DQN.DQN - INFO - episode 7 step 18 reward tensor([-1]) loss 79.89964294433594 epsilon 0.6725424389895897
26-Feb-25 09:39:04 - agent.DQN.DQN - INFO - episode 7 step 19 reward tensor([-1]) loss 2.7347140312194824 epsilon 0.6725424389895897
26-Feb-25 09:39:04 - agent.DQN.DQN - INFO - episode 7 step 20 reward tensor([-1]) loss 3.3567237854003906 epsilon 0.6725424389895897
26-Feb-25 09:39:04 - agent.DQN.DQN - INFO - episode 7 step 21 reward tensor([-1]) loss 2.2886228561401367 epsilon 0.6725424389895897
26-Feb-25 09:39:04 - agent.DQN.DQN - INFO - episode 7 step 22 reward tensor([-1]) loss 1.7734827995300293 epsilon 0.6725424389895897
26-Feb-25 09:39:04 - agent.DQN.DQN - INFO - episode 7 step 23 reward tensor([-1]) loss 1.3078563213348389 epsilon 0.6725424389895897
26-Feb-25 09:39:04 - agent.DQN.DQN - INFO - episode 7 step 24 reward tensor([-1]) loss 52.237545013427734 epsilon 0.6725424389895897
26-Feb-25 09:39:04 - agent.DQN.DQN - INFO - episode 7 step 25 reward tensor([-1]) loss 2.307671308517456 epsilon 0.6725424389895897
26-Feb-25 09:39:04 - agent.DQN.DQN - INFO - episode 7 step 26 reward tensor([-1]) loss 2.014448881149292 epsilon 0.6725424389895897
26-Feb-25 09:39:04 - agent.DQN.DQN - INFO - episode 7 step 27 reward tensor([-1]) loss 1.2733967304229736 epsilon 0.6725424389895897
26-Feb-25 09:39:04 - agent.DQN.DQN - INFO - episode 7 step 28 reward tensor([-1]) loss 1.393413782119751 epsilon 0.6725424389895897
26-Feb-25 09:39:04 - agent.DQN.DQN - INFO - episode 7 step 29 reward tensor([-1]) loss 2.301762819290161 epsilon 0.6725424389895897
26-Feb-25 09:39:04 - agent.DQN.DQN - INFO - episode 7 step 30 reward tensor([-1]) loss 3.3196918964385986 epsilon 0.6725424389895897
26-Feb-25 09:39:04 - agent.DQN.DQN - INFO - episode 7 step 31 reward tensor([-1]) loss 1.8484930992126465 epsilon 0.6725424389895897
26-Feb-25 09:39:04 - agent.DQN.DQN - INFO - episode 7 step 32 reward tensor([-1]) loss 1.5090652704238892 epsilon 0.6725424389895897
26-Feb-25 09:39:04 - agent.DQN.DQN - INFO - episode 7 step 33 reward tensor([-1]) loss 1.8302356004714966 epsilon 0.6725424389895897
26-Feb-25 09:39:04 - agent.DQN.DQN - INFO - episode 7 step 34 reward tensor([-1]) loss 1.3611406087875366 epsilon 0.6725424389895897
26-Feb-25 09:39:04 - agent.DQN.DQN - INFO - episode 7 step 35 reward tensor([-1]) loss 50.82870101928711 epsilon 0.6725424389895897
26-Feb-25 09:39:04 - agent.DQN.DQN - INFO - episode 7 step 36 reward tensor([-1]) loss 1.5279576778411865 epsilon 0.6725424389895897
26-Feb-25 09:39:04 - agent.DQN.DQN - INFO - episode 7 step 37 reward tensor([-1]) loss 2.5156314373016357 epsilon 0.6725424389895897
26-Feb-25 09:39:04 - agent.DQN.DQN - INFO - episode 7 step 38 reward tensor([-1]) loss 1.190270185470581 epsilon 0.6725424389895897
26-Feb-25 09:39:04 - agent.DQN.DQN - INFO - episode 7 step 39 reward tensor([-1]) loss 1.5936460494995117 epsilon 0.6725424389895897
26-Feb-25 09:39:04 - agent.DQN.DQN - INFO - episode 7 step 40 reward tensor([-1]) loss 1.8004941940307617 epsilon 0.6725424389895897
26-Feb-25 09:39:04 - agent.DQN.DQN - INFO - episode 7 step 41 reward tensor([-1]) loss 50.26564407348633 epsilon 0.6725424389895897
26-Feb-25 09:39:04 - agent.DQN.DQN - INFO - episode 7 step 42 reward tensor([-1]) loss 1.493889570236206 epsilon 0.6725424389895897
26-Feb-25 09:39:04 - agent.DQN.DQN - INFO - episode 7 step 43 reward tensor([-1]) loss 2.112417459487915 epsilon 0.6725424389895897
26-Feb-25 09:39:04 - agent.DQN.DQN - INFO - episode 7 step 44 reward tensor([-1]) loss 1.29472017288208 epsilon 0.6725424389895897
26-Feb-25 09:39:04 - agent.DQN.DQN - INFO - episode 7 step 45 reward tensor([-1]) loss 1.8703452348709106 epsilon 0.6725424389895897
26-Feb-25 09:39:04 - agent.DQN.DQN - INFO - episode 7 step 46 reward tensor([-1]) loss 1.0837960243225098 epsilon 0.6725424389895897
26-Feb-25 09:39:04 - agent.DQN.DQN - INFO - episode 7 step 47 reward tensor([-1]) loss 2.7480595111846924 epsilon 0.6725424389895897
26-Feb-25 09:39:04 - agent.DQN.DQN - INFO - episode 7 step 48 reward tensor([-1]) loss 49.56874465942383 epsilon 0.6725424389895897
26-Feb-25 09:39:04 - agent.DQN.DQN - INFO - episode 7 step 49 reward tensor([-1]) loss 78.99312591552734 epsilon 0.6725424389895897
26-Feb-25 09:39:04 - agent.DQN.DQN - INFO - episode 7 step 50 reward tensor([-1]) loss 2.082784652709961 epsilon 0.6725424389895897
26-Feb-25 09:39:05 - agent.DQN.DQN - INFO - episode 7 step 51 reward tensor([-1]) loss 2.055972099304199 epsilon 0.6725424389895897
26-Feb-25 09:39:05 - agent.DQN.DQN - INFO - episode 7 step 52 reward tensor([-1]) loss 1.8709948062896729 epsilon 0.6725424389895897
26-Feb-25 09:39:05 - agent.DQN.DQN - INFO - episode 7 step 53 reward tensor([-1]) loss 0.8659133315086365 epsilon 0.6725424389895897
26-Feb-25 09:39:05 - agent.DQN.DQN - INFO - episode 7 step 54 reward tensor([-1]) loss 1.3624762296676636 epsilon 0.6725424389895897
26-Feb-25 09:39:05 - agent.DQN.DQN - INFO - episode 7 step 55 reward tensor([-1]) loss 1.8035434484481812 epsilon 0.6725424389895897
26-Feb-25 09:39:05 - agent.DQN.DQN - INFO - episode 7 step 56 reward tensor([-1]) loss 1.6523197889328003 epsilon 0.6725424389895897
26-Feb-25 09:39:05 - agent.DQN.DQN - INFO - episode 7 step 57 reward tensor([-1]) loss 1.2213168144226074 epsilon 0.6725424389895897
26-Feb-25 09:39:05 - agent.DQN.DQN - INFO - episode 7 step 58 reward tensor([-1]) loss 1.3525099754333496 epsilon 0.6725424389895897
26-Feb-25 09:39:05 - agent.DQN.DQN - INFO - episode 7 step 59 reward tensor([-1]) loss 50.2275505065918 epsilon 0.6725424389895897
26-Feb-25 09:39:05 - agent.DQN.DQN - INFO - episode 7 step 60 reward tensor([-1]) loss 3.514816999435425 epsilon 0.6725424389895897
26-Feb-25 09:39:05 - agent.DQN.DQN - INFO - episode 7 step 61 reward tensor([-1]) loss 1.9193720817565918 epsilon 0.6725424389895897
26-Feb-25 09:39:05 - agent.DQN.DQN - INFO - episode 7 step 62 reward tensor([-1]) loss 1.3929356336593628 epsilon 0.6725424389895897
26-Feb-25 09:39:05 - agent.DQN.DQN - INFO - episode 7 step 63 reward tensor([-1]) loss 1.6551496982574463 epsilon 0.6725424389895897
26-Feb-25 09:39:05 - agent.DQN.DQN - INFO - episode 7 step 64 reward tensor([-1]) loss 0.8653472661972046 epsilon 0.6725424389895897
26-Feb-25 09:39:05 - agent.DQN.DQN - INFO - episode 7 step 65 reward tensor([-1]) loss 78.77738952636719 epsilon 0.6725424389895897
26-Feb-25 09:39:05 - agent.DQN.DQN - INFO - episode 7 step 66 reward tensor([-1]) loss 1.0489948987960815 epsilon 0.6725424389895897
26-Feb-25 09:39:05 - agent.DQN.DQN - INFO - episode 7 step 67 reward tensor([-1]) loss 1.2942335605621338 epsilon 0.6725424389895897
26-Feb-25 09:39:05 - agent.DQN.DQN - INFO - episode 7 step 68 reward tensor([-1]) loss 49.968502044677734 epsilon 0.6725424389895897
26-Feb-25 09:39:05 - agent.DQN.DQN - INFO - episode 7 step 69 reward tensor([-1]) loss 2.1162781715393066 epsilon 0.6725424389895897
26-Feb-25 09:39:05 - agent.DQN.DQN - INFO - episode 7 step 70 reward tensor([-1]) loss 1.9653078317642212 epsilon 0.6725424389895897
26-Feb-25 09:39:05 - agent.DQN.DQN - INFO - episode 7 step 71 reward tensor([-1]) loss 78.23822784423828 epsilon 0.6725424389895897
26-Feb-25 09:39:05 - agent.DQN.DQN - INFO - episode 7 step 72 reward tensor([-1]) loss 1.3285958766937256 epsilon 0.6725424389895897
26-Feb-25 09:39:05 - agent.DQN.DQN - INFO - episode 7 step 73 reward tensor([-1]) loss 2.7355294227600098 epsilon 0.6725424389895897
26-Feb-25 09:39:05 - agent.DQN.DQN - INFO - episode 7 step 74 reward tensor([-1]) loss 2.4839959144592285 epsilon 0.6725424389895897
26-Feb-25 09:39:05 - agent.DQN.DQN - INFO - episode 7 step 75 reward tensor([-1]) loss 1.1000990867614746 epsilon 0.6725424389895897
26-Feb-25 09:39:05 - agent.DQN.DQN - INFO - episode 7 step 76 reward tensor([-1]) loss 3.077990770339966 epsilon 0.6725424389895897
26-Feb-25 09:39:05 - agent.DQN.DQN - INFO - episode 7 step 77 reward tensor([-1]) loss 1.4008467197418213 epsilon 0.6725424389895897
26-Feb-25 09:39:05 - agent.DQN.DQN - INFO - episode 7 step 78 reward tensor([-1]) loss 0.9307851195335388 epsilon 0.6725424389895897
26-Feb-25 09:39:05 - agent.DQN.DQN - INFO - episode 7 step 79 reward tensor([-1]) loss 2.521160840988159 epsilon 0.6725424389895897
26-Feb-25 09:39:05 - agent.DQN.DQN - INFO - episode 7 step 80 reward tensor([-1]) loss 1.6815123558044434 epsilon 0.6725424389895897
26-Feb-25 09:39:05 - agent.DQN.DQN - INFO - episode 7 step 81 reward tensor([-1]) loss 2.3159000873565674 epsilon 0.6725424389895897
26-Feb-25 09:39:05 - agent.DQN.DQN - INFO - episode 7 step 82 reward tensor([-1]) loss 1.7063570022583008 epsilon 0.6725424389895897
26-Feb-25 09:39:05 - agent.DQN.DQN - INFO - episode 7 step 83 reward tensor([-1]) loss 0.8984165787696838 epsilon 0.6725424389895897
26-Feb-25 09:39:05 - agent.DQN.DQN - INFO - episode 7 step 84 reward tensor([-1]) loss 79.68229675292969 epsilon 0.6725424389895897
26-Feb-25 09:39:05 - agent.DQN.DQN - INFO - episode 7 step 85 reward tensor([-1]) loss 0.7353922724723816 epsilon 0.6725424389895897
26-Feb-25 09:39:05 - agent.DQN.DQN - INFO - episode 7 step 86 reward tensor([-1]) loss 1.828134298324585 epsilon 0.6725424389895897
26-Feb-25 09:39:05 - agent.DQN.DQN - INFO - episode 7 step 87 reward tensor([-1]) loss 49.435447692871094 epsilon 0.6725424389895897
26-Feb-25 09:39:05 - agent.DQN.DQN - INFO - episode 7 step 88 reward tensor([-1]) loss 1.5760217905044556 epsilon 0.6725424389895897
26-Feb-25 09:39:05 - agent.DQN.DQN - INFO - episode 7 step 89 reward tensor([-1]) loss 1.4754940271377563 epsilon 0.6725424389895897
26-Feb-25 09:39:05 - agent.DQN.DQN - INFO - episode 7 step 90 reward tensor([-1]) loss 2.0115017890930176 epsilon 0.6725424389895897
26-Feb-25 09:39:05 - agent.DQN.DQN - INFO - episode 7 step 91 reward tensor([-1]) loss 1.6542997360229492 epsilon 0.6725424389895897
26-Feb-25 09:39:05 - agent.DQN.DQN - INFO - episode 7 step 92 reward tensor([-1]) loss 79.48361206054688 epsilon 0.6725424389895897
26-Feb-25 09:39:05 - agent.DQN.DQN - INFO - episode 7 step 93 reward tensor([-1]) loss 1.3889474868774414 epsilon 0.6725424389895897
26-Feb-25 09:39:05 - agent.DQN.DQN - INFO - episode 7 step 94 reward tensor([-1]) loss 1.1680151224136353 epsilon 0.6725424389895897
26-Feb-25 09:39:05 - agent.DQN.DQN - INFO - episode 7 step 95 reward tensor([-1]) loss 1.3844140768051147 epsilon 0.6725424389895897
26-Feb-25 09:39:05 - agent.DQN.DQN - INFO - episode 7 step 96 reward tensor([-1]) loss 1.3888365030288696 epsilon 0.6725424389895897
26-Feb-25 09:39:05 - agent.DQN.DQN - INFO - episode 7 step 97 reward tensor([-1]) loss 1.5288505554199219 epsilon 0.6725424389895897
26-Feb-25 09:39:05 - agent.DQN.DQN - INFO - episode 7 step 98 reward tensor([-1]) loss 1.76229727268219 epsilon 0.6725424389895897
26-Feb-25 09:39:05 - agent.DQN.DQN - INFO - episode 7 step 99 reward tensor([-1]) loss 50.32847213745117 epsilon 0.6725424389895897
26-Feb-25 09:39:05 - agent.DQN.DQN - INFO - episode 7 step 100 reward tensor([-1]) loss 1.424768090248108 epsilon 0.6725424389895897
26-Feb-25 09:39:05 - agent.DQN.DQN - INFO - episode 7 step 101 reward tensor([-1]) loss 1.0456408262252808 epsilon 0.6725424389895897
26-Feb-25 09:39:05 - agent.DQN.DQN - INFO - episode 7 step 102 reward tensor([-1]) loss 0.7355548143386841 epsilon 0.6725424389895897
26-Feb-25 09:39:05 - agent.DQN.DQN - INFO - episode 7 step 103 reward tensor([-1]) loss 1.2797034978866577 epsilon 0.6725424389895897
26-Feb-25 09:39:05 - agent.DQN.DQN - INFO - episode 7 step 104 reward tensor([-1]) loss 50.312625885009766 epsilon 0.6725424389895897
26-Feb-25 09:39:05 - agent.DQN.DQN - INFO - episode 7 step 105 reward tensor([-1]) loss 1.2211555242538452 epsilon 0.6725424389895897
26-Feb-25 09:39:05 - agent.DQN.DQN - INFO - episode 7 step 106 reward tensor([-1]) loss 51.182682037353516 epsilon 0.6725424389895897
26-Feb-25 09:39:05 - agent.DQN.DQN - INFO - episode 7 step 107 reward tensor([-1]) loss 1.231186866760254 epsilon 0.6725424389895897
26-Feb-25 09:39:05 - agent.DQN.DQN - INFO - episode 7 step 108 reward tensor([-1]) loss 1.4541757106781006 epsilon 0.6725424389895897
26-Feb-25 09:39:05 - agent.DQN.DQN - INFO - episode 7 step 109 reward tensor([-1]) loss 1.0404976606369019 epsilon 0.6725424389895897
26-Feb-25 09:39:05 - agent.DQN.DQN - INFO - episode 7 step 110 reward tensor([-1]) loss 0.830474853515625 epsilon 0.6725424389895897
26-Feb-25 09:39:05 - agent.DQN.DQN - INFO - episode 7 step 111 reward tensor([-1]) loss 1.110440731048584 epsilon 0.6725424389895897
26-Feb-25 09:39:05 - agent.DQN.DQN - INFO - episode 7 step 112 reward tensor([-1]) loss 50.689300537109375 epsilon 0.6725424389895897
26-Feb-25 09:39:05 - agent.DQN.DQN - INFO - episode 7 step 113 reward tensor([-1]) loss 1.0952454805374146 epsilon 0.6725424389895897
26-Feb-25 09:39:05 - agent.DQN.DQN - INFO - episode 7 step 114 reward tensor([-1]) loss 78.68010711669922 epsilon 0.6725424389895897
26-Feb-25 09:39:05 - agent.DQN.DQN - INFO - episode 7 step 115 reward tensor([-1]) loss 0.6979244947433472 epsilon 0.6725424389895897
26-Feb-25 09:39:05 - agent.DQN.DQN - INFO - episode 7 step 116 reward tensor([-1]) loss 1.0028282403945923 epsilon 0.6725424389895897
26-Feb-25 09:39:05 - agent.DQN.DQN - INFO - episode 7 step 117 reward tensor([-1]) loss 1.4123001098632812 epsilon 0.6725424389895897
26-Feb-25 09:39:05 - agent.DQN.DQN - INFO - episode 7 step 118 reward tensor([-1]) loss 1.5527331829071045 epsilon 0.6725424389895897
26-Feb-25 09:39:05 - agent.DQN.DQN - INFO - episode 7 step 119 reward tensor([-1]) loss 1.6279902458190918 epsilon 0.6725424389895897
26-Feb-25 09:39:05 - agent.DQN.DQN - INFO - episode 7 step 120 reward tensor([-1]) loss 78.80461120605469 epsilon 0.6725424389895897
26-Feb-25 09:39:05 - agent.DQN.DQN - INFO - episode 7 step 121 reward tensor([-1]) loss 0.9984411001205444 epsilon 0.6725424389895897
26-Feb-25 09:39:05 - agent.DQN.DQN - INFO - episode 7 step 122 reward tensor([-1]) loss 2.3017706871032715 epsilon 0.6725424389895897
26-Feb-25 09:39:05 - agent.DQN.DQN - INFO - episode 7 step 123 reward tensor([-1]) loss 0.7001773715019226 epsilon 0.6725424389895897
26-Feb-25 09:39:05 - agent.DQN.DQN - INFO - episode 7 step 124 reward tensor([-1]) loss 2.2885100841522217 epsilon 0.6725424389895897
26-Feb-25 09:39:05 - agent.DQN.DQN - INFO - episode 7 step 125 reward tensor([-1]) loss 1.4400689601898193 epsilon 0.6725424389895897
26-Feb-25 09:39:05 - agent.DQN.DQN - INFO - episode 7 step 126 reward tensor([-1]) loss 1.0001015663146973 epsilon 0.6725424389895897
26-Feb-25 09:39:05 - agent.DQN.DQN - INFO - episode 7 step 127 reward tensor([-1]) loss 1.683058500289917 epsilon 0.6725424389895897
26-Feb-25 09:39:05 - agent.DQN.DQN - INFO - episode 7 step 128 reward tensor([-1]) loss 1.381824016571045 epsilon 0.6725424389895897
26-Feb-25 09:39:05 - agent.DQN.DQN - INFO - episode 7 step 129 reward tensor([-1]) loss 1.35701584815979 epsilon 0.6725424389895897
26-Feb-25 09:39:05 - agent.DQN.DQN - INFO - episode 7 step 130 reward tensor([-1]) loss 1.2349432706832886 epsilon 0.6725424389895897
26-Feb-25 09:39:05 - agent.DQN.DQN - INFO - episode 7 step 131 reward tensor([-1]) loss 1.5072073936462402 epsilon 0.6725424389895897
26-Feb-25 09:39:05 - agent.DQN.DQN - INFO - episode 7 step 132 reward tensor([-1]) loss 49.548194885253906 epsilon 0.6725424389895897
26-Feb-25 09:39:05 - agent.DQN.DQN - INFO - episode 7 step 133 reward tensor([-1]) loss 1.1800940036773682 epsilon 0.6725424389895897
26-Feb-25 09:39:05 - agent.DQN.DQN - INFO - episode 7 step 134 reward tensor([-1]) loss 79.08089447021484 epsilon 0.6725424389895897
26-Feb-25 09:39:06 - agent.DQN.DQN - INFO - episode 7 step 135 reward tensor([-1]) loss 0.672410249710083 epsilon 0.6725424389895897
26-Feb-25 09:39:06 - agent.DQN.DQN - INFO - episode 7 step 136 reward tensor([-1]) loss 0.9355124235153198 epsilon 0.6725424389895897
26-Feb-25 09:39:06 - agent.DQN.DQN - INFO - episode 7 step 137 reward tensor([-1]) loss 49.627872467041016 epsilon 0.6725424389895897
26-Feb-25 09:39:06 - agent.DQN.DQN - INFO - episode 7 step 138 reward tensor([-1]) loss 1.1843894720077515 epsilon 0.6725424389895897
26-Feb-25 09:39:06 - agent.DQN.DQN - INFO - episode 7 step 139 reward tensor([-1]) loss 1.0457878112792969 epsilon 0.6725424389895897
26-Feb-25 09:39:06 - agent.DQN.DQN - INFO - episode 7 step 140 reward tensor([-1]) loss 1.1521294116973877 epsilon 0.6725424389895897
26-Feb-25 09:39:06 - agent.DQN.DQN - INFO - episode 7 step 141 reward tensor([-1]) loss 0.9399831891059875 epsilon 0.6725424389895897
26-Feb-25 09:39:06 - agent.DQN.DQN - INFO - episode 7 step 142 reward tensor([-1]) loss 0.82794588804245 epsilon 0.6725424389895897
26-Feb-25 09:39:06 - agent.DQN.DQN - INFO - episode 7 step 143 reward tensor([-1]) loss 77.90782165527344 epsilon 0.6725424389895897
26-Feb-25 09:39:06 - agent.DQN.DQN - INFO - episode 7 step 144 reward tensor([-1]) loss 1.0229942798614502 epsilon 0.6725424389895897
26-Feb-25 09:39:06 - agent.DQN.DQN - INFO - episode 7 step 145 reward tensor([-1]) loss 0.8294034004211426 epsilon 0.6725424389895897
26-Feb-25 09:39:06 - agent.DQN.DQN - INFO - episode 7 step 146 reward tensor([-1]) loss 1.1207791566848755 epsilon 0.6725424389895897
26-Feb-25 09:39:06 - agent.DQN.DQN - INFO - episode 7 step 147 reward tensor([-1]) loss 2.3356785774230957 epsilon 0.6725424389895897
26-Feb-25 09:39:06 - agent.DQN.DQN - INFO - episode 7 step 148 reward tensor([-1]) loss 78.3814926147461 epsilon 0.6725424389895897
26-Feb-25 09:39:06 - agent.DQN.DQN - INFO - episode 7 step 149 reward tensor([-1]) loss 1.5558576583862305 epsilon 0.6725424389895897
26-Feb-25 09:39:06 - agent.DQN.DQN - INFO - episode 7 step 150 reward tensor([-1]) loss 1.2815946340560913 epsilon 0.6725424389895897
26-Feb-25 09:39:06 - agent.DQN.DQN - INFO - episode 7 step 151 reward tensor([-1]) loss 1.0591694116592407 epsilon 0.6725424389895897
26-Feb-25 09:39:06 - agent.DQN.DQN - INFO - episode 7 step 152 reward tensor([-1]) loss 1.0048397779464722 epsilon 0.6725424389895897
26-Feb-25 09:39:06 - agent.DQN.DQN - INFO - episode 7 step 153 reward tensor([-1]) loss 2.134629487991333 epsilon 0.6725424389895897
26-Feb-25 09:39:06 - agent.DQN.DQN - INFO - episode 7 step 154 reward tensor([-1]) loss 78.01337432861328 epsilon 0.6725424389895897
26-Feb-25 09:39:06 - agent.DQN.DQN - INFO - episode 7 step 155 reward tensor([-1]) loss 0.5681301355361938 epsilon 0.6725424389895897
26-Feb-25 09:39:06 - agent.DQN.DQN - INFO - episode 7 step 156 reward tensor([-1]) loss 1.3565165996551514 epsilon 0.6725424389895897
26-Feb-25 09:39:06 - agent.DQN.DQN - INFO - episode 7 step 157 reward tensor([-1]) loss 1.3380686044692993 epsilon 0.6725424389895897
26-Feb-25 09:39:06 - agent.DQN.DQN - INFO - episode 7 step 158 reward tensor([-1]) loss 1.2628673315048218 epsilon 0.6725424389895897
26-Feb-25 09:39:06 - agent.DQN.DQN - INFO - episode 7 step 159 reward tensor([-1]) loss 0.7093807458877563 epsilon 0.6725424389895897
26-Feb-25 09:39:06 - agent.DQN.DQN - INFO - episode 7 step 160 reward tensor([-1]) loss 0.9005467891693115 epsilon 0.6725424389895897
26-Feb-25 09:39:06 - agent.DQN.DQN - INFO - episode 7 step 161 reward tensor([-1]) loss 1.1328482627868652 epsilon 0.6725424389895897
26-Feb-25 09:39:06 - agent.DQN.DQN - INFO - episode 7 step 162 reward tensor([-1]) loss 50.273685455322266 epsilon 0.6725424389895897
26-Feb-25 09:39:06 - agent.DQN.DQN - INFO - episode 7 step 163 reward tensor([-1]) loss 0.9370882511138916 epsilon 0.6725424389895897
26-Feb-25 09:39:06 - agent.DQN.DQN - INFO - episode 7 step 164 reward tensor([-1]) loss 50.26407241821289 epsilon 0.6725424389895897
26-Feb-25 09:39:06 - agent.DQN.DQN - INFO - episode 7 step 165 reward tensor([-1]) loss 1.3186336755752563 epsilon 0.6725424389895897
26-Feb-25 09:39:06 - agent.DQN.DQN - INFO - episode 7 step 166 reward tensor([-1]) loss 1.0219087600708008 epsilon 0.6725424389895897
26-Feb-25 09:39:06 - agent.DQN.DQN - INFO - episode 7 step 167 reward tensor([-1]) loss 1.1022837162017822 epsilon 0.6725424389895897
26-Feb-25 09:39:06 - agent.DQN.DQN - INFO - episode 7 step 168 reward tensor([-1]) loss 0.7956340909004211 epsilon 0.6725424389895897
26-Feb-25 09:39:06 - agent.DQN.DQN - INFO - episode 7 step 169 reward tensor([-1]) loss 127.36647033691406 epsilon 0.6725424389895897
26-Feb-25 09:39:06 - agent.DQN.DQN - INFO - episode 7 step 170 reward tensor([-1]) loss 1.138481616973877 epsilon 0.6725424389895897
26-Feb-25 09:39:06 - agent.DQN.DQN - INFO - episode 7 step 171 reward tensor([-1]) loss 0.954053521156311 epsilon 0.6725424389895897
26-Feb-25 09:39:06 - agent.DQN.DQN - INFO - episode 7 step 172 reward tensor([-1]) loss 2.1339051723480225 epsilon 0.6725424389895897
26-Feb-25 09:39:06 - agent.DQN.DQN - INFO - episode 7 step 173 reward tensor([-1]) loss 1.0134340524673462 epsilon 0.6725424389895897
26-Feb-25 09:39:06 - agent.DQN.DQN - INFO - episode 7 step 174 reward tensor([-1]) loss 77.73139190673828 epsilon 0.6725424389895897
26-Feb-25 09:39:06 - agent.DQN.DQN - INFO - episode 7 step 175 reward tensor([-1]) loss 0.809055745601654 epsilon 0.6725424389895897
26-Feb-25 09:39:06 - agent.DQN.DQN - INFO - episode 7 step 176 reward tensor([-1]) loss 1.3012558221817017 epsilon 0.6725424389895897
26-Feb-25 09:39:06 - agent.DQN.DQN - INFO - episode 7 step 177 reward tensor([-1]) loss 1.1057811975479126 epsilon 0.6725424389895897
26-Feb-25 09:39:06 - agent.DQN.DQN - INFO - episode 7 step 178 reward tensor([-1]) loss 1.2579209804534912 epsilon 0.6725424389895897
26-Feb-25 09:39:06 - agent.DQN.DQN - INFO - episode 7 step 179 reward tensor([-1]) loss 1.5732911825180054 epsilon 0.6725424389895897
26-Feb-25 09:39:06 - agent.DQN.DQN - INFO - episode 7 step 180 reward tensor([-1]) loss 1.1046792268753052 epsilon 0.6725424389895897
26-Feb-25 09:39:06 - agent.DQN.DQN - INFO - episode 7 step 181 reward tensor([-1]) loss 50.358638763427734 epsilon 0.6725424389895897
26-Feb-25 09:39:06 - agent.DQN.DQN - INFO - episode 7 step 182 reward tensor([-1]) loss 77.7634506225586 epsilon 0.6725424389895897
26-Feb-25 09:39:06 - agent.DQN.DQN - INFO - episode 7 step 183 reward tensor([-1]) loss 1.528883457183838 epsilon 0.6725424389895897
26-Feb-25 09:39:06 - agent.DQN.DQN - INFO - episode 7 step 184 reward tensor([-1]) loss 50.112403869628906 epsilon 0.6725424389895897
26-Feb-25 09:39:06 - agent.DQN.DQN - INFO - episode 7 step 185 reward tensor([-1]) loss 0.9529491662979126 epsilon 0.6725424389895897
26-Feb-25 09:39:06 - agent.DQN.DQN - INFO - episode 7 step 186 reward tensor([-1]) loss 1.6096320152282715 epsilon 0.6725424389895897
26-Feb-25 09:39:06 - agent.DQN.DQN - INFO - episode 7 step 187 reward tensor([-1]) loss 0.9336885213851929 epsilon 0.6725424389895897
26-Feb-25 09:39:06 - agent.DQN.DQN - INFO - episode 7 step 188 reward tensor([-1]) loss 0.9986134171485901 epsilon 0.6725424389895897
26-Feb-25 09:39:06 - agent.DQN.DQN - INFO - episode 7 step 189 reward tensor([-1]) loss 77.96798706054688 epsilon 0.6725424389895897
26-Feb-25 09:39:06 - agent.DQN.DQN - INFO - episode 7 step 190 reward tensor([-1]) loss 0.9487192034721375 epsilon 0.6725424389895897
26-Feb-25 09:39:06 - agent.DQN.DQN - INFO - episode 7 step 191 reward tensor([-1]) loss 0.9364679455757141 epsilon 0.6725424389895897
26-Feb-25 09:39:06 - agent.DQN.DQN - INFO - episode 7 step 192 reward tensor([-1]) loss 0.9637860059738159 epsilon 0.6725424389895897
26-Feb-25 09:39:06 - agent.DQN.DQN - INFO - episode 7 step 193 reward tensor([-1]) loss 50.19450759887695 epsilon 0.6725424389895897
26-Feb-25 09:39:06 - agent.DQN.DQN - INFO - episode 7 step 194 reward tensor([-1]) loss 0.6908541917800903 epsilon 0.6725424389895897
26-Feb-25 09:39:06 - agent.DQN.DQN - INFO - episode 7 step 195 reward tensor([-1]) loss 1.0076894760131836 epsilon 0.6725424389895897
26-Feb-25 09:39:06 - agent.DQN.DQN - INFO - episode 7 step 196 reward tensor([-1]) loss 1.1113213300704956 epsilon 0.6725424389895897
26-Feb-25 09:39:06 - agent.DQN.DQN - INFO - episode 7 step 197 reward tensor([-1]) loss 49.800636291503906 epsilon 0.6725424389895897
26-Feb-25 09:39:06 - agent.DQN.DQN - INFO - episode 7 step 198 reward tensor([-1]) loss 1.06707763671875 epsilon 0.6725424389895897
26-Feb-25 09:39:06 - agent.DQN.DQN - INFO - episode 7 step 199 reward tensor([-1]) loss 0.4625987410545349 epsilon 0.6725424389895897
26-Feb-25 09:39:06 - agent.DQN.DQN - INFO - episode 7 step 200 reward tensor([-1]) loss 1.1910756826400757 epsilon 0.6725424389895897
26-Feb-25 09:39:06 - agent.DQN.DQN - INFO - episode 7 step 201 reward tensor([-1]) loss 1.1288280487060547 epsilon 0.6725424389895897
26-Feb-25 09:39:06 - agent.DQN.DQN - INFO - episode 7 step 202 reward tensor([-1]) loss 1.3551160097122192 epsilon 0.6725424389895897
26-Feb-25 09:39:06 - agent.DQN.DQN - INFO - episode 7 step 203 reward tensor([-1]) loss 77.93709564208984 epsilon 0.6725424389895897
26-Feb-25 09:39:06 - agent.DQN.DQN - INFO - episode 7 step 204 reward tensor([-1]) loss 1.064170002937317 epsilon 0.6725424389895897
26-Feb-25 09:39:06 - agent.DQN.DQN - INFO - episode 7 step 205 reward tensor([-1]) loss 1.1941120624542236 epsilon 0.6725424389895897
26-Feb-25 09:39:06 - agent.DQN.DQN - INFO - episode 7 step 206 reward tensor([-1]) loss 0.7823123335838318 epsilon 0.6725424389895897
26-Feb-25 09:39:07 - agent.DQN.DQN - INFO - episode 7 step 207 reward tensor([-1]) loss 1.202858567237854 epsilon 0.6725424389895897
26-Feb-25 09:39:07 - agent.DQN.DQN - INFO - episode 7 step 208 reward tensor([-1]) loss 0.6341561079025269 epsilon 0.6725424389895897
26-Feb-25 09:39:07 - agent.DQN.DQN - INFO - episode 7 step 209 reward tensor([-1]) loss 2.0344955921173096 epsilon 0.6725424389895897
26-Feb-25 09:39:07 - agent.DQN.DQN - INFO - episode 7 step 210 reward tensor([-1]) loss 1.14699387550354 epsilon 0.6725424389895897
26-Feb-25 09:39:07 - agent.DQN.DQN - INFO - episode 7 step 211 reward tensor([-1]) loss 1.2120522260665894 epsilon 0.6725424389895897
26-Feb-25 09:39:07 - agent.DQN.DQN - INFO - episode 7 step 212 reward tensor([-1]) loss 1.1523197889328003 epsilon 0.6725424389895897
26-Feb-25 09:39:07 - agent.DQN.DQN - INFO - episode 7 step 213 reward tensor([-1]) loss 1.8075889348983765 epsilon 0.6725424389895897
26-Feb-25 09:39:07 - agent.DQN.DQN - INFO - episode 7 step 214 reward tensor([-1]) loss 1.331275224685669 epsilon 0.6725424389895897
26-Feb-25 09:39:07 - agent.DQN.DQN - INFO - episode 7 step 215 reward tensor([-1]) loss 1.2936822175979614 epsilon 0.6725424389895897
26-Feb-25 09:39:07 - agent.DQN.DQN - INFO - episode 7 step 216 reward tensor([-1]) loss 77.3432388305664 epsilon 0.6725424389895897
26-Feb-25 09:39:07 - agent.DQN.DQN - INFO - episode 7 step 217 reward tensor([-1]) loss 0.6187463402748108 epsilon 0.6725424389895897
26-Feb-25 09:39:07 - agent.DQN.DQN - INFO - episode 7 step 218 reward tensor([-1]) loss 1.0521631240844727 epsilon 0.6725424389895897
26-Feb-25 09:39:07 - agent.DQN.DQN - INFO - episode 7 step 219 reward tensor([-1]) loss 1.286885380744934 epsilon 0.6725424389895897
26-Feb-25 09:39:07 - agent.DQN.DQN - INFO - episode 7 step 220 reward tensor([-1]) loss 0.9085606336593628 epsilon 0.6725424389895897
26-Feb-25 09:39:07 - agent.DQN.DQN - INFO - episode 7 step 221 reward tensor([-1]) loss 77.5833511352539 epsilon 0.6725424389895897
26-Feb-25 09:39:07 - agent.DQN.DQN - INFO - episode 7 step 222 reward tensor([-1]) loss 1.1792937517166138 epsilon 0.6725424389895897
26-Feb-25 09:39:07 - agent.DQN.DQN - INFO - episode 7 step 223 reward tensor([-1]) loss 1.0049431324005127 epsilon 0.6725424389895897
26-Feb-25 09:39:07 - agent.DQN.DQN - INFO - episode 7 step 224 reward tensor([-1]) loss 1.5466909408569336 epsilon 0.6725424389895897
26-Feb-25 09:39:07 - agent.DQN.DQN - INFO - episode 7 step 225 reward tensor([-1]) loss 1.860853910446167 epsilon 0.6725424389895897
26-Feb-25 09:39:07 - agent.DQN.DQN - INFO - episode 7 step 226 reward tensor([-1]) loss 1.0133843421936035 epsilon 0.6725424389895897
26-Feb-25 09:39:07 - agent.DQN.DQN - INFO - episode 7 step 227 reward tensor([-1]) loss 1.019122838973999 epsilon 0.6725424389895897
26-Feb-25 09:39:07 - agent.DQN.DQN - INFO - episode 7 step 228 reward tensor([-1]) loss 1.9972641468048096 epsilon 0.6725424389895897
26-Feb-25 09:39:07 - agent.DQN.DQN - INFO - episode 7 step 229 reward tensor([-1]) loss 77.45323944091797 epsilon 0.6725424389895897
26-Feb-25 09:39:07 - agent.DQN.DQN - INFO - episode 7 step 230 reward tensor([-1]) loss 0.8218258023262024 epsilon 0.6725424389895897
26-Feb-25 09:39:07 - agent.DQN.DQN - INFO - episode 7 step 231 reward tensor([-1]) loss 1.1687315702438354 epsilon 0.6725424389895897
26-Feb-25 09:39:07 - agent.DQN.DQN - INFO - episode 7 step 232 reward tensor([-1]) loss 1.5574393272399902 epsilon 0.6725424389895897
26-Feb-25 09:39:07 - agent.DQN.DQN - INFO - episode 7 step 233 reward tensor([-1]) loss 0.9500049948692322 epsilon 0.6725424389895897
26-Feb-25 09:39:07 - agent.DQN.DQN - INFO - episode 7 step 234 reward tensor([-1]) loss 1.1374915838241577 epsilon 0.6725424389895897
26-Feb-25 09:39:07 - agent.DQN.DQN - INFO - episode 7 step 235 reward tensor([-1]) loss 77.7471694946289 epsilon 0.6725424389895897
26-Feb-25 09:39:07 - agent.DQN.DQN - INFO - episode 7 step 236 reward tensor([-1]) loss 1.232000708580017 epsilon 0.6725424389895897
26-Feb-25 09:39:07 - agent.DQN.DQN - INFO - episode 7 step 237 reward tensor([-1]) loss 1.414439082145691 epsilon 0.6725424389895897
26-Feb-25 09:39:07 - agent.DQN.DQN - INFO - episode 7 step 238 reward tensor([-1]) loss 50.95142364501953 epsilon 0.6725424389895897
26-Feb-25 09:39:07 - agent.DQN.DQN - INFO - episode 7 step 239 reward tensor([-1]) loss 1.044593334197998 epsilon 0.6725424389895897
26-Feb-25 09:39:07 - agent.DQN.DQN - INFO - episode 7 step 240 reward tensor([-1]) loss 1.4102612733840942 epsilon 0.6725424389895897
26-Feb-25 09:39:07 - agent.DQN.DQN - INFO - episode 7 step 241 reward tensor([-1]) loss 1.2427388429641724 epsilon 0.6725424389895897
26-Feb-25 09:39:07 - agent.DQN.DQN - INFO - episode 7 step 242 reward tensor([-1]) loss 1.4003806114196777 epsilon 0.6725424389895897
26-Feb-25 09:39:07 - agent.DQN.DQN - INFO - episode 7 step 243 reward tensor([-1]) loss 0.9579561948776245 epsilon 0.6725424389895897
26-Feb-25 09:39:07 - agent.DQN.DQN - INFO - episode 7 step 244 reward tensor([-1]) loss 0.87918621301651 epsilon 0.6725424389895897
26-Feb-25 09:39:07 - agent.DQN.DQN - INFO - episode 7 step 245 reward tensor([-1]) loss 1.2827627658843994 epsilon 0.6725424389895897
26-Feb-25 09:39:07 - agent.DQN.DQN - INFO - episode 7 step 246 reward tensor([-1]) loss 0.9121538996696472 epsilon 0.6725424389895897
26-Feb-25 09:39:07 - agent.DQN.DQN - INFO - episode 7 step 247 reward tensor([-1]) loss 0.7832246422767639 epsilon 0.6725424389895897
26-Feb-25 09:39:07 - agent.DQN.DQN - INFO - episode 7 step 248 reward tensor([-1]) loss 0.9022358059883118 epsilon 0.6725424389895897
26-Feb-25 09:39:07 - agent.DQN.DQN - INFO - episode 7 step 249 reward tensor([-1]) loss 0.9183304309844971 epsilon 0.6725424389895897
26-Feb-25 09:39:07 - agent.DQN.DQN - INFO - episode 7 step 250 reward tensor([-1]) loss 1.104792833328247 epsilon 0.6725424389895897
26-Feb-25 09:39:07 - agent.DQN.DQN - INFO - episode 7 step 251 reward tensor([-1]) loss 1.2269790172576904 epsilon 0.6725424389895897
26-Feb-25 09:39:07 - agent.DQN.DQN - INFO - episode 7 step 252 reward tensor([-1]) loss 77.21356964111328 epsilon 0.6725424389895897
26-Feb-25 09:39:07 - agent.DQN.DQN - INFO - episode 7 step 253 reward tensor([-1]) loss 0.746627688407898 epsilon 0.6725424389895897
26-Feb-25 09:39:07 - agent.DQN.DQN - INFO - episode 7 step 254 reward tensor([-1]) loss 50.68549728393555 epsilon 0.6725424389895897
26-Feb-25 09:39:07 - agent.DQN.DQN - INFO - episode 7 step 255 reward tensor([-1]) loss 50.627952575683594 epsilon 0.6725424389895897
26-Feb-25 09:39:07 - agent.DQN.DQN - INFO - episode 7 step 256 reward tensor([-1]) loss 1.0475232601165771 epsilon 0.6725424389895897
26-Feb-25 09:39:07 - agent.DQN.DQN - INFO - episode 7 step 257 reward tensor([-1]) loss 1.051587700843811 epsilon 0.6725424389895897
26-Feb-25 09:39:07 - agent.DQN.DQN - INFO - episode 7 step 258 reward tensor([-1]) loss 0.7136321663856506 epsilon 0.6725424389895897
26-Feb-25 09:39:07 - agent.DQN.DQN - INFO - episode 7 step 259 reward tensor([-1]) loss 1.1946347951889038 epsilon 0.6725424389895897
26-Feb-25 09:39:07 - agent.DQN.DQN - INFO - episode 7 step 260 reward tensor([-1]) loss 50.274845123291016 epsilon 0.6725424389895897
26-Feb-25 09:39:07 - agent.DQN.DQN - INFO - episode 7 step 261 reward tensor([-1]) loss 1.3386722803115845 epsilon 0.6725424389895897
26-Feb-25 09:39:07 - agent.DQN.DQN - INFO - episode 7 step 262 reward tensor([-1]) loss 1.5149219036102295 epsilon 0.6725424389895897
26-Feb-25 09:39:07 - agent.DQN.DQN - INFO - episode 7 step 263 reward tensor([-1]) loss 49.95720291137695 epsilon 0.6725424389895897
26-Feb-25 09:39:07 - agent.DQN.DQN - INFO - episode 7 step 264 reward tensor([-1]) loss 1.3670215606689453 epsilon 0.6725424389895897
26-Feb-25 09:39:07 - agent.DQN.DQN - INFO - episode 7 step 265 reward tensor([-1]) loss 0.6935824155807495 epsilon 0.6725424389895897
26-Feb-25 09:39:07 - agent.DQN.DQN - INFO - episode 7 step 266 reward tensor([-1]) loss 1.1764543056488037 epsilon 0.6725424389895897
26-Feb-25 09:39:07 - agent.DQN.DQN - INFO - episode 7 step 267 reward tensor([-1]) loss 0.905084490776062 epsilon 0.6725424389895897
26-Feb-25 09:39:07 - agent.DQN.DQN - INFO - episode 7 step 268 reward tensor([-1]) loss 0.8135215640068054 epsilon 0.6725424389895897
26-Feb-25 09:39:07 - agent.DQN.DQN - INFO - episode 7 step 269 reward tensor([-1]) loss 1.7345019578933716 epsilon 0.6725424389895897
26-Feb-25 09:39:07 - agent.DQN.DQN - INFO - episode 7 step 270 reward tensor([-1]) loss 77.1655044555664 epsilon 0.6725424389895897
26-Feb-25 09:39:07 - agent.DQN.DQN - INFO - episode 7 step 271 reward tensor([-1]) loss 1.0642484426498413 epsilon 0.6725424389895897
26-Feb-25 09:39:07 - agent.DQN.DQN - INFO - episode 7 step 272 reward tensor([-1]) loss 0.9315592050552368 epsilon 0.6725424389895897
26-Feb-25 09:39:07 - agent.DQN.DQN - INFO - episode 7 step 273 reward tensor([-1]) loss 0.9611063003540039 epsilon 0.6725424389895897
26-Feb-25 09:39:07 - agent.DQN.DQN - INFO - episode 7 step 274 reward tensor([-1]) loss 0.9055317640304565 epsilon 0.6725424389895897
26-Feb-25 09:39:07 - agent.DQN.DQN - INFO - episode 7 step 275 reward tensor([-1]) loss 0.7522704601287842 epsilon 0.6725424389895897
26-Feb-25 09:39:07 - agent.DQN.DQN - INFO - episode 7 step 276 reward tensor([-1]) loss 1.4159654378890991 epsilon 0.6725424389895897
26-Feb-25 09:39:07 - agent.DQN.DQN - INFO - episode 7 step 277 reward tensor([-1]) loss 50.6194953918457 epsilon 0.6725424389895897
26-Feb-25 09:39:07 - agent.DQN.DQN - INFO - episode 7 step 278 reward tensor([-1]) loss 1.0027823448181152 epsilon 0.6725424389895897
26-Feb-25 09:39:07 - agent.DQN.DQN - INFO - episode 7 step 279 reward tensor([-1]) loss 0.909953773021698 epsilon 0.6725424389895897
26-Feb-25 09:39:07 - agent.DQN.DQN - INFO - episode 7 step 280 reward tensor([-1]) loss 0.9194613099098206 epsilon 0.6725424389895897
26-Feb-25 09:39:07 - agent.DQN.DQN - INFO - episode 7 step 281 reward tensor([-1]) loss 1.120883822441101 epsilon 0.6725424389895897
26-Feb-25 09:39:07 - agent.DQN.DQN - INFO - episode 7 step 282 reward tensor([-1]) loss 49.97934341430664 epsilon 0.6725424389895897
26-Feb-25 09:39:07 - agent.DQN.DQN - INFO - episode 7 step 283 reward tensor([-1]) loss 0.613544225692749 epsilon 0.6725424389895897
26-Feb-25 09:39:08 - agent.DQN.DQN - INFO - episode 7 step 284 reward tensor([-1]) loss 1.0585747957229614 epsilon 0.6725424389895897
26-Feb-25 09:39:08 - agent.DQN.DQN - INFO - episode 7 step 285 reward tensor([-1]) loss 1.0290958881378174 epsilon 0.6725424389895897
26-Feb-25 09:39:08 - agent.DQN.DQN - INFO - episode 7 step 286 reward tensor([-1]) loss 1.3511855602264404 epsilon 0.6725424389895897
26-Feb-25 09:39:08 - agent.DQN.DQN - INFO - episode 7 step 287 reward tensor([-1]) loss 77.3155746459961 epsilon 0.6725424389895897
26-Feb-25 09:39:08 - agent.DQN.DQN - INFO - episode 7 step 288 reward tensor([-1]) loss 49.69181823730469 epsilon 0.6725424389895897
26-Feb-25 09:39:08 - agent.DQN.DQN - INFO - episode 7 step 289 reward tensor([-1]) loss 1.0255558490753174 epsilon 0.6725424389895897
26-Feb-25 09:39:08 - agent.DQN.DQN - INFO - episode 7 step 290 reward tensor([-1]) loss 0.9508333206176758 epsilon 0.6725424389895897
26-Feb-25 09:39:08 - agent.DQN.DQN - INFO - episode 7 step 291 reward tensor([-1]) loss 1.1297664642333984 epsilon 0.6725424389895897
26-Feb-25 09:39:08 - agent.DQN.DQN - INFO - episode 7 step 292 reward tensor([-1]) loss 0.7466993927955627 epsilon 0.6725424389895897
26-Feb-25 09:39:08 - agent.DQN.DQN - INFO - episode 7 step 293 reward tensor([-1]) loss 1.5153881311416626 epsilon 0.6725424389895897
26-Feb-25 09:39:08 - agent.DQN.DQN - INFO - episode 7 step 294 reward tensor([-1]) loss 76.79869079589844 epsilon 0.6725424389895897
26-Feb-25 09:39:08 - agent.DQN.DQN - INFO - episode 7 step 295 reward tensor([-1]) loss 1.0965222120285034 epsilon 0.6725424389895897
26-Feb-25 09:39:08 - agent.DQN.DQN - INFO - episode 7 step 296 reward tensor([-1]) loss 1.1284072399139404 epsilon 0.6725424389895897
26-Feb-25 09:39:08 - agent.DQN.DQN - INFO - episode 7 step 297 reward tensor([-1]) loss 0.8098114132881165 epsilon 0.6725424389895897
26-Feb-25 09:39:08 - agent.DQN.DQN - INFO - episode 7 step 298 reward tensor([-1]) loss 0.6983091831207275 epsilon 0.6725424389895897
26-Feb-25 09:39:08 - agent.DQN.DQN - INFO - episode 7 step 299 reward tensor([-1]) loss 1.0327541828155518 epsilon 0.6725424389895897
26-Feb-25 09:39:08 - agent.DQN.DQN - INFO - episode 7 step 300 reward tensor([-1]) loss 0.9075825214385986 epsilon 0.6725424389895897
26-Feb-25 09:39:08 - agent.DQN.DQN - INFO - episode 7 step 301 reward tensor([-1]) loss 1.042932391166687 epsilon 0.6725424389895897
26-Feb-25 09:39:08 - agent.DQN.DQN - INFO - episode 8 step 0 reward tensor([-1]) loss 76.88072204589844 epsilon 0.650684809722428
26-Feb-25 09:39:08 - agent.DQN.DQN - INFO - episode 8 step 1 reward tensor([-1]) loss 1.061515212059021 epsilon 0.650684809722428
26-Feb-25 09:39:08 - agent.DQN.DQN - INFO - episode 8 step 2 reward tensor([-1]) loss 0.9369418621063232 epsilon 0.650684809722428
26-Feb-25 09:39:08 - agent.DQN.DQN - INFO - episode 8 step 3 reward tensor([-1]) loss 0.5466403961181641 epsilon 0.650684809722428
26-Feb-25 09:39:08 - agent.DQN.DQN - INFO - episode 8 step 4 reward tensor([-1]) loss 0.809126615524292 epsilon 0.650684809722428
26-Feb-25 09:39:08 - agent.DQN.DQN - INFO - episode 8 step 5 reward tensor([-1]) loss 49.725929260253906 epsilon 0.650684809722428
26-Feb-25 09:39:08 - agent.DQN.DQN - INFO - episode 8 step 6 reward tensor([-1]) loss 1.0854405164718628 epsilon 0.650684809722428
26-Feb-25 09:39:08 - agent.DQN.DQN - INFO - episode 8 step 7 reward tensor([-1]) loss 76.9727554321289 epsilon 0.650684809722428
26-Feb-25 09:39:08 - agent.DQN.DQN - INFO - episode 8 step 8 reward tensor([-1]) loss 0.9586337804794312 epsilon 0.650684809722428
26-Feb-25 09:39:08 - agent.DQN.DQN - INFO - episode 8 step 9 reward tensor([-1]) loss 0.7247079610824585 epsilon 0.650684809722428
26-Feb-25 09:39:08 - agent.DQN.DQN - INFO - episode 8 step 10 reward tensor([-1]) loss 1.0972305536270142 epsilon 0.650684809722428
26-Feb-25 09:39:08 - agent.DQN.DQN - INFO - episode 8 step 11 reward tensor([-1]) loss 0.643721878528595 epsilon 0.650684809722428
26-Feb-25 09:39:08 - agent.DQN.DQN - INFO - episode 8 step 12 reward tensor([-1]) loss 0.8277671337127686 epsilon 0.650684809722428
26-Feb-25 09:39:08 - agent.DQN.DQN - INFO - episode 8 step 13 reward tensor([-1]) loss 49.66449737548828 epsilon 0.650684809722428
26-Feb-25 09:39:08 - agent.DQN.DQN - INFO - episode 8 step 14 reward tensor([-1]) loss 1.0604807138442993 epsilon 0.650684809722428
26-Feb-25 09:39:08 - agent.DQN.DQN - INFO - episode 8 step 15 reward tensor([-1]) loss 0.8979917764663696 epsilon 0.650684809722428
26-Feb-25 09:39:08 - agent.DQN.DQN - INFO - episode 8 step 16 reward tensor([-1]) loss 1.3081954717636108 epsilon 0.650684809722428
26-Feb-25 09:39:08 - agent.DQN.DQN - INFO - episode 8 step 17 reward tensor([-1]) loss 0.6691010594367981 epsilon 0.650684809722428
26-Feb-25 09:39:08 - agent.DQN.DQN - INFO - episode 8 step 18 reward tensor([-1]) loss 0.6499442458152771 epsilon 0.650684809722428
26-Feb-25 09:39:08 - agent.DQN.DQN - INFO - episode 8 step 19 reward tensor([-1]) loss 1.0135829448699951 epsilon 0.650684809722428
26-Feb-25 09:39:08 - agent.DQN.DQN - INFO - episode 8 step 20 reward tensor([-1]) loss 1.0796736478805542 epsilon 0.650684809722428
26-Feb-25 09:39:08 - agent.DQN.DQN - INFO - episode 8 step 21 reward tensor([-1]) loss 0.79714435338974 epsilon 0.650684809722428
26-Feb-25 09:39:08 - agent.DQN.DQN - INFO - episode 8 step 22 reward tensor([-1]) loss 0.9516806602478027 epsilon 0.650684809722428
26-Feb-25 09:39:08 - agent.DQN.DQN - INFO - episode 8 step 23 reward tensor([-1]) loss 0.6614323854446411 epsilon 0.650684809722428
26-Feb-25 09:39:08 - agent.DQN.DQN - INFO - episode 8 step 24 reward tensor([-1]) loss 1.2415491342544556 epsilon 0.650684809722428
26-Feb-25 09:39:08 - agent.DQN.DQN - INFO - episode 8 step 25 reward tensor([-1]) loss 1.1303606033325195 epsilon 0.650684809722428
26-Feb-25 09:39:08 - agent.DQN.DQN - INFO - episode 8 step 26 reward tensor([-1]) loss 0.9344274997711182 epsilon 0.650684809722428
26-Feb-25 09:39:08 - agent.DQN.DQN - INFO - episode 8 step 27 reward tensor([-1]) loss 0.6790567636489868 epsilon 0.650684809722428
26-Feb-25 09:39:08 - agent.DQN.DQN - INFO - episode 8 step 28 reward tensor([-1]) loss 0.71702641248703 epsilon 0.650684809722428
26-Feb-25 09:39:08 - agent.DQN.DQN - INFO - episode 8 step 29 reward tensor([-1]) loss 0.6033370494842529 epsilon 0.650684809722428
26-Feb-25 09:39:08 - agent.DQN.DQN - INFO - episode 8 step 30 reward tensor([-1]) loss 76.84358215332031 epsilon 0.650684809722428
26-Feb-25 09:39:08 - agent.DQN.DQN - INFO - episode 8 step 31 reward tensor([-1]) loss 0.6180373430252075 epsilon 0.650684809722428
26-Feb-25 09:39:08 - agent.DQN.DQN - INFO - episode 8 step 32 reward tensor([-1]) loss 0.715101420879364 epsilon 0.650684809722428
26-Feb-25 09:39:08 - agent.DQN.DQN - INFO - episode 8 step 33 reward tensor([-1]) loss 0.901692271232605 epsilon 0.650684809722428
26-Feb-25 09:39:08 - agent.DQN.DQN - INFO - episode 8 step 34 reward tensor([-1]) loss 0.9227579832077026 epsilon 0.650684809722428
26-Feb-25 09:39:08 - agent.DQN.DQN - INFO - episode 8 step 35 reward tensor([-1]) loss 0.7101336717605591 epsilon 0.650684809722428
26-Feb-25 09:39:08 - agent.DQN.DQN - INFO - episode 8 step 36 reward tensor([-1]) loss 0.7768824696540833 epsilon 0.650684809722428
26-Feb-25 09:39:08 - agent.DQN.DQN - INFO - episode 8 step 37 reward tensor([-1]) loss 0.8080230355262756 epsilon 0.650684809722428
26-Feb-25 09:39:08 - agent.DQN.DQN - INFO - episode 8 step 38 reward tensor([-1]) loss 0.5838552117347717 epsilon 0.650684809722428
26-Feb-25 09:39:08 - agent.DQN.DQN - INFO - episode 8 step 39 reward tensor([-1]) loss 0.6179347038269043 epsilon 0.650684809722428
26-Feb-25 09:39:08 - agent.DQN.DQN - INFO - episode 8 step 40 reward tensor([-1]) loss 76.56498718261719 epsilon 0.650684809722428
26-Feb-25 09:39:08 - agent.DQN.DQN - INFO - episode 8 step 41 reward tensor([-1]) loss 0.6429122686386108 epsilon 0.650684809722428
26-Feb-25 09:39:08 - agent.DQN.DQN - INFO - episode 8 step 42 reward tensor([-1]) loss 0.5494183897972107 epsilon 0.650684809722428
26-Feb-25 09:39:08 - agent.DQN.DQN - INFO - episode 8 step 43 reward tensor([-1]) loss 0.9189426302909851 epsilon 0.650684809722428
26-Feb-25 09:39:08 - agent.DQN.DQN - INFO - episode 8 step 44 reward tensor([-1]) loss 0.632939338684082 epsilon 0.650684809722428
26-Feb-25 09:39:08 - agent.DQN.DQN - INFO - episode 8 step 45 reward tensor([-1]) loss 0.6034424304962158 epsilon 0.650684809722428
26-Feb-25 09:39:08 - agent.DQN.DQN - INFO - episode 8 step 46 reward tensor([-1]) loss 76.69263458251953 epsilon 0.650684809722428
26-Feb-25 09:39:08 - agent.DQN.DQN - INFO - episode 8 step 47 reward tensor([-1]) loss 0.7574875354766846 epsilon 0.650684809722428
26-Feb-25 09:39:08 - agent.DQN.DQN - INFO - episode 8 step 48 reward tensor([-1]) loss 0.7973014116287231 epsilon 0.650684809722428
26-Feb-25 09:39:08 - agent.DQN.DQN - INFO - episode 8 step 49 reward tensor([-1]) loss 0.5300010442733765 epsilon 0.650684809722428
26-Feb-25 09:39:08 - agent.DQN.DQN - INFO - episode 8 step 50 reward tensor([-1]) loss 0.5515891313552856 epsilon 0.650684809722428
26-Feb-25 09:39:08 - agent.DQN.DQN - INFO - episode 8 step 51 reward tensor([-1]) loss 0.9266451597213745 epsilon 0.650684809722428
26-Feb-25 09:39:08 - agent.DQN.DQN - INFO - episode 8 step 52 reward tensor([-1]) loss 0.4954548180103302 epsilon 0.650684809722428
26-Feb-25 09:39:08 - agent.DQN.DQN - INFO - episode 8 step 53 reward tensor([-1]) loss 0.7505638003349304 epsilon 0.650684809722428
26-Feb-25 09:39:08 - agent.DQN.DQN - INFO - episode 8 step 54 reward tensor([-1]) loss 0.8866157531738281 epsilon 0.650684809722428
26-Feb-25 09:39:08 - agent.DQN.DQN - INFO - episode 8 step 55 reward tensor([-1]) loss 0.6132370829582214 epsilon 0.650684809722428
26-Feb-25 09:39:08 - agent.DQN.DQN - INFO - episode 8 step 56 reward tensor([-1]) loss 0.43388810753822327 epsilon 0.650684809722428
26-Feb-25 09:39:08 - agent.DQN.DQN - INFO - episode 8 step 57 reward tensor([-1]) loss 1.1229537725448608 epsilon 0.650684809722428
26-Feb-25 09:39:08 - agent.DQN.DQN - INFO - episode 8 step 58 reward tensor([-1]) loss 0.7089481353759766 epsilon 0.650684809722428
26-Feb-25 09:39:08 - agent.DQN.DQN - INFO - episode 8 step 59 reward tensor([-1]) loss 0.7765116095542908 epsilon 0.650684809722428
26-Feb-25 09:39:08 - agent.DQN.DQN - INFO - episode 8 step 60 reward tensor([-1]) loss 0.8426221013069153 epsilon 0.650684809722428
26-Feb-25 09:39:08 - agent.DQN.DQN - INFO - episode 8 step 61 reward tensor([-1]) loss 0.7301418781280518 epsilon 0.650684809722428
26-Feb-25 09:39:08 - agent.DQN.DQN - INFO - episode 8 step 62 reward tensor([-1]) loss 0.6650466322898865 epsilon 0.650684809722428
26-Feb-25 09:39:09 - agent.DQN.DQN - INFO - episode 8 step 63 reward tensor([-1]) loss 76.61593627929688 epsilon 0.650684809722428
26-Feb-25 09:39:09 - agent.DQN.DQN - INFO - episode 8 step 64 reward tensor([-1]) loss 0.5049566030502319 epsilon 0.650684809722428
26-Feb-25 09:39:09 - agent.DQN.DQN - INFO - episode 8 step 65 reward tensor([-1]) loss 0.6083463430404663 epsilon 0.650684809722428
26-Feb-25 09:39:09 - agent.DQN.DQN - INFO - episode 8 step 66 reward tensor([-1]) loss 0.5927743315696716 epsilon 0.650684809722428
26-Feb-25 09:39:09 - agent.DQN.DQN - INFO - episode 8 step 67 reward tensor([-1]) loss 0.6264755725860596 epsilon 0.650684809722428
26-Feb-25 09:39:09 - agent.DQN.DQN - INFO - episode 8 step 68 reward tensor([-1]) loss 0.6798545718193054 epsilon 0.650684809722428
26-Feb-25 09:39:09 - agent.DQN.DQN - INFO - episode 8 step 69 reward tensor([-1]) loss 0.6262732744216919 epsilon 0.650684809722428
26-Feb-25 09:39:09 - agent.DQN.DQN - INFO - episode 8 step 70 reward tensor([-1]) loss 0.490185022354126 epsilon 0.650684809722428
26-Feb-25 09:39:09 - agent.DQN.DQN - INFO - episode 8 step 71 reward tensor([-1]) loss 0.6060613393783569 epsilon 0.650684809722428
26-Feb-25 09:39:09 - agent.DQN.DQN - INFO - episode 8 step 72 reward tensor([-1]) loss 0.5045874118804932 epsilon 0.650684809722428
26-Feb-25 09:39:09 - agent.DQN.DQN - INFO - episode 8 step 73 reward tensor([-1]) loss 0.7431922554969788 epsilon 0.650684809722428
26-Feb-25 09:39:09 - agent.DQN.DQN - INFO - episode 8 step 74 reward tensor([-1]) loss 51.082523345947266 epsilon 0.650684809722428
26-Feb-25 09:39:09 - agent.DQN.DQN - INFO - episode 8 step 75 reward tensor([-1]) loss 0.8081172108650208 epsilon 0.650684809722428
26-Feb-25 09:39:09 - agent.DQN.DQN - INFO - episode 8 step 76 reward tensor([-1]) loss 0.730120837688446 epsilon 0.650684809722428
26-Feb-25 09:39:09 - agent.DQN.DQN - INFO - episode 8 step 77 reward tensor([-1]) loss 0.7750577330589294 epsilon 0.650684809722428
26-Feb-25 09:39:09 - agent.DQN.DQN - INFO - episode 8 step 78 reward tensor([-1]) loss 0.455313503742218 epsilon 0.650684809722428
26-Feb-25 09:39:09 - agent.DQN.DQN - INFO - episode 8 step 79 reward tensor([-1]) loss 1.119950294494629 epsilon 0.650684809722428
26-Feb-25 09:39:09 - agent.DQN.DQN - INFO - episode 8 step 80 reward tensor([-1]) loss 0.490725040435791 epsilon 0.650684809722428
26-Feb-25 09:39:09 - agent.DQN.DQN - INFO - episode 8 step 81 reward tensor([-1]) loss 76.48171997070312 epsilon 0.650684809722428
26-Feb-25 09:39:09 - agent.DQN.DQN - INFO - episode 8 step 82 reward tensor([-1]) loss 0.44536349177360535 epsilon 0.650684809722428
26-Feb-25 09:39:09 - agent.DQN.DQN - INFO - episode 8 step 83 reward tensor([-1]) loss 0.8162992596626282 epsilon 0.650684809722428
26-Feb-25 09:39:09 - agent.DQN.DQN - INFO - episode 8 step 84 reward tensor([-1]) loss 0.7406551837921143 epsilon 0.650684809722428
26-Feb-25 09:39:09 - agent.DQN.DQN - INFO - episode 8 step 85 reward tensor([-1]) loss 0.6490168571472168 epsilon 0.650684809722428
26-Feb-25 09:39:09 - agent.DQN.DQN - INFO - episode 8 step 86 reward tensor([-1]) loss 0.6883638501167297 epsilon 0.650684809722428
26-Feb-25 09:39:09 - agent.DQN.DQN - INFO - episode 8 step 87 reward tensor([-1]) loss 0.6627182960510254 epsilon 0.650684809722428
26-Feb-25 09:39:09 - agent.DQN.DQN - INFO - episode 8 step 88 reward tensor([-1]) loss 126.7303695678711 epsilon 0.650684809722428
26-Feb-25 09:39:09 - agent.DQN.DQN - INFO - episode 8 step 89 reward tensor([-1]) loss 0.7511318922042847 epsilon 0.650684809722428
26-Feb-25 09:39:09 - agent.DQN.DQN - INFO - episode 8 step 90 reward tensor([-1]) loss 0.7360440492630005 epsilon 0.650684809722428
26-Feb-25 09:39:09 - agent.DQN.DQN - INFO - episode 8 step 91 reward tensor([-1]) loss 0.5044103860855103 epsilon 0.650684809722428
26-Feb-25 09:39:09 - agent.DQN.DQN - INFO - episode 8 step 92 reward tensor([-1]) loss 0.45167076587677 epsilon 0.650684809722428
26-Feb-25 09:39:09 - agent.DQN.DQN - INFO - episode 8 step 93 reward tensor([-1]) loss 0.8010497689247131 epsilon 0.650684809722428
26-Feb-25 09:39:09 - agent.DQN.DQN - INFO - episode 8 step 94 reward tensor([-1]) loss 0.7318299412727356 epsilon 0.650684809722428
26-Feb-25 09:39:09 - agent.DQN.DQN - INFO - episode 8 step 95 reward tensor([-1]) loss 0.5551011562347412 epsilon 0.650684809722428
26-Feb-25 09:39:09 - agent.DQN.DQN - INFO - episode 8 step 96 reward tensor([-1]) loss 1.0068647861480713 epsilon 0.650684809722428
26-Feb-25 09:39:09 - agent.DQN.DQN - INFO - episode 8 step 97 reward tensor([-1]) loss 0.572837233543396 epsilon 0.650684809722428
26-Feb-25 09:39:09 - agent.DQN.DQN - INFO - episode 8 step 98 reward tensor([-1]) loss 76.4967041015625 epsilon 0.650684809722428
26-Feb-25 09:39:09 - agent.DQN.DQN - INFO - episode 8 step 99 reward tensor([-1]) loss 0.5588436722755432 epsilon 0.650684809722428
26-Feb-25 09:39:09 - agent.DQN.DQN - INFO - episode 8 step 100 reward tensor([-1]) loss 0.7397274374961853 epsilon 0.650684809722428
26-Feb-25 09:39:09 - agent.DQN.DQN - INFO - episode 8 step 101 reward tensor([-1]) loss 0.8050505518913269 epsilon 0.650684809722428
26-Feb-25 09:39:09 - agent.DQN.DQN - INFO - episode 8 step 102 reward tensor([-1]) loss 0.6986368894577026 epsilon 0.650684809722428
26-Feb-25 09:39:09 - agent.DQN.DQN - INFO - episode 8 step 103 reward tensor([-1]) loss 0.72246253490448 epsilon 0.650684809722428
26-Feb-25 09:39:09 - agent.DQN.DQN - INFO - episode 8 step 104 reward tensor([-1]) loss 0.9999735355377197 epsilon 0.650684809722428
26-Feb-25 09:39:09 - agent.DQN.DQN - INFO - episode 8 step 105 reward tensor([-1]) loss 0.4746146500110626 epsilon 0.650684809722428
26-Feb-25 09:39:09 - agent.DQN.DQN - INFO - episode 8 step 106 reward tensor([-1]) loss 0.7461581230163574 epsilon 0.650684809722428
26-Feb-25 09:39:09 - agent.DQN.DQN - INFO - episode 8 step 107 reward tensor([-1]) loss 0.767457127571106 epsilon 0.650684809722428
26-Feb-25 09:39:09 - agent.DQN.DQN - INFO - episode 8 step 108 reward tensor([-1]) loss 0.4666077196598053 epsilon 0.650684809722428
26-Feb-25 09:39:09 - agent.DQN.DQN - INFO - episode 8 step 109 reward tensor([-1]) loss 0.7380401492118835 epsilon 0.650684809722428
26-Feb-25 09:39:09 - agent.DQN.DQN - INFO - episode 8 step 110 reward tensor([-1]) loss 51.1912727355957 epsilon 0.650684809722428
26-Feb-25 09:39:09 - agent.DQN.DQN - INFO - episode 8 step 111 reward tensor([-1]) loss 0.7909101843833923 epsilon 0.650684809722428
26-Feb-25 09:39:09 - agent.DQN.DQN - INFO - episode 8 step 112 reward tensor([-1]) loss 0.4049311578273773 epsilon 0.650684809722428
26-Feb-25 09:39:09 - agent.DQN.DQN - INFO - episode 8 step 113 reward tensor([-1]) loss 0.6755461692810059 epsilon 0.650684809722428
26-Feb-25 09:39:09 - agent.DQN.DQN - INFO - episode 8 step 114 reward tensor([-1]) loss 0.6203135848045349 epsilon 0.650684809722428
26-Feb-25 09:39:09 - agent.DQN.DQN - INFO - episode 8 step 115 reward tensor([-1]) loss 0.8601459860801697 epsilon 0.650684809722428
26-Feb-25 09:39:09 - agent.DQN.DQN - INFO - episode 8 step 116 reward tensor([-1]) loss 0.5362191796302795 epsilon 0.650684809722428
26-Feb-25 09:39:09 - agent.DQN.DQN - INFO - episode 8 step 117 reward tensor([-1]) loss 0.6217829585075378 epsilon 0.650684809722428
26-Feb-25 09:39:09 - agent.DQN.DQN - INFO - episode 8 step 118 reward tensor([-1]) loss 0.5959858894348145 epsilon 0.650684809722428
26-Feb-25 09:39:09 - agent.DQN.DQN - INFO - episode 8 step 119 reward tensor([-1]) loss 0.6167504191398621 epsilon 0.650684809722428
26-Feb-25 09:39:09 - agent.DQN.DQN - INFO - episode 8 step 120 reward tensor([-1]) loss 0.5887471437454224 epsilon 0.650684809722428
26-Feb-25 09:39:09 - agent.DQN.DQN - INFO - episode 8 step 121 reward tensor([-1]) loss 0.5879011154174805 epsilon 0.650684809722428
26-Feb-25 09:39:09 - agent.DQN.DQN - INFO - episode 8 step 122 reward tensor([-1]) loss 0.5861668586730957 epsilon 0.650684809722428
26-Feb-25 09:39:09 - agent.DQN.DQN - INFO - episode 8 step 123 reward tensor([-1]) loss 0.6667606830596924 epsilon 0.650684809722428
26-Feb-25 09:39:09 - agent.DQN.DQN - INFO - episode 8 step 124 reward tensor([-1]) loss 0.65891432762146 epsilon 0.650684809722428
26-Feb-25 09:39:09 - agent.DQN.DQN - INFO - episode 8 step 125 reward tensor([-1]) loss 0.8770220279693604 epsilon 0.650684809722428
26-Feb-25 09:39:09 - agent.DQN.DQN - INFO - episode 8 step 126 reward tensor([-1]) loss 0.5899296402931213 epsilon 0.650684809722428
26-Feb-25 09:39:09 - agent.DQN.DQN - INFO - episode 8 step 127 reward tensor([-1]) loss 0.47015145421028137 epsilon 0.650684809722428
26-Feb-25 09:39:09 - agent.DQN.DQN - INFO - episode 8 step 128 reward tensor([-1]) loss 0.6962529420852661 epsilon 0.650684809722428
26-Feb-25 09:39:09 - agent.DQN.DQN - INFO - episode 8 step 129 reward tensor([-1]) loss 0.7274723052978516 epsilon 0.650684809722428
26-Feb-25 09:39:09 - agent.DQN.DQN - INFO - episode 8 step 130 reward tensor([-1]) loss 51.31816864013672 epsilon 0.650684809722428
26-Feb-25 09:39:09 - agent.DQN.DQN - INFO - episode 8 step 131 reward tensor([-1]) loss 0.8405332565307617 epsilon 0.650684809722428
26-Feb-25 09:39:09 - agent.DQN.DQN - INFO - episode 8 step 132 reward tensor([-1]) loss 0.8504297733306885 epsilon 0.650684809722428
26-Feb-25 09:39:09 - agent.DQN.DQN - INFO - episode 8 step 133 reward tensor([-1]) loss 0.7141650915145874 epsilon 0.650684809722428
26-Feb-25 09:39:10 - agent.DQN.DQN - INFO - episode 8 step 134 reward tensor([-1]) loss 0.5308366417884827 epsilon 0.650684809722428
26-Feb-25 09:39:10 - agent.DQN.DQN - INFO - episode 8 step 135 reward tensor([-1]) loss 0.7721662521362305 epsilon 0.650684809722428
26-Feb-25 09:39:10 - agent.DQN.DQN - INFO - episode 8 step 136 reward tensor([-1]) loss 0.7365247011184692 epsilon 0.650684809722428
26-Feb-25 09:39:10 - agent.DQN.DQN - INFO - episode 8 step 137 reward tensor([-1]) loss 0.5441405773162842 epsilon 0.650684809722428
26-Feb-25 09:39:10 - agent.DQN.DQN - INFO - episode 8 step 138 reward tensor([-1]) loss 0.4367145895957947 epsilon 0.650684809722428
26-Feb-25 09:39:10 - agent.DQN.DQN - INFO - episode 8 step 139 reward tensor([-1]) loss 0.3814556300640106 epsilon 0.650684809722428
26-Feb-25 09:39:10 - agent.DQN.DQN - INFO - episode 8 step 140 reward tensor([-1]) loss 0.5971134901046753 epsilon 0.650684809722428
26-Feb-25 09:39:10 - agent.DQN.DQN - INFO - episode 8 step 141 reward tensor([-1]) loss 0.6403915286064148 epsilon 0.650684809722428
26-Feb-25 09:39:10 - agent.DQN.DQN - INFO - episode 8 step 142 reward tensor([-1]) loss 0.8330472111701965 epsilon 0.650684809722428
26-Feb-25 09:39:10 - agent.DQN.DQN - INFO - episode 8 step 143 reward tensor([-1]) loss 0.7047480344772339 epsilon 0.650684809722428
26-Feb-25 09:39:10 - agent.DQN.DQN - INFO - episode 8 step 144 reward tensor([-1]) loss 0.6162681579589844 epsilon 0.650684809722428
26-Feb-25 09:39:10 - agent.DQN.DQN - INFO - episode 8 step 145 reward tensor([-1]) loss 0.5630347728729248 epsilon 0.650684809722428
26-Feb-25 09:39:10 - agent.DQN.DQN - INFO - episode 8 step 146 reward tensor([-1]) loss 51.249053955078125 epsilon 0.650684809722428
26-Feb-25 09:39:10 - agent.DQN.DQN - INFO - episode 8 step 147 reward tensor([-1]) loss 127.02498626708984 epsilon 0.650684809722428
26-Feb-25 09:39:10 - agent.DQN.DQN - INFO - episode 8 step 148 reward tensor([-1]) loss 0.5928492546081543 epsilon 0.650684809722428
26-Feb-25 09:39:10 - agent.DQN.DQN - INFO - episode 8 step 149 reward tensor([-1]) loss 0.7420596480369568 epsilon 0.650684809722428
26-Feb-25 09:39:10 - agent.DQN.DQN - INFO - episode 8 step 150 reward tensor([-1]) loss 1.0973641872406006 epsilon 0.650684809722428
26-Feb-25 09:39:10 - agent.DQN.DQN - INFO - episode 8 step 151 reward tensor([-1]) loss 0.648955225944519 epsilon 0.650684809722428
26-Feb-25 09:39:10 - agent.DQN.DQN - INFO - episode 8 step 152 reward tensor([-1]) loss 76.04570770263672 epsilon 0.650684809722428
26-Feb-25 09:39:10 - agent.DQN.DQN - INFO - episode 8 step 153 reward tensor([-1]) loss 0.5332767367362976 epsilon 0.650684809722428
26-Feb-25 09:39:10 - agent.DQN.DQN - INFO - episode 8 step 154 reward tensor([-1]) loss 0.612809419631958 epsilon 0.650684809722428
26-Feb-25 09:39:10 - agent.DQN.DQN - INFO - episode 8 step 155 reward tensor([-1]) loss 0.6755965352058411 epsilon 0.650684809722428
26-Feb-25 09:39:10 - agent.DQN.DQN - INFO - episode 8 step 156 reward tensor([-1]) loss 0.5464993119239807 epsilon 0.650684809722428
26-Feb-25 09:39:10 - agent.DQN.DQN - INFO - episode 8 step 157 reward tensor([-1]) loss 0.7719350457191467 epsilon 0.650684809722428
26-Feb-25 09:39:10 - agent.DQN.DQN - INFO - episode 8 step 158 reward tensor([-1]) loss 0.4713711738586426 epsilon 0.650684809722428
26-Feb-25 09:39:10 - agent.DQN.DQN - INFO - episode 8 step 159 reward tensor([-1]) loss 1.051357388496399 epsilon 0.650684809722428
26-Feb-25 09:39:10 - agent.DQN.DQN - INFO - episode 8 step 160 reward tensor([-1]) loss 0.4923900365829468 epsilon 0.650684809722428
26-Feb-25 09:39:10 - agent.DQN.DQN - INFO - episode 8 step 161 reward tensor([-1]) loss 0.5921143889427185 epsilon 0.650684809722428
26-Feb-25 09:39:10 - agent.DQN.DQN - INFO - episode 8 step 162 reward tensor([-1]) loss 0.43120115995407104 epsilon 0.650684809722428
26-Feb-25 09:39:10 - agent.DQN.DQN - INFO - episode 8 step 163 reward tensor([-1]) loss 0.49296310544013977 epsilon 0.650684809722428
26-Feb-25 09:39:10 - agent.DQN.DQN - INFO - episode 8 step 164 reward tensor([-1]) loss 76.00198364257812 epsilon 0.650684809722428
26-Feb-25 09:39:10 - agent.DQN.DQN - INFO - episode 8 step 165 reward tensor([-1]) loss 0.5436984896659851 epsilon 0.650684809722428
26-Feb-25 09:39:10 - agent.DQN.DQN - INFO - episode 8 step 166 reward tensor([-1]) loss 50.766990661621094 epsilon 0.650684809722428
26-Feb-25 09:39:10 - agent.DQN.DQN - INFO - episode 8 step 167 reward tensor([-1]) loss 1.0703248977661133 epsilon 0.650684809722428
26-Feb-25 09:39:10 - agent.DQN.DQN - INFO - episode 8 step 168 reward tensor([-1]) loss 0.6110671162605286 epsilon 0.650684809722428
26-Feb-25 09:39:10 - agent.DQN.DQN - INFO - episode 8 step 169 reward tensor([-1]) loss 76.09986877441406 epsilon 0.650684809722428
26-Feb-25 09:39:10 - agent.DQN.DQN - INFO - episode 8 step 170 reward tensor([-1]) loss 0.8633644580841064 epsilon 0.650684809722428
26-Feb-25 09:39:10 - agent.DQN.DQN - INFO - episode 8 step 171 reward tensor([-1]) loss 50.99478530883789 epsilon 0.650684809722428
26-Feb-25 09:39:10 - agent.DQN.DQN - INFO - episode 8 step 172 reward tensor([-1]) loss 0.6890885829925537 epsilon 0.650684809722428
26-Feb-25 09:39:10 - agent.DQN.DQN - INFO - episode 8 step 173 reward tensor([-1]) loss 0.8993608355522156 epsilon 0.650684809722428
26-Feb-25 09:39:10 - agent.DQN.DQN - INFO - episode 8 step 174 reward tensor([-1]) loss 0.6869897246360779 epsilon 0.650684809722428
26-Feb-25 09:39:10 - agent.DQN.DQN - INFO - episode 8 step 175 reward tensor([-1]) loss 0.5482304096221924 epsilon 0.650684809722428
26-Feb-25 09:39:10 - agent.DQN.DQN - INFO - episode 8 step 176 reward tensor([-1]) loss 0.5324664115905762 epsilon 0.650684809722428
26-Feb-25 09:39:10 - agent.DQN.DQN - INFO - episode 8 step 177 reward tensor([-1]) loss 0.5282716155052185 epsilon 0.650684809722428
26-Feb-25 09:39:10 - agent.DQN.DQN - INFO - episode 8 step 178 reward tensor([-1]) loss 0.6930990219116211 epsilon 0.650684809722428
26-Feb-25 09:39:10 - agent.DQN.DQN - INFO - episode 8 step 179 reward tensor([-1]) loss 0.7306733727455139 epsilon 0.650684809722428
26-Feb-25 09:39:10 - agent.DQN.DQN - INFO - episode 8 step 180 reward tensor([-1]) loss 0.6326818466186523 epsilon 0.650684809722428
26-Feb-25 09:39:10 - agent.DQN.DQN - INFO - episode 8 step 181 reward tensor([-1]) loss 0.6366397738456726 epsilon 0.650684809722428
26-Feb-25 09:39:10 - agent.DQN.DQN - INFO - episode 8 step 182 reward tensor([-1]) loss 0.43908563256263733 epsilon 0.650684809722428
26-Feb-25 09:39:10 - agent.DQN.DQN - INFO - episode 8 step 183 reward tensor([-1]) loss 0.6962165832519531 epsilon 0.650684809722428
26-Feb-25 09:39:10 - agent.DQN.DQN - INFO - episode 8 step 184 reward tensor([-1]) loss 0.4736410975456238 epsilon 0.650684809722428
26-Feb-25 09:39:10 - agent.DQN.DQN - INFO - episode 8 step 185 reward tensor([-1]) loss 0.6482971906661987 epsilon 0.650684809722428
26-Feb-25 09:39:10 - agent.DQN.DQN - INFO - episode 8 step 186 reward tensor([-1]) loss 0.49636217951774597 epsilon 0.650684809722428
26-Feb-25 09:39:10 - agent.DQN.DQN - INFO - episode 8 step 187 reward tensor([-1]) loss 0.472591370344162 epsilon 0.650684809722428
26-Feb-25 09:39:10 - agent.DQN.DQN - INFO - episode 8 step 188 reward tensor([-1]) loss 76.02499389648438 epsilon 0.650684809722428
26-Feb-25 09:39:10 - agent.DQN.DQN - INFO - episode 8 step 189 reward tensor([-1]) loss 0.49106159806251526 epsilon 0.650684809722428
26-Feb-25 09:39:10 - agent.DQN.DQN - INFO - episode 8 step 190 reward tensor([-1]) loss 0.7228271961212158 epsilon 0.650684809722428
26-Feb-25 09:39:10 - agent.DQN.DQN - INFO - episode 8 step 191 reward tensor([-1]) loss 75.71656799316406 epsilon 0.650684809722428
26-Feb-25 09:39:10 - agent.DQN.DQN - INFO - episode 8 step 192 reward tensor([-1]) loss 0.4789615869522095 epsilon 0.650684809722428
26-Feb-25 09:39:10 - agent.DQN.DQN - INFO - episode 8 step 193 reward tensor([-1]) loss 0.6263857483863831 epsilon 0.650684809722428
26-Feb-25 09:39:10 - agent.DQN.DQN - INFO - episode 8 step 194 reward tensor([-1]) loss 0.40403950214385986 epsilon 0.650684809722428
26-Feb-25 09:39:10 - agent.DQN.DQN - INFO - episode 8 step 195 reward tensor([-1]) loss 0.40735894441604614 epsilon 0.650684809722428
26-Feb-25 09:39:10 - agent.DQN.DQN - INFO - episode 8 step 196 reward tensor([-1]) loss 0.42989039421081543 epsilon 0.650684809722428
26-Feb-25 09:39:10 - agent.DQN.DQN - INFO - episode 8 step 197 reward tensor([-1]) loss 0.5986889600753784 epsilon 0.650684809722428
26-Feb-25 09:39:10 - agent.DQN.DQN - INFO - episode 8 step 198 reward tensor([-1]) loss 0.548626184463501 epsilon 0.650684809722428
26-Feb-25 09:39:10 - agent.DQN.DQN - INFO - episode 8 step 199 reward tensor([-1]) loss 0.3801437020301819 epsilon 0.650684809722428
26-Feb-25 09:39:10 - agent.DQN.DQN - INFO - episode 8 step 200 reward tensor([-1]) loss 1.079817533493042 epsilon 0.650684809722428
26-Feb-25 09:39:10 - agent.DQN.DQN - INFO - episode 8 step 201 reward tensor([-1]) loss 0.613644003868103 epsilon 0.650684809722428
26-Feb-25 09:39:10 - agent.DQN.DQN - INFO - episode 8 step 202 reward tensor([-1]) loss 0.45455434918403625 epsilon 0.650684809722428
26-Feb-25 09:39:10 - agent.DQN.DQN - INFO - episode 8 step 203 reward tensor([-1]) loss 0.5971551537513733 epsilon 0.650684809722428
26-Feb-25 09:39:10 - agent.DQN.DQN - INFO - episode 8 step 204 reward tensor([-1]) loss 0.6104425191879272 epsilon 0.650684809722428
26-Feb-25 09:39:10 - agent.DQN.DQN - INFO - episode 8 step 205 reward tensor([-1]) loss 1.0581507682800293 epsilon 0.650684809722428
26-Feb-25 09:39:10 - agent.DQN.DQN - INFO - episode 8 step 206 reward tensor([-1]) loss 0.583484947681427 epsilon 0.650684809722428
26-Feb-25 09:39:10 - agent.DQN.DQN - INFO - episode 8 step 207 reward tensor([-1]) loss 75.91740417480469 epsilon 0.650684809722428
26-Feb-25 09:39:10 - agent.DQN.DQN - INFO - episode 8 step 208 reward tensor([-1]) loss 0.9901285171508789 epsilon 0.650684809722428
26-Feb-25 09:39:10 - agent.DQN.DQN - INFO - episode 8 step 209 reward tensor([-1]) loss 0.6898512840270996 epsilon 0.650684809722428
26-Feb-25 09:39:11 - agent.DQN.DQN - INFO - episode 8 step 210 reward tensor([-1]) loss 75.57133483886719 epsilon 0.650684809722428
26-Feb-25 09:39:11 - agent.DQN.DQN - INFO - episode 8 step 211 reward tensor([-1]) loss 0.8849575519561768 epsilon 0.650684809722428
26-Feb-25 09:39:11 - agent.DQN.DQN - INFO - episode 8 step 212 reward tensor([-1]) loss 0.4375201165676117 epsilon 0.650684809722428
26-Feb-25 09:39:11 - agent.DQN.DQN - INFO - episode 8 step 213 reward tensor([-1]) loss 0.6487772464752197 epsilon 0.650684809722428
26-Feb-25 09:39:11 - agent.DQN.DQN - INFO - episode 8 step 214 reward tensor([-1]) loss 0.9416885375976562 epsilon 0.650684809722428
26-Feb-25 09:39:11 - agent.DQN.DQN - INFO - episode 8 step 215 reward tensor([-1]) loss 0.652625322341919 epsilon 0.650684809722428
26-Feb-25 09:39:11 - agent.DQN.DQN - INFO - episode 8 step 216 reward tensor([-1]) loss 0.4609715938568115 epsilon 0.650684809722428
26-Feb-25 09:39:11 - agent.DQN.DQN - INFO - episode 8 step 217 reward tensor([-1]) loss 0.46292462944984436 epsilon 0.650684809722428
26-Feb-25 09:39:11 - agent.DQN.DQN - INFO - episode 8 step 218 reward tensor([-1]) loss 0.4698701500892639 epsilon 0.650684809722428
26-Feb-25 09:39:11 - agent.DQN.DQN - INFO - episode 8 step 219 reward tensor([-1]) loss 0.5424730181694031 epsilon 0.650684809722428
26-Feb-25 09:39:11 - agent.DQN.DQN - INFO - episode 8 step 220 reward tensor([-1]) loss 0.7800908088684082 epsilon 0.650684809722428
26-Feb-25 09:39:11 - agent.DQN.DQN - INFO - episode 8 step 221 reward tensor([-1]) loss 0.5293881297111511 epsilon 0.650684809722428
26-Feb-25 09:39:11 - agent.DQN.DQN - INFO - episode 8 step 222 reward tensor([-1]) loss 51.75044250488281 epsilon 0.650684809722428
26-Feb-25 09:39:11 - agent.DQN.DQN - INFO - episode 8 step 223 reward tensor([-1]) loss 0.7188606262207031 epsilon 0.650684809722428
26-Feb-25 09:39:11 - agent.DQN.DQN - INFO - episode 8 step 224 reward tensor([-1]) loss 0.660364031791687 epsilon 0.650684809722428
26-Feb-25 09:39:11 - agent.DQN.DQN - INFO - episode 8 step 225 reward tensor([-1]) loss 0.48004505038261414 epsilon 0.650684809722428
26-Feb-25 09:39:11 - agent.DQN.DQN - INFO - episode 8 step 226 reward tensor([-1]) loss 51.61069107055664 epsilon 0.650684809722428
26-Feb-25 09:39:11 - agent.DQN.DQN - INFO - episode 8 step 227 reward tensor([-1]) loss 0.5129917860031128 epsilon 0.650684809722428
26-Feb-25 09:39:11 - agent.DQN.DQN - INFO - episode 8 step 228 reward tensor([-1]) loss 0.4543963670730591 epsilon 0.650684809722428
26-Feb-25 09:39:11 - agent.DQN.DQN - INFO - episode 8 step 229 reward tensor([-1]) loss 0.5180991291999817 epsilon 0.650684809722428
26-Feb-25 09:39:11 - agent.DQN.DQN - INFO - episode 8 step 230 reward tensor([-1]) loss 0.40003085136413574 epsilon 0.650684809722428
26-Feb-25 09:39:11 - agent.DQN.DQN - INFO - episode 8 step 231 reward tensor([-1]) loss 0.397725373506546 epsilon 0.650684809722428
26-Feb-25 09:39:11 - agent.DQN.DQN - INFO - episode 8 step 232 reward tensor([-1]) loss 0.4573870897293091 epsilon 0.650684809722428
26-Feb-25 09:39:11 - agent.DQN.DQN - INFO - episode 8 step 233 reward tensor([-1]) loss 0.7757861614227295 epsilon 0.650684809722428
26-Feb-25 09:39:11 - agent.DQN.DQN - INFO - episode 8 step 234 reward tensor([-1]) loss 0.5548595786094666 epsilon 0.650684809722428
26-Feb-25 09:39:11 - agent.DQN.DQN - INFO - episode 8 step 235 reward tensor([-1]) loss 0.582990825176239 epsilon 0.650684809722428
26-Feb-25 09:39:11 - agent.DQN.DQN - INFO - episode 8 step 236 reward tensor([-1]) loss 0.49655774235725403 epsilon 0.650684809722428
26-Feb-25 09:39:11 - agent.DQN.DQN - INFO - episode 8 step 237 reward tensor([-1]) loss 0.694154679775238 epsilon 0.650684809722428
26-Feb-25 09:39:11 - agent.DQN.DQN - INFO - episode 8 step 238 reward tensor([-1]) loss 0.46508482098579407 epsilon 0.650684809722428
26-Feb-25 09:39:11 - agent.DQN.DQN - INFO - episode 8 step 239 reward tensor([-1]) loss 0.836836576461792 epsilon 0.650684809722428
26-Feb-25 09:39:11 - agent.DQN.DQN - INFO - episode 8 step 240 reward tensor([-1]) loss 0.6230541467666626 epsilon 0.650684809722428
26-Feb-25 09:39:11 - agent.DQN.DQN - INFO - episode 8 step 241 reward tensor([-1]) loss 0.44080203771591187 epsilon 0.650684809722428
26-Feb-25 09:39:11 - agent.DQN.DQN - INFO - episode 8 step 242 reward tensor([-1]) loss 0.4823035001754761 epsilon 0.650684809722428
26-Feb-25 09:39:11 - agent.DQN.DQN - INFO - episode 8 step 243 reward tensor([-1]) loss 0.5535619258880615 epsilon 0.650684809722428
26-Feb-25 09:39:11 - agent.DQN.DQN - INFO - episode 8 step 244 reward tensor([-1]) loss 75.49934387207031 epsilon 0.650684809722428
26-Feb-25 09:39:11 - agent.DQN.DQN - INFO - episode 8 step 245 reward tensor([-1]) loss 0.443444162607193 epsilon 0.650684809722428
26-Feb-25 09:39:11 - agent.DQN.DQN - INFO - episode 8 step 246 reward tensor([-1]) loss 0.38565292954444885 epsilon 0.650684809722428
26-Feb-25 09:39:11 - agent.DQN.DQN - INFO - episode 8 step 247 reward tensor([-1]) loss 0.4689854681491852 epsilon 0.650684809722428
26-Feb-25 09:39:11 - agent.DQN.DQN - INFO - episode 8 step 248 reward tensor([-1]) loss 51.34642028808594 epsilon 0.650684809722428
26-Feb-25 09:39:11 - agent.DQN.DQN - INFO - episode 8 step 249 reward tensor([-1]) loss 0.543678343296051 epsilon 0.650684809722428
26-Feb-25 09:39:11 - agent.DQN.DQN - INFO - episode 8 step 250 reward tensor([-1]) loss 0.5885453224182129 epsilon 0.650684809722428
26-Feb-25 09:39:11 - agent.DQN.DQN - INFO - episode 8 step 251 reward tensor([-1]) loss 0.7855244874954224 epsilon 0.650684809722428
26-Feb-25 09:39:11 - agent.DQN.DQN - INFO - episode 8 step 252 reward tensor([-1]) loss 0.8774579167366028 epsilon 0.650684809722428
26-Feb-25 09:39:11 - agent.DQN.DQN - INFO - episode 8 step 253 reward tensor([-1]) loss 0.5358309149742126 epsilon 0.650684809722428
26-Feb-25 09:39:11 - agent.DQN.DQN - INFO - episode 8 step 254 reward tensor([-1]) loss 51.39628219604492 epsilon 0.650684809722428
26-Feb-25 09:39:11 - agent.DQN.DQN - INFO - episode 8 step 255 reward tensor([-1]) loss 0.5210703611373901 epsilon 0.650684809722428
26-Feb-25 09:39:11 - agent.DQN.DQN - INFO - episode 8 step 256 reward tensor([-1]) loss 0.6185989379882812 epsilon 0.650684809722428
26-Feb-25 09:39:11 - agent.DQN.DQN - INFO - episode 8 step 257 reward tensor([-1]) loss 0.4739399552345276 epsilon 0.650684809722428
26-Feb-25 09:39:11 - agent.DQN.DQN - INFO - episode 8 step 258 reward tensor([-1]) loss 1.0595896244049072 epsilon 0.650684809722428
26-Feb-25 09:39:11 - agent.DQN.DQN - INFO - episode 8 step 259 reward tensor([-1]) loss 0.44748371839523315 epsilon 0.650684809722428
26-Feb-25 09:39:11 - agent.DQN.DQN - INFO - episode 8 step 260 reward tensor([-1]) loss 0.48904478549957275 epsilon 0.650684809722428
26-Feb-25 09:39:11 - agent.DQN.DQN - INFO - episode 8 step 261 reward tensor([-1]) loss 0.45839980244636536 epsilon 0.650684809722428
26-Feb-25 09:39:11 - agent.DQN.DQN - INFO - episode 8 step 262 reward tensor([-1]) loss 0.6905742287635803 epsilon 0.650684809722428
26-Feb-25 09:39:11 - agent.DQN.DQN - INFO - episode 8 step 263 reward tensor([-1]) loss 0.5343303680419922 epsilon 0.650684809722428
26-Feb-25 09:39:11 - agent.DQN.DQN - INFO - episode 8 step 264 reward tensor([-1]) loss 0.45832234621047974 epsilon 0.650684809722428
26-Feb-25 09:39:11 - agent.DQN.DQN - INFO - episode 8 step 265 reward tensor([-1]) loss 0.6632729172706604 epsilon 0.650684809722428
26-Feb-25 09:39:11 - agent.DQN.DQN - INFO - episode 8 step 266 reward tensor([-1]) loss 0.8592294454574585 epsilon 0.650684809722428
26-Feb-25 09:39:11 - agent.DQN.DQN - INFO - episode 8 step 267 reward tensor([-1]) loss 75.34943389892578 epsilon 0.650684809722428
26-Feb-25 09:39:11 - agent.DQN.DQN - INFO - episode 8 step 268 reward tensor([-1]) loss 75.54828643798828 epsilon 0.650684809722428
26-Feb-25 09:39:11 - agent.DQN.DQN - INFO - episode 8 step 269 reward tensor([-1]) loss 75.39412689208984 epsilon 0.650684809722428
26-Feb-25 09:39:11 - agent.DQN.DQN - INFO - episode 8 step 270 reward tensor([-1]) loss 0.772981584072113 epsilon 0.650684809722428
26-Feb-25 09:39:11 - agent.DQN.DQN - INFO - episode 8 step 271 reward tensor([-1]) loss 0.7366525530815125 epsilon 0.650684809722428
26-Feb-25 09:39:11 - agent.DQN.DQN - INFO - episode 8 step 272 reward tensor([-1]) loss 0.617364227771759 epsilon 0.650684809722428
26-Feb-25 09:39:11 - agent.DQN.DQN - INFO - episode 8 step 273 reward tensor([-1]) loss 0.5856634378433228 epsilon 0.650684809722428
26-Feb-25 09:39:11 - agent.DQN.DQN - INFO - episode 8 step 274 reward tensor([-1]) loss 0.733375072479248 epsilon 0.650684809722428
26-Feb-25 09:39:11 - agent.DQN.DQN - INFO - episode 8 step 275 reward tensor([-1]) loss 0.8790695667266846 epsilon 0.650684809722428
26-Feb-25 09:39:11 - agent.DQN.DQN - INFO - episode 8 step 276 reward tensor([-1]) loss 0.5128575563430786 epsilon 0.650684809722428
26-Feb-25 09:39:11 - agent.DQN.DQN - INFO - episode 8 step 277 reward tensor([-1]) loss 0.9104083776473999 epsilon 0.650684809722428
26-Feb-25 09:39:11 - agent.DQN.DQN - INFO - episode 8 step 278 reward tensor([-1]) loss 0.7464547157287598 epsilon 0.650684809722428
26-Feb-25 09:39:11 - agent.DQN.DQN - INFO - episode 8 step 279 reward tensor([-1]) loss 0.6488072276115417 epsilon 0.650684809722428
26-Feb-25 09:39:11 - agent.DQN.DQN - INFO - episode 8 step 280 reward tensor([-1]) loss 0.40760496258735657 epsilon 0.650684809722428
26-Feb-25 09:39:11 - agent.DQN.DQN - INFO - episode 8 step 281 reward tensor([-1]) loss 0.5351654291152954 epsilon 0.650684809722428
26-Feb-25 09:39:11 - agent.DQN.DQN - INFO - episode 8 step 282 reward tensor([-1]) loss 0.5068790912628174 epsilon 0.650684809722428
26-Feb-25 09:39:11 - agent.DQN.DQN - INFO - episode 8 step 283 reward tensor([-1]) loss 75.5038070678711 epsilon 0.650684809722428
26-Feb-25 09:39:11 - agent.DQN.DQN - INFO - episode 8 step 284 reward tensor([-1]) loss 0.634766697883606 epsilon 0.650684809722428
26-Feb-25 09:39:11 - agent.DQN.DQN - INFO - episode 8 step 285 reward tensor([-1]) loss 0.7100669145584106 epsilon 0.650684809722428
26-Feb-25 09:39:11 - agent.DQN.DQN - INFO - episode 8 step 286 reward tensor([-1]) loss 0.8738932609558105 epsilon 0.650684809722428
26-Feb-25 09:39:11 - agent.DQN.DQN - INFO - episode 8 step 287 reward tensor([-1]) loss 75.26535034179688 epsilon 0.650684809722428
26-Feb-25 09:39:11 - agent.DQN.DQN - INFO - episode 8 step 288 reward tensor([-1]) loss 0.7831328511238098 epsilon 0.650684809722428
26-Feb-25 09:39:12 - agent.DQN.DQN - INFO - episode 8 step 289 reward tensor([-1]) loss 0.45301303267478943 epsilon 0.650684809722428
26-Feb-25 09:39:12 - agent.DQN.DQN - INFO - episode 8 step 290 reward tensor([-1]) loss 0.37158310413360596 epsilon 0.650684809722428
26-Feb-25 09:39:12 - agent.DQN.DQN - INFO - episode 8 step 291 reward tensor([-1]) loss 51.81869125366211 epsilon 0.650684809722428
26-Feb-25 09:39:12 - agent.DQN.DQN - INFO - episode 8 step 292 reward tensor([-1]) loss 0.5960202813148499 epsilon 0.650684809722428
26-Feb-25 09:39:12 - agent.DQN.DQN - INFO - episode 8 step 293 reward tensor([-1]) loss 0.5747044086456299 epsilon 0.650684809722428
26-Feb-25 09:39:12 - agent.DQN.DQN - INFO - episode 8 step 294 reward tensor([-1]) loss 1.1384872198104858 epsilon 0.650684809722428
26-Feb-25 09:39:12 - agent.DQN.DQN - INFO - episode 8 step 295 reward tensor([-1]) loss 0.46929293870925903 epsilon 0.650684809722428
26-Feb-25 09:39:12 - agent.DQN.DQN - INFO - episode 8 step 296 reward tensor([-1]) loss 0.5503308773040771 epsilon 0.650684809722428
26-Feb-25 09:39:12 - agent.DQN.DQN - INFO - episode 8 step 297 reward tensor([-1]) loss 0.6634901762008667 epsilon 0.650684809722428
26-Feb-25 09:39:12 - agent.DQN.DQN - INFO - episode 8 step 298 reward tensor([-1]) loss 0.40443265438079834 epsilon 0.650684809722428
26-Feb-25 09:39:12 - agent.DQN.DQN - INFO - episode 8 step 299 reward tensor([-1]) loss 0.8867676258087158 epsilon 0.650684809722428
26-Feb-25 09:39:12 - agent.DQN.DQN - INFO - episode 8 step 300 reward tensor([-1]) loss 51.54055404663086 epsilon 0.650684809722428
26-Feb-25 09:39:12 - agent.DQN.DQN - INFO - episode 8 step 301 reward tensor([-1]) loss 0.5482780933380127 epsilon 0.650684809722428
26-Feb-25 09:39:12 - agent.DQN.DQN - INFO - episode 9 step 0 reward tensor([-1]) loss 0.6131249666213989 epsilon 0.6295375534064491
26-Feb-25 09:39:12 - agent.DQN.DQN - INFO - episode 9 step 1 reward tensor([-1]) loss 75.29659271240234 epsilon 0.6295375534064491
26-Feb-25 09:39:12 - agent.DQN.DQN - INFO - episode 9 step 2 reward tensor([-1]) loss 0.682191014289856 epsilon 0.6295375534064491
26-Feb-25 09:39:12 - agent.DQN.DQN - INFO - episode 9 step 3 reward tensor([-1]) loss 0.5456709265708923 epsilon 0.6295375534064491
26-Feb-25 09:39:12 - agent.DQN.DQN - INFO - episode 9 step 4 reward tensor([-1]) loss 0.7063934206962585 epsilon 0.6295375534064491
26-Feb-25 09:39:12 - agent.DQN.DQN - INFO - episode 9 step 5 reward tensor([-1]) loss 0.5662491321563721 epsilon 0.6295375534064491
26-Feb-25 09:39:12 - agent.DQN.DQN - INFO - episode 9 step 6 reward tensor([-1]) loss 75.17704772949219 epsilon 0.6295375534064491
26-Feb-25 09:39:12 - agent.DQN.DQN - INFO - episode 9 step 7 reward tensor([-1]) loss 0.47995495796203613 epsilon 0.6295375534064491
26-Feb-25 09:39:12 - agent.DQN.DQN - INFO - episode 9 step 8 reward tensor([-1]) loss 0.6691716313362122 epsilon 0.6295375534064491
26-Feb-25 09:39:12 - agent.DQN.DQN - INFO - episode 9 step 9 reward tensor([-1]) loss 0.8006604909896851 epsilon 0.6295375534064491
26-Feb-25 09:39:12 - agent.DQN.DQN - INFO - episode 9 step 10 reward tensor([-1]) loss 0.7490630745887756 epsilon 0.6295375534064491
26-Feb-25 09:39:12 - agent.DQN.DQN - INFO - episode 9 step 11 reward tensor([-1]) loss 0.36306488513946533 epsilon 0.6295375534064491
26-Feb-25 09:39:12 - agent.DQN.DQN - INFO - episode 9 step 12 reward tensor([-1]) loss 0.5269867181777954 epsilon 0.6295375534064491
26-Feb-25 09:39:12 - agent.DQN.DQN - INFO - episode 9 step 13 reward tensor([-1]) loss 0.8493090271949768 epsilon 0.6295375534064491
26-Feb-25 09:39:12 - agent.DQN.DQN - INFO - episode 9 step 14 reward tensor([-1]) loss 0.5746548771858215 epsilon 0.6295375534064491
26-Feb-25 09:39:12 - agent.DQN.DQN - INFO - episode 9 step 15 reward tensor([-1]) loss 0.4715486168861389 epsilon 0.6295375534064491
26-Feb-25 09:39:12 - agent.DQN.DQN - INFO - episode 9 step 16 reward tensor([-1]) loss 51.311100006103516 epsilon 0.6295375534064491
26-Feb-25 09:39:12 - agent.DQN.DQN - INFO - episode 9 step 17 reward tensor([-1]) loss 0.8405252695083618 epsilon 0.6295375534064491
26-Feb-25 09:39:12 - agent.DQN.DQN - INFO - episode 9 step 18 reward tensor([-1]) loss 51.269718170166016 epsilon 0.6295375534064491
26-Feb-25 09:39:12 - agent.DQN.DQN - INFO - episode 9 step 19 reward tensor([-1]) loss 0.5947864055633545 epsilon 0.6295375534064491
26-Feb-25 09:39:12 - agent.DQN.DQN - INFO - episode 9 step 20 reward tensor([-1]) loss 0.6087976694107056 epsilon 0.6295375534064491
26-Feb-25 09:39:12 - agent.DQN.DQN - INFO - episode 9 step 21 reward tensor([-1]) loss 0.714362621307373 epsilon 0.6295375534064491
26-Feb-25 09:39:12 - agent.DQN.DQN - INFO - episode 9 step 22 reward tensor([-1]) loss 0.6355015635490417 epsilon 0.6295375534064491
26-Feb-25 09:39:12 - agent.DQN.DQN - INFO - episode 9 step 23 reward tensor([-1]) loss 0.9240515232086182 epsilon 0.6295375534064491
26-Feb-25 09:39:12 - agent.DQN.DQN - INFO - episode 9 step 24 reward tensor([-1]) loss 0.5335081219673157 epsilon 0.6295375534064491
26-Feb-25 09:39:12 - agent.DQN.DQN - INFO - episode 9 step 25 reward tensor([-1]) loss 0.642767608165741 epsilon 0.6295375534064491
26-Feb-25 09:39:12 - agent.DQN.DQN - INFO - episode 9 step 26 reward tensor([-1]) loss 0.9769616723060608 epsilon 0.6295375534064491
26-Feb-25 09:39:12 - agent.DQN.DQN - INFO - episode 9 step 27 reward tensor([-1]) loss 0.7295128107070923 epsilon 0.6295375534064491
26-Feb-25 09:39:12 - agent.DQN.DQN - INFO - episode 9 step 28 reward tensor([-1]) loss 0.6431087255477905 epsilon 0.6295375534064491
26-Feb-25 09:39:12 - agent.DQN.DQN - INFO - episode 9 step 29 reward tensor([-1]) loss 75.50479125976562 epsilon 0.6295375534064491
26-Feb-25 09:39:12 - agent.DQN.DQN - INFO - episode 9 step 30 reward tensor([-1]) loss 0.7523370981216431 epsilon 0.6295375534064491
26-Feb-25 09:39:12 - agent.DQN.DQN - INFO - episode 9 step 31 reward tensor([-1]) loss 0.4431217908859253 epsilon 0.6295375534064491
26-Feb-25 09:39:12 - agent.DQN.DQN - INFO - episode 9 step 32 reward tensor([-1]) loss 0.670595109462738 epsilon 0.6295375534064491
26-Feb-25 09:39:12 - agent.DQN.DQN - INFO - episode 9 step 33 reward tensor([-1]) loss 0.5064530372619629 epsilon 0.6295375534064491
26-Feb-25 09:39:12 - agent.DQN.DQN - INFO - episode 9 step 34 reward tensor([-1]) loss 0.5548397302627563 epsilon 0.6295375534064491
26-Feb-25 09:39:12 - agent.DQN.DQN - INFO - episode 9 step 35 reward tensor([-1]) loss 0.7404610514640808 epsilon 0.6295375534064491
26-Feb-25 09:39:12 - agent.DQN.DQN - INFO - episode 9 step 36 reward tensor([-1]) loss 125.86681365966797 epsilon 0.6295375534064491
26-Feb-25 09:39:12 - agent.DQN.DQN - INFO - episode 9 step 37 reward tensor([-1]) loss 75.0109634399414 epsilon 0.6295375534064491
26-Feb-25 09:39:12 - agent.DQN.DQN - INFO - episode 9 step 38 reward tensor([-1]) loss 0.6901991367340088 epsilon 0.6295375534064491
26-Feb-25 09:39:12 - agent.DQN.DQN - INFO - episode 9 step 39 reward tensor([-1]) loss 0.47446706891059875 epsilon 0.6295375534064491
26-Feb-25 09:39:12 - agent.DQN.DQN - INFO - episode 9 step 40 reward tensor([-1]) loss 0.5980954170227051 epsilon 0.6295375534064491
26-Feb-25 09:39:12 - agent.DQN.DQN - INFO - episode 9 step 41 reward tensor([-1]) loss 0.5679664015769958 epsilon 0.6295375534064491
26-Feb-25 09:39:12 - agent.DQN.DQN - INFO - episode 9 step 42 reward tensor([-1]) loss 0.8718560338020325 epsilon 0.6295375534064491
26-Feb-25 09:39:12 - agent.DQN.DQN - INFO - episode 9 step 43 reward tensor([-1]) loss 75.13369750976562 epsilon 0.6295375534064491
26-Feb-25 09:39:12 - agent.DQN.DQN - INFO - episode 9 step 44 reward tensor([-1]) loss 0.6997043490409851 epsilon 0.6295375534064491
26-Feb-25 09:39:12 - agent.DQN.DQN - INFO - episode 9 step 45 reward tensor([-1]) loss 0.7773870825767517 epsilon 0.6295375534064491
26-Feb-25 09:39:12 - agent.DQN.DQN - INFO - episode 9 step 46 reward tensor([-1]) loss 0.48735058307647705 epsilon 0.6295375534064491
26-Feb-25 09:39:12 - agent.DQN.DQN - INFO - episode 9 step 47 reward tensor([-1]) loss 0.466553658246994 epsilon 0.6295375534064491
26-Feb-25 09:39:12 - agent.DQN.DQN - INFO - episode 9 step 48 reward tensor([-1]) loss 0.6606350541114807 epsilon 0.6295375534064491
26-Feb-25 09:39:12 - agent.DQN.DQN - INFO - episode 9 step 49 reward tensor([-1]) loss 0.7063778042793274 epsilon 0.6295375534064491
26-Feb-25 09:39:12 - agent.DQN.DQN - INFO - episode 9 step 50 reward tensor([-1]) loss 0.6575666069984436 epsilon 0.6295375534064491
26-Feb-25 09:39:12 - agent.DQN.DQN - INFO - episode 9 step 51 reward tensor([-1]) loss 0.5807696580886841 epsilon 0.6295375534064491
26-Feb-25 09:39:12 - agent.DQN.DQN - INFO - episode 9 step 52 reward tensor([-1]) loss 0.5651254057884216 epsilon 0.6295375534064491
26-Feb-25 09:39:12 - agent.DQN.DQN - INFO - episode 9 step 53 reward tensor([-1]) loss 0.8013319969177246 epsilon 0.6295375534064491
26-Feb-25 09:39:12 - agent.DQN.DQN - INFO - episode 9 step 54 reward tensor([-1]) loss 51.25310516357422 epsilon 0.6295375534064491
26-Feb-25 09:39:12 - agent.DQN.DQN - INFO - episode 9 step 55 reward tensor([-1]) loss 0.504788339138031 epsilon 0.6295375534064491
26-Feb-25 09:39:12 - agent.DQN.DQN - INFO - episode 9 step 56 reward tensor([-1]) loss 0.8470497131347656 epsilon 0.6295375534064491
26-Feb-25 09:39:12 - agent.DQN.DQN - INFO - episode 9 step 57 reward tensor([-1]) loss 0.7907223105430603 epsilon 0.6295375534064491
26-Feb-25 09:39:12 - agent.DQN.DQN - INFO - episode 9 step 58 reward tensor([-1]) loss 0.48663610219955444 epsilon 0.6295375534064491
26-Feb-25 09:39:13 - agent.DQN.DQN - INFO - episode 9 step 59 reward tensor([-1]) loss 0.5957971215248108 epsilon 0.6295375534064491
26-Feb-25 09:39:13 - agent.DQN.DQN - INFO - episode 9 step 60 reward tensor([-1]) loss 0.3807492256164551 epsilon 0.6295375534064491
26-Feb-25 09:39:13 - agent.DQN.DQN - INFO - episode 9 step 61 reward tensor([-1]) loss 0.537222146987915 epsilon 0.6295375534064491
26-Feb-25 09:39:13 - agent.DQN.DQN - INFO - episode 9 step 62 reward tensor([-1]) loss 0.4987512230873108 epsilon 0.6295375534064491
26-Feb-25 09:39:13 - agent.DQN.DQN - INFO - episode 9 step 63 reward tensor([-1]) loss 0.8235465288162231 epsilon 0.6295375534064491
26-Feb-25 09:39:13 - agent.DQN.DQN - INFO - episode 9 step 64 reward tensor([-1]) loss 0.8902361392974854 epsilon 0.6295375534064491
26-Feb-25 09:39:13 - agent.DQN.DQN - INFO - episode 9 step 65 reward tensor([-1]) loss 0.4340400695800781 epsilon 0.6295375534064491
26-Feb-25 09:39:13 - agent.DQN.DQN - INFO - episode 9 step 66 reward tensor([-1]) loss 75.09705352783203 epsilon 0.6295375534064491
26-Feb-25 09:39:13 - agent.DQN.DQN - INFO - episode 9 step 67 reward tensor([-1]) loss 0.5687068700790405 epsilon 0.6295375534064491
26-Feb-25 09:39:13 - agent.DQN.DQN - INFO - episode 9 step 68 reward tensor([-1]) loss 0.7575212717056274 epsilon 0.6295375534064491
26-Feb-25 09:39:13 - agent.DQN.DQN - INFO - episode 9 step 69 reward tensor([-1]) loss 0.3940803110599518 epsilon 0.6295375534064491
26-Feb-25 09:39:13 - agent.DQN.DQN - INFO - episode 9 step 70 reward tensor([-1]) loss 0.7731103301048279 epsilon 0.6295375534064491
26-Feb-25 09:39:13 - agent.DQN.DQN - INFO - episode 9 step 71 reward tensor([-1]) loss 0.6524158120155334 epsilon 0.6295375534064491
26-Feb-25 09:39:13 - agent.DQN.DQN - INFO - episode 9 step 72 reward tensor([-1]) loss 0.4676015377044678 epsilon 0.6295375534064491
26-Feb-25 09:39:13 - agent.DQN.DQN - INFO - episode 9 step 73 reward tensor([-1]) loss 0.4217764735221863 epsilon 0.6295375534064491
26-Feb-25 09:39:13 - agent.DQN.DQN - INFO - episode 9 step 74 reward tensor([-1]) loss 0.6827360987663269 epsilon 0.6295375534064491
26-Feb-25 09:39:13 - agent.DQN.DQN - INFO - episode 9 step 75 reward tensor([-1]) loss 0.679627001285553 epsilon 0.6295375534064491
26-Feb-25 09:39:13 - agent.DQN.DQN - INFO - episode 9 step 76 reward tensor([-1]) loss 0.48190808296203613 epsilon 0.6295375534064491
26-Feb-25 09:39:13 - agent.DQN.DQN - INFO - episode 9 step 77 reward tensor([-1]) loss 0.44339245557785034 epsilon 0.6295375534064491
26-Feb-25 09:39:13 - agent.DQN.DQN - INFO - episode 9 step 78 reward tensor([-1]) loss 0.5433779954910278 epsilon 0.6295375534064491
26-Feb-25 09:39:13 - agent.DQN.DQN - INFO - episode 9 step 79 reward tensor([-1]) loss 0.48055166006088257 epsilon 0.6295375534064491
26-Feb-25 09:39:13 - agent.DQN.DQN - INFO - episode 9 step 80 reward tensor([-1]) loss 0.4740751385688782 epsilon 0.6295375534064491
26-Feb-25 09:39:13 - agent.DQN.DQN - INFO - episode 9 step 81 reward tensor([-1]) loss 0.5317443609237671 epsilon 0.6295375534064491
26-Feb-25 09:39:13 - agent.DQN.DQN - INFO - episode 9 step 82 reward tensor([-1]) loss 0.5216630697250366 epsilon 0.6295375534064491
26-Feb-25 09:39:13 - agent.DQN.DQN - INFO - episode 9 step 83 reward tensor([-1]) loss 0.5390256643295288 epsilon 0.6295375534064491
26-Feb-25 09:39:13 - agent.DQN.DQN - INFO - episode 9 step 84 reward tensor([-1]) loss 0.5464100241661072 epsilon 0.6295375534064491
26-Feb-25 09:39:13 - agent.DQN.DQN - INFO - episode 9 step 85 reward tensor([-1]) loss 0.7132570743560791 epsilon 0.6295375534064491
26-Feb-25 09:39:13 - agent.DQN.DQN - INFO - episode 9 step 86 reward tensor([-1]) loss 75.23216247558594 epsilon 0.6295375534064491
26-Feb-25 09:39:13 - agent.DQN.DQN - INFO - episode 9 step 87 reward tensor([-1]) loss 0.9113607406616211 epsilon 0.6295375534064491
26-Feb-25 09:39:13 - agent.DQN.DQN - INFO - episode 9 step 88 reward tensor([-1]) loss 0.5264745950698853 epsilon 0.6295375534064491
26-Feb-25 09:39:13 - agent.DQN.DQN - INFO - episode 9 step 89 reward tensor([-1]) loss 0.4331320524215698 epsilon 0.6295375534064491
26-Feb-25 09:39:13 - agent.DQN.DQN - INFO - episode 9 step 90 reward tensor([-1]) loss 0.6840062737464905 epsilon 0.6295375534064491
26-Feb-25 09:39:13 - agent.DQN.DQN - INFO - episode 9 step 91 reward tensor([-1]) loss 0.557431697845459 epsilon 0.6295375534064491
26-Feb-25 09:39:13 - agent.DQN.DQN - INFO - episode 9 step 92 reward tensor([-1]) loss 0.7443134188652039 epsilon 0.6295375534064491
26-Feb-25 09:39:13 - agent.DQN.DQN - INFO - episode 9 step 93 reward tensor([-1]) loss 0.5060240030288696 epsilon 0.6295375534064491
26-Feb-25 09:39:13 - agent.DQN.DQN - INFO - episode 9 step 94 reward tensor([-1]) loss 0.6259315609931946 epsilon 0.6295375534064491
26-Feb-25 09:39:13 - agent.DQN.DQN - INFO - episode 9 step 95 reward tensor([-1]) loss 0.6315637826919556 epsilon 0.6295375534064491
26-Feb-25 09:39:13 - agent.DQN.DQN - INFO - episode 9 step 96 reward tensor([-1]) loss 0.5356526374816895 epsilon 0.6295375534064491
26-Feb-25 09:39:13 - agent.DQN.DQN - INFO - episode 9 step 97 reward tensor([-1]) loss 0.5169775485992432 epsilon 0.6295375534064491
26-Feb-25 09:39:13 - agent.DQN.DQN - INFO - episode 9 step 98 reward tensor([-1]) loss 0.5727531313896179 epsilon 0.6295375534064491
26-Feb-25 09:39:13 - agent.DQN.DQN - INFO - episode 9 step 99 reward tensor([-1]) loss 0.470022052526474 epsilon 0.6295375534064491
26-Feb-25 09:39:13 - agent.DQN.DQN - INFO - episode 9 step 100 reward tensor([-1]) loss 0.5530329942703247 epsilon 0.6295375534064491
26-Feb-25 09:39:13 - agent.DQN.DQN - INFO - episode 9 step 101 reward tensor([-1]) loss 0.7491551041603088 epsilon 0.6295375534064491
26-Feb-25 09:39:13 - agent.DQN.DQN - INFO - episode 9 step 102 reward tensor([-1]) loss 0.502090334892273 epsilon 0.6295375534064491
26-Feb-25 09:39:13 - agent.DQN.DQN - INFO - episode 9 step 103 reward tensor([-1]) loss 0.92183917760849 epsilon 0.6295375534064491
26-Feb-25 09:39:13 - agent.DQN.DQN - INFO - episode 9 step 104 reward tensor([-1]) loss 0.6502997875213623 epsilon 0.6295375534064491
26-Feb-25 09:39:13 - agent.DQN.DQN - INFO - episode 9 step 105 reward tensor([-1]) loss 0.7109571695327759 epsilon 0.6295375534064491
26-Feb-25 09:39:13 - agent.DQN.DQN - INFO - episode 9 step 106 reward tensor([-1]) loss 0.7025317549705505 epsilon 0.6295375534064491
26-Feb-25 09:39:13 - agent.DQN.DQN - INFO - episode 9 step 107 reward tensor([-1]) loss 0.47322773933410645 epsilon 0.6295375534064491
26-Feb-25 09:39:13 - agent.DQN.DQN - INFO - episode 9 step 108 reward tensor([-1]) loss 0.4827363193035126 epsilon 0.6295375534064491
26-Feb-25 09:39:13 - agent.DQN.DQN - INFO - episode 9 step 109 reward tensor([-1]) loss 0.37287256121635437 epsilon 0.6295375534064491
26-Feb-25 09:39:13 - agent.DQN.DQN - INFO - episode 9 step 110 reward tensor([-1]) loss 0.7681165933609009 epsilon 0.6295375534064491
26-Feb-25 09:39:13 - agent.DQN.DQN - INFO - episode 9 step 111 reward tensor([-1]) loss 0.44520506262779236 epsilon 0.6295375534064491
26-Feb-25 09:39:13 - agent.DQN.DQN - INFO - episode 9 step 112 reward tensor([-1]) loss 0.5047000646591187 epsilon 0.6295375534064491
26-Feb-25 09:39:13 - agent.DQN.DQN - INFO - episode 9 step 113 reward tensor([-1]) loss 0.609763503074646 epsilon 0.6295375534064491
26-Feb-25 09:39:13 - agent.DQN.DQN - INFO - episode 9 step 114 reward tensor([-1]) loss 0.4502488076686859 epsilon 0.6295375534064491
26-Feb-25 09:39:13 - agent.DQN.DQN - INFO - episode 9 step 115 reward tensor([-1]) loss 0.5911184549331665 epsilon 0.6295375534064491
26-Feb-25 09:39:13 - agent.DQN.DQN - INFO - episode 9 step 116 reward tensor([-1]) loss 0.5414142608642578 epsilon 0.6295375534064491
26-Feb-25 09:39:13 - agent.DQN.DQN - INFO - episode 9 step 117 reward tensor([-1]) loss 0.6169514060020447 epsilon 0.6295375534064491
26-Feb-25 09:39:13 - agent.DQN.DQN - INFO - episode 9 step 118 reward tensor([-1]) loss 74.7828369140625 epsilon 0.6295375534064491
26-Feb-25 09:39:13 - agent.DQN.DQN - INFO - episode 9 step 119 reward tensor([-1]) loss 0.6139703989028931 epsilon 0.6295375534064491
26-Feb-25 09:39:13 - agent.DQN.DQN - INFO - episode 9 step 120 reward tensor([-1]) loss 0.6306633949279785 epsilon 0.6295375534064491
26-Feb-25 09:39:13 - agent.DQN.DQN - INFO - episode 9 step 121 reward tensor([-1]) loss 52.17582321166992 epsilon 0.6295375534064491
26-Feb-25 09:39:13 - agent.DQN.DQN - INFO - episode 9 step 122 reward tensor([-1]) loss 0.48124730587005615 epsilon 0.6295375534064491
26-Feb-25 09:39:13 - agent.DQN.DQN - INFO - episode 9 step 123 reward tensor([-1]) loss 0.5705682039260864 epsilon 0.6295375534064491
26-Feb-25 09:39:13 - agent.DQN.DQN - INFO - episode 9 step 124 reward tensor([-1]) loss 0.7720997333526611 epsilon 0.6295375534064491
26-Feb-25 09:39:13 - agent.DQN.DQN - INFO - episode 9 step 125 reward tensor([-1]) loss 0.5981425046920776 epsilon 0.6295375534064491
26-Feb-25 09:39:13 - agent.DQN.DQN - INFO - episode 9 step 126 reward tensor([-1]) loss 0.4729086756706238 epsilon 0.6295375534064491
26-Feb-25 09:39:13 - agent.DQN.DQN - INFO - episode 9 step 127 reward tensor([-1]) loss 0.38695552945137024 epsilon 0.6295375534064491
26-Feb-25 09:39:13 - agent.DQN.DQN - INFO - episode 9 step 128 reward tensor([-1]) loss 0.6068220734596252 epsilon 0.6295375534064491
26-Feb-25 09:39:13 - agent.DQN.DQN - INFO - episode 9 step 129 reward tensor([-1]) loss 0.6427764892578125 epsilon 0.6295375534064491
26-Feb-25 09:39:13 - agent.DQN.DQN - INFO - episode 9 step 130 reward tensor([-1]) loss 0.4758729636669159 epsilon 0.6295375534064491
26-Feb-25 09:39:13 - agent.DQN.DQN - INFO - episode 9 step 131 reward tensor([-1]) loss 0.5118253231048584 epsilon 0.6295375534064491
26-Feb-25 09:39:13 - agent.DQN.DQN - INFO - episode 9 step 132 reward tensor([-1]) loss 0.44401776790618896 epsilon 0.6295375534064491
26-Feb-25 09:39:14 - agent.DQN.DQN - INFO - episode 9 step 133 reward tensor([-1]) loss 0.4348931908607483 epsilon 0.6295375534064491
26-Feb-25 09:39:14 - agent.DQN.DQN - INFO - episode 9 step 134 reward tensor([-1]) loss 0.4048859477043152 epsilon 0.6295375534064491
26-Feb-25 09:39:14 - agent.DQN.DQN - INFO - episode 9 step 135 reward tensor([-1]) loss 0.49524739384651184 epsilon 0.6295375534064491
26-Feb-25 09:39:14 - agent.DQN.DQN - INFO - episode 9 step 136 reward tensor([-1]) loss 0.5064178109169006 epsilon 0.6295375534064491
26-Feb-25 09:39:14 - agent.DQN.DQN - INFO - episode 9 step 137 reward tensor([-1]) loss 0.6502996683120728 epsilon 0.6295375534064491
26-Feb-25 09:39:14 - agent.DQN.DQN - INFO - episode 9 step 138 reward tensor([-1]) loss 0.5507092475891113 epsilon 0.6295375534064491
26-Feb-25 09:39:14 - agent.DQN.DQN - INFO - episode 9 step 139 reward tensor([-1]) loss 0.5362323522567749 epsilon 0.6295375534064491
26-Feb-25 09:39:14 - agent.DQN.DQN - INFO - episode 9 step 140 reward tensor([-1]) loss 0.5231367945671082 epsilon 0.6295375534064491
26-Feb-25 09:39:14 - agent.DQN.DQN - INFO - episode 9 step 141 reward tensor([-1]) loss 0.31722694635391235 epsilon 0.6295375534064491
26-Feb-25 09:39:14 - agent.DQN.DQN - INFO - episode 9 step 142 reward tensor([-1]) loss 0.46819180250167847 epsilon 0.6295375534064491
26-Feb-25 09:39:14 - agent.DQN.DQN - INFO - episode 9 step 143 reward tensor([-1]) loss 0.4827535152435303 epsilon 0.6295375534064491
26-Feb-25 09:39:14 - agent.DQN.DQN - INFO - episode 9 step 144 reward tensor([-1]) loss 0.4876787066459656 epsilon 0.6295375534064491
26-Feb-25 09:39:14 - agent.DQN.DQN - INFO - episode 9 step 145 reward tensor([-1]) loss 0.5431666374206543 epsilon 0.6295375534064491
26-Feb-25 09:39:14 - agent.DQN.DQN - INFO - episode 9 step 146 reward tensor([-1]) loss 0.775482177734375 epsilon 0.6295375534064491
26-Feb-25 09:39:14 - agent.DQN.DQN - INFO - episode 9 step 147 reward tensor([-1]) loss 0.49155980348587036 epsilon 0.6295375534064491
26-Feb-25 09:39:14 - agent.DQN.DQN - INFO - episode 9 step 148 reward tensor([-1]) loss 0.7023319602012634 epsilon 0.6295375534064491
26-Feb-25 09:39:14 - agent.DQN.DQN - INFO - episode 9 step 149 reward tensor([-1]) loss 52.07280731201172 epsilon 0.6295375534064491
26-Feb-25 09:39:14 - agent.DQN.DQN - INFO - episode 9 step 150 reward tensor([-1]) loss 0.6838243007659912 epsilon 0.6295375534064491
26-Feb-25 09:39:14 - agent.DQN.DQN - INFO - episode 9 step 151 reward tensor([-1]) loss 0.49169865250587463 epsilon 0.6295375534064491
26-Feb-25 09:39:14 - agent.DQN.DQN - INFO - episode 9 step 152 reward tensor([-1]) loss 52.00636672973633 epsilon 0.6295375534064491
26-Feb-25 09:39:14 - agent.DQN.DQN - INFO - episode 9 step 153 reward tensor([-1]) loss 0.5732133984565735 epsilon 0.6295375534064491
26-Feb-25 09:39:14 - agent.DQN.DQN - INFO - episode 9 step 154 reward tensor([-1]) loss 51.77223587036133 epsilon 0.6295375534064491
26-Feb-25 09:39:14 - agent.DQN.DQN - INFO - episode 9 step 155 reward tensor([-1]) loss 1.0292593240737915 epsilon 0.6295375534064491
26-Feb-25 09:39:14 - agent.DQN.DQN - INFO - episode 9 step 156 reward tensor([-1]) loss 0.9633499383926392 epsilon 0.6295375534064491
26-Feb-25 09:39:14 - agent.DQN.DQN - INFO - episode 9 step 157 reward tensor([-1]) loss 0.5611043572425842 epsilon 0.6295375534064491
26-Feb-25 09:39:14 - agent.DQN.DQN - INFO - episode 9 step 158 reward tensor([-1]) loss 0.5052099823951721 epsilon 0.6295375534064491
26-Feb-25 09:39:14 - agent.DQN.DQN - INFO - episode 9 step 159 reward tensor([-1]) loss 0.41256803274154663 epsilon 0.6295375534064491
26-Feb-25 09:39:14 - agent.DQN.DQN - INFO - episode 9 step 160 reward tensor([-1]) loss 0.9555642008781433 epsilon 0.6295375534064491
26-Feb-25 09:39:14 - agent.DQN.DQN - INFO - episode 9 step 161 reward tensor([-1]) loss 0.6796697378158569 epsilon 0.6295375534064491
26-Feb-25 09:39:14 - agent.DQN.DQN - INFO - episode 9 step 162 reward tensor([-1]) loss 51.80805587768555 epsilon 0.6295375534064491
26-Feb-25 09:39:14 - agent.DQN.DQN - INFO - episode 9 step 163 reward tensor([-1]) loss 0.9499037861824036 epsilon 0.6295375534064491
26-Feb-25 09:39:14 - agent.DQN.DQN - INFO - episode 9 step 164 reward tensor([-1]) loss 51.44086837768555 epsilon 0.6295375534064491
26-Feb-25 09:39:14 - agent.DQN.DQN - INFO - episode 9 step 165 reward tensor([-1]) loss 0.644662618637085 epsilon 0.6295375534064491
26-Feb-25 09:39:14 - agent.DQN.DQN - INFO - episode 9 step 166 reward tensor([-1]) loss 0.6373962163925171 epsilon 0.6295375534064491
26-Feb-25 09:39:14 - agent.DQN.DQN - INFO - episode 9 step 167 reward tensor([-1]) loss 74.61942291259766 epsilon 0.6295375534064491
26-Feb-25 09:39:14 - agent.DQN.DQN - INFO - episode 9 step 168 reward tensor([-1]) loss 0.5742817521095276 epsilon 0.6295375534064491
26-Feb-25 09:39:14 - agent.DQN.DQN - INFO - episode 9 step 169 reward tensor([-1]) loss 0.5177645683288574 epsilon 0.6295375534064491
26-Feb-25 09:39:14 - agent.DQN.DQN - INFO - episode 9 step 170 reward tensor([-1]) loss 0.8202513456344604 epsilon 0.6295375534064491
26-Feb-25 09:39:14 - agent.DQN.DQN - INFO - episode 9 step 171 reward tensor([-1]) loss 0.9663704037666321 epsilon 0.6295375534064491
26-Feb-25 09:39:14 - agent.DQN.DQN - INFO - episode 9 step 172 reward tensor([-1]) loss 0.7827069759368896 epsilon 0.6295375534064491
26-Feb-25 09:39:14 - agent.DQN.DQN - INFO - episode 9 step 173 reward tensor([-1]) loss 0.5114433169364929 epsilon 0.6295375534064491
26-Feb-25 09:39:14 - agent.DQN.DQN - INFO - episode 9 step 174 reward tensor([-1]) loss 0.5576265454292297 epsilon 0.6295375534064491
26-Feb-25 09:39:14 - agent.DQN.DQN - INFO - episode 9 step 175 reward tensor([-1]) loss 0.5901867151260376 epsilon 0.6295375534064491
26-Feb-25 09:39:14 - agent.DQN.DQN - INFO - episode 9 step 176 reward tensor([-1]) loss 0.35851719975471497 epsilon 0.6295375534064491
26-Feb-25 09:39:14 - agent.DQN.DQN - INFO - episode 9 step 177 reward tensor([-1]) loss 0.6967816948890686 epsilon 0.6295375534064491
26-Feb-25 09:39:14 - agent.DQN.DQN - INFO - episode 9 step 178 reward tensor([-1]) loss 50.994720458984375 epsilon 0.6295375534064491
26-Feb-25 09:39:14 - agent.DQN.DQN - INFO - episode 9 step 179 reward tensor([-1]) loss 0.47200167179107666 epsilon 0.6295375534064491
26-Feb-25 09:39:14 - agent.DQN.DQN - INFO - episode 9 step 180 reward tensor([-1]) loss 0.465874582529068 epsilon 0.6295375534064491
26-Feb-25 09:39:14 - agent.DQN.DQN - INFO - episode 9 step 181 reward tensor([-1]) loss 0.5810137987136841 epsilon 0.6295375534064491
26-Feb-25 09:39:14 - agent.DQN.DQN - INFO - episode 9 step 182 reward tensor([-1]) loss 0.5366833806037903 epsilon 0.6295375534064491
26-Feb-25 09:39:14 - agent.DQN.DQN - INFO - episode 9 step 183 reward tensor([-1]) loss 75.34044647216797 epsilon 0.6295375534064491
26-Feb-25 09:39:14 - agent.DQN.DQN - INFO - episode 9 step 184 reward tensor([-1]) loss 0.6626682281494141 epsilon 0.6295375534064491
26-Feb-25 09:39:14 - agent.DQN.DQN - INFO - episode 9 step 185 reward tensor([-1]) loss 0.5404545664787292 epsilon 0.6295375534064491
26-Feb-25 09:39:14 - agent.DQN.DQN - INFO - episode 9 step 186 reward tensor([-1]) loss 74.6590347290039 epsilon 0.6295375534064491
26-Feb-25 09:39:14 - agent.DQN.DQN - INFO - episode 9 step 187 reward tensor([-1]) loss 0.5579220056533813 epsilon 0.6295375534064491
26-Feb-25 09:39:14 - agent.DQN.DQN - INFO - episode 9 step 188 reward tensor([-1]) loss 0.7687588930130005 epsilon 0.6295375534064491
26-Feb-25 09:39:14 - agent.DQN.DQN - INFO - episode 9 step 189 reward tensor([-1]) loss 0.4967179000377655 epsilon 0.6295375534064491
26-Feb-25 09:39:14 - agent.DQN.DQN - INFO - episode 9 step 190 reward tensor([-1]) loss 0.7345677614212036 epsilon 0.6295375534064491
26-Feb-25 09:39:14 - agent.DQN.DQN - INFO - episode 9 step 191 reward tensor([-1]) loss 0.6884403228759766 epsilon 0.6295375534064491
26-Feb-25 09:39:14 - agent.DQN.DQN - INFO - episode 9 step 192 reward tensor([-1]) loss 0.7841576337814331 epsilon 0.6295375534064491
26-Feb-25 09:39:14 - agent.DQN.DQN - INFO - episode 9 step 193 reward tensor([-1]) loss 74.83168029785156 epsilon 0.6295375534064491
26-Feb-25 09:39:14 - agent.DQN.DQN - INFO - episode 9 step 194 reward tensor([-1]) loss 0.5195776224136353 epsilon 0.6295375534064491
26-Feb-25 09:39:14 - agent.DQN.DQN - INFO - episode 9 step 195 reward tensor([-1]) loss 1.0576967000961304 epsilon 0.6295375534064491
26-Feb-25 09:39:14 - agent.DQN.DQN - INFO - episode 9 step 196 reward tensor([-1]) loss 0.924606442451477 epsilon 0.6295375534064491
26-Feb-25 09:39:14 - agent.DQN.DQN - INFO - episode 9 step 197 reward tensor([-1]) loss 0.6682528257369995 epsilon 0.6295375534064491
26-Feb-25 09:39:14 - agent.DQN.DQN - INFO - episode 9 step 198 reward tensor([-1]) loss 0.5423790812492371 epsilon 0.6295375534064491
26-Feb-25 09:39:14 - agent.DQN.DQN - INFO - episode 9 step 199 reward tensor([-1]) loss 0.5091902613639832 epsilon 0.6295375534064491
26-Feb-25 09:39:14 - agent.DQN.DQN - INFO - episode 9 step 200 reward tensor([-1]) loss 0.5050077438354492 epsilon 0.6295375534064491
26-Feb-25 09:39:14 - agent.DQN.DQN - INFO - episode 9 step 201 reward tensor([-1]) loss 0.6226431131362915 epsilon 0.6295375534064491
26-Feb-25 09:39:14 - agent.DQN.DQN - INFO - episode 9 step 202 reward tensor([-1]) loss 0.4289398789405823 epsilon 0.6295375534064491
26-Feb-25 09:39:14 - agent.DQN.DQN - INFO - episode 9 step 203 reward tensor([-1]) loss 52.642704010009766 epsilon 0.6295375534064491
26-Feb-25 09:39:14 - agent.DQN.DQN - INFO - episode 9 step 204 reward tensor([-1]) loss 51.20936584472656 epsilon 0.6295375534064491
26-Feb-25 09:39:14 - agent.DQN.DQN - INFO - episode 9 step 205 reward tensor([-1]) loss 0.5506991147994995 epsilon 0.6295375534064491
26-Feb-25 09:39:15 - agent.DQN.DQN - INFO - episode 9 step 206 reward tensor([-1]) loss 1.586890697479248 epsilon 0.6295375534064491
26-Feb-25 09:39:15 - agent.DQN.DQN - INFO - episode 9 step 207 reward tensor([-1]) loss 0.9781830906867981 epsilon 0.6295375534064491
26-Feb-25 09:39:15 - agent.DQN.DQN - INFO - episode 9 step 208 reward tensor([-1]) loss 1.2435786724090576 epsilon 0.6295375534064491
26-Feb-25 09:39:15 - agent.DQN.DQN - INFO - episode 9 step 209 reward tensor([-1]) loss 0.5097579956054688 epsilon 0.6295375534064491
26-Feb-25 09:39:15 - agent.DQN.DQN - INFO - episode 9 step 210 reward tensor([-1]) loss 0.5887988805770874 epsilon 0.6295375534064491
26-Feb-25 09:39:15 - agent.DQN.DQN - INFO - episode 9 step 211 reward tensor([-1]) loss 0.49589136242866516 epsilon 0.6295375534064491
26-Feb-25 09:39:15 - agent.DQN.DQN - INFO - episode 9 step 212 reward tensor([-1]) loss 1.1813708543777466 epsilon 0.6295375534064491
26-Feb-25 09:39:15 - agent.DQN.DQN - INFO - episode 9 step 213 reward tensor([-1]) loss 0.6392253041267395 epsilon 0.6295375534064491
26-Feb-25 09:39:15 - agent.DQN.DQN - INFO - episode 9 step 214 reward tensor([-1]) loss 0.7411743402481079 epsilon 0.6295375534064491
26-Feb-25 09:39:15 - agent.DQN.DQN - INFO - episode 9 step 215 reward tensor([-1]) loss 1.1225638389587402 epsilon 0.6295375534064491
26-Feb-25 09:39:15 - agent.DQN.DQN - INFO - episode 9 step 216 reward tensor([-1]) loss 0.4869456887245178 epsilon 0.6295375534064491
26-Feb-25 09:39:15 - agent.DQN.DQN - INFO - episode 9 step 217 reward tensor([-1]) loss 1.0477715730667114 epsilon 0.6295375534064491
26-Feb-25 09:39:15 - agent.DQN.DQN - INFO - episode 9 step 218 reward tensor([-1]) loss 1.0205950736999512 epsilon 0.6295375534064491
26-Feb-25 09:39:15 - agent.DQN.DQN - INFO - episode 9 step 219 reward tensor([-1]) loss 1.1282119750976562 epsilon 0.6295375534064491
26-Feb-25 09:39:15 - agent.DQN.DQN - INFO - episode 9 step 220 reward tensor([-1]) loss 0.4871147871017456 epsilon 0.6295375534064491
26-Feb-25 09:39:15 - agent.DQN.DQN - INFO - episode 9 step 221 reward tensor([-1]) loss 1.0461077690124512 epsilon 0.6295375534064491
26-Feb-25 09:39:15 - agent.DQN.DQN - INFO - episode 9 step 222 reward tensor([-1]) loss 1.3550167083740234 epsilon 0.6295375534064491
26-Feb-25 09:39:15 - agent.DQN.DQN - INFO - episode 9 step 223 reward tensor([-1]) loss 0.9008614420890808 epsilon 0.6295375534064491
26-Feb-25 09:39:15 - agent.DQN.DQN - INFO - episode 9 step 224 reward tensor([-1]) loss 0.7712234258651733 epsilon 0.6295375534064491
26-Feb-25 09:39:15 - agent.DQN.DQN - INFO - episode 9 step 225 reward tensor([-1]) loss 1.083214521408081 epsilon 0.6295375534064491
26-Feb-25 09:39:15 - agent.DQN.DQN - INFO - episode 9 step 226 reward tensor([-1]) loss 1.1971490383148193 epsilon 0.6295375534064491
26-Feb-25 09:39:15 - agent.DQN.DQN - INFO - episode 9 step 227 reward tensor([-1]) loss 0.5933166146278381 epsilon 0.6295375534064491
26-Feb-25 09:39:15 - agent.DQN.DQN - INFO - episode 9 step 228 reward tensor([-1]) loss 0.32782164216041565 epsilon 0.6295375534064491
26-Feb-25 09:39:15 - agent.DQN.DQN - INFO - episode 9 step 229 reward tensor([-1]) loss 74.7088851928711 epsilon 0.6295375534064491
26-Feb-25 09:39:15 - agent.DQN.DQN - INFO - episode 9 step 230 reward tensor([-1]) loss 0.6583959460258484 epsilon 0.6295375534064491
26-Feb-25 09:39:15 - agent.DQN.DQN - INFO - episode 9 step 231 reward tensor([-1]) loss 0.4176428020000458 epsilon 0.6295375534064491
26-Feb-25 09:39:15 - agent.DQN.DQN - INFO - episode 9 step 232 reward tensor([-1]) loss 75.09597778320312 epsilon 0.6295375534064491
26-Feb-25 09:39:15 - agent.DQN.DQN - INFO - episode 9 step 233 reward tensor([-1]) loss 0.4266267418861389 epsilon 0.6295375534064491
26-Feb-25 09:39:15 - agent.DQN.DQN - INFO - episode 9 step 234 reward tensor([-1]) loss 0.6089572310447693 epsilon 0.6295375534064491
26-Feb-25 09:39:15 - agent.DQN.DQN - INFO - episode 9 step 235 reward tensor([-1]) loss 0.8909886479377747 epsilon 0.6295375534064491
26-Feb-25 09:39:15 - agent.DQN.DQN - INFO - episode 9 step 236 reward tensor([-1]) loss 0.898588240146637 epsilon 0.6295375534064491
26-Feb-25 09:39:15 - agent.DQN.DQN - INFO - episode 9 step 237 reward tensor([-1]) loss 50.653175354003906 epsilon 0.6295375534064491
26-Feb-25 09:39:15 - agent.DQN.DQN - INFO - episode 9 step 238 reward tensor([-1]) loss 0.545575737953186 epsilon 0.6295375534064491
26-Feb-25 09:39:15 - agent.DQN.DQN - INFO - episode 9 step 239 reward tensor([-1]) loss 0.6727946400642395 epsilon 0.6295375534064491
26-Feb-25 09:39:15 - agent.DQN.DQN - INFO - episode 9 step 240 reward tensor([-1]) loss 1.2912462949752808 epsilon 0.6295375534064491
26-Feb-25 09:39:15 - agent.DQN.DQN - INFO - episode 9 step 241 reward tensor([-1]) loss 0.6185709834098816 epsilon 0.6295375534064491
26-Feb-25 09:39:15 - agent.DQN.DQN - INFO - episode 9 step 242 reward tensor([-1]) loss 50.78554916381836 epsilon 0.6295375534064491
26-Feb-25 09:39:15 - agent.DQN.DQN - INFO - episode 9 step 243 reward tensor([-1]) loss 0.8330586552619934 epsilon 0.6295375534064491
26-Feb-25 09:39:15 - agent.DQN.DQN - INFO - episode 9 step 244 reward tensor([-1]) loss 1.1249473094940186 epsilon 0.6295375534064491
26-Feb-25 09:39:15 - agent.DQN.DQN - INFO - episode 9 step 245 reward tensor([-1]) loss 0.7263303995132446 epsilon 0.6295375534064491
26-Feb-25 09:39:15 - agent.DQN.DQN - INFO - episode 9 step 246 reward tensor([-1]) loss 0.6067025065422058 epsilon 0.6295375534064491
26-Feb-25 09:39:15 - agent.DQN.DQN - INFO - episode 9 step 247 reward tensor([-1]) loss 0.3992484509944916 epsilon 0.6295375534064491
26-Feb-25 09:39:15 - agent.DQN.DQN - INFO - episode 9 step 248 reward tensor([-1]) loss 0.8210539817810059 epsilon 0.6295375534064491
26-Feb-25 09:39:15 - agent.DQN.DQN - INFO - episode 9 step 249 reward tensor([-1]) loss 1.1419079303741455 epsilon 0.6295375534064491
26-Feb-25 09:39:15 - agent.DQN.DQN - INFO - episode 9 step 250 reward tensor([-1]) loss 0.5817369222640991 epsilon 0.6295375534064491
26-Feb-25 09:39:15 - agent.DQN.DQN - INFO - episode 9 step 251 reward tensor([-1]) loss 0.5604272484779358 epsilon 0.6295375534064491
26-Feb-25 09:39:15 - agent.DQN.DQN - INFO - episode 9 step 252 reward tensor([-1]) loss 0.796386182308197 epsilon 0.6295375534064491
26-Feb-25 09:39:15 - agent.DQN.DQN - INFO - episode 9 step 253 reward tensor([-1]) loss 0.7482274174690247 epsilon 0.6295375534064491
26-Feb-25 09:39:15 - agent.DQN.DQN - INFO - episode 9 step 254 reward tensor([-1]) loss 0.850220263004303 epsilon 0.6295375534064491
26-Feb-25 09:39:15 - agent.DQN.DQN - INFO - episode 9 step 255 reward tensor([-1]) loss 0.9811378717422485 epsilon 0.6295375534064491
26-Feb-25 09:39:15 - agent.DQN.DQN - INFO - episode 9 step 256 reward tensor([-1]) loss 1.0891002416610718 epsilon 0.6295375534064491
26-Feb-25 09:39:15 - agent.DQN.DQN - INFO - episode 9 step 257 reward tensor([-1]) loss 0.9586146473884583 epsilon 0.6295375534064491
26-Feb-25 09:39:15 - agent.DQN.DQN - INFO - episode 9 step 258 reward tensor([-1]) loss 0.8381530046463013 epsilon 0.6295375534064491
26-Feb-25 09:39:15 - agent.DQN.DQN - INFO - episode 9 step 259 reward tensor([-1]) loss 0.7506742477416992 epsilon 0.6295375534064491
26-Feb-25 09:39:15 - agent.DQN.DQN - INFO - episode 9 step 260 reward tensor([-1]) loss 0.5121921300888062 epsilon 0.6295375534064491
26-Feb-25 09:39:15 - agent.DQN.DQN - INFO - episode 9 step 261 reward tensor([-1]) loss 1.0321376323699951 epsilon 0.6295375534064491
26-Feb-25 09:39:15 - agent.DQN.DQN - INFO - episode 9 step 262 reward tensor([-1]) loss 1.055542230606079 epsilon 0.6295375534064491
26-Feb-25 09:39:15 - agent.DQN.DQN - INFO - episode 9 step 263 reward tensor([-1]) loss 0.41799721121788025 epsilon 0.6295375534064491
26-Feb-25 09:39:15 - agent.DQN.DQN - INFO - episode 9 step 264 reward tensor([-1]) loss 0.8012193441390991 epsilon 0.6295375534064491
26-Feb-25 09:39:15 - agent.DQN.DQN - INFO - episode 9 step 265 reward tensor([-1]) loss 0.9452884197235107 epsilon 0.6295375534064491
26-Feb-25 09:39:15 - agent.DQN.DQN - INFO - episode 9 step 266 reward tensor([-1]) loss 0.8333936929702759 epsilon 0.6295375534064491
26-Feb-25 09:39:15 - agent.DQN.DQN - INFO - episode 9 step 267 reward tensor([-1]) loss 50.909080505371094 epsilon 0.6295375534064491
26-Feb-25 09:39:15 - agent.DQN.DQN - INFO - episode 9 step 268 reward tensor([-1]) loss 0.487979531288147 epsilon 0.6295375534064491
26-Feb-25 09:39:15 - agent.DQN.DQN - INFO - episode 9 step 269 reward tensor([-1]) loss 1.0312076807022095 epsilon 0.6295375534064491
26-Feb-25 09:39:15 - agent.DQN.DQN - INFO - episode 9 step 270 reward tensor([-1]) loss 0.5238387584686279 epsilon 0.6295375534064491
26-Feb-25 09:39:15 - agent.DQN.DQN - INFO - episode 9 step 271 reward tensor([-1]) loss 0.5245575308799744 epsilon 0.6295375534064491
26-Feb-25 09:39:15 - agent.DQN.DQN - INFO - episode 9 step 272 reward tensor([-1]) loss 0.5874392986297607 epsilon 0.6295375534064491
26-Feb-25 09:39:15 - agent.DQN.DQN - INFO - episode 9 step 273 reward tensor([-1]) loss 0.5509905815124512 epsilon 0.6295375534064491
26-Feb-25 09:39:15 - agent.DQN.DQN - INFO - episode 9 step 274 reward tensor([-1]) loss 124.21282196044922 epsilon 0.6295375534064491
26-Feb-25 09:39:15 - agent.DQN.DQN - INFO - episode 9 step 275 reward tensor([-1]) loss 0.7065001130104065 epsilon 0.6295375534064491
26-Feb-25 09:39:15 - agent.DQN.DQN - INFO - episode 9 step 276 reward tensor([-1]) loss 0.4235183894634247 epsilon 0.6295375534064491
26-Feb-25 09:39:15 - agent.DQN.DQN - INFO - episode 9 step 277 reward tensor([-1]) loss 0.6205953359603882 epsilon 0.6295375534064491
26-Feb-25 09:39:15 - agent.DQN.DQN - INFO - episode 9 step 278 reward tensor([-1]) loss 74.41624450683594 epsilon 0.6295375534064491
26-Feb-25 09:39:15 - agent.DQN.DQN - INFO - episode 9 step 279 reward tensor([-1]) loss 0.5703808069229126 epsilon 0.6295375534064491
26-Feb-25 09:39:15 - agent.DQN.DQN - INFO - episode 9 step 280 reward tensor([-1]) loss 0.8384168148040771 epsilon 0.6295375534064491
26-Feb-25 09:39:16 - agent.DQN.DQN - INFO - episode 9 step 281 reward tensor([-1]) loss 0.5833480358123779 epsilon 0.6295375534064491
26-Feb-25 09:39:16 - agent.DQN.DQN - INFO - episode 9 step 282 reward tensor([-1]) loss 0.5735073685646057 epsilon 0.6295375534064491
26-Feb-25 09:39:16 - agent.DQN.DQN - INFO - episode 9 step 283 reward tensor([-1]) loss 0.8319721817970276 epsilon 0.6295375534064491
26-Feb-25 09:39:16 - agent.DQN.DQN - INFO - episode 9 step 284 reward tensor([-1]) loss 0.7237513661384583 epsilon 0.6295375534064491
26-Feb-25 09:39:16 - agent.DQN.DQN - INFO - episode 9 step 285 reward tensor([-1]) loss 0.8170024752616882 epsilon 0.6295375534064491
26-Feb-25 09:39:16 - agent.DQN.DQN - INFO - episode 9 step 286 reward tensor([-1]) loss 50.154945373535156 epsilon 0.6295375534064491
26-Feb-25 09:39:16 - agent.DQN.DQN - INFO - episode 9 step 287 reward tensor([-1]) loss 0.8856344223022461 epsilon 0.6295375534064491
26-Feb-25 09:39:16 - agent.DQN.DQN - INFO - episode 9 step 288 reward tensor([-1]) loss 0.7500646710395813 epsilon 0.6295375534064491
26-Feb-25 09:39:16 - agent.DQN.DQN - INFO - episode 9 step 289 reward tensor([-1]) loss 0.48520627617836 epsilon 0.6295375534064491
26-Feb-25 09:39:16 - agent.DQN.DQN - INFO - episode 9 step 290 reward tensor([-1]) loss 0.7004295587539673 epsilon 0.6295375534064491
26-Feb-25 09:39:16 - agent.DQN.DQN - INFO - episode 9 step 291 reward tensor([-1]) loss 0.9361317157745361 epsilon 0.6295375534064491
26-Feb-25 09:39:16 - agent.DQN.DQN - INFO - episode 9 step 292 reward tensor([-1]) loss 0.5611268281936646 epsilon 0.6295375534064491
26-Feb-25 09:39:16 - agent.DQN.DQN - INFO - episode 9 step 293 reward tensor([-1]) loss 0.6310256123542786 epsilon 0.6295375534064491
26-Feb-25 09:39:16 - agent.DQN.DQN - INFO - episode 9 step 294 reward tensor([-1]) loss 0.6138233542442322 epsilon 0.6295375534064491
26-Feb-25 09:39:16 - agent.DQN.DQN - INFO - episode 9 step 295 reward tensor([-1]) loss 0.5904353260993958 epsilon 0.6295375534064491
26-Feb-25 09:39:16 - agent.DQN.DQN - INFO - episode 9 step 296 reward tensor([-1]) loss 0.6162371635437012 epsilon 0.6295375534064491
26-Feb-25 09:39:16 - agent.DQN.DQN - INFO - episode 9 step 297 reward tensor([-1]) loss 0.617404043674469 epsilon 0.6295375534064491
26-Feb-25 09:39:16 - agent.DQN.DQN - INFO - episode 9 step 298 reward tensor([-1]) loss 50.2138786315918 epsilon 0.6295375534064491
26-Feb-25 09:39:16 - agent.DQN.DQN - INFO - episode 9 step 299 reward tensor([-1]) loss 50.339839935302734 epsilon 0.6295375534064491
26-Feb-25 09:39:16 - agent.DQN.DQN - INFO - episode 9 step 300 reward tensor([-1]) loss 0.6520894765853882 epsilon 0.6295375534064491
26-Feb-25 09:39:16 - agent.DQN.DQN - INFO - episode 9 step 301 reward tensor([-1]) loss 0.7892488241195679 epsilon 0.6295375534064491
26-Feb-25 09:39:16 - __main__ - INFO - Training finished for epoch 2, training time: 25.83 seconds
26-Feb-25 09:39:16 - __main__ - INFO - Starting epoch 3
26-Feb-25 09:39:16 - agent.DQN.DQN - INFO - QNetwork initialized with 10 observations and 9 actions
26-Feb-25 09:39:16 - agent.DQN.DQN - INFO - QNetwork initialized with 10 observations and 9 actions
26-Feb-25 09:39:16 - __main__ - INFO - Q-Networks initialized and synchronized
26-Feb-25 09:39:16 - __main__ - INFO - Optimizer, LR scheduler, and loss function initialized
26-Feb-25 09:39:16 - __main__ - INFO - Epsilon-greedy strategy initialized
26-Feb-25 09:39:16 - __main__ - INFO - Replay buffer initialized
26-Feb-25 09:39:16 - __main__ - INFO - Training DQN2 agent
26-Feb-25 09:39:16 - agent.DQN.DQN - INFO - episode 1 step 128 reward tensor([-1]) loss 720.5440063476562 epsilon 0.82
26-Feb-25 09:39:16 - agent.DQN.DQN - INFO - episode 1 step 129 reward tensor([-1]) loss 215.35064697265625 epsilon 0.82
26-Feb-25 09:39:16 - agent.DQN.DQN - INFO - episode 1 step 130 reward tensor([-1]) loss 342.780029296875 epsilon 0.82
26-Feb-25 09:39:16 - agent.DQN.DQN - INFO - episode 1 step 131 reward tensor([-1]) loss 182.07943725585938 epsilon 0.82
26-Feb-25 09:39:16 - agent.DQN.DQN - INFO - episode 1 step 132 reward tensor([-1]) loss 66.54911041259766 epsilon 0.82
26-Feb-25 09:39:16 - agent.DQN.DQN - INFO - episode 1 step 133 reward tensor([-1]) loss 84.23681640625 epsilon 0.82
26-Feb-25 09:39:16 - agent.DQN.DQN - INFO - episode 1 step 134 reward tensor([-1]) loss 81.58013153076172 epsilon 0.82
26-Feb-25 09:39:16 - agent.DQN.DQN - INFO - episode 1 step 135 reward tensor([-1]) loss 64.29773712158203 epsilon 0.82
26-Feb-25 09:39:16 - agent.DQN.DQN - INFO - episode 1 step 136 reward tensor([-1]) loss 65.08171844482422 epsilon 0.82
26-Feb-25 09:39:16 - agent.DQN.DQN - INFO - episode 1 step 137 reward tensor([-1]) loss 61.829559326171875 epsilon 0.82
26-Feb-25 09:39:16 - agent.DQN.DQN - INFO - episode 1 step 138 reward tensor([-1]) loss 47.466304779052734 epsilon 0.82
26-Feb-25 09:39:16 - agent.DQN.DQN - INFO - episode 1 step 139 reward tensor([-1]) loss 33.74768829345703 epsilon 0.82
26-Feb-25 09:39:16 - agent.DQN.DQN - INFO - episode 1 step 140 reward tensor([-1]) loss 29.203994750976562 epsilon 0.82
26-Feb-25 09:39:16 - agent.DQN.DQN - INFO - episode 1 step 141 reward tensor([-1]) loss 35.60585403442383 epsilon 0.82
26-Feb-25 09:39:16 - agent.DQN.DQN - INFO - episode 1 step 142 reward tensor([-1]) loss 35.143531799316406 epsilon 0.82
26-Feb-25 09:39:16 - agent.DQN.DQN - INFO - episode 1 step 143 reward tensor([-1]) loss 29.544849395751953 epsilon 0.82
26-Feb-25 09:39:16 - agent.DQN.DQN - INFO - episode 1 step 144 reward tensor([-1]) loss 19.05722999572754 epsilon 0.82
26-Feb-25 09:39:16 - agent.DQN.DQN - INFO - episode 1 step 145 reward tensor([-1]) loss 13.357183456420898 epsilon 0.82
26-Feb-25 09:39:16 - agent.DQN.DQN - INFO - episode 1 step 146 reward tensor([-1]) loss 12.736912727355957 epsilon 0.82
26-Feb-25 09:39:16 - agent.DQN.DQN - INFO - episode 1 step 147 reward tensor([-1]) loss 13.43112564086914 epsilon 0.82
26-Feb-25 09:39:16 - agent.DQN.DQN - INFO - episode 1 step 148 reward tensor([-1]) loss 13.649969100952148 epsilon 0.82
26-Feb-25 09:39:16 - agent.DQN.DQN - INFO - episode 1 step 149 reward tensor([-1]) loss 13.117244720458984 epsilon 0.82
26-Feb-25 09:39:16 - agent.DQN.DQN - INFO - episode 1 step 150 reward tensor([-1]) loss 12.57424545288086 epsilon 0.82
26-Feb-25 09:39:16 - agent.DQN.DQN - INFO - episode 1 step 151 reward tensor([-1]) loss 24.752779006958008 epsilon 0.82
26-Feb-25 09:39:16 - agent.DQN.DQN - INFO - episode 1 step 152 reward tensor([-1]) loss 24.601953506469727 epsilon 0.82
26-Feb-25 09:39:16 - agent.DQN.DQN - INFO - episode 1 step 153 reward tensor([-1]) loss 19.73204231262207 epsilon 0.82
26-Feb-25 09:39:16 - agent.DQN.DQN - INFO - episode 1 step 154 reward tensor([-1]) loss 13.734299659729004 epsilon 0.82
26-Feb-25 09:39:16 - agent.DQN.DQN - INFO - episode 1 step 155 reward tensor([-1]) loss 9.028523445129395 epsilon 0.82
26-Feb-25 09:39:16 - agent.DQN.DQN - INFO - episode 1 step 156 reward tensor([-1]) loss 6.201151371002197 epsilon 0.82
26-Feb-25 09:39:16 - agent.DQN.DQN - INFO - episode 1 step 157 reward tensor([-1]) loss 7.506191730499268 epsilon 0.82
26-Feb-25 09:39:16 - agent.DQN.DQN - INFO - episode 1 step 158 reward tensor([-1]) loss 6.547567367553711 epsilon 0.82
26-Feb-25 09:39:16 - agent.DQN.DQN - INFO - episode 1 step 159 reward tensor([-1]) loss 9.323410034179688 epsilon 0.82
26-Feb-25 09:39:16 - agent.DQN.DQN - INFO - episode 1 step 160 reward tensor([-1]) loss 7.980008125305176 epsilon 0.82
26-Feb-25 09:39:16 - agent.DQN.DQN - INFO - episode 1 step 161 reward tensor([-1]) loss 8.70927619934082 epsilon 0.82
26-Feb-25 09:39:16 - agent.DQN.DQN - INFO - episode 1 step 162 reward tensor([-1]) loss 7.9427924156188965 epsilon 0.82
26-Feb-25 09:39:16 - agent.DQN.DQN - INFO - episode 1 step 163 reward tensor([-1]) loss 7.898311614990234 epsilon 0.82
26-Feb-25 09:39:16 - agent.DQN.DQN - INFO - episode 1 step 164 reward tensor([-1]) loss 7.426223278045654 epsilon 0.82
26-Feb-25 09:39:16 - agent.DQN.DQN - INFO - episode 1 step 165 reward tensor([-1]) loss 7.1502766609191895 epsilon 0.82
26-Feb-25 09:39:16 - agent.DQN.DQN - INFO - episode 1 step 166 reward tensor([-1]) loss 6.6528730392456055 epsilon 0.82
26-Feb-25 09:39:16 - agent.DQN.DQN - INFO - episode 1 step 167 reward tensor([-1]) loss 5.121735572814941 epsilon 0.82
26-Feb-25 09:39:16 - agent.DQN.DQN - INFO - episode 1 step 168 reward tensor([-1]) loss 4.8844499588012695 epsilon 0.82
26-Feb-25 09:39:17 - agent.DQN.DQN - INFO - episode 1 step 169 reward tensor([-1]) loss 4.329568386077881 epsilon 0.82
26-Feb-25 09:39:17 - agent.DQN.DQN - INFO - episode 1 step 170 reward tensor([-1]) loss 3.8499677181243896 epsilon 0.82
26-Feb-25 09:39:17 - agent.DQN.DQN - INFO - episode 1 step 171 reward tensor([-1]) loss 4.278820037841797 epsilon 0.82
26-Feb-25 09:39:17 - agent.DQN.DQN - INFO - episode 1 step 172 reward tensor([-1]) loss 4.350802421569824 epsilon 0.82
26-Feb-25 09:39:17 - agent.DQN.DQN - INFO - episode 1 step 173 reward tensor([-1]) loss 4.566965579986572 epsilon 0.82
26-Feb-25 09:39:17 - agent.DQN.DQN - INFO - episode 1 step 174 reward tensor([-1]) loss 4.143033504486084 epsilon 0.82
26-Feb-25 09:39:17 - agent.DQN.DQN - INFO - episode 1 step 175 reward tensor([-1]) loss 4.218700885772705 epsilon 0.82
26-Feb-25 09:39:17 - agent.DQN.DQN - INFO - episode 1 step 176 reward tensor([-1]) loss 3.4764065742492676 epsilon 0.82
26-Feb-25 09:39:17 - agent.DQN.DQN - INFO - episode 1 step 177 reward tensor([-1]) loss 3.7640011310577393 epsilon 0.82
26-Feb-25 09:39:17 - agent.DQN.DQN - INFO - episode 1 step 178 reward tensor([-1]) loss 3.593902826309204 epsilon 0.82
26-Feb-25 09:39:17 - agent.DQN.DQN - INFO - episode 1 step 179 reward tensor([-1]) loss 3.871448278427124 epsilon 0.82
26-Feb-25 09:39:17 - agent.DQN.DQN - INFO - episode 1 step 180 reward tensor([-1]) loss 2.573817491531372 epsilon 0.82
26-Feb-25 09:39:17 - agent.DQN.DQN - INFO - episode 1 step 181 reward tensor([-1]) loss 6.527154922485352 epsilon 0.82
26-Feb-25 09:39:17 - agent.DQN.DQN - INFO - episode 1 step 182 reward tensor([-1]) loss 5.396075248718262 epsilon 0.82
26-Feb-25 09:39:17 - agent.DQN.DQN - INFO - episode 1 step 183 reward tensor([-1]) loss 5.726120471954346 epsilon 0.82
26-Feb-25 09:39:17 - agent.DQN.DQN - INFO - episode 1 step 184 reward tensor([-1]) loss 4.351540565490723 epsilon 0.82
26-Feb-25 09:39:17 - agent.DQN.DQN - INFO - episode 1 step 185 reward tensor([-1]) loss 3.3090481758117676 epsilon 0.82
26-Feb-25 09:39:17 - agent.DQN.DQN - INFO - episode 1 step 186 reward tensor([-1]) loss 2.6063661575317383 epsilon 0.82
26-Feb-25 09:39:17 - agent.DQN.DQN - INFO - episode 1 step 187 reward tensor([-1]) loss 3.01389217376709 epsilon 0.82
26-Feb-25 09:39:17 - agent.DQN.DQN - INFO - episode 1 step 188 reward tensor([-1]) loss 3.369204521179199 epsilon 0.82
26-Feb-25 09:39:17 - agent.DQN.DQN - INFO - episode 1 step 189 reward tensor([-1]) loss 3.7118310928344727 epsilon 0.82
26-Feb-25 09:39:17 - agent.DQN.DQN - INFO - episode 1 step 190 reward tensor([-1]) loss 2.899411678314209 epsilon 0.82
26-Feb-25 09:39:17 - agent.DQN.DQN - INFO - episode 1 step 191 reward tensor([-1]) loss 2.804075241088867 epsilon 0.82
26-Feb-25 09:39:17 - agent.DQN.DQN - INFO - episode 1 step 192 reward tensor([-1]) loss 2.911891460418701 epsilon 0.82
26-Feb-25 09:39:17 - agent.DQN.DQN - INFO - episode 1 step 193 reward tensor([-1]) loss 3.251352071762085 epsilon 0.82
26-Feb-25 09:39:17 - agent.DQN.DQN - INFO - episode 1 step 194 reward tensor([-1]) loss 2.6471500396728516 epsilon 0.82
26-Feb-25 09:39:17 - agent.DQN.DQN - INFO - episode 1 step 195 reward tensor([-1]) loss 2.8746604919433594 epsilon 0.82
26-Feb-25 09:39:17 - agent.DQN.DQN - INFO - episode 1 step 196 reward tensor([-1]) loss 2.493588924407959 epsilon 0.82
26-Feb-25 09:39:17 - agent.DQN.DQN - INFO - episode 1 step 197 reward tensor([-1]) loss 1.7105129957199097 epsilon 0.82
26-Feb-25 09:39:17 - agent.DQN.DQN - INFO - episode 1 step 198 reward tensor([-1]) loss 2.1699538230895996 epsilon 0.82
26-Feb-25 09:39:17 - agent.DQN.DQN - INFO - episode 1 step 199 reward tensor([-1]) loss 3.310729742050171 epsilon 0.82
26-Feb-25 09:39:17 - agent.DQN.DQN - INFO - episode 1 step 200 reward tensor([-1]) loss 3.099675178527832 epsilon 0.82
26-Feb-25 09:39:17 - agent.DQN.DQN - INFO - episode 1 step 201 reward tensor([-1]) loss 2.769256830215454 epsilon 0.82
26-Feb-25 09:39:17 - agent.DQN.DQN - INFO - episode 1 step 202 reward tensor([-1]) loss 1.6668847799301147 epsilon 0.82
26-Feb-25 09:39:17 - agent.DQN.DQN - INFO - episode 1 step 203 reward tensor([-1]) loss 2.279872417449951 epsilon 0.82
26-Feb-25 09:39:17 - agent.DQN.DQN - INFO - episode 1 step 204 reward tensor([-1]) loss 1.9212790727615356 epsilon 0.82
26-Feb-25 09:39:17 - agent.DQN.DQN - INFO - episode 1 step 205 reward tensor([-1]) loss 2.413156509399414 epsilon 0.82
26-Feb-25 09:39:17 - agent.DQN.DQN - INFO - episode 1 step 206 reward tensor([-1]) loss 2.1414341926574707 epsilon 0.82
26-Feb-25 09:39:17 - agent.DQN.DQN - INFO - episode 1 step 207 reward tensor([-1]) loss 1.872068166732788 epsilon 0.82
26-Feb-25 09:39:17 - agent.DQN.DQN - INFO - episode 1 step 208 reward tensor([-1]) loss 2.2621989250183105 epsilon 0.82
26-Feb-25 09:39:17 - agent.DQN.DQN - INFO - episode 1 step 209 reward tensor([-1]) loss 1.9534720182418823 epsilon 0.82
26-Feb-25 09:39:17 - agent.DQN.DQN - INFO - episode 1 step 210 reward tensor([-1]) loss 2.1128029823303223 epsilon 0.82
26-Feb-25 09:39:17 - agent.DQN.DQN - INFO - episode 1 step 211 reward tensor([-1]) loss 10.08106517791748 epsilon 0.82
26-Feb-25 09:39:17 - agent.DQN.DQN - INFO - episode 1 step 212 reward tensor([-1]) loss 8.583063125610352 epsilon 0.82
26-Feb-25 09:39:17 - agent.DQN.DQN - INFO - episode 1 step 213 reward tensor([-1]) loss 6.564218044281006 epsilon 0.82
26-Feb-25 09:39:17 - agent.DQN.DQN - INFO - episode 1 step 214 reward tensor([-1]) loss 4.529877185821533 epsilon 0.82
26-Feb-25 09:39:17 - agent.DQN.DQN - INFO - episode 1 step 215 reward tensor([-1]) loss 3.8905773162841797 epsilon 0.82
26-Feb-25 09:39:17 - agent.DQN.DQN - INFO - episode 1 step 216 reward tensor([-1]) loss 3.4997034072875977 epsilon 0.82
26-Feb-25 09:39:17 - agent.DQN.DQN - INFO - episode 1 step 217 reward tensor([-1]) loss 8.728504180908203 epsilon 0.82
26-Feb-25 09:39:17 - agent.DQN.DQN - INFO - episode 1 step 218 reward tensor([-1]) loss 3.0021588802337646 epsilon 0.82
26-Feb-25 09:39:17 - agent.DQN.DQN - INFO - episode 1 step 219 reward tensor([-1]) loss 8.384185791015625 epsilon 0.82
26-Feb-25 09:39:17 - agent.DQN.DQN - INFO - episode 1 step 220 reward tensor([-1]) loss 2.451162338256836 epsilon 0.82
26-Feb-25 09:39:17 - agent.DQN.DQN - INFO - episode 1 step 221 reward tensor([-1]) loss 6.756463527679443 epsilon 0.82
26-Feb-25 09:39:17 - agent.DQN.DQN - INFO - episode 1 step 222 reward tensor([-1]) loss 6.683923244476318 epsilon 0.82
26-Feb-25 09:39:17 - agent.DQN.DQN - INFO - episode 1 step 223 reward tensor([-1]) loss 5.920404434204102 epsilon 0.82
26-Feb-25 09:39:17 - agent.DQN.DQN - INFO - episode 1 step 224 reward tensor([-1]) loss 7.442795753479004 epsilon 0.82
26-Feb-25 09:39:17 - agent.DQN.DQN - INFO - episode 1 step 225 reward tensor([-1]) loss 4.468649864196777 epsilon 0.82
26-Feb-25 09:39:17 - agent.DQN.DQN - INFO - episode 1 step 226 reward tensor([-1]) loss 5.216514587402344 epsilon 0.82
26-Feb-25 09:39:17 - agent.DQN.DQN - INFO - episode 1 step 227 reward tensor([-1]) loss 4.051298141479492 epsilon 0.82
26-Feb-25 09:39:17 - agent.DQN.DQN - INFO - episode 1 step 228 reward tensor([-1]) loss 3.0384464263916016 epsilon 0.82
26-Feb-25 09:39:17 - agent.DQN.DQN - INFO - episode 1 step 229 reward tensor([-1]) loss 3.031233310699463 epsilon 0.82
26-Feb-25 09:39:17 - agent.DQN.DQN - INFO - episode 1 step 230 reward tensor([-1]) loss 2.6697254180908203 epsilon 0.82
26-Feb-25 09:39:17 - agent.DQN.DQN - INFO - episode 1 step 231 reward tensor([-1]) loss 2.774542808532715 epsilon 0.82
26-Feb-25 09:39:17 - agent.DQN.DQN - INFO - episode 1 step 232 reward tensor([-1]) loss 2.309659719467163 epsilon 0.82
26-Feb-25 09:39:17 - agent.DQN.DQN - INFO - episode 1 step 233 reward tensor([-1]) loss 2.194774866104126 epsilon 0.82
26-Feb-25 09:39:17 - agent.DQN.DQN - INFO - episode 1 step 234 reward tensor([-1]) loss 2.216520309448242 epsilon 0.82
26-Feb-25 09:39:17 - agent.DQN.DQN - INFO - episode 1 step 235 reward tensor([-1]) loss 2.2637226581573486 epsilon 0.82
26-Feb-25 09:39:17 - agent.DQN.DQN - INFO - episode 1 step 236 reward tensor([-1]) loss 2.4048523902893066 epsilon 0.82
26-Feb-25 09:39:17 - agent.DQN.DQN - INFO - episode 1 step 237 reward tensor([-1]) loss 2.153103828430176 epsilon 0.82
26-Feb-25 09:39:17 - agent.DQN.DQN - INFO - episode 1 step 238 reward tensor([-1]) loss 2.011646032333374 epsilon 0.82
26-Feb-25 09:39:17 - agent.DQN.DQN - INFO - episode 1 step 239 reward tensor([-1]) loss 2.158061981201172 epsilon 0.82
26-Feb-25 09:39:17 - agent.DQN.DQN - INFO - episode 1 step 240 reward tensor([-1]) loss 2.021130323410034 epsilon 0.82
26-Feb-25 09:39:17 - agent.DQN.DQN - INFO - episode 1 step 241 reward tensor([-1]) loss 9.944559097290039 epsilon 0.82
26-Feb-25 09:39:17 - agent.DQN.DQN - INFO - episode 1 step 242 reward tensor([-1]) loss 8.419075965881348 epsilon 0.82
26-Feb-25 09:39:17 - agent.DQN.DQN - INFO - episode 1 step 243 reward tensor([-1]) loss 7.5699849128723145 epsilon 0.82
26-Feb-25 09:39:18 - agent.DQN.DQN - INFO - episode 1 step 244 reward tensor([-1]) loss 6.121530055999756 epsilon 0.82
26-Feb-25 09:39:18 - agent.DQN.DQN - INFO - episode 1 step 245 reward tensor([-1]) loss 5.965008735656738 epsilon 0.82
26-Feb-25 09:39:18 - agent.DQN.DQN - INFO - episode 1 step 246 reward tensor([-1]) loss 4.348269939422607 epsilon 0.82
26-Feb-25 09:39:18 - agent.DQN.DQN - INFO - episode 1 step 247 reward tensor([-1]) loss 3.093686819076538 epsilon 0.82
26-Feb-25 09:39:18 - agent.DQN.DQN - INFO - episode 1 step 248 reward tensor([-1]) loss 3.4416754245758057 epsilon 0.82
26-Feb-25 09:39:18 - agent.DQN.DQN - INFO - episode 1 step 249 reward tensor([-1]) loss 2.9172754287719727 epsilon 0.82
26-Feb-25 09:39:18 - agent.DQN.DQN - INFO - episode 1 step 250 reward tensor([-1]) loss 2.5180892944335938 epsilon 0.82
26-Feb-25 09:39:18 - agent.DQN.DQN - INFO - episode 1 step 251 reward tensor([-1]) loss 3.4285738468170166 epsilon 0.82
26-Feb-25 09:39:18 - agent.DQN.DQN - INFO - episode 1 step 252 reward tensor([-1]) loss 3.649718761444092 epsilon 0.82
26-Feb-25 09:39:18 - agent.DQN.DQN - INFO - episode 1 step 253 reward tensor([-1]) loss 2.4444339275360107 epsilon 0.82
26-Feb-25 09:39:18 - agent.DQN.DQN - INFO - episode 1 step 254 reward tensor([-1]) loss 3.131688117980957 epsilon 0.82
26-Feb-25 09:39:18 - agent.DQN.DQN - INFO - episode 1 step 255 reward tensor([-1]) loss 2.5703482627868652 epsilon 0.82
26-Feb-25 09:39:18 - agent.DQN.DQN - INFO - episode 1 step 256 reward tensor([-1]) loss 2.5849881172180176 epsilon 0.82
26-Feb-25 09:39:18 - agent.DQN.DQN - INFO - episode 1 step 257 reward tensor([-1]) loss 2.4922564029693604 epsilon 0.82
26-Feb-25 09:39:18 - agent.DQN.DQN - INFO - episode 1 step 258 reward tensor([-1]) loss 2.4613873958587646 epsilon 0.82
26-Feb-25 09:39:18 - agent.DQN.DQN - INFO - episode 1 step 259 reward tensor([-1]) loss 2.24576735496521 epsilon 0.82
26-Feb-25 09:39:18 - agent.DQN.DQN - INFO - episode 1 step 260 reward tensor([-1]) loss 2.047961711883545 epsilon 0.82
26-Feb-25 09:39:18 - agent.DQN.DQN - INFO - episode 1 step 261 reward tensor([-1]) loss 1.837321400642395 epsilon 0.82
26-Feb-25 09:39:18 - agent.DQN.DQN - INFO - episode 1 step 262 reward tensor([-1]) loss 2.0770139694213867 epsilon 0.82
26-Feb-25 09:39:18 - agent.DQN.DQN - INFO - episode 1 step 263 reward tensor([-1]) loss 2.1693203449249268 epsilon 0.82
26-Feb-25 09:39:18 - agent.DQN.DQN - INFO - episode 1 step 264 reward tensor([-1]) loss 1.5732486248016357 epsilon 0.82
26-Feb-25 09:39:18 - agent.DQN.DQN - INFO - episode 1 step 265 reward tensor([-1]) loss 1.6252297163009644 epsilon 0.82
26-Feb-25 09:39:18 - agent.DQN.DQN - INFO - episode 1 step 266 reward tensor([-1]) loss 2.212999105453491 epsilon 0.82
26-Feb-25 09:39:18 - agent.DQN.DQN - INFO - episode 1 step 267 reward tensor([-1]) loss 1.6228456497192383 epsilon 0.82
26-Feb-25 09:39:18 - agent.DQN.DQN - INFO - episode 1 step 268 reward tensor([-1]) loss 1.870737910270691 epsilon 0.82
26-Feb-25 09:39:18 - agent.DQN.DQN - INFO - episode 1 step 269 reward tensor([-1]) loss 2.0952298641204834 epsilon 0.82
26-Feb-25 09:39:18 - agent.DQN.DQN - INFO - episode 1 step 270 reward tensor([-1]) loss 1.667097568511963 epsilon 0.82
26-Feb-25 09:39:18 - agent.DQN.DQN - INFO - episode 1 step 271 reward tensor([-1]) loss 13.102800369262695 epsilon 0.82
26-Feb-25 09:39:18 - agent.DQN.DQN - INFO - episode 1 step 272 reward tensor([-1]) loss 10.610523223876953 epsilon 0.82
26-Feb-25 09:39:18 - agent.DQN.DQN - INFO - episode 1 step 273 reward tensor([-1]) loss 7.162292003631592 epsilon 0.82
26-Feb-25 09:39:18 - agent.DQN.DQN - INFO - episode 1 step 274 reward tensor([-1]) loss 6.52001953125 epsilon 0.82
26-Feb-25 09:39:18 - agent.DQN.DQN - INFO - episode 1 step 275 reward tensor([-1]) loss 5.367290019989014 epsilon 0.82
26-Feb-25 09:39:18 - agent.DQN.DQN - INFO - episode 1 step 276 reward tensor([-1]) loss 3.7959320545196533 epsilon 0.82
26-Feb-25 09:39:18 - agent.DQN.DQN - INFO - episode 1 step 277 reward tensor([-1]) loss 2.9323527812957764 epsilon 0.82
26-Feb-25 09:39:18 - agent.DQN.DQN - INFO - episode 1 step 278 reward tensor([-1]) loss 3.1379218101501465 epsilon 0.82
26-Feb-25 09:39:18 - agent.DQN.DQN - INFO - episode 1 step 279 reward tensor([-1]) loss 3.747767448425293 epsilon 0.82
26-Feb-25 09:39:18 - agent.DQN.DQN - INFO - episode 1 step 280 reward tensor([-1]) loss 3.073394775390625 epsilon 0.82
26-Feb-25 09:39:18 - agent.DQN.DQN - INFO - episode 1 step 281 reward tensor([-1]) loss 3.1231610774993896 epsilon 0.82
26-Feb-25 09:39:18 - agent.DQN.DQN - INFO - episode 1 step 282 reward tensor([-1]) loss 4.093234062194824 epsilon 0.82
26-Feb-25 09:39:18 - agent.DQN.DQN - INFO - episode 1 step 283 reward tensor([-1]) loss 3.1390771865844727 epsilon 0.82
26-Feb-25 09:39:18 - agent.DQN.DQN - INFO - episode 1 step 284 reward tensor([-1]) loss 3.2801284790039062 epsilon 0.82
26-Feb-25 09:39:18 - agent.DQN.DQN - INFO - episode 1 step 285 reward tensor([-1]) loss 2.807889461517334 epsilon 0.82
26-Feb-25 09:39:18 - agent.DQN.DQN - INFO - episode 1 step 286 reward tensor([-1]) loss 2.593623638153076 epsilon 0.82
26-Feb-25 09:39:18 - agent.DQN.DQN - INFO - episode 1 step 287 reward tensor([-1]) loss 2.007002115249634 epsilon 0.82
26-Feb-25 09:39:18 - agent.DQN.DQN - INFO - episode 1 step 288 reward tensor([-1]) loss 1.6287612915039062 epsilon 0.82
26-Feb-25 09:39:18 - agent.DQN.DQN - INFO - episode 1 step 289 reward tensor([-1]) loss 1.6425420045852661 epsilon 0.82
26-Feb-25 09:39:18 - agent.DQN.DQN - INFO - episode 1 step 290 reward tensor([-1]) loss 1.7285048961639404 epsilon 0.82
26-Feb-25 09:39:18 - agent.DQN.DQN - INFO - episode 1 step 291 reward tensor([-1]) loss 1.6267260313034058 epsilon 0.82
26-Feb-25 09:39:18 - agent.DQN.DQN - INFO - episode 1 step 292 reward tensor([-1]) loss 1.9987001419067383 epsilon 0.82
26-Feb-25 09:39:18 - agent.DQN.DQN - INFO - episode 1 step 293 reward tensor([-1]) loss 1.9561302661895752 epsilon 0.82
26-Feb-25 09:39:18 - agent.DQN.DQN - INFO - episode 1 step 294 reward tensor([-1]) loss 1.6232117414474487 epsilon 0.82
26-Feb-25 09:39:18 - agent.DQN.DQN - INFO - episode 1 step 295 reward tensor([-1]) loss 1.8466874361038208 epsilon 0.82
26-Feb-25 09:39:18 - agent.DQN.DQN - INFO - episode 1 step 296 reward tensor([-1]) loss 2.133273124694824 epsilon 0.82
26-Feb-25 09:39:18 - agent.DQN.DQN - INFO - episode 1 step 297 reward tensor([-1]) loss 1.3481194972991943 epsilon 0.82
26-Feb-25 09:39:18 - agent.DQN.DQN - INFO - episode 1 step 298 reward tensor([-1]) loss 1.561596393585205 epsilon 0.82
26-Feb-25 09:39:18 - agent.DQN.DQN - INFO - episode 1 step 299 reward tensor([-1]) loss 1.3949298858642578 epsilon 0.82
26-Feb-25 09:39:18 - agent.DQN.DQN - INFO - episode 1 step 300 reward tensor([-1]) loss 1.3443162441253662 epsilon 0.82
26-Feb-25 09:39:18 - agent.DQN.DQN - INFO - episode 1 step 301 reward tensor([-1]) loss 56.10263442993164 epsilon 0.82
26-Feb-25 09:39:18 - agent.DQN.DQN - INFO - episode 2 step 0 reward tensor([-1]) loss 10.450166702270508 epsilon 0.79335
26-Feb-25 09:39:18 - agent.DQN.DQN - INFO - episode 2 step 1 reward tensor([-1]) loss 8.525270462036133 epsilon 0.79335
26-Feb-25 09:39:18 - agent.DQN.DQN - INFO - episode 2 step 2 reward tensor([-1]) loss 42.97615432739258 epsilon 0.79335
26-Feb-25 09:39:18 - agent.DQN.DQN - INFO - episode 2 step 3 reward tensor([-1]) loss 38.842952728271484 epsilon 0.79335
26-Feb-25 09:39:18 - agent.DQN.DQN - INFO - episode 2 step 4 reward tensor([-1]) loss 4.896499156951904 epsilon 0.79335
26-Feb-25 09:39:18 - agent.DQN.DQN - INFO - episode 2 step 5 reward tensor([-1]) loss 5.006450176239014 epsilon 0.79335
26-Feb-25 09:39:18 - agent.DQN.DQN - INFO - episode 2 step 6 reward tensor([-1]) loss 5.292820930480957 epsilon 0.79335
26-Feb-25 09:39:18 - agent.DQN.DQN - INFO - episode 2 step 7 reward tensor([-1]) loss 33.88252639770508 epsilon 0.79335
26-Feb-25 09:39:18 - agent.DQN.DQN - INFO - episode 2 step 8 reward tensor([-1]) loss 6.527482509613037 epsilon 0.79335
26-Feb-25 09:39:18 - agent.DQN.DQN - INFO - episode 2 step 9 reward tensor([-1]) loss 7.413410186767578 epsilon 0.79335
26-Feb-25 09:39:18 - agent.DQN.DQN - INFO - episode 2 step 10 reward tensor([-1]) loss 33.434810638427734 epsilon 0.79335
26-Feb-25 09:39:18 - agent.DQN.DQN - INFO - episode 2 step 11 reward tensor([-1]) loss 31.585002899169922 epsilon 0.79335
26-Feb-25 09:39:18 - agent.DQN.DQN - INFO - episode 2 step 12 reward tensor([-1]) loss 29.498619079589844 epsilon 0.79335
26-Feb-25 09:39:18 - agent.DQN.DQN - INFO - episode 2 step 13 reward tensor([-1]) loss 4.0691237449646 epsilon 0.79335
26-Feb-25 09:39:18 - agent.DQN.DQN - INFO - episode 2 step 14 reward tensor([-1]) loss 31.080833435058594 epsilon 0.79335
26-Feb-25 09:39:18 - agent.DQN.DQN - INFO - episode 2 step 15 reward tensor([-1]) loss 30.469486236572266 epsilon 0.79335
26-Feb-25 09:39:18 - agent.DQN.DQN - INFO - episode 2 step 16 reward tensor([-1]) loss 5.443164348602295 epsilon 0.79335
26-Feb-25 09:39:18 - agent.DQN.DQN - INFO - episode 2 step 17 reward tensor([-1]) loss 30.70611000061035 epsilon 0.79335
26-Feb-25 09:39:19 - agent.DQN.DQN - INFO - episode 2 step 18 reward tensor([-1]) loss 29.985206604003906 epsilon 0.79335
26-Feb-25 09:39:19 - agent.DQN.DQN - INFO - episode 2 step 19 reward tensor([-1]) loss 5.385777950286865 epsilon 0.79335
26-Feb-25 09:39:19 - agent.DQN.DQN - INFO - episode 2 step 20 reward tensor([-1]) loss 31.37575340270996 epsilon 0.79335
26-Feb-25 09:39:19 - agent.DQN.DQN - INFO - episode 2 step 21 reward tensor([-1]) loss 4.296257495880127 epsilon 0.79335
26-Feb-25 09:39:19 - agent.DQN.DQN - INFO - episode 2 step 22 reward tensor([-1]) loss 2.0119552612304688 epsilon 0.79335
26-Feb-25 09:39:19 - agent.DQN.DQN - INFO - episode 2 step 23 reward tensor([-1]) loss 3.199167013168335 epsilon 0.79335
26-Feb-25 09:39:19 - agent.DQN.DQN - INFO - episode 2 step 24 reward tensor([-1]) loss 2.1331582069396973 epsilon 0.79335
26-Feb-25 09:39:19 - agent.DQN.DQN - INFO - episode 2 step 25 reward tensor([-1]) loss 1.7735316753387451 epsilon 0.79335
26-Feb-25 09:39:19 - agent.DQN.DQN - INFO - episode 2 step 26 reward tensor([-1]) loss 2.026860237121582 epsilon 0.79335
26-Feb-25 09:39:19 - agent.DQN.DQN - INFO - episode 2 step 27 reward tensor([-1]) loss 1.7750989198684692 epsilon 0.79335
26-Feb-25 09:39:19 - agent.DQN.DQN - INFO - episode 2 step 28 reward tensor([-1]) loss 1.772647738456726 epsilon 0.79335
26-Feb-25 09:39:19 - agent.DQN.DQN - INFO - episode 2 step 29 reward tensor([-1]) loss 44.5071907043457 epsilon 0.79335
26-Feb-25 09:39:19 - agent.DQN.DQN - INFO - episode 2 step 30 reward tensor([-1]) loss 43.81808090209961 epsilon 0.79335
26-Feb-25 09:39:19 - agent.DQN.DQN - INFO - episode 2 step 31 reward tensor([-1]) loss 42.019161224365234 epsilon 0.79335
26-Feb-25 09:39:19 - agent.DQN.DQN - INFO - episode 2 step 32 reward tensor([-1]) loss 3.899604320526123 epsilon 0.79335
26-Feb-25 09:39:19 - agent.DQN.DQN - INFO - episode 2 step 33 reward tensor([-1]) loss 33.925140380859375 epsilon 0.79335
26-Feb-25 09:39:19 - agent.DQN.DQN - INFO - episode 2 step 34 reward tensor([-1]) loss 31.413835525512695 epsilon 0.79335
26-Feb-25 09:39:19 - agent.DQN.DQN - INFO - episode 2 step 35 reward tensor([-1]) loss 3.3768081665039062 epsilon 0.79335
26-Feb-25 09:39:19 - agent.DQN.DQN - INFO - episode 2 step 36 reward tensor([-1]) loss 3.424032211303711 epsilon 0.79335
26-Feb-25 09:39:19 - agent.DQN.DQN - INFO - episode 2 step 37 reward tensor([-1]) loss 4.015585899353027 epsilon 0.79335
26-Feb-25 09:39:19 - agent.DQN.DQN - INFO - episode 2 step 38 reward tensor([-1]) loss 3.008124589920044 epsilon 0.79335
26-Feb-25 09:39:19 - agent.DQN.DQN - INFO - episode 2 step 39 reward tensor([-1]) loss 25.614261627197266 epsilon 0.79335
26-Feb-25 09:39:19 - agent.DQN.DQN - INFO - episode 2 step 40 reward tensor([-1]) loss 25.168941497802734 epsilon 0.79335
26-Feb-25 09:39:19 - agent.DQN.DQN - INFO - episode 2 step 41 reward tensor([-1]) loss 8.239090919494629 epsilon 0.79335
26-Feb-25 09:39:19 - agent.DQN.DQN - INFO - episode 2 step 42 reward tensor([-1]) loss 6.049488067626953 epsilon 0.79335
26-Feb-25 09:39:19 - agent.DQN.DQN - INFO - episode 2 step 43 reward tensor([-1]) loss 9.483511924743652 epsilon 0.79335
26-Feb-25 09:39:19 - agent.DQN.DQN - INFO - episode 2 step 44 reward tensor([-1]) loss 5.594231128692627 epsilon 0.79335
26-Feb-25 09:39:19 - agent.DQN.DQN - INFO - episode 2 step 45 reward tensor([-1]) loss 25.511964797973633 epsilon 0.79335
26-Feb-25 09:39:19 - agent.DQN.DQN - INFO - episode 2 step 46 reward tensor([-1]) loss 25.024492263793945 epsilon 0.79335
26-Feb-25 09:39:19 - agent.DQN.DQN - INFO - episode 2 step 47 reward tensor([-1]) loss 27.39595603942871 epsilon 0.79335
26-Feb-25 09:39:19 - agent.DQN.DQN - INFO - episode 2 step 48 reward tensor([-1]) loss 3.288771390914917 epsilon 0.79335
26-Feb-25 09:39:19 - agent.DQN.DQN - INFO - episode 2 step 49 reward tensor([-1]) loss 26.387405395507812 epsilon 0.79335
26-Feb-25 09:39:19 - agent.DQN.DQN - INFO - episode 2 step 50 reward tensor([-1]) loss 28.373943328857422 epsilon 0.79335
26-Feb-25 09:39:19 - agent.DQN.DQN - INFO - episode 2 step 51 reward tensor([-1]) loss 2.825626850128174 epsilon 0.79335
26-Feb-25 09:39:19 - agent.DQN.DQN - INFO - episode 2 step 52 reward tensor([-1]) loss 29.667999267578125 epsilon 0.79335
26-Feb-25 09:39:19 - agent.DQN.DQN - INFO - episode 2 step 53 reward tensor([-1]) loss 1.8994784355163574 epsilon 0.79335
26-Feb-25 09:39:19 - agent.DQN.DQN - INFO - episode 2 step 54 reward tensor([-1]) loss 4.26085901260376 epsilon 0.79335
26-Feb-25 09:39:19 - agent.DQN.DQN - INFO - episode 2 step 55 reward tensor([-1]) loss 3.2551605701446533 epsilon 0.79335
26-Feb-25 09:39:19 - agent.DQN.DQN - INFO - episode 2 step 56 reward tensor([-1]) loss 4.800408363342285 epsilon 0.79335
26-Feb-25 09:39:19 - agent.DQN.DQN - INFO - episode 2 step 57 reward tensor([-1]) loss 6.554203987121582 epsilon 0.79335
26-Feb-25 09:39:19 - agent.DQN.DQN - INFO - episode 2 step 58 reward tensor([-1]) loss 4.112574100494385 epsilon 0.79335
26-Feb-25 09:39:19 - agent.DQN.DQN - INFO - episode 2 step 59 reward tensor([-1]) loss 8.135396957397461 epsilon 0.79335
26-Feb-25 09:39:19 - agent.DQN.DQN - INFO - episode 2 step 60 reward tensor([-1]) loss 36.25870895385742 epsilon 0.79335
26-Feb-25 09:39:19 - agent.DQN.DQN - INFO - episode 2 step 61 reward tensor([-1]) loss 36.92320251464844 epsilon 0.79335
26-Feb-25 09:39:19 - agent.DQN.DQN - INFO - episode 2 step 62 reward tensor([-1]) loss 34.02317810058594 epsilon 0.79335
26-Feb-25 09:39:19 - agent.DQN.DQN - INFO - episode 2 step 63 reward tensor([-1]) loss 29.368183135986328 epsilon 0.79335
26-Feb-25 09:39:19 - agent.DQN.DQN - INFO - episode 2 step 64 reward tensor([-1]) loss 28.568740844726562 epsilon 0.79335
26-Feb-25 09:39:19 - agent.DQN.DQN - INFO - episode 2 step 65 reward tensor([-1]) loss 3.6359338760375977 epsilon 0.79335
26-Feb-25 09:39:19 - agent.DQN.DQN - INFO - episode 2 step 66 reward tensor([-1]) loss 6.547366142272949 epsilon 0.79335
26-Feb-25 09:39:19 - agent.DQN.DQN - INFO - episode 2 step 67 reward tensor([-1]) loss 24.15375328063965 epsilon 0.79335
26-Feb-25 09:39:19 - agent.DQN.DQN - INFO - episode 2 step 68 reward tensor([-1]) loss 24.387441635131836 epsilon 0.79335
26-Feb-25 09:39:19 - agent.DQN.DQN - INFO - episode 2 step 69 reward tensor([-1]) loss 7.443505764007568 epsilon 0.79335
26-Feb-25 09:39:19 - agent.DQN.DQN - INFO - episode 2 step 70 reward tensor([-1]) loss 8.452352523803711 epsilon 0.79335
26-Feb-25 09:39:19 - agent.DQN.DQN - INFO - episode 2 step 71 reward tensor([-1]) loss 6.032813549041748 epsilon 0.79335
26-Feb-25 09:39:19 - agent.DQN.DQN - INFO - episode 2 step 72 reward tensor([-1]) loss 10.194113731384277 epsilon 0.79335
26-Feb-25 09:39:19 - agent.DQN.DQN - INFO - episode 2 step 73 reward tensor([-1]) loss 11.060068130493164 epsilon 0.79335
26-Feb-25 09:39:19 - agent.DQN.DQN - INFO - episode 2 step 74 reward tensor([-1]) loss 25.63336181640625 epsilon 0.79335
26-Feb-25 09:39:19 - agent.DQN.DQN - INFO - episode 2 step 75 reward tensor([-1]) loss 6.760939598083496 epsilon 0.79335
26-Feb-25 09:39:19 - agent.DQN.DQN - INFO - episode 2 step 76 reward tensor([-1]) loss 6.10222864151001 epsilon 0.79335
26-Feb-25 09:39:19 - agent.DQN.DQN - INFO - episode 2 step 77 reward tensor([-1]) loss 5.599897384643555 epsilon 0.79335
26-Feb-25 09:39:19 - agent.DQN.DQN - INFO - episode 2 step 78 reward tensor([-1]) loss 28.23634147644043 epsilon 0.79335
26-Feb-25 09:39:19 - agent.DQN.DQN - INFO - episode 2 step 79 reward tensor([-1]) loss 8.752052307128906 epsilon 0.79335
26-Feb-25 09:39:19 - agent.DQN.DQN - INFO - episode 2 step 80 reward tensor([-1]) loss 4.3667449951171875 epsilon 0.79335
26-Feb-25 09:39:19 - agent.DQN.DQN - INFO - episode 2 step 81 reward tensor([-1]) loss 9.107685089111328 epsilon 0.79335
26-Feb-25 09:39:19 - agent.DQN.DQN - INFO - episode 2 step 82 reward tensor([-1]) loss 7.082796573638916 epsilon 0.79335
26-Feb-25 09:39:19 - agent.DQN.DQN - INFO - episode 2 step 83 reward tensor([-1]) loss 8.094809532165527 epsilon 0.79335
26-Feb-25 09:39:19 - agent.DQN.DQN - INFO - episode 2 step 84 reward tensor([-1]) loss 35.46574783325195 epsilon 0.79335
26-Feb-25 09:39:19 - agent.DQN.DQN - INFO - episode 2 step 85 reward tensor([-1]) loss 30.503616333007812 epsilon 0.79335
26-Feb-25 09:39:19 - agent.DQN.DQN - INFO - episode 2 step 86 reward tensor([-1]) loss 8.567018508911133 epsilon 0.79335
26-Feb-25 09:39:19 - agent.DQN.DQN - INFO - episode 2 step 87 reward tensor([-1]) loss 29.90592384338379 epsilon 0.79335
26-Feb-25 09:39:19 - agent.DQN.DQN - INFO - episode 2 step 88 reward tensor([-1]) loss 5.542325973510742 epsilon 0.79335
26-Feb-25 09:39:19 - agent.DQN.DQN - INFO - episode 2 step 89 reward tensor([-1]) loss 30.731571197509766 epsilon 0.79335
26-Feb-25 09:39:19 - agent.DQN.DQN - INFO - episode 2 step 90 reward tensor([-1]) loss 8.500158309936523 epsilon 0.79335
26-Feb-25 09:39:19 - agent.DQN.DQN - INFO - episode 2 step 91 reward tensor([-1]) loss 27.79106330871582 epsilon 0.79335
26-Feb-25 09:39:19 - agent.DQN.DQN - INFO - episode 2 step 92 reward tensor([-1]) loss 26.560718536376953 epsilon 0.79335
26-Feb-25 09:39:19 - agent.DQN.DQN - INFO - episode 2 step 93 reward tensor([-1]) loss 6.246708869934082 epsilon 0.79335
26-Feb-25 09:39:19 - agent.DQN.DQN - INFO - episode 2 step 94 reward tensor([-1]) loss 4.620079517364502 epsilon 0.79335
26-Feb-25 09:39:19 - agent.DQN.DQN - INFO - episode 2 step 95 reward tensor([-1]) loss 5.300464630126953 epsilon 0.79335
26-Feb-25 09:39:19 - agent.DQN.DQN - INFO - episode 2 step 96 reward tensor([-1]) loss 4.282883644104004 epsilon 0.79335
26-Feb-25 09:39:19 - agent.DQN.DQN - INFO - episode 2 step 97 reward tensor([-1]) loss 21.139482498168945 epsilon 0.79335
26-Feb-25 09:39:20 - agent.DQN.DQN - INFO - episode 2 step 98 reward tensor([-1]) loss 4.568944931030273 epsilon 0.79335
26-Feb-25 09:39:20 - agent.DQN.DQN - INFO - episode 2 step 99 reward tensor([-1]) loss 12.420031547546387 epsilon 0.79335
26-Feb-25 09:39:20 - agent.DQN.DQN - INFO - episode 2 step 100 reward tensor([-1]) loss 13.367944717407227 epsilon 0.79335
26-Feb-25 09:39:20 - agent.DQN.DQN - INFO - episode 2 step 101 reward tensor([-1]) loss 11.972875595092773 epsilon 0.79335
26-Feb-25 09:39:20 - agent.DQN.DQN - INFO - episode 2 step 102 reward tensor([-1]) loss 28.043718338012695 epsilon 0.79335
26-Feb-25 09:39:20 - agent.DQN.DQN - INFO - episode 2 step 103 reward tensor([-1]) loss 14.484664916992188 epsilon 0.79335
26-Feb-25 09:39:20 - agent.DQN.DQN - INFO - episode 2 step 104 reward tensor([-1]) loss 3.1776621341705322 epsilon 0.79335
26-Feb-25 09:39:20 - agent.DQN.DQN - INFO - episode 2 step 105 reward tensor([-1]) loss 3.64199161529541 epsilon 0.79335
26-Feb-25 09:39:20 - agent.DQN.DQN - INFO - episode 2 step 106 reward tensor([-1]) loss 2.7303431034088135 epsilon 0.79335
26-Feb-25 09:39:20 - agent.DQN.DQN - INFO - episode 2 step 107 reward tensor([-1]) loss 2.6025567054748535 epsilon 0.79335
26-Feb-25 09:39:20 - agent.DQN.DQN - INFO - episode 2 step 108 reward tensor([-1]) loss 5.324614524841309 epsilon 0.79335
26-Feb-25 09:39:20 - agent.DQN.DQN - INFO - episode 2 step 109 reward tensor([-1]) loss 24.740131378173828 epsilon 0.79335
26-Feb-25 09:39:20 - agent.DQN.DQN - INFO - episode 2 step 110 reward tensor([-1]) loss 3.3173816204071045 epsilon 0.79335
26-Feb-25 09:39:20 - agent.DQN.DQN - INFO - episode 2 step 111 reward tensor([-1]) loss 2.817368507385254 epsilon 0.79335
26-Feb-25 09:39:20 - agent.DQN.DQN - INFO - episode 2 step 112 reward tensor([-1]) loss 23.706863403320312 epsilon 0.79335
26-Feb-25 09:39:20 - agent.DQN.DQN - INFO - episode 2 step 113 reward tensor([-1]) loss 23.248783111572266 epsilon 0.79335
26-Feb-25 09:39:20 - agent.DQN.DQN - INFO - episode 2 step 114 reward tensor([-1]) loss 2.165189743041992 epsilon 0.79335
26-Feb-25 09:39:20 - agent.DQN.DQN - INFO - episode 2 step 115 reward tensor([-1]) loss 4.430653095245361 epsilon 0.79335
26-Feb-25 09:39:20 - agent.DQN.DQN - INFO - episode 2 step 116 reward tensor([-1]) loss 21.251850128173828 epsilon 0.79335
26-Feb-25 09:39:20 - agent.DQN.DQN - INFO - episode 2 step 117 reward tensor([-1]) loss 20.088180541992188 epsilon 0.79335
26-Feb-25 09:39:20 - agent.DQN.DQN - INFO - episode 2 step 118 reward tensor([-1]) loss 2.7255942821502686 epsilon 0.79335
26-Feb-25 09:39:20 - agent.DQN.DQN - INFO - episode 2 step 119 reward tensor([-1]) loss 6.507493495941162 epsilon 0.79335
26-Feb-25 09:39:20 - agent.DQN.DQN - INFO - episode 2 step 120 reward tensor([-1]) loss 45.25564956665039 epsilon 0.79335
26-Feb-25 09:39:20 - agent.DQN.DQN - INFO - episode 2 step 121 reward tensor([-1]) loss 42.964881896972656 epsilon 0.79335
26-Feb-25 09:39:20 - agent.DQN.DQN - INFO - episode 2 step 122 reward tensor([-1]) loss 20.35689926147461 epsilon 0.79335
26-Feb-25 09:39:20 - agent.DQN.DQN - INFO - episode 2 step 123 reward tensor([-1]) loss 20.569400787353516 epsilon 0.79335
26-Feb-25 09:39:20 - agent.DQN.DQN - INFO - episode 2 step 124 reward tensor([-1]) loss 3.467073678970337 epsilon 0.79335
26-Feb-25 09:39:20 - agent.DQN.DQN - INFO - episode 2 step 125 reward tensor([-1]) loss 36.03366470336914 epsilon 0.79335
26-Feb-25 09:39:20 - agent.DQN.DQN - INFO - episode 2 step 126 reward tensor([-1]) loss 22.550872802734375 epsilon 0.79335
26-Feb-25 09:39:20 - agent.DQN.DQN - INFO - episode 2 step 127 reward tensor([-1]) loss 25.035602569580078 epsilon 0.79335
26-Feb-25 09:39:20 - agent.DQN.DQN - INFO - episode 2 step 128 reward tensor([-1]) loss 23.324268341064453 epsilon 0.79335
26-Feb-25 09:39:20 - agent.DQN.DQN - INFO - episode 2 step 129 reward tensor([-1]) loss 5.219595432281494 epsilon 0.79335
26-Feb-25 09:39:20 - agent.DQN.DQN - INFO - episode 2 step 130 reward tensor([-1]) loss 32.00415802001953 epsilon 0.79335
26-Feb-25 09:39:20 - agent.DQN.DQN - INFO - episode 2 step 131 reward tensor([-1]) loss 3.6959195137023926 epsilon 0.79335
26-Feb-25 09:39:20 - agent.DQN.DQN - INFO - episode 2 step 132 reward tensor([-1]) loss 3.9899775981903076 epsilon 0.79335
26-Feb-25 09:39:20 - agent.DQN.DQN - INFO - episode 2 step 133 reward tensor([-1]) loss 3.5224695205688477 epsilon 0.79335
26-Feb-25 09:39:20 - agent.DQN.DQN - INFO - episode 2 step 134 reward tensor([-1]) loss 3.547189950942993 epsilon 0.79335
26-Feb-25 09:39:20 - agent.DQN.DQN - INFO - episode 2 step 135 reward tensor([-1]) loss 2.9762980937957764 epsilon 0.79335
26-Feb-25 09:39:20 - agent.DQN.DQN - INFO - episode 2 step 136 reward tensor([-1]) loss 17.126258850097656 epsilon 0.79335
26-Feb-25 09:39:20 - agent.DQN.DQN - INFO - episode 2 step 137 reward tensor([-1]) loss 17.3784122467041 epsilon 0.79335
26-Feb-25 09:39:20 - agent.DQN.DQN - INFO - episode 2 step 138 reward tensor([-1]) loss 29.269908905029297 epsilon 0.79335
26-Feb-25 09:39:20 - agent.DQN.DQN - INFO - episode 2 step 139 reward tensor([-1]) loss 2.163376569747925 epsilon 0.79335
26-Feb-25 09:39:20 - agent.DQN.DQN - INFO - episode 2 step 140 reward tensor([-1]) loss 2.9731552600860596 epsilon 0.79335
26-Feb-25 09:39:20 - agent.DQN.DQN - INFO - episode 2 step 141 reward tensor([-1]) loss 26.222209930419922 epsilon 0.79335
26-Feb-25 09:39:20 - agent.DQN.DQN - INFO - episode 2 step 142 reward tensor([-1]) loss 61.00096130371094 epsilon 0.79335
26-Feb-25 09:39:20 - agent.DQN.DQN - INFO - episode 2 step 143 reward tensor([-1]) loss 3.053060531616211 epsilon 0.79335
26-Feb-25 09:39:20 - agent.DQN.DQN - INFO - episode 2 step 144 reward tensor([-1]) loss 21.482131958007812 epsilon 0.79335
26-Feb-25 09:39:20 - agent.DQN.DQN - INFO - episode 2 step 145 reward tensor([-1]) loss 35.3107795715332 epsilon 0.79335
26-Feb-25 09:39:20 - agent.DQN.DQN - INFO - episode 2 step 146 reward tensor([-1]) loss 32.45412063598633 epsilon 0.79335
26-Feb-25 09:39:20 - agent.DQN.DQN - INFO - episode 2 step 147 reward tensor([-1]) loss 28.792434692382812 epsilon 0.79335
26-Feb-25 09:39:20 - agent.DQN.DQN - INFO - episode 2 step 148 reward tensor([-1]) loss 41.724761962890625 epsilon 0.79335
26-Feb-25 09:39:20 - agent.DQN.DQN - INFO - episode 2 step 149 reward tensor([-1]) loss 6.481350421905518 epsilon 0.79335
26-Feb-25 09:39:20 - agent.DQN.DQN - INFO - episode 2 step 150 reward tensor([-1]) loss 27.078855514526367 epsilon 0.79335
26-Feb-25 09:39:20 - agent.DQN.DQN - INFO - episode 2 step 151 reward tensor([-1]) loss 24.244138717651367 epsilon 0.79335
26-Feb-25 09:39:20 - agent.DQN.DQN - INFO - episode 2 step 152 reward tensor([-1]) loss 29.675081253051758 epsilon 0.79335
26-Feb-25 09:39:20 - agent.DQN.DQN - INFO - episode 2 step 153 reward tensor([-1]) loss 5.534736633300781 epsilon 0.79335
26-Feb-25 09:39:20 - agent.DQN.DQN - INFO - episode 2 step 154 reward tensor([-1]) loss 13.709312438964844 epsilon 0.79335
26-Feb-25 09:39:20 - agent.DQN.DQN - INFO - episode 2 step 155 reward tensor([-1]) loss 16.211639404296875 epsilon 0.79335
26-Feb-25 09:39:20 - agent.DQN.DQN - INFO - episode 2 step 156 reward tensor([-1]) loss 3.561323881149292 epsilon 0.79335
26-Feb-25 09:39:20 - agent.DQN.DQN - INFO - episode 2 step 157 reward tensor([-1]) loss 15.377814292907715 epsilon 0.79335
26-Feb-25 09:39:20 - agent.DQN.DQN - INFO - episode 2 step 158 reward tensor([-1]) loss 3.6259303092956543 epsilon 0.79335
26-Feb-25 09:39:20 - agent.DQN.DQN - INFO - episode 2 step 159 reward tensor([-1]) loss 14.024726867675781 epsilon 0.79335
26-Feb-25 09:39:20 - agent.DQN.DQN - INFO - episode 2 step 160 reward tensor([-1]) loss 3.648906707763672 epsilon 0.79335
26-Feb-25 09:39:20 - agent.DQN.DQN - INFO - episode 2 step 161 reward tensor([-1]) loss 5.683387756347656 epsilon 0.79335
26-Feb-25 09:39:20 - agent.DQN.DQN - INFO - episode 2 step 162 reward tensor([-1]) loss 4.064283847808838 epsilon 0.79335
26-Feb-25 09:39:20 - agent.DQN.DQN - INFO - episode 2 step 163 reward tensor([-1]) loss 3.556617259979248 epsilon 0.79335
26-Feb-25 09:39:20 - agent.DQN.DQN - INFO - episode 2 step 164 reward tensor([-1]) loss 4.878551483154297 epsilon 0.79335
26-Feb-25 09:39:20 - agent.DQN.DQN - INFO - episode 2 step 165 reward tensor([-1]) loss 5.614617347717285 epsilon 0.79335
26-Feb-25 09:39:20 - agent.DQN.DQN - INFO - episode 2 step 166 reward tensor([-1]) loss 14.64415168762207 epsilon 0.79335
26-Feb-25 09:39:20 - agent.DQN.DQN - INFO - episode 2 step 167 reward tensor([-1]) loss 12.64716625213623 epsilon 0.79335
26-Feb-25 09:39:20 - agent.DQN.DQN - INFO - episode 2 step 168 reward tensor([-1]) loss 2.4443721771240234 epsilon 0.79335
26-Feb-25 09:39:20 - agent.DQN.DQN - INFO - episode 2 step 169 reward tensor([-1]) loss 15.154854774475098 epsilon 0.79335
26-Feb-25 09:39:20 - agent.DQN.DQN - INFO - episode 2 step 170 reward tensor([-1]) loss 13.795778274536133 epsilon 0.79335
26-Feb-25 09:39:20 - agent.DQN.DQN - INFO - episode 2 step 171 reward tensor([-1]) loss 2.312535047531128 epsilon 0.79335
26-Feb-25 09:39:20 - agent.DQN.DQN - INFO - episode 2 step 172 reward tensor([-1]) loss 14.191882133483887 epsilon 0.79335
26-Feb-25 09:39:20 - agent.DQN.DQN - INFO - episode 2 step 173 reward tensor([-1]) loss 4.286576747894287 epsilon 0.79335
26-Feb-25 09:39:20 - agent.DQN.DQN - INFO - episode 2 step 174 reward tensor([-1]) loss 14.255285263061523 epsilon 0.79335
26-Feb-25 09:39:20 - agent.DQN.DQN - INFO - episode 2 step 175 reward tensor([-1]) loss 2.8362221717834473 epsilon 0.79335
26-Feb-25 09:39:20 - agent.DQN.DQN - INFO - episode 2 step 176 reward tensor([-1]) loss 12.89810848236084 epsilon 0.79335
26-Feb-25 09:39:20 - agent.DQN.DQN - INFO - episode 2 step 177 reward tensor([-1]) loss 2.400940179824829 epsilon 0.79335
26-Feb-25 09:39:20 - agent.DQN.DQN - INFO - episode 2 step 178 reward tensor([-1]) loss 2.4993486404418945 epsilon 0.79335
26-Feb-25 09:39:21 - agent.DQN.DQN - INFO - episode 2 step 179 reward tensor([-1]) loss 5.548625946044922 epsilon 0.79335
26-Feb-25 09:39:21 - agent.DQN.DQN - INFO - episode 2 step 180 reward tensor([-1]) loss 5.372204303741455 epsilon 0.79335
26-Feb-25 09:39:21 - agent.DQN.DQN - INFO - episode 2 step 181 reward tensor([-1]) loss 4.946351528167725 epsilon 0.79335
26-Feb-25 09:39:21 - agent.DQN.DQN - INFO - episode 2 step 182 reward tensor([-1]) loss 3.8980228900909424 epsilon 0.79335
26-Feb-25 09:39:21 - agent.DQN.DQN - INFO - episode 2 step 183 reward tensor([-1]) loss 3.823484420776367 epsilon 0.79335
26-Feb-25 09:39:21 - agent.DQN.DQN - INFO - episode 2 step 184 reward tensor([-1]) loss 13.997478485107422 epsilon 0.79335
26-Feb-25 09:39:21 - agent.DQN.DQN - INFO - episode 2 step 185 reward tensor([-1]) loss 2.261157274246216 epsilon 0.79335
26-Feb-25 09:39:21 - agent.DQN.DQN - INFO - episode 2 step 186 reward tensor([-1]) loss 2.62250018119812 epsilon 0.79335
26-Feb-25 09:39:21 - agent.DQN.DQN - INFO - episode 2 step 187 reward tensor([-1]) loss 12.7723970413208 epsilon 0.79335
26-Feb-25 09:39:21 - agent.DQN.DQN - INFO - episode 2 step 188 reward tensor([-1]) loss 1.7427374124526978 epsilon 0.79335
26-Feb-25 09:39:21 - agent.DQN.DQN - INFO - episode 2 step 189 reward tensor([-1]) loss 1.1786881685256958 epsilon 0.79335
26-Feb-25 09:39:21 - agent.DQN.DQN - INFO - episode 2 step 190 reward tensor([-1]) loss 1.2014820575714111 epsilon 0.79335
26-Feb-25 09:39:21 - agent.DQN.DQN - INFO - episode 2 step 191 reward tensor([-1]) loss 2.443749189376831 epsilon 0.79335
26-Feb-25 09:39:21 - agent.DQN.DQN - INFO - episode 2 step 192 reward tensor([-1]) loss 1.6785184144973755 epsilon 0.79335
26-Feb-25 09:39:21 - agent.DQN.DQN - INFO - episode 2 step 193 reward tensor([-1]) loss 12.486116409301758 epsilon 0.79335
26-Feb-25 09:39:21 - agent.DQN.DQN - INFO - episode 2 step 194 reward tensor([-1]) loss 2.3082211017608643 epsilon 0.79335
26-Feb-25 09:39:21 - agent.DQN.DQN - INFO - episode 2 step 195 reward tensor([-1]) loss 2.038343667984009 epsilon 0.79335
26-Feb-25 09:39:21 - agent.DQN.DQN - INFO - episode 2 step 196 reward tensor([-1]) loss 2.207078695297241 epsilon 0.79335
26-Feb-25 09:39:21 - agent.DQN.DQN - INFO - episode 2 step 197 reward tensor([-1]) loss 1.6054507493972778 epsilon 0.79335
26-Feb-25 09:39:21 - agent.DQN.DQN - INFO - episode 2 step 198 reward tensor([-1]) loss 2.4041593074798584 epsilon 0.79335
26-Feb-25 09:39:21 - agent.DQN.DQN - INFO - episode 2 step 199 reward tensor([-1]) loss 11.864432334899902 epsilon 0.79335
26-Feb-25 09:39:21 - agent.DQN.DQN - INFO - episode 2 step 200 reward tensor([-1]) loss 2.6479544639587402 epsilon 0.79335
26-Feb-25 09:39:21 - agent.DQN.DQN - INFO - episode 2 step 201 reward tensor([-1]) loss 1.4838531017303467 epsilon 0.79335
26-Feb-25 09:39:21 - agent.DQN.DQN - INFO - episode 2 step 202 reward tensor([-1]) loss 2.0960211753845215 epsilon 0.79335
26-Feb-25 09:39:21 - agent.DQN.DQN - INFO - episode 2 step 203 reward tensor([-1]) loss 2.4713358879089355 epsilon 0.79335
26-Feb-25 09:39:21 - agent.DQN.DQN - INFO - episode 2 step 204 reward tensor([-1]) loss 2.0794990062713623 epsilon 0.79335
26-Feb-25 09:39:21 - agent.DQN.DQN - INFO - episode 2 step 205 reward tensor([-1]) loss 13.016538619995117 epsilon 0.79335
26-Feb-25 09:39:21 - agent.DQN.DQN - INFO - episode 2 step 206 reward tensor([-1]) loss 1.938551425933838 epsilon 0.79335
26-Feb-25 09:39:21 - agent.DQN.DQN - INFO - episode 2 step 207 reward tensor([-1]) loss 1.6105482578277588 epsilon 0.79335
26-Feb-25 09:39:21 - agent.DQN.DQN - INFO - episode 2 step 208 reward tensor([-1]) loss 3.497074604034424 epsilon 0.79335
26-Feb-25 09:39:21 - agent.DQN.DQN - INFO - episode 2 step 209 reward tensor([-1]) loss 16.38863754272461 epsilon 0.79335
26-Feb-25 09:39:21 - agent.DQN.DQN - INFO - episode 2 step 210 reward tensor([-1]) loss 5.4813361167907715 epsilon 0.79335
26-Feb-25 09:39:21 - agent.DQN.DQN - INFO - episode 2 step 211 reward tensor([-1]) loss 5.53413724899292 epsilon 0.79335
26-Feb-25 09:39:21 - agent.DQN.DQN - INFO - episode 2 step 212 reward tensor([-1]) loss 3.9184510707855225 epsilon 0.79335
26-Feb-25 09:39:21 - agent.DQN.DQN - INFO - episode 2 step 213 reward tensor([-1]) loss 3.3365769386291504 epsilon 0.79335
26-Feb-25 09:39:21 - agent.DQN.DQN - INFO - episode 2 step 214 reward tensor([-1]) loss 13.453177452087402 epsilon 0.79335
26-Feb-25 09:39:21 - agent.DQN.DQN - INFO - episode 2 step 215 reward tensor([-1]) loss 3.003833532333374 epsilon 0.79335
26-Feb-25 09:39:21 - agent.DQN.DQN - INFO - episode 2 step 216 reward tensor([-1]) loss 12.1940336227417 epsilon 0.79335
26-Feb-25 09:39:21 - agent.DQN.DQN - INFO - episode 2 step 217 reward tensor([-1]) loss 5.064727783203125 epsilon 0.79335
26-Feb-25 09:39:21 - agent.DQN.DQN - INFO - episode 2 step 218 reward tensor([-1]) loss 2.323554039001465 epsilon 0.79335
26-Feb-25 09:39:21 - agent.DQN.DQN - INFO - episode 2 step 219 reward tensor([-1]) loss 2.5670559406280518 epsilon 0.79335
26-Feb-25 09:39:21 - agent.DQN.DQN - INFO - episode 2 step 220 reward tensor([-1]) loss 4.535569667816162 epsilon 0.79335
26-Feb-25 09:39:21 - agent.DQN.DQN - INFO - episode 2 step 221 reward tensor([-1]) loss 2.1634342670440674 epsilon 0.79335
26-Feb-25 09:39:21 - agent.DQN.DQN - INFO - episode 2 step 222 reward tensor([-1]) loss 2.4203925132751465 epsilon 0.79335
26-Feb-25 09:39:21 - agent.DQN.DQN - INFO - episode 2 step 223 reward tensor([-1]) loss 2.374490261077881 epsilon 0.79335
26-Feb-25 09:39:21 - agent.DQN.DQN - INFO - episode 2 step 224 reward tensor([-1]) loss 4.079006195068359 epsilon 0.79335
26-Feb-25 09:39:21 - agent.DQN.DQN - INFO - episode 2 step 225 reward tensor([-1]) loss 3.149876356124878 epsilon 0.79335
26-Feb-25 09:39:21 - agent.DQN.DQN - INFO - episode 2 step 226 reward tensor([-1]) loss 2.529888153076172 epsilon 0.79335
26-Feb-25 09:39:21 - agent.DQN.DQN - INFO - episode 2 step 227 reward tensor([-1]) loss 10.742330551147461 epsilon 0.79335
26-Feb-25 09:39:21 - agent.DQN.DQN - INFO - episode 2 step 228 reward tensor([-1]) loss 2.370971202850342 epsilon 0.79335
26-Feb-25 09:39:21 - agent.DQN.DQN - INFO - episode 2 step 229 reward tensor([-1]) loss 2.3862292766571045 epsilon 0.79335
26-Feb-25 09:39:21 - agent.DQN.DQN - INFO - episode 2 step 230 reward tensor([-1]) loss 1.9439384937286377 epsilon 0.79335
26-Feb-25 09:39:21 - agent.DQN.DQN - INFO - episode 2 step 231 reward tensor([-1]) loss 1.8760638236999512 epsilon 0.79335
26-Feb-25 09:39:21 - agent.DQN.DQN - INFO - episode 2 step 232 reward tensor([-1]) loss 11.18620777130127 epsilon 0.79335
26-Feb-25 09:39:21 - agent.DQN.DQN - INFO - episode 2 step 233 reward tensor([-1]) loss 1.2807207107543945 epsilon 0.79335
26-Feb-25 09:39:21 - agent.DQN.DQN - INFO - episode 2 step 234 reward tensor([-1]) loss 10.14830207824707 epsilon 0.79335
26-Feb-25 09:39:21 - agent.DQN.DQN - INFO - episode 2 step 235 reward tensor([-1]) loss 10.390509605407715 epsilon 0.79335
26-Feb-25 09:39:21 - agent.DQN.DQN - INFO - episode 2 step 236 reward tensor([-1]) loss 2.083716630935669 epsilon 0.79335
26-Feb-25 09:39:21 - agent.DQN.DQN - INFO - episode 2 step 237 reward tensor([-1]) loss 10.02524471282959 epsilon 0.79335
26-Feb-25 09:39:21 - agent.DQN.DQN - INFO - episode 2 step 238 reward tensor([-1]) loss 1.425675630569458 epsilon 0.79335
26-Feb-25 09:39:21 - agent.DQN.DQN - INFO - episode 2 step 239 reward tensor([-1]) loss 5.611799240112305 epsilon 0.79335
26-Feb-25 09:39:21 - agent.DQN.DQN - INFO - episode 2 step 240 reward tensor([-1]) loss 5.003600120544434 epsilon 0.79335
26-Feb-25 09:39:21 - agent.DQN.DQN - INFO - episode 2 step 241 reward tensor([-1]) loss 5.366494655609131 epsilon 0.79335
26-Feb-25 09:39:21 - agent.DQN.DQN - INFO - episode 2 step 242 reward tensor([-1]) loss 4.170087814331055 epsilon 0.79335
26-Feb-25 09:39:21 - agent.DQN.DQN - INFO - episode 2 step 243 reward tensor([-1]) loss 3.1458351612091064 epsilon 0.79335
26-Feb-25 09:39:21 - agent.DQN.DQN - INFO - episode 2 step 244 reward tensor([-1]) loss 2.594243288040161 epsilon 0.79335
26-Feb-25 09:39:21 - agent.DQN.DQN - INFO - episode 2 step 245 reward tensor([-1]) loss 1.7759963274002075 epsilon 0.79335
26-Feb-25 09:39:21 - agent.DQN.DQN - INFO - episode 2 step 246 reward tensor([-1]) loss 2.069584369659424 epsilon 0.79335
26-Feb-25 09:39:21 - agent.DQN.DQN - INFO - episode 2 step 247 reward tensor([-1]) loss 2.8835697174072266 epsilon 0.79335
26-Feb-25 09:39:21 - agent.DQN.DQN - INFO - episode 2 step 248 reward tensor([-1]) loss 9.653782844543457 epsilon 0.79335
26-Feb-25 09:39:21 - agent.DQN.DQN - INFO - episode 2 step 249 reward tensor([-1]) loss 2.510586738586426 epsilon 0.79335
26-Feb-25 09:39:21 - agent.DQN.DQN - INFO - episode 2 step 250 reward tensor([-1]) loss 1.6096793413162231 epsilon 0.79335
26-Feb-25 09:39:21 - agent.DQN.DQN - INFO - episode 2 step 251 reward tensor([-1]) loss 2.396498918533325 epsilon 0.79335
26-Feb-25 09:39:21 - agent.DQN.DQN - INFO - episode 2 step 252 reward tensor([-1]) loss 9.946187973022461 epsilon 0.79335
26-Feb-25 09:39:21 - agent.DQN.DQN - INFO - episode 2 step 253 reward tensor([-1]) loss 2.360724687576294 epsilon 0.79335
26-Feb-25 09:39:21 - agent.DQN.DQN - INFO - episode 2 step 254 reward tensor([-1]) loss 2.369006872177124 epsilon 0.79335
26-Feb-25 09:39:21 - agent.DQN.DQN - INFO - episode 2 step 255 reward tensor([-1]) loss 2.131359815597534 epsilon 0.79335
26-Feb-25 09:39:21 - agent.DQN.DQN - INFO - episode 2 step 256 reward tensor([-1]) loss 1.9108577966690063 epsilon 0.79335
26-Feb-25 09:39:21 - agent.DQN.DQN - INFO - episode 2 step 257 reward tensor([-1]) loss 2.1903467178344727 epsilon 0.79335
26-Feb-25 09:39:21 - agent.DQN.DQN - INFO - episode 2 step 258 reward tensor([-1]) loss 2.0691826343536377 epsilon 0.79335
26-Feb-25 09:39:21 - agent.DQN.DQN - INFO - episode 2 step 259 reward tensor([-1]) loss 2.4438018798828125 epsilon 0.79335
26-Feb-25 09:39:21 - agent.DQN.DQN - INFO - episode 2 step 260 reward tensor([-1]) loss 2.0813791751861572 epsilon 0.79335
26-Feb-25 09:39:22 - agent.DQN.DQN - INFO - episode 2 step 261 reward tensor([-1]) loss 1.3113534450531006 epsilon 0.79335
26-Feb-25 09:39:22 - agent.DQN.DQN - INFO - episode 2 step 262 reward tensor([-1]) loss 1.6172596216201782 epsilon 0.79335
26-Feb-25 09:39:22 - agent.DQN.DQN - INFO - episode 2 step 263 reward tensor([-1]) loss 1.2577824592590332 epsilon 0.79335
26-Feb-25 09:39:22 - agent.DQN.DQN - INFO - episode 2 step 264 reward tensor([-1]) loss 1.433772087097168 epsilon 0.79335
26-Feb-25 09:39:22 - agent.DQN.DQN - INFO - episode 2 step 265 reward tensor([-1]) loss 1.4495389461517334 epsilon 0.79335
26-Feb-25 09:39:22 - agent.DQN.DQN - INFO - episode 2 step 266 reward tensor([-1]) loss 1.4931774139404297 epsilon 0.79335
26-Feb-25 09:39:22 - agent.DQN.DQN - INFO - episode 2 step 267 reward tensor([-1]) loss 1.363774061203003 epsilon 0.79335
26-Feb-25 09:39:22 - agent.DQN.DQN - INFO - episode 2 step 268 reward tensor([-1]) loss 2.039409637451172 epsilon 0.79335
26-Feb-25 09:39:22 - agent.DQN.DQN - INFO - episode 2 step 269 reward tensor([-1]) loss 6.039822101593018 epsilon 0.79335
26-Feb-25 09:39:22 - agent.DQN.DQN - INFO - episode 2 step 270 reward tensor([-1]) loss 14.271967887878418 epsilon 0.79335
26-Feb-25 09:39:22 - agent.DQN.DQN - INFO - episode 2 step 271 reward tensor([-1]) loss 4.941934585571289 epsilon 0.79335
26-Feb-25 09:39:22 - agent.DQN.DQN - INFO - episode 2 step 272 reward tensor([-1]) loss 2.9538536071777344 epsilon 0.79335
26-Feb-25 09:39:22 - agent.DQN.DQN - INFO - episode 2 step 273 reward tensor([-1]) loss 2.528559446334839 epsilon 0.79335
26-Feb-25 09:39:22 - agent.DQN.DQN - INFO - episode 2 step 274 reward tensor([-1]) loss 9.278691291809082 epsilon 0.79335
26-Feb-25 09:39:22 - agent.DQN.DQN - INFO - episode 2 step 275 reward tensor([-1]) loss 8.942401885986328 epsilon 0.79335
26-Feb-25 09:39:22 - agent.DQN.DQN - INFO - episode 2 step 276 reward tensor([-1]) loss 1.8704732656478882 epsilon 0.79335
26-Feb-25 09:39:22 - agent.DQN.DQN - INFO - episode 2 step 277 reward tensor([-1]) loss 1.6555167436599731 epsilon 0.79335
26-Feb-25 09:39:22 - agent.DQN.DQN - INFO - episode 2 step 278 reward tensor([-1]) loss 1.6153115034103394 epsilon 0.79335
26-Feb-25 09:39:22 - agent.DQN.DQN - INFO - episode 2 step 279 reward tensor([-1]) loss 7.411839962005615 epsilon 0.79335
26-Feb-25 09:39:22 - agent.DQN.DQN - INFO - episode 2 step 280 reward tensor([-1]) loss 2.2175133228302 epsilon 0.79335
26-Feb-25 09:39:22 - agent.DQN.DQN - INFO - episode 2 step 281 reward tensor([-1]) loss 2.149113416671753 epsilon 0.79335
26-Feb-25 09:39:22 - agent.DQN.DQN - INFO - episode 2 step 282 reward tensor([-1]) loss 1.3277033567428589 epsilon 0.79335
26-Feb-25 09:39:22 - agent.DQN.DQN - INFO - episode 2 step 283 reward tensor([-1]) loss 1.1509506702423096 epsilon 0.79335
26-Feb-25 09:39:22 - agent.DQN.DQN - INFO - episode 2 step 284 reward tensor([-1]) loss 6.35413122177124 epsilon 0.79335
26-Feb-25 09:39:22 - agent.DQN.DQN - INFO - episode 2 step 285 reward tensor([-1]) loss 1.4967931509017944 epsilon 0.79335
26-Feb-25 09:39:22 - agent.DQN.DQN - INFO - episode 2 step 286 reward tensor([-1]) loss 6.92393684387207 epsilon 0.79335
26-Feb-25 09:39:22 - agent.DQN.DQN - INFO - episode 2 step 287 reward tensor([-1]) loss 1.6221848726272583 epsilon 0.79335
26-Feb-25 09:39:22 - agent.DQN.DQN - INFO - episode 2 step 288 reward tensor([-1]) loss 1.4513030052185059 epsilon 0.79335
26-Feb-25 09:39:22 - agent.DQN.DQN - INFO - episode 2 step 289 reward tensor([-1]) loss 1.2278780937194824 epsilon 0.79335
26-Feb-25 09:39:22 - agent.DQN.DQN - INFO - episode 2 step 290 reward tensor([-1]) loss 2.111250638961792 epsilon 0.79335
26-Feb-25 09:39:22 - agent.DQN.DQN - INFO - episode 2 step 291 reward tensor([-1]) loss 1.7155694961547852 epsilon 0.79335
26-Feb-25 09:39:22 - agent.DQN.DQN - INFO - episode 2 step 292 reward tensor([-1]) loss 2.1938223838806152 epsilon 0.79335
26-Feb-25 09:39:22 - agent.DQN.DQN - INFO - episode 2 step 293 reward tensor([-1]) loss 1.9178271293640137 epsilon 0.79335
26-Feb-25 09:39:22 - agent.DQN.DQN - INFO - episode 2 step 294 reward tensor([-1]) loss 1.8290321826934814 epsilon 0.79335
26-Feb-25 09:39:22 - agent.DQN.DQN - INFO - episode 2 step 295 reward tensor([-1]) loss 0.8117210268974304 epsilon 0.79335
26-Feb-25 09:39:22 - agent.DQN.DQN - INFO - episode 2 step 296 reward tensor([-1]) loss 6.632078170776367 epsilon 0.79335
26-Feb-25 09:39:22 - agent.DQN.DQN - INFO - episode 2 step 297 reward tensor([-1]) loss 1.1977245807647705 epsilon 0.79335
26-Feb-25 09:39:22 - agent.DQN.DQN - INFO - episode 2 step 298 reward tensor([-1]) loss 0.9696128368377686 epsilon 0.79335
26-Feb-25 09:39:22 - agent.DQN.DQN - INFO - episode 2 step 299 reward tensor([-1]) loss 6.997387409210205 epsilon 0.79335
26-Feb-25 09:39:22 - agent.DQN.DQN - INFO - episode 2 step 300 reward tensor([-1]) loss 5.37624454498291 epsilon 0.79335
26-Feb-25 09:39:22 - agent.DQN.DQN - INFO - episode 2 step 301 reward tensor([-1]) loss 3.402780055999756 epsilon 0.79335
26-Feb-25 09:39:22 - agent.DQN.DQN - INFO - episode 3 step 0 reward tensor([-1]) loss 41.39395523071289 epsilon 0.767566125
26-Feb-25 09:39:22 - agent.DQN.DQN - INFO - episode 3 step 1 reward tensor([-1]) loss 2.5330188274383545 epsilon 0.767566125
26-Feb-25 09:39:22 - agent.DQN.DQN - INFO - episode 3 step 2 reward tensor([-1]) loss 1.8685262203216553 epsilon 0.767566125
26-Feb-25 09:39:22 - agent.DQN.DQN - INFO - episode 3 step 3 reward tensor([-1]) loss 1.5879669189453125 epsilon 0.767566125
26-Feb-25 09:39:22 - agent.DQN.DQN - INFO - episode 3 step 4 reward tensor([-1]) loss 1.8901605606079102 epsilon 0.767566125
26-Feb-25 09:39:22 - agent.DQN.DQN - INFO - episode 3 step 5 reward tensor([-1]) loss 35.95930099487305 epsilon 0.767566125
26-Feb-25 09:39:22 - agent.DQN.DQN - INFO - episode 3 step 6 reward tensor([-1]) loss 2.1895673274993896 epsilon 0.767566125
26-Feb-25 09:39:22 - agent.DQN.DQN - INFO - episode 3 step 7 reward tensor([-1]) loss 26.044950485229492 epsilon 0.767566125
26-Feb-25 09:39:22 - agent.DQN.DQN - INFO - episode 3 step 8 reward tensor([-1]) loss 9.265935897827148 epsilon 0.767566125
26-Feb-25 09:39:22 - agent.DQN.DQN - INFO - episode 3 step 9 reward tensor([-1]) loss 22.088420867919922 epsilon 0.767566125
26-Feb-25 09:39:22 - agent.DQN.DQN - INFO - episode 3 step 10 reward tensor([-1]) loss 19.125179290771484 epsilon 0.767566125
26-Feb-25 09:39:22 - agent.DQN.DQN - INFO - episode 3 step 11 reward tensor([-1]) loss 4.206872940063477 epsilon 0.767566125
26-Feb-25 09:39:22 - agent.DQN.DQN - INFO - episode 3 step 12 reward tensor([-1]) loss 13.617253303527832 epsilon 0.767566125
26-Feb-25 09:39:22 - agent.DQN.DQN - INFO - episode 3 step 13 reward tensor([-1]) loss 16.53615951538086 epsilon 0.767566125
26-Feb-25 09:39:22 - agent.DQN.DQN - INFO - episode 3 step 14 reward tensor([-1]) loss 16.637269973754883 epsilon 0.767566125
26-Feb-25 09:39:22 - agent.DQN.DQN - INFO - episode 3 step 15 reward tensor([-1]) loss 2.841341257095337 epsilon 0.767566125
26-Feb-25 09:39:22 - agent.DQN.DQN - INFO - episode 3 step 16 reward tensor([-1]) loss 20.48175811767578 epsilon 0.767566125
26-Feb-25 09:39:22 - agent.DQN.DQN - INFO - episode 3 step 17 reward tensor([-1]) loss 9.074860572814941 epsilon 0.767566125
26-Feb-25 09:39:22 - agent.DQN.DQN - INFO - episode 3 step 18 reward tensor([-1]) loss 7.684943199157715 epsilon 0.767566125
26-Feb-25 09:39:22 - agent.DQN.DQN - INFO - episode 3 step 19 reward tensor([-1]) loss 4.493616580963135 epsilon 0.767566125
26-Feb-25 09:39:22 - agent.DQN.DQN - INFO - episode 3 step 20 reward tensor([-1]) loss 1.789338231086731 epsilon 0.767566125
26-Feb-25 09:39:22 - agent.DQN.DQN - INFO - episode 3 step 21 reward tensor([-1]) loss 1.929449439048767 epsilon 0.767566125
26-Feb-25 09:39:22 - agent.DQN.DQN - INFO - episode 3 step 22 reward tensor([-1]) loss 1.2215732336044312 epsilon 0.767566125
26-Feb-25 09:39:22 - agent.DQN.DQN - INFO - episode 3 step 23 reward tensor([-1]) loss 1.4221367835998535 epsilon 0.767566125
26-Feb-25 09:39:22 - agent.DQN.DQN - INFO - episode 3 step 24 reward tensor([-1]) loss 2.6723785400390625 epsilon 0.767566125
26-Feb-25 09:39:22 - agent.DQN.DQN - INFO - episode 3 step 25 reward tensor([-1]) loss 5.296430587768555 epsilon 0.767566125
26-Feb-25 09:39:22 - agent.DQN.DQN - INFO - episode 3 step 26 reward tensor([-1]) loss 44.58123016357422 epsilon 0.767566125
26-Feb-25 09:39:22 - agent.DQN.DQN - INFO - episode 3 step 27 reward tensor([-1]) loss 7.359361171722412 epsilon 0.767566125
26-Feb-25 09:39:22 - agent.DQN.DQN - INFO - episode 3 step 28 reward tensor([-1]) loss 3.137716293334961 epsilon 0.767566125
26-Feb-25 09:39:22 - agent.DQN.DQN - INFO - episode 3 step 29 reward tensor([-1]) loss 38.871952056884766 epsilon 0.767566125
26-Feb-25 09:39:22 - agent.DQN.DQN - INFO - episode 3 step 30 reward tensor([-1]) loss 3.4234304428100586 epsilon 0.767566125
26-Feb-25 09:39:22 - agent.DQN.DQN - INFO - episode 3 step 31 reward tensor([-1]) loss 2.5691816806793213 epsilon 0.767566125
26-Feb-25 09:39:22 - agent.DQN.DQN - INFO - episode 3 step 32 reward tensor([-1]) loss 5.50275993347168 epsilon 0.767566125
26-Feb-25 09:39:23 - agent.DQN.DQN - INFO - episode 3 step 33 reward tensor([-1]) loss 5.372386932373047 epsilon 0.767566125
26-Feb-25 09:39:23 - agent.DQN.DQN - INFO - episode 3 step 34 reward tensor([-1]) loss 1.9712111949920654 epsilon 0.767566125
26-Feb-25 09:39:23 - agent.DQN.DQN - INFO - episode 3 step 35 reward tensor([-1]) loss 1.5526132583618164 epsilon 0.767566125
26-Feb-25 09:39:23 - agent.DQN.DQN - INFO - episode 3 step 36 reward tensor([-1]) loss 2.2145609855651855 epsilon 0.767566125
26-Feb-25 09:39:23 - agent.DQN.DQN - INFO - episode 3 step 37 reward tensor([-1]) loss 2.5781784057617188 epsilon 0.767566125
26-Feb-25 09:39:23 - agent.DQN.DQN - INFO - episode 3 step 38 reward tensor([-1]) loss 1.3805420398712158 epsilon 0.767566125
26-Feb-25 09:39:23 - agent.DQN.DQN - INFO - episode 3 step 39 reward tensor([-1]) loss 2.135871410369873 epsilon 0.767566125
26-Feb-25 09:39:23 - agent.DQN.DQN - INFO - episode 3 step 40 reward tensor([-1]) loss 2.035324811935425 epsilon 0.767566125
26-Feb-25 09:39:23 - agent.DQN.DQN - INFO - episode 3 step 41 reward tensor([-1]) loss 2.057244062423706 epsilon 0.767566125
26-Feb-25 09:39:23 - agent.DQN.DQN - INFO - episode 3 step 42 reward tensor([-1]) loss 1.4806605577468872 epsilon 0.767566125
26-Feb-25 09:39:23 - agent.DQN.DQN - INFO - episode 3 step 43 reward tensor([-1]) loss 2.257728099822998 epsilon 0.767566125
26-Feb-25 09:39:23 - agent.DQN.DQN - INFO - episode 3 step 44 reward tensor([-1]) loss 5.080610752105713 epsilon 0.767566125
26-Feb-25 09:39:23 - agent.DQN.DQN - INFO - episode 3 step 45 reward tensor([-1]) loss 1.001865267753601 epsilon 0.767566125
26-Feb-25 09:39:23 - agent.DQN.DQN - INFO - episode 3 step 46 reward tensor([-1]) loss 4.857301235198975 epsilon 0.767566125
26-Feb-25 09:39:23 - agent.DQN.DQN - INFO - episode 3 step 47 reward tensor([-1]) loss 1.2469311952590942 epsilon 0.767566125
26-Feb-25 09:39:23 - agent.DQN.DQN - INFO - episode 3 step 48 reward tensor([-1]) loss 1.2920209169387817 epsilon 0.767566125
26-Feb-25 09:39:23 - agent.DQN.DQN - INFO - episode 3 step 49 reward tensor([-1]) loss 27.458560943603516 epsilon 0.767566125
26-Feb-25 09:39:23 - agent.DQN.DQN - INFO - episode 3 step 50 reward tensor([-1]) loss 1.3034471273422241 epsilon 0.767566125
26-Feb-25 09:39:23 - agent.DQN.DQN - INFO - episode 3 step 51 reward tensor([-1]) loss 0.8039351105690002 epsilon 0.767566125
26-Feb-25 09:39:23 - agent.DQN.DQN - INFO - episode 3 step 52 reward tensor([-1]) loss 1.157962441444397 epsilon 0.767566125
26-Feb-25 09:39:23 - agent.DQN.DQN - INFO - episode 3 step 53 reward tensor([-1]) loss 0.7981871366500854 epsilon 0.767566125
26-Feb-25 09:39:23 - agent.DQN.DQN - INFO - episode 3 step 54 reward tensor([-1]) loss 25.766815185546875 epsilon 0.767566125
26-Feb-25 09:39:23 - agent.DQN.DQN - INFO - episode 3 step 55 reward tensor([-1]) loss 24.712142944335938 epsilon 0.767566125
26-Feb-25 09:39:23 - agent.DQN.DQN - INFO - episode 3 step 56 reward tensor([-1]) loss 0.9857534170150757 epsilon 0.767566125
26-Feb-25 09:39:23 - agent.DQN.DQN - INFO - episode 3 step 57 reward tensor([-1]) loss 5.339982032775879 epsilon 0.767566125
26-Feb-25 09:39:23 - agent.DQN.DQN - INFO - episode 3 step 58 reward tensor([-1]) loss 3.918368101119995 epsilon 0.767566125
26-Feb-25 09:39:23 - agent.DQN.DQN - INFO - episode 3 step 59 reward tensor([-1]) loss 3.7206642627716064 epsilon 0.767566125
26-Feb-25 09:39:23 - agent.DQN.DQN - INFO - episode 3 step 60 reward tensor([-1]) loss 3.6305413246154785 epsilon 0.767566125
26-Feb-25 09:39:23 - agent.DQN.DQN - INFO - episode 3 step 61 reward tensor([-1]) loss 2.1753978729248047 epsilon 0.767566125
26-Feb-25 09:39:23 - agent.DQN.DQN - INFO - episode 3 step 62 reward tensor([-1]) loss 1.6623990535736084 epsilon 0.767566125
26-Feb-25 09:39:23 - agent.DQN.DQN - INFO - episode 3 step 63 reward tensor([-1]) loss 20.74336051940918 epsilon 0.767566125
26-Feb-25 09:39:23 - agent.DQN.DQN - INFO - episode 3 step 64 reward tensor([-1]) loss 1.9978837966918945 epsilon 0.767566125
26-Feb-25 09:39:23 - agent.DQN.DQN - INFO - episode 3 step 65 reward tensor([-1]) loss 19.964187622070312 epsilon 0.767566125
26-Feb-25 09:39:23 - agent.DQN.DQN - INFO - episode 3 step 66 reward tensor([-1]) loss 6.873989105224609 epsilon 0.767566125
26-Feb-25 09:39:23 - agent.DQN.DQN - INFO - episode 3 step 67 reward tensor([-1]) loss 22.63609504699707 epsilon 0.767566125
26-Feb-25 09:39:23 - agent.DQN.DQN - INFO - episode 3 step 68 reward tensor([-1]) loss 1.5877104997634888 epsilon 0.767566125
26-Feb-25 09:39:23 - agent.DQN.DQN - INFO - episode 3 step 69 reward tensor([-1]) loss 15.671375274658203 epsilon 0.767566125
26-Feb-25 09:39:23 - agent.DQN.DQN - INFO - episode 3 step 70 reward tensor([-1]) loss 5.068871974945068 epsilon 0.767566125
26-Feb-25 09:39:23 - agent.DQN.DQN - INFO - episode 3 step 71 reward tensor([-1]) loss 3.202214002609253 epsilon 0.767566125
26-Feb-25 09:39:23 - agent.DQN.DQN - INFO - episode 3 step 72 reward tensor([-1]) loss 4.383957386016846 epsilon 0.767566125
26-Feb-25 09:39:23 - agent.DQN.DQN - INFO - episode 3 step 73 reward tensor([-1]) loss 2.938868522644043 epsilon 0.767566125
26-Feb-25 09:39:23 - agent.DQN.DQN - INFO - episode 3 step 74 reward tensor([-1]) loss 5.518089771270752 epsilon 0.767566125
26-Feb-25 09:39:23 - agent.DQN.DQN - INFO - episode 3 step 75 reward tensor([-1]) loss 6.432581901550293 epsilon 0.767566125
26-Feb-25 09:39:23 - agent.DQN.DQN - INFO - episode 3 step 76 reward tensor([-1]) loss 3.417299747467041 epsilon 0.767566125
26-Feb-25 09:39:23 - agent.DQN.DQN - INFO - episode 3 step 77 reward tensor([-1]) loss 1.5863499641418457 epsilon 0.767566125
26-Feb-25 09:39:23 - agent.DQN.DQN - INFO - episode 3 step 78 reward tensor([-1]) loss 2.036050319671631 epsilon 0.767566125
26-Feb-25 09:39:23 - agent.DQN.DQN - INFO - episode 3 step 79 reward tensor([-1]) loss 1.171952486038208 epsilon 0.767566125
26-Feb-25 09:39:23 - agent.DQN.DQN - INFO - episode 3 step 80 reward tensor([-1]) loss 1.6526514291763306 epsilon 0.767566125
26-Feb-25 09:39:23 - agent.DQN.DQN - INFO - episode 3 step 81 reward tensor([-1]) loss 1.6896377801895142 epsilon 0.767566125
26-Feb-25 09:39:23 - agent.DQN.DQN - INFO - episode 3 step 82 reward tensor([-1]) loss 23.14510154724121 epsilon 0.767566125
26-Feb-25 09:39:23 - agent.DQN.DQN - INFO - episode 3 step 83 reward tensor([-1]) loss 23.363401412963867 epsilon 0.767566125
26-Feb-25 09:39:23 - agent.DQN.DQN - INFO - episode 3 step 84 reward tensor([-1]) loss 25.523012161254883 epsilon 0.767566125
26-Feb-25 09:39:23 - agent.DQN.DQN - INFO - episode 3 step 85 reward tensor([-1]) loss 0.9687656760215759 epsilon 0.767566125
26-Feb-25 09:39:23 - agent.DQN.DQN - INFO - episode 3 step 86 reward tensor([-1]) loss 4.106457710266113 epsilon 0.767566125
26-Feb-25 09:39:23 - agent.DQN.DQN - INFO - episode 3 step 87 reward tensor([-1]) loss 4.005270004272461 epsilon 0.767566125
26-Feb-25 09:39:23 - agent.DQN.DQN - INFO - episode 3 step 88 reward tensor([-1]) loss 25.045974731445312 epsilon 0.767566125
26-Feb-25 09:39:23 - agent.DQN.DQN - INFO - episode 3 step 89 reward tensor([-1]) loss 3.217526912689209 epsilon 0.767566125
26-Feb-25 09:39:23 - agent.DQN.DQN - INFO - episode 3 step 90 reward tensor([-1]) loss 1.9466701745986938 epsilon 0.767566125
26-Feb-25 09:39:23 - agent.DQN.DQN - INFO - episode 3 step 91 reward tensor([-1]) loss 5.348553657531738 epsilon 0.767566125
26-Feb-25 09:39:23 - agent.DQN.DQN - INFO - episode 3 step 92 reward tensor([-1]) loss 2.1123578548431396 epsilon 0.767566125
26-Feb-25 09:39:23 - agent.DQN.DQN - INFO - episode 3 step 93 reward tensor([-1]) loss 3.6410632133483887 epsilon 0.767566125
26-Feb-25 09:39:23 - agent.DQN.DQN - INFO - episode 3 step 94 reward tensor([-1]) loss 15.143686294555664 epsilon 0.767566125
26-Feb-25 09:39:23 - agent.DQN.DQN - INFO - episode 3 step 95 reward tensor([-1]) loss 14.608059883117676 epsilon 0.767566125
26-Feb-25 09:39:23 - agent.DQN.DQN - INFO - episode 3 step 96 reward tensor([-1]) loss 3.581467866897583 epsilon 0.767566125
26-Feb-25 09:39:23 - agent.DQN.DQN - INFO - episode 3 step 97 reward tensor([-1]) loss 2.090273857116699 epsilon 0.767566125
26-Feb-25 09:39:23 - agent.DQN.DQN - INFO - episode 3 step 98 reward tensor([-1]) loss 13.845100402832031 epsilon 0.767566125
26-Feb-25 09:39:23 - agent.DQN.DQN - INFO - episode 3 step 99 reward tensor([-1]) loss 2.124008893966675 epsilon 0.767566125
26-Feb-25 09:39:23 - agent.DQN.DQN - INFO - episode 3 step 100 reward tensor([-1]) loss 2.4281883239746094 epsilon 0.767566125
26-Feb-25 09:39:23 - agent.DQN.DQN - INFO - episode 3 step 101 reward tensor([-1]) loss 3.0117027759552 epsilon 0.767566125
26-Feb-25 09:39:23 - agent.DQN.DQN - INFO - episode 3 step 102 reward tensor([-1]) loss 2.1849687099456787 epsilon 0.767566125
26-Feb-25 09:39:23 - agent.DQN.DQN - INFO - episode 3 step 103 reward tensor([-1]) loss 2.9883811473846436 epsilon 0.767566125
26-Feb-25 09:39:23 - agent.DQN.DQN - INFO - episode 3 step 104 reward tensor([-1]) loss 1.868503212928772 epsilon 0.767566125
26-Feb-25 09:39:23 - agent.DQN.DQN - INFO - episode 3 step 105 reward tensor([-1]) loss 5.783364772796631 epsilon 0.767566125
26-Feb-25 09:39:23 - agent.DQN.DQN - INFO - episode 3 step 106 reward tensor([-1]) loss 12.010634422302246 epsilon 0.767566125
26-Feb-25 09:39:23 - agent.DQN.DQN - INFO - episode 3 step 107 reward tensor([-1]) loss 4.0434393882751465 epsilon 0.767566125
26-Feb-25 09:39:24 - agent.DQN.DQN - INFO - episode 3 step 108 reward tensor([-1]) loss 3.7092983722686768 epsilon 0.767566125
26-Feb-25 09:39:24 - agent.DQN.DQN - INFO - episode 3 step 109 reward tensor([-1]) loss 1.6210541725158691 epsilon 0.767566125
26-Feb-25 09:39:24 - agent.DQN.DQN - INFO - episode 3 step 110 reward tensor([-1]) loss 1.213926911354065 epsilon 0.767566125
26-Feb-25 09:39:24 - agent.DQN.DQN - INFO - episode 3 step 111 reward tensor([-1]) loss 3.6518051624298096 epsilon 0.767566125
26-Feb-25 09:39:24 - agent.DQN.DQN - INFO - episode 3 step 112 reward tensor([-1]) loss 1.0421797037124634 epsilon 0.767566125
26-Feb-25 09:39:24 - agent.DQN.DQN - INFO - episode 3 step 113 reward tensor([-1]) loss 1.0381064414978027 epsilon 0.767566125
26-Feb-25 09:39:24 - agent.DQN.DQN - INFO - episode 3 step 114 reward tensor([-1]) loss 0.8707249760627747 epsilon 0.767566125
26-Feb-25 09:39:24 - agent.DQN.DQN - INFO - episode 3 step 115 reward tensor([-1]) loss 0.7284749746322632 epsilon 0.767566125
26-Feb-25 09:39:24 - agent.DQN.DQN - INFO - episode 3 step 116 reward tensor([-1]) loss 2.0571792125701904 epsilon 0.767566125
26-Feb-25 09:39:24 - agent.DQN.DQN - INFO - episode 3 step 117 reward tensor([-1]) loss 2.891054630279541 epsilon 0.767566125
26-Feb-25 09:39:24 - agent.DQN.DQN - INFO - episode 3 step 118 reward tensor([-1]) loss 2.9336776733398438 epsilon 0.767566125
26-Feb-25 09:39:24 - agent.DQN.DQN - INFO - episode 3 step 119 reward tensor([-1]) loss 19.91962432861328 epsilon 0.767566125
26-Feb-25 09:39:24 - agent.DQN.DQN - INFO - episode 3 step 120 reward tensor([-1]) loss 2.2492899894714355 epsilon 0.767566125
26-Feb-25 09:39:24 - agent.DQN.DQN - INFO - episode 3 step 121 reward tensor([-1]) loss 19.724916458129883 epsilon 0.767566125
26-Feb-25 09:39:24 - agent.DQN.DQN - INFO - episode 3 step 122 reward tensor([-1]) loss 18.227968215942383 epsilon 0.767566125
26-Feb-25 09:39:24 - agent.DQN.DQN - INFO - episode 3 step 123 reward tensor([-1]) loss 3.837310791015625 epsilon 0.767566125
26-Feb-25 09:39:24 - agent.DQN.DQN - INFO - episode 3 step 124 reward tensor([-1]) loss 15.232612609863281 epsilon 0.767566125
26-Feb-25 09:39:24 - agent.DQN.DQN - INFO - episode 3 step 125 reward tensor([-1]) loss 1.5766116380691528 epsilon 0.767566125
26-Feb-25 09:39:24 - agent.DQN.DQN - INFO - episode 3 step 126 reward tensor([-1]) loss 12.990869522094727 epsilon 0.767566125
26-Feb-25 09:39:24 - agent.DQN.DQN - INFO - episode 3 step 127 reward tensor([-1]) loss 1.4218279123306274 epsilon 0.767566125
26-Feb-25 09:39:24 - agent.DQN.DQN - INFO - episode 3 step 128 reward tensor([-1]) loss 3.8983542919158936 epsilon 0.767566125
26-Feb-25 09:39:24 - agent.DQN.DQN - INFO - episode 3 step 129 reward tensor([-1]) loss 1.4974801540374756 epsilon 0.767566125
26-Feb-25 09:39:24 - agent.DQN.DQN - INFO - episode 3 step 130 reward tensor([-1]) loss 9.842966079711914 epsilon 0.767566125
26-Feb-25 09:39:24 - agent.DQN.DQN - INFO - episode 3 step 131 reward tensor([-1]) loss 3.5186779499053955 epsilon 0.767566125
26-Feb-25 09:39:24 - agent.DQN.DQN - INFO - episode 3 step 132 reward tensor([-1]) loss 1.7952526807785034 epsilon 0.767566125
26-Feb-25 09:39:24 - agent.DQN.DQN - INFO - episode 3 step 133 reward tensor([-1]) loss 3.7114858627319336 epsilon 0.767566125
26-Feb-25 09:39:24 - agent.DQN.DQN - INFO - episode 3 step 134 reward tensor([-1]) loss 1.206101417541504 epsilon 0.767566125
26-Feb-25 09:39:24 - agent.DQN.DQN - INFO - episode 3 step 135 reward tensor([-1]) loss 2.7824785709381104 epsilon 0.767566125
26-Feb-25 09:39:24 - agent.DQN.DQN - INFO - episode 3 step 136 reward tensor([-1]) loss 9.516711235046387 epsilon 0.767566125
26-Feb-25 09:39:24 - agent.DQN.DQN - INFO - episode 3 step 137 reward tensor([-1]) loss 2.5542960166931152 epsilon 0.767566125
26-Feb-25 09:39:24 - agent.DQN.DQN - INFO - episode 3 step 138 reward tensor([-1]) loss 2.961453676223755 epsilon 0.767566125
26-Feb-25 09:39:24 - agent.DQN.DQN - INFO - episode 3 step 139 reward tensor([-1]) loss 2.0701069831848145 epsilon 0.767566125
26-Feb-25 09:39:24 - agent.DQN.DQN - INFO - episode 3 step 140 reward tensor([-1]) loss 4.842767238616943 epsilon 0.767566125
26-Feb-25 09:39:24 - agent.DQN.DQN - INFO - episode 3 step 141 reward tensor([-1]) loss 1.2786568403244019 epsilon 0.767566125
26-Feb-25 09:39:24 - agent.DQN.DQN - INFO - episode 3 step 142 reward tensor([-1]) loss 1.3183088302612305 epsilon 0.767566125
26-Feb-25 09:39:24 - agent.DQN.DQN - INFO - episode 3 step 143 reward tensor([-1]) loss 8.982670783996582 epsilon 0.767566125
26-Feb-25 09:39:24 - agent.DQN.DQN - INFO - episode 3 step 144 reward tensor([-1]) loss 9.42482852935791 epsilon 0.767566125
26-Feb-25 09:39:24 - agent.DQN.DQN - INFO - episode 3 step 145 reward tensor([-1]) loss 3.326549768447876 epsilon 0.767566125
26-Feb-25 09:39:24 - agent.DQN.DQN - INFO - episode 3 step 146 reward tensor([-1]) loss 1.3186200857162476 epsilon 0.767566125
26-Feb-25 09:39:24 - agent.DQN.DQN - INFO - episode 3 step 147 reward tensor([-1]) loss 13.301783561706543 epsilon 0.767566125
26-Feb-25 09:39:24 - agent.DQN.DQN - INFO - episode 3 step 148 reward tensor([-1]) loss 2.7446482181549072 epsilon 0.767566125
26-Feb-25 09:39:24 - agent.DQN.DQN - INFO - episode 3 step 149 reward tensor([-1]) loss 3.1304783821105957 epsilon 0.767566125
26-Feb-25 09:39:24 - agent.DQN.DQN - INFO - episode 3 step 150 reward tensor([-1]) loss 2.7602076530456543 epsilon 0.767566125
26-Feb-25 09:39:24 - agent.DQN.DQN - INFO - episode 3 step 151 reward tensor([-1]) loss 1.6291804313659668 epsilon 0.767566125
26-Feb-25 09:39:24 - agent.DQN.DQN - INFO - episode 3 step 152 reward tensor([-1]) loss 1.9427297115325928 epsilon 0.767566125
26-Feb-25 09:39:24 - agent.DQN.DQN - INFO - episode 3 step 153 reward tensor([-1]) loss 0.8949226140975952 epsilon 0.767566125
26-Feb-25 09:39:24 - agent.DQN.DQN - INFO - episode 3 step 154 reward tensor([-1]) loss 11.537941932678223 epsilon 0.767566125
26-Feb-25 09:39:24 - agent.DQN.DQN - INFO - episode 3 step 155 reward tensor([-1]) loss 1.6161085367202759 epsilon 0.767566125
26-Feb-25 09:39:24 - agent.DQN.DQN - INFO - episode 3 step 156 reward tensor([-1]) loss 13.800983428955078 epsilon 0.767566125
26-Feb-25 09:39:24 - agent.DQN.DQN - INFO - episode 3 step 157 reward tensor([-1]) loss 10.789801597595215 epsilon 0.767566125
26-Feb-25 09:39:24 - agent.DQN.DQN - INFO - episode 3 step 158 reward tensor([-1]) loss 2.5327978134155273 epsilon 0.767566125
26-Feb-25 09:39:24 - agent.DQN.DQN - INFO - episode 3 step 159 reward tensor([-1]) loss 3.3579261302948 epsilon 0.767566125
26-Feb-25 09:39:24 - agent.DQN.DQN - INFO - episode 3 step 160 reward tensor([-1]) loss 2.2349772453308105 epsilon 0.767566125
26-Feb-25 09:39:24 - agent.DQN.DQN - INFO - episode 3 step 161 reward tensor([-1]) loss 9.3607177734375 epsilon 0.767566125
26-Feb-25 09:39:24 - agent.DQN.DQN - INFO - episode 3 step 162 reward tensor([-1]) loss 9.21705150604248 epsilon 0.767566125
26-Feb-25 09:39:24 - agent.DQN.DQN - INFO - episode 3 step 163 reward tensor([-1]) loss 1.259648323059082 epsilon 0.767566125
26-Feb-25 09:39:24 - agent.DQN.DQN - INFO - episode 3 step 164 reward tensor([-1]) loss 3.0061633586883545 epsilon 0.767566125
26-Feb-25 09:39:24 - agent.DQN.DQN - INFO - episode 3 step 165 reward tensor([-1]) loss 2.9057390689849854 epsilon 0.767566125
26-Feb-25 09:39:24 - agent.DQN.DQN - INFO - episode 3 step 166 reward tensor([-1]) loss 8.556512832641602 epsilon 0.767566125
26-Feb-25 09:39:24 - agent.DQN.DQN - INFO - episode 3 step 167 reward tensor([-1]) loss 3.382878065109253 epsilon 0.767566125
26-Feb-25 09:39:24 - agent.DQN.DQN - INFO - episode 3 step 168 reward tensor([-1]) loss 0.9330083131790161 epsilon 0.767566125
26-Feb-25 09:39:24 - agent.DQN.DQN - INFO - episode 3 step 169 reward tensor([-1]) loss 1.6107643842697144 epsilon 0.767566125
26-Feb-25 09:39:24 - agent.DQN.DQN - INFO - episode 3 step 170 reward tensor([-1]) loss 1.8332314491271973 epsilon 0.767566125
26-Feb-25 09:39:24 - agent.DQN.DQN - INFO - episode 3 step 171 reward tensor([-1]) loss 2.881741523742676 epsilon 0.767566125
26-Feb-25 09:39:24 - agent.DQN.DQN - INFO - episode 3 step 172 reward tensor([-1]) loss 1.978804111480713 epsilon 0.767566125
26-Feb-25 09:39:24 - agent.DQN.DQN - INFO - episode 3 step 173 reward tensor([-1]) loss 9.656469345092773 epsilon 0.767566125
26-Feb-25 09:39:24 - agent.DQN.DQN - INFO - episode 3 step 174 reward tensor([-1]) loss 1.5570493936538696 epsilon 0.767566125
26-Feb-25 09:39:24 - agent.DQN.DQN - INFO - episode 3 step 175 reward tensor([-1]) loss 1.1619864702224731 epsilon 0.767566125
26-Feb-25 09:39:24 - agent.DQN.DQN - INFO - episode 3 step 176 reward tensor([-1]) loss 0.7566598057746887 epsilon 0.767566125
26-Feb-25 09:39:24 - agent.DQN.DQN - INFO - episode 3 step 177 reward tensor([-1]) loss 4.3280816078186035 epsilon 0.767566125
26-Feb-25 09:39:24 - agent.DQN.DQN - INFO - episode 3 step 178 reward tensor([-1]) loss 10.022273063659668 epsilon 0.767566125
26-Feb-25 09:39:24 - agent.DQN.DQN - INFO - episode 3 step 179 reward tensor([-1]) loss 2.7086665630340576 epsilon 0.767566125
26-Feb-25 09:39:24 - agent.DQN.DQN - INFO - episode 3 step 180 reward tensor([-1]) loss 1.7661665678024292 epsilon 0.767566125
26-Feb-25 09:39:24 - agent.DQN.DQN - INFO - episode 3 step 181 reward tensor([-1]) loss 1.3354146480560303 epsilon 0.767566125
26-Feb-25 09:39:24 - agent.DQN.DQN - INFO - episode 3 step 182 reward tensor([-1]) loss 0.8973088264465332 epsilon 0.767566125
26-Feb-25 09:39:24 - agent.DQN.DQN - INFO - episode 3 step 183 reward tensor([-1]) loss 0.7199684381484985 epsilon 0.767566125
26-Feb-25 09:39:24 - agent.DQN.DQN - INFO - episode 3 step 184 reward tensor([-1]) loss 0.7723827362060547 epsilon 0.767566125
26-Feb-25 09:39:24 - agent.DQN.DQN - INFO - episode 3 step 185 reward tensor([-1]) loss 9.255980491638184 epsilon 0.767566125
26-Feb-25 09:39:24 - agent.DQN.DQN - INFO - episode 3 step 186 reward tensor([-1]) loss 1.0314089059829712 epsilon 0.767566125
26-Feb-25 09:39:24 - agent.DQN.DQN - INFO - episode 3 step 187 reward tensor([-1]) loss 1.2423272132873535 epsilon 0.767566125
26-Feb-25 09:39:24 - agent.DQN.DQN - INFO - episode 3 step 188 reward tensor([-1]) loss 1.0811283588409424 epsilon 0.767566125
26-Feb-25 09:39:24 - agent.DQN.DQN - INFO - episode 3 step 189 reward tensor([-1]) loss 1.1833429336547852 epsilon 0.767566125
26-Feb-25 09:39:24 - agent.DQN.DQN - INFO - episode 3 step 190 reward tensor([-1]) loss 9.470562934875488 epsilon 0.767566125
26-Feb-25 09:39:24 - agent.DQN.DQN - INFO - episode 3 step 191 reward tensor([-1]) loss 0.9063208103179932 epsilon 0.767566125
26-Feb-25 09:39:25 - agent.DQN.DQN - INFO - episode 3 step 192 reward tensor([-1]) loss 7.002394199371338 epsilon 0.767566125
26-Feb-25 09:39:25 - agent.DQN.DQN - INFO - episode 3 step 193 reward tensor([-1]) loss 6.7632622718811035 epsilon 0.767566125
26-Feb-25 09:39:25 - agent.DQN.DQN - INFO - episode 3 step 194 reward tensor([-1]) loss 2.687802791595459 epsilon 0.767566125
26-Feb-25 09:39:25 - agent.DQN.DQN - INFO - episode 3 step 195 reward tensor([-1]) loss 2.9708077907562256 epsilon 0.767566125
26-Feb-25 09:39:25 - agent.DQN.DQN - INFO - episode 3 step 196 reward tensor([-1]) loss 4.84919548034668 epsilon 0.767566125
26-Feb-25 09:39:25 - agent.DQN.DQN - INFO - episode 3 step 197 reward tensor([-1]) loss 1.2441434860229492 epsilon 0.767566125
26-Feb-25 09:39:25 - agent.DQN.DQN - INFO - episode 3 step 198 reward tensor([-1]) loss 1.76450514793396 epsilon 0.767566125
26-Feb-25 09:39:25 - agent.DQN.DQN - INFO - episode 3 step 199 reward tensor([-1]) loss 1.4436297416687012 epsilon 0.767566125
26-Feb-25 09:39:25 - agent.DQN.DQN - INFO - episode 3 step 200 reward tensor([-1]) loss 3.1660637855529785 epsilon 0.767566125
26-Feb-25 09:39:25 - agent.DQN.DQN - INFO - episode 3 step 201 reward tensor([-1]) loss 2.772289752960205 epsilon 0.767566125
26-Feb-25 09:39:25 - agent.DQN.DQN - INFO - episode 3 step 202 reward tensor([-1]) loss 2.5801963806152344 epsilon 0.767566125
26-Feb-25 09:39:25 - agent.DQN.DQN - INFO - episode 3 step 203 reward tensor([-1]) loss 1.1315412521362305 epsilon 0.767566125
26-Feb-25 09:39:25 - agent.DQN.DQN - INFO - episode 3 step 204 reward tensor([-1]) loss 1.2880358695983887 epsilon 0.767566125
26-Feb-25 09:39:25 - agent.DQN.DQN - INFO - episode 3 step 205 reward tensor([-1]) loss 1.0167750120162964 epsilon 0.767566125
26-Feb-25 09:39:25 - agent.DQN.DQN - INFO - episode 3 step 206 reward tensor([-1]) loss 3.353476047515869 epsilon 0.767566125
26-Feb-25 09:39:25 - agent.DQN.DQN - INFO - episode 3 step 207 reward tensor([-1]) loss 6.545945644378662 epsilon 0.767566125
26-Feb-25 09:39:25 - agent.DQN.DQN - INFO - episode 3 step 208 reward tensor([-1]) loss 2.1250340938568115 epsilon 0.767566125
26-Feb-25 09:39:25 - agent.DQN.DQN - INFO - episode 3 step 209 reward tensor([-1]) loss 2.133002281188965 epsilon 0.767566125
26-Feb-25 09:39:25 - agent.DQN.DQN - INFO - episode 3 step 210 reward tensor([-1]) loss 3.2068426609039307 epsilon 0.767566125
26-Feb-25 09:39:25 - agent.DQN.DQN - INFO - episode 3 step 211 reward tensor([-1]) loss 1.2671236991882324 epsilon 0.767566125
26-Feb-25 09:39:25 - agent.DQN.DQN - INFO - episode 3 step 212 reward tensor([-1]) loss 0.9313626885414124 epsilon 0.767566125
26-Feb-25 09:39:25 - agent.DQN.DQN - INFO - episode 3 step 213 reward tensor([-1]) loss 0.8291348218917847 epsilon 0.767566125
26-Feb-25 09:39:25 - agent.DQN.DQN - INFO - episode 3 step 214 reward tensor([-1]) loss 0.9166893362998962 epsilon 0.767566125
26-Feb-25 09:39:25 - agent.DQN.DQN - INFO - episode 3 step 215 reward tensor([-1]) loss 0.8990249633789062 epsilon 0.767566125
26-Feb-25 09:39:25 - agent.DQN.DQN - INFO - episode 3 step 216 reward tensor([-1]) loss 6.9390034675598145 epsilon 0.767566125
26-Feb-25 09:39:25 - agent.DQN.DQN - INFO - episode 3 step 217 reward tensor([-1]) loss 1.241058588027954 epsilon 0.767566125
26-Feb-25 09:39:25 - agent.DQN.DQN - INFO - episode 3 step 218 reward tensor([-1]) loss 1.5633453130722046 epsilon 0.767566125
26-Feb-25 09:39:25 - agent.DQN.DQN - INFO - episode 3 step 219 reward tensor([-1]) loss 1.9239253997802734 epsilon 0.767566125
26-Feb-25 09:39:25 - agent.DQN.DQN - INFO - episode 3 step 220 reward tensor([-1]) loss 1.0100799798965454 epsilon 0.767566125
26-Feb-25 09:39:25 - agent.DQN.DQN - INFO - episode 3 step 221 reward tensor([-1]) loss 2.142375946044922 epsilon 0.767566125
26-Feb-25 09:39:25 - agent.DQN.DQN - INFO - episode 3 step 222 reward tensor([-1]) loss 0.6491974592208862 epsilon 0.767566125
26-Feb-25 09:39:25 - agent.DQN.DQN - INFO - episode 3 step 223 reward tensor([-1]) loss 0.7706934213638306 epsilon 0.767566125
26-Feb-25 09:39:25 - agent.DQN.DQN - INFO - episode 3 step 224 reward tensor([-1]) loss 0.7876001000404358 epsilon 0.767566125
26-Feb-25 09:39:25 - agent.DQN.DQN - INFO - episode 3 step 225 reward tensor([-1]) loss 2.056245803833008 epsilon 0.767566125
26-Feb-25 09:39:25 - agent.DQN.DQN - INFO - episode 3 step 226 reward tensor([-1]) loss 0.8128039836883545 epsilon 0.767566125
26-Feb-25 09:39:25 - agent.DQN.DQN - INFO - episode 3 step 227 reward tensor([-1]) loss 2.0942904949188232 epsilon 0.767566125
26-Feb-25 09:39:25 - agent.DQN.DQN - INFO - episode 3 step 228 reward tensor([-1]) loss 0.5638369917869568 epsilon 0.767566125
26-Feb-25 09:39:25 - agent.DQN.DQN - INFO - episode 3 step 229 reward tensor([-1]) loss 0.6029500961303711 epsilon 0.767566125
26-Feb-25 09:39:25 - agent.DQN.DQN - INFO - episode 3 step 230 reward tensor([-1]) loss 5.506702899932861 epsilon 0.767566125
26-Feb-25 09:39:25 - agent.DQN.DQN - INFO - episode 3 step 231 reward tensor([-1]) loss 0.5622178912162781 epsilon 0.767566125
26-Feb-25 09:39:25 - agent.DQN.DQN - INFO - episode 3 step 232 reward tensor([-1]) loss 5.189792633056641 epsilon 0.767566125
26-Feb-25 09:39:25 - agent.DQN.DQN - INFO - episode 3 step 233 reward tensor([-1]) loss 0.6641259789466858 epsilon 0.767566125
26-Feb-25 09:39:25 - agent.DQN.DQN - INFO - episode 3 step 234 reward tensor([-1]) loss 1.9441168308258057 epsilon 0.767566125
26-Feb-25 09:39:25 - agent.DQN.DQN - INFO - episode 3 step 235 reward tensor([-1]) loss 2.0368916988372803 epsilon 0.767566125
26-Feb-25 09:39:25 - agent.DQN.DQN - INFO - episode 3 step 236 reward tensor([-1]) loss 2.401501178741455 epsilon 0.767566125
26-Feb-25 09:39:25 - agent.DQN.DQN - INFO - episode 3 step 237 reward tensor([-1]) loss 2.101651906967163 epsilon 0.767566125
26-Feb-25 09:39:25 - agent.DQN.DQN - INFO - episode 3 step 238 reward tensor([-1]) loss 2.145740032196045 epsilon 0.767566125
26-Feb-25 09:39:25 - agent.DQN.DQN - INFO - episode 3 step 239 reward tensor([-1]) loss 2.313899517059326 epsilon 0.767566125
26-Feb-25 09:39:25 - agent.DQN.DQN - INFO - episode 3 step 240 reward tensor([-1]) loss 1.657895565032959 epsilon 0.767566125
26-Feb-25 09:39:25 - agent.DQN.DQN - INFO - episode 3 step 241 reward tensor([-1]) loss 1.5923043489456177 epsilon 0.767566125
26-Feb-25 09:39:25 - agent.DQN.DQN - INFO - episode 3 step 242 reward tensor([-1]) loss 0.9803621768951416 epsilon 0.767566125
26-Feb-25 09:39:25 - agent.DQN.DQN - INFO - episode 3 step 243 reward tensor([-1]) loss 5.843906402587891 epsilon 0.767566125
26-Feb-25 09:39:25 - agent.DQN.DQN - INFO - episode 3 step 244 reward tensor([-1]) loss 0.714680552482605 epsilon 0.767566125
26-Feb-25 09:39:25 - agent.DQN.DQN - INFO - episode 3 step 245 reward tensor([-1]) loss 1.7670624256134033 epsilon 0.767566125
26-Feb-25 09:39:25 - agent.DQN.DQN - INFO - episode 3 step 246 reward tensor([-1]) loss 1.550700068473816 epsilon 0.767566125
26-Feb-25 09:39:25 - agent.DQN.DQN - INFO - episode 3 step 247 reward tensor([-1]) loss 0.8688803911209106 epsilon 0.767566125
26-Feb-25 09:39:25 - agent.DQN.DQN - INFO - episode 3 step 248 reward tensor([-1]) loss 5.53682804107666 epsilon 0.767566125
26-Feb-25 09:39:25 - agent.DQN.DQN - INFO - episode 3 step 249 reward tensor([-1]) loss 0.8657715320587158 epsilon 0.767566125
26-Feb-25 09:39:25 - agent.DQN.DQN - INFO - episode 3 step 250 reward tensor([-1]) loss 1.021403431892395 epsilon 0.767566125
26-Feb-25 09:39:25 - agent.DQN.DQN - INFO - episode 3 step 251 reward tensor([-1]) loss 1.1563535928726196 epsilon 0.767566125
26-Feb-25 09:39:25 - agent.DQN.DQN - INFO - episode 3 step 252 reward tensor([-1]) loss 0.7370818853378296 epsilon 0.767566125
26-Feb-25 09:39:25 - agent.DQN.DQN - INFO - episode 3 step 253 reward tensor([-1]) loss 1.1032828092575073 epsilon 0.767566125
26-Feb-25 09:39:25 - agent.DQN.DQN - INFO - episode 3 step 254 reward tensor([-1]) loss 0.8418891429901123 epsilon 0.767566125
26-Feb-25 09:39:25 - agent.DQN.DQN - INFO - episode 3 step 255 reward tensor([-1]) loss 0.7106634378433228 epsilon 0.767566125
26-Feb-25 09:39:25 - agent.DQN.DQN - INFO - episode 3 step 256 reward tensor([-1]) loss 0.7110934853553772 epsilon 0.767566125
26-Feb-25 09:39:25 - agent.DQN.DQN - INFO - episode 3 step 257 reward tensor([-1]) loss 0.656336784362793 epsilon 0.767566125
26-Feb-25 09:39:25 - agent.DQN.DQN - INFO - episode 3 step 258 reward tensor([-1]) loss 1.7309609651565552 epsilon 0.767566125
26-Feb-25 09:39:25 - agent.DQN.DQN - INFO - episode 3 step 259 reward tensor([-1]) loss 1.8728368282318115 epsilon 0.767566125
26-Feb-25 09:39:25 - agent.DQN.DQN - INFO - episode 3 step 260 reward tensor([-1]) loss 4.336150169372559 epsilon 0.767566125
26-Feb-25 09:39:25 - agent.DQN.DQN - INFO - episode 3 step 261 reward tensor([-1]) loss 0.6931126713752747 epsilon 0.767566125
26-Feb-25 09:39:25 - agent.DQN.DQN - INFO - episode 3 step 262 reward tensor([-1]) loss 0.6207482814788818 epsilon 0.767566125
26-Feb-25 09:39:25 - agent.DQN.DQN - INFO - episode 3 step 263 reward tensor([-1]) loss 1.7437056303024292 epsilon 0.767566125
26-Feb-25 09:39:25 - agent.DQN.DQN - INFO - episode 3 step 264 reward tensor([-1]) loss 0.7409558296203613 epsilon 0.767566125
26-Feb-25 09:39:25 - agent.DQN.DQN - INFO - episode 3 step 265 reward tensor([-1]) loss 0.5754416584968567 epsilon 0.767566125
26-Feb-25 09:39:25 - agent.DQN.DQN - INFO - episode 3 step 266 reward tensor([-1]) loss 4.487540245056152 epsilon 0.767566125
26-Feb-25 09:39:25 - agent.DQN.DQN - INFO - episode 3 step 267 reward tensor([-1]) loss 2.3821420669555664 epsilon 0.767566125
26-Feb-25 09:39:25 - agent.DQN.DQN - INFO - episode 3 step 268 reward tensor([-1]) loss 1.5073180198669434 epsilon 0.767566125
26-Feb-25 09:39:25 - agent.DQN.DQN - INFO - episode 3 step 269 reward tensor([-1]) loss 1.2734863758087158 epsilon 0.767566125
26-Feb-25 09:39:25 - agent.DQN.DQN - INFO - episode 3 step 270 reward tensor([-1]) loss 1.1329127550125122 epsilon 0.767566125
26-Feb-25 09:39:25 - agent.DQN.DQN - INFO - episode 3 step 271 reward tensor([-1]) loss 0.8766009211540222 epsilon 0.767566125
26-Feb-25 09:39:25 - agent.DQN.DQN - INFO - episode 3 step 272 reward tensor([-1]) loss 0.9419933557510376 epsilon 0.767566125
26-Feb-25 09:39:25 - agent.DQN.DQN - INFO - episode 3 step 273 reward tensor([-1]) loss 1.5351049900054932 epsilon 0.767566125
26-Feb-25 09:39:26 - agent.DQN.DQN - INFO - episode 3 step 274 reward tensor([-1]) loss 0.630100429058075 epsilon 0.767566125
26-Feb-25 09:39:26 - agent.DQN.DQN - INFO - episode 3 step 275 reward tensor([-1]) loss 4.433747291564941 epsilon 0.767566125
26-Feb-25 09:39:26 - agent.DQN.DQN - INFO - episode 3 step 276 reward tensor([-1]) loss 0.5909339785575867 epsilon 0.767566125
26-Feb-25 09:39:26 - agent.DQN.DQN - INFO - episode 3 step 277 reward tensor([-1]) loss 0.6062750220298767 epsilon 0.767566125
26-Feb-25 09:39:26 - agent.DQN.DQN - INFO - episode 3 step 278 reward tensor([-1]) loss 0.7315447926521301 epsilon 0.767566125
26-Feb-25 09:39:26 - agent.DQN.DQN - INFO - episode 3 step 279 reward tensor([-1]) loss 0.7648712396621704 epsilon 0.767566125
26-Feb-25 09:39:26 - agent.DQN.DQN - INFO - episode 3 step 280 reward tensor([-1]) loss 2.3790199756622314 epsilon 0.767566125
26-Feb-25 09:39:26 - agent.DQN.DQN - INFO - episode 3 step 281 reward tensor([-1]) loss 4.0073981285095215 epsilon 0.767566125
26-Feb-25 09:39:26 - agent.DQN.DQN - INFO - episode 3 step 282 reward tensor([-1]) loss 0.7269624471664429 epsilon 0.767566125
26-Feb-25 09:39:26 - agent.DQN.DQN - INFO - episode 3 step 283 reward tensor([-1]) loss 3.923114061355591 epsilon 0.767566125
26-Feb-25 09:39:26 - agent.DQN.DQN - INFO - episode 3 step 284 reward tensor([-1]) loss 0.6945639848709106 epsilon 0.767566125
26-Feb-25 09:39:26 - agent.DQN.DQN - INFO - episode 3 step 285 reward tensor([-1]) loss 0.5964592695236206 epsilon 0.767566125
26-Feb-25 09:39:26 - agent.DQN.DQN - INFO - episode 3 step 286 reward tensor([-1]) loss 0.4469420313835144 epsilon 0.767566125
26-Feb-25 09:39:26 - agent.DQN.DQN - INFO - episode 3 step 287 reward tensor([-1]) loss 2.0277459621429443 epsilon 0.767566125
26-Feb-25 09:39:26 - agent.DQN.DQN - INFO - episode 3 step 288 reward tensor([-1]) loss 0.6364907026290894 epsilon 0.767566125
26-Feb-25 09:39:26 - agent.DQN.DQN - INFO - episode 3 step 289 reward tensor([-1]) loss 1.5590239763259888 epsilon 0.767566125
26-Feb-25 09:39:26 - agent.DQN.DQN - INFO - episode 3 step 290 reward tensor([-1]) loss 1.4289352893829346 epsilon 0.767566125
26-Feb-25 09:39:26 - agent.DQN.DQN - INFO - episode 3 step 291 reward tensor([-1]) loss 1.8893883228302002 epsilon 0.767566125
26-Feb-25 09:39:26 - agent.DQN.DQN - INFO - episode 3 step 292 reward tensor([-1]) loss 1.782580852508545 epsilon 0.767566125
26-Feb-25 09:39:26 - agent.DQN.DQN - INFO - episode 3 step 293 reward tensor([-1]) loss 1.731353521347046 epsilon 0.767566125
26-Feb-25 09:39:26 - agent.DQN.DQN - INFO - episode 3 step 294 reward tensor([-1]) loss 0.6116077899932861 epsilon 0.767566125
26-Feb-25 09:39:26 - agent.DQN.DQN - INFO - episode 3 step 295 reward tensor([-1]) loss 3.6761133670806885 epsilon 0.767566125
26-Feb-25 09:39:26 - agent.DQN.DQN - INFO - episode 3 step 296 reward tensor([-1]) loss 0.46554863452911377 epsilon 0.767566125
26-Feb-25 09:39:26 - agent.DQN.DQN - INFO - episode 3 step 297 reward tensor([-1]) loss 2.198211431503296 epsilon 0.767566125
26-Feb-25 09:39:26 - agent.DQN.DQN - INFO - episode 3 step 298 reward tensor([-1]) loss 1.0972158908843994 epsilon 0.767566125
26-Feb-25 09:39:26 - agent.DQN.DQN - INFO - episode 3 step 299 reward tensor([-1]) loss 1.0547434091567993 epsilon 0.767566125
26-Feb-25 09:39:26 - agent.DQN.DQN - INFO - episode 3 step 300 reward tensor([-1]) loss 4.576556205749512 epsilon 0.767566125
26-Feb-25 09:39:26 - agent.DQN.DQN - INFO - episode 3 step 301 reward tensor([-1]) loss 4.901639461517334 epsilon 0.767566125
26-Feb-25 09:39:26 - agent.DQN.DQN - INFO - episode 4 step 0 reward tensor([-1]) loss 0.7789863348007202 epsilon 0.7426202259375
26-Feb-25 09:39:26 - agent.DQN.DQN - INFO - episode 4 step 1 reward tensor([-1]) loss 0.80585777759552 epsilon 0.7426202259375
26-Feb-25 09:39:26 - agent.DQN.DQN - INFO - episode 4 step 2 reward tensor([-1]) loss 0.6819459795951843 epsilon 0.7426202259375
26-Feb-25 09:39:26 - agent.DQN.DQN - INFO - episode 4 step 3 reward tensor([-1]) loss 0.6726678609848022 epsilon 0.7426202259375
26-Feb-25 09:39:26 - agent.DQN.DQN - INFO - episode 4 step 4 reward tensor([-1]) loss 1.4974228143692017 epsilon 0.7426202259375
26-Feb-25 09:39:26 - agent.DQN.DQN - INFO - episode 4 step 5 reward tensor([-1]) loss 3.135262966156006 epsilon 0.7426202259375
26-Feb-25 09:39:26 - agent.DQN.DQN - INFO - episode 4 step 6 reward tensor([-1]) loss 0.7819706201553345 epsilon 0.7426202259375
26-Feb-25 09:39:26 - agent.DQN.DQN - INFO - episode 4 step 7 reward tensor([-1]) loss 0.6993070840835571 epsilon 0.7426202259375
26-Feb-25 09:39:26 - agent.DQN.DQN - INFO - episode 4 step 8 reward tensor([-1]) loss 1.1530756950378418 epsilon 0.7426202259375
26-Feb-25 09:39:26 - agent.DQN.DQN - INFO - episode 4 step 9 reward tensor([-1]) loss 1.695136547088623 epsilon 0.7426202259375
26-Feb-25 09:39:26 - agent.DQN.DQN - INFO - episode 4 step 10 reward tensor([-1]) loss 1.215017557144165 epsilon 0.7426202259375
26-Feb-25 09:39:26 - agent.DQN.DQN - INFO - episode 4 step 11 reward tensor([-1]) loss 0.6350534558296204 epsilon 0.7426202259375
26-Feb-25 09:39:26 - agent.DQN.DQN - INFO - episode 4 step 12 reward tensor([-1]) loss 1.1428767442703247 epsilon 0.7426202259375
26-Feb-25 09:39:26 - agent.DQN.DQN - INFO - episode 4 step 13 reward tensor([-1]) loss 1.625728726387024 epsilon 0.7426202259375
26-Feb-25 09:39:26 - agent.DQN.DQN - INFO - episode 4 step 14 reward tensor([-1]) loss 2.742602825164795 epsilon 0.7426202259375
26-Feb-25 09:39:26 - agent.DQN.DQN - INFO - episode 4 step 15 reward tensor([-1]) loss 0.919365644454956 epsilon 0.7426202259375
26-Feb-25 09:39:26 - agent.DQN.DQN - INFO - episode 4 step 16 reward tensor([-1]) loss 0.5507161021232605 epsilon 0.7426202259375
26-Feb-25 09:39:26 - agent.DQN.DQN - INFO - episode 4 step 17 reward tensor([-1]) loss 0.7033319473266602 epsilon 0.7426202259375
26-Feb-25 09:39:26 - agent.DQN.DQN - INFO - episode 4 step 18 reward tensor([-1]) loss 0.9191062450408936 epsilon 0.7426202259375
26-Feb-25 09:39:26 - agent.DQN.DQN - INFO - episode 4 step 19 reward tensor([-1]) loss 3.440365791320801 epsilon 0.7426202259375
26-Feb-25 09:39:26 - agent.DQN.DQN - INFO - episode 4 step 20 reward tensor([-1]) loss 0.5333632826805115 epsilon 0.7426202259375
26-Feb-25 09:39:26 - agent.DQN.DQN - INFO - episode 4 step 21 reward tensor([-1]) loss 0.741146445274353 epsilon 0.7426202259375
26-Feb-25 09:39:26 - agent.DQN.DQN - INFO - episode 4 step 22 reward tensor([-1]) loss 0.6527248620986938 epsilon 0.7426202259375
26-Feb-25 09:39:26 - agent.DQN.DQN - INFO - episode 4 step 23 reward tensor([-1]) loss 0.29419779777526855 epsilon 0.7426202259375
26-Feb-25 09:39:26 - agent.DQN.DQN - INFO - episode 4 step 24 reward tensor([-1]) loss 0.6101711988449097 epsilon 0.7426202259375
26-Feb-25 09:39:26 - agent.DQN.DQN - INFO - episode 4 step 25 reward tensor([-1]) loss 3.6854565143585205 epsilon 0.7426202259375
26-Feb-25 09:39:26 - agent.DQN.DQN - INFO - episode 4 step 26 reward tensor([-1]) loss 1.5367107391357422 epsilon 0.7426202259375
26-Feb-25 09:39:26 - agent.DQN.DQN - INFO - episode 4 step 27 reward tensor([-1]) loss 1.3150849342346191 epsilon 0.7426202259375
26-Feb-25 09:39:26 - agent.DQN.DQN - INFO - episode 4 step 28 reward tensor([-1]) loss 1.6884297132492065 epsilon 0.7426202259375
26-Feb-25 09:39:26 - agent.DQN.DQN - INFO - episode 4 step 29 reward tensor([-1]) loss 1.4860485792160034 epsilon 0.7426202259375
26-Feb-25 09:39:26 - agent.DQN.DQN - INFO - episode 4 step 30 reward tensor([-1]) loss 0.7873497605323792 epsilon 0.7426202259375
26-Feb-25 09:39:26 - agent.DQN.DQN - INFO - episode 4 step 31 reward tensor([-1]) loss 0.9151583313941956 epsilon 0.7426202259375
26-Feb-25 09:39:26 - agent.DQN.DQN - INFO - episode 4 step 32 reward tensor([-1]) loss 1.6021896600723267 epsilon 0.7426202259375
26-Feb-25 09:39:26 - agent.DQN.DQN - INFO - episode 4 step 33 reward tensor([-1]) loss 0.759610652923584 epsilon 0.7426202259375
26-Feb-25 09:39:26 - agent.DQN.DQN - INFO - episode 4 step 34 reward tensor([-1]) loss 1.2063161134719849 epsilon 0.7426202259375
26-Feb-25 09:39:26 - agent.DQN.DQN - INFO - episode 4 step 35 reward tensor([-1]) loss 0.5115213990211487 epsilon 0.7426202259375
26-Feb-25 09:39:26 - agent.DQN.DQN - INFO - episode 4 step 36 reward tensor([-1]) loss 0.8984489440917969 epsilon 0.7426202259375
26-Feb-25 09:39:26 - agent.DQN.DQN - INFO - episode 4 step 37 reward tensor([-1]) loss 2.998868942260742 epsilon 0.7426202259375
26-Feb-25 09:39:26 - agent.DQN.DQN - INFO - episode 4 step 38 reward tensor([-1]) loss 0.6956943273544312 epsilon 0.7426202259375
26-Feb-25 09:39:26 - agent.DQN.DQN - INFO - episode 4 step 39 reward tensor([-1]) loss 1.1471683979034424 epsilon 0.7426202259375
26-Feb-25 09:39:26 - agent.DQN.DQN - INFO - episode 4 step 40 reward tensor([-1]) loss 0.5529632568359375 epsilon 0.7426202259375
26-Feb-25 09:39:26 - agent.DQN.DQN - INFO - episode 4 step 41 reward tensor([-1]) loss 0.665397047996521 epsilon 0.7426202259375
26-Feb-25 09:39:26 - agent.DQN.DQN - INFO - episode 4 step 42 reward tensor([-1]) loss 0.6679829359054565 epsilon 0.7426202259375
26-Feb-25 09:39:26 - agent.DQN.DQN - INFO - episode 4 step 43 reward tensor([-1]) loss 1.291439175605774 epsilon 0.7426202259375
26-Feb-25 09:39:26 - agent.DQN.DQN - INFO - episode 4 step 44 reward tensor([-1]) loss 0.7884961366653442 epsilon 0.7426202259375
26-Feb-25 09:39:26 - agent.DQN.DQN - INFO - episode 4 step 45 reward tensor([-1]) loss 1.0890202522277832 epsilon 0.7426202259375
26-Feb-25 09:39:26 - agent.DQN.DQN - INFO - episode 4 step 46 reward tensor([-1]) loss 1.1150509119033813 epsilon 0.7426202259375
26-Feb-25 09:39:27 - agent.DQN.DQN - INFO - episode 4 step 47 reward tensor([-1]) loss 0.6120489835739136 epsilon 0.7426202259375
26-Feb-25 09:39:27 - agent.DQN.DQN - INFO - episode 4 step 48 reward tensor([-1]) loss 0.8800215125083923 epsilon 0.7426202259375
26-Feb-25 09:39:27 - agent.DQN.DQN - INFO - episode 4 step 49 reward tensor([-1]) loss 2.225598096847534 epsilon 0.7426202259375
26-Feb-25 09:39:27 - agent.DQN.DQN - INFO - episode 4 step 50 reward tensor([-1]) loss 1.1842615604400635 epsilon 0.7426202259375
26-Feb-25 09:39:27 - agent.DQN.DQN - INFO - episode 4 step 51 reward tensor([-1]) loss 0.5781023502349854 epsilon 0.7426202259375
26-Feb-25 09:39:27 - agent.DQN.DQN - INFO - episode 4 step 52 reward tensor([-1]) loss 0.9735601544380188 epsilon 0.7426202259375
26-Feb-25 09:39:27 - agent.DQN.DQN - INFO - episode 4 step 53 reward tensor([-1]) loss 0.5450948476791382 epsilon 0.7426202259375
26-Feb-25 09:39:27 - agent.DQN.DQN - INFO - episode 4 step 54 reward tensor([-1]) loss 0.711410641670227 epsilon 0.7426202259375
26-Feb-25 09:39:27 - agent.DQN.DQN - INFO - episode 4 step 55 reward tensor([-1]) loss 1.2473711967468262 epsilon 0.7426202259375
26-Feb-25 09:39:27 - agent.DQN.DQN - INFO - episode 4 step 56 reward tensor([-1]) loss 1.1254491806030273 epsilon 0.7426202259375
26-Feb-25 09:39:27 - agent.DQN.DQN - INFO - episode 4 step 57 reward tensor([-1]) loss 1.3862507343292236 epsilon 0.7426202259375
26-Feb-25 09:39:27 - agent.DQN.DQN - INFO - episode 4 step 58 reward tensor([-1]) loss 0.7960761785507202 epsilon 0.7426202259375
26-Feb-25 09:39:27 - agent.DQN.DQN - INFO - episode 4 step 59 reward tensor([-1]) loss 1.2288299798965454 epsilon 0.7426202259375
26-Feb-25 09:39:27 - agent.DQN.DQN - INFO - episode 4 step 60 reward tensor([-1]) loss 1.0208449363708496 epsilon 0.7426202259375
26-Feb-25 09:39:27 - agent.DQN.DQN - INFO - episode 4 step 61 reward tensor([-1]) loss 0.9998288154602051 epsilon 0.7426202259375
26-Feb-25 09:39:27 - agent.DQN.DQN - INFO - episode 4 step 62 reward tensor([-1]) loss 0.7093062996864319 epsilon 0.7426202259375
26-Feb-25 09:39:27 - agent.DQN.DQN - INFO - episode 4 step 63 reward tensor([-1]) loss 0.555286169052124 epsilon 0.7426202259375
26-Feb-25 09:39:27 - agent.DQN.DQN - INFO - episode 4 step 64 reward tensor([-1]) loss 0.7984849810600281 epsilon 0.7426202259375
26-Feb-25 09:39:27 - agent.DQN.DQN - INFO - episode 4 step 65 reward tensor([-1]) loss 0.5903716087341309 epsilon 0.7426202259375
26-Feb-25 09:39:27 - agent.DQN.DQN - INFO - episode 4 step 66 reward tensor([-1]) loss 0.816274881362915 epsilon 0.7426202259375
26-Feb-25 09:39:27 - agent.DQN.DQN - INFO - episode 4 step 67 reward tensor([-1]) loss 2.4627065658569336 epsilon 0.7426202259375
26-Feb-25 09:39:27 - agent.DQN.DQN - INFO - episode 4 step 68 reward tensor([-1]) loss 0.8455634117126465 epsilon 0.7426202259375
26-Feb-25 09:39:27 - agent.DQN.DQN - INFO - episode 4 step 69 reward tensor([-1]) loss 0.6297825574874878 epsilon 0.7426202259375
26-Feb-25 09:39:27 - agent.DQN.DQN - INFO - episode 4 step 70 reward tensor([-1]) loss 1.7352486848831177 epsilon 0.7426202259375
26-Feb-25 09:39:27 - agent.DQN.DQN - INFO - episode 4 step 71 reward tensor([-1]) loss 1.3236644268035889 epsilon 0.7426202259375
26-Feb-25 09:39:27 - agent.DQN.DQN - INFO - episode 4 step 72 reward tensor([-1]) loss 0.7775864601135254 epsilon 0.7426202259375
26-Feb-25 09:39:27 - agent.DQN.DQN - INFO - episode 4 step 73 reward tensor([-1]) loss 0.5700099468231201 epsilon 0.7426202259375
26-Feb-25 09:39:27 - agent.DQN.DQN - INFO - episode 4 step 74 reward tensor([-1]) loss 0.4587978720664978 epsilon 0.7426202259375
26-Feb-25 09:39:27 - agent.DQN.DQN - INFO - episode 4 step 75 reward tensor([-1]) loss 1.7300282716751099 epsilon 0.7426202259375
26-Feb-25 09:39:27 - agent.DQN.DQN - INFO - episode 4 step 76 reward tensor([-1]) loss 0.5982398390769958 epsilon 0.7426202259375
26-Feb-25 09:39:27 - agent.DQN.DQN - INFO - episode 4 step 77 reward tensor([-1]) loss 0.6814164519309998 epsilon 0.7426202259375
26-Feb-25 09:39:27 - agent.DQN.DQN - INFO - episode 4 step 78 reward tensor([-1]) loss 0.5413549542427063 epsilon 0.7426202259375
26-Feb-25 09:39:27 - agent.DQN.DQN - INFO - episode 4 step 79 reward tensor([-1]) loss 0.4706183969974518 epsilon 0.7426202259375
26-Feb-25 09:39:27 - agent.DQN.DQN - INFO - episode 4 step 80 reward tensor([-1]) loss 0.44748014211654663 epsilon 0.7426202259375
26-Feb-25 09:39:27 - agent.DQN.DQN - INFO - episode 4 step 81 reward tensor([-1]) loss 1.5705503225326538 epsilon 0.7426202259375
26-Feb-25 09:39:27 - agent.DQN.DQN - INFO - episode 4 step 82 reward tensor([-1]) loss 1.9926148653030396 epsilon 0.7426202259375
26-Feb-25 09:39:27 - agent.DQN.DQN - INFO - episode 4 step 83 reward tensor([-1]) loss 0.4823122024536133 epsilon 0.7426202259375
26-Feb-25 09:39:27 - agent.DQN.DQN - INFO - episode 4 step 84 reward tensor([-1]) loss 0.4169378876686096 epsilon 0.7426202259375
26-Feb-25 09:39:27 - agent.DQN.DQN - INFO - episode 4 step 85 reward tensor([-1]) loss 1.4278733730316162 epsilon 0.7426202259375
26-Feb-25 09:39:27 - agent.DQN.DQN - INFO - episode 4 step 86 reward tensor([-1]) loss 2.5442099571228027 epsilon 0.7426202259375
26-Feb-25 09:39:27 - agent.DQN.DQN - INFO - episode 4 step 87 reward tensor([-1]) loss 0.9810978174209595 epsilon 0.7426202259375
26-Feb-25 09:39:27 - agent.DQN.DQN - INFO - episode 4 step 88 reward tensor([-1]) loss 1.3584654331207275 epsilon 0.7426202259375
26-Feb-25 09:39:27 - agent.DQN.DQN - INFO - episode 4 step 89 reward tensor([-1]) loss 0.7035006284713745 epsilon 0.7426202259375
26-Feb-25 09:39:27 - agent.DQN.DQN - INFO - episode 4 step 90 reward tensor([-1]) loss 0.8937998414039612 epsilon 0.7426202259375
26-Feb-25 09:39:27 - agent.DQN.DQN - INFO - episode 4 step 91 reward tensor([-1]) loss 0.687057614326477 epsilon 0.7426202259375
26-Feb-25 09:39:27 - agent.DQN.DQN - INFO - episode 4 step 92 reward tensor([-1]) loss 0.5365333557128906 epsilon 0.7426202259375
26-Feb-25 09:39:27 - agent.DQN.DQN - INFO - episode 4 step 93 reward tensor([-1]) loss 1.6252533197402954 epsilon 0.7426202259375
26-Feb-25 09:39:27 - agent.DQN.DQN - INFO - episode 4 step 94 reward tensor([-1]) loss 1.0567420721054077 epsilon 0.7426202259375
26-Feb-25 09:39:27 - agent.DQN.DQN - INFO - episode 4 step 95 reward tensor([-1]) loss 0.760573148727417 epsilon 0.7426202259375
26-Feb-25 09:39:27 - agent.DQN.DQN - INFO - episode 4 step 96 reward tensor([-1]) loss 0.6309192180633545 epsilon 0.7426202259375
26-Feb-25 09:39:27 - agent.DQN.DQN - INFO - episode 4 step 97 reward tensor([-1]) loss 1.4519603252410889 epsilon 0.7426202259375
26-Feb-25 09:39:27 - agent.DQN.DQN - INFO - episode 4 step 98 reward tensor([-1]) loss 0.6937146186828613 epsilon 0.7426202259375
26-Feb-25 09:39:27 - agent.DQN.DQN - INFO - episode 4 step 99 reward tensor([-1]) loss 1.1136302947998047 epsilon 0.7426202259375
26-Feb-25 09:39:27 - agent.DQN.DQN - INFO - episode 4 step 100 reward tensor([-1]) loss 0.8966902494430542 epsilon 0.7426202259375
26-Feb-25 09:39:27 - agent.DQN.DQN - INFO - episode 4 step 101 reward tensor([-1]) loss 0.5704724192619324 epsilon 0.7426202259375
26-Feb-25 09:39:27 - agent.DQN.DQN - INFO - episode 4 step 102 reward tensor([-1]) loss 1.1111259460449219 epsilon 0.7426202259375
26-Feb-25 09:39:27 - agent.DQN.DQN - INFO - episode 4 step 103 reward tensor([-1]) loss 0.7485796213150024 epsilon 0.7426202259375
26-Feb-25 09:39:27 - agent.DQN.DQN - INFO - episode 4 step 104 reward tensor([-1]) loss 0.9790302515029907 epsilon 0.7426202259375
26-Feb-25 09:39:27 - agent.DQN.DQN - INFO - episode 4 step 105 reward tensor([-1]) loss 0.9443585276603699 epsilon 0.7426202259375
26-Feb-25 09:39:27 - agent.DQN.DQN - INFO - episode 4 step 106 reward tensor([-1]) loss 0.5142899751663208 epsilon 0.7426202259375
26-Feb-25 09:39:27 - agent.DQN.DQN - INFO - episode 4 step 107 reward tensor([-1]) loss 0.46577876806259155 epsilon 0.7426202259375
26-Feb-25 09:39:27 - agent.DQN.DQN - INFO - episode 4 step 108 reward tensor([-1]) loss 1.720369815826416 epsilon 0.7426202259375
26-Feb-25 09:39:27 - agent.DQN.DQN - INFO - episode 4 step 109 reward tensor([-1]) loss 1.7650649547576904 epsilon 0.7426202259375
26-Feb-25 09:39:27 - agent.DQN.DQN - INFO - episode 4 step 110 reward tensor([-1]) loss 0.5494092702865601 epsilon 0.7426202259375
26-Feb-25 09:39:27 - agent.DQN.DQN - INFO - episode 4 step 111 reward tensor([-1]) loss 0.6080958247184753 epsilon 0.7426202259375
26-Feb-25 09:39:27 - agent.DQN.DQN - INFO - episode 4 step 112 reward tensor([-1]) loss 0.6739221215248108 epsilon 0.7426202259375
26-Feb-25 09:39:27 - agent.DQN.DQN - INFO - episode 4 step 113 reward tensor([-1]) loss 0.9238306283950806 epsilon 0.7426202259375
26-Feb-25 09:39:27 - agent.DQN.DQN - INFO - episode 4 step 114 reward tensor([-1]) loss 1.8748300075531006 epsilon 0.7426202259375
26-Feb-25 09:39:27 - agent.DQN.DQN - INFO - episode 4 step 115 reward tensor([-1]) loss 1.289057731628418 epsilon 0.7426202259375
26-Feb-25 09:39:27 - agent.DQN.DQN - INFO - episode 4 step 116 reward tensor([-1]) loss 1.3753435611724854 epsilon 0.7426202259375
26-Feb-25 09:39:27 - agent.DQN.DQN - INFO - episode 4 step 117 reward tensor([-1]) loss 1.9572596549987793 epsilon 0.7426202259375
26-Feb-25 09:39:27 - agent.DQN.DQN - INFO - episode 4 step 118 reward tensor([-1]) loss 1.046756625175476 epsilon 0.7426202259375
26-Feb-25 09:39:27 - agent.DQN.DQN - INFO - episode 4 step 119 reward tensor([-1]) loss 0.8773893713951111 epsilon 0.7426202259375
26-Feb-25 09:39:27 - agent.DQN.DQN - INFO - episode 4 step 120 reward tensor([-1]) loss 0.7760889530181885 epsilon 0.7426202259375
26-Feb-25 09:39:27 - agent.DQN.DQN - INFO - episode 4 step 121 reward tensor([-1]) loss 0.6161835193634033 epsilon 0.7426202259375
26-Feb-25 09:39:27 - agent.DQN.DQN - INFO - episode 4 step 122 reward tensor([-1]) loss 0.9451602101325989 epsilon 0.7426202259375
26-Feb-25 09:39:27 - agent.DQN.DQN - INFO - episode 4 step 123 reward tensor([-1]) loss 0.6726287007331848 epsilon 0.7426202259375
26-Feb-25 09:39:27 - agent.DQN.DQN - INFO - episode 4 step 124 reward tensor([-1]) loss 1.368013858795166 epsilon 0.7426202259375
26-Feb-25 09:39:28 - agent.DQN.DQN - INFO - episode 4 step 125 reward tensor([-1]) loss 1.236132264137268 epsilon 0.7426202259375
26-Feb-25 09:39:28 - agent.DQN.DQN - INFO - episode 4 step 126 reward tensor([-1]) loss 1.5390729904174805 epsilon 0.7426202259375
26-Feb-25 09:39:28 - agent.DQN.DQN - INFO - episode 4 step 127 reward tensor([-1]) loss 0.9187411665916443 epsilon 0.7426202259375
26-Feb-25 09:39:28 - agent.DQN.DQN - INFO - episode 4 step 128 reward tensor([-1]) loss 0.6068508625030518 epsilon 0.7426202259375
26-Feb-25 09:39:28 - agent.DQN.DQN - INFO - episode 4 step 129 reward tensor([-1]) loss 0.7530847191810608 epsilon 0.7426202259375
26-Feb-25 09:39:28 - agent.DQN.DQN - INFO - episode 4 step 130 reward tensor([-1]) loss 0.6717773675918579 epsilon 0.7426202259375
26-Feb-25 09:39:28 - agent.DQN.DQN - INFO - episode 4 step 131 reward tensor([-1]) loss 1.9401726722717285 epsilon 0.7426202259375
26-Feb-25 09:39:28 - agent.DQN.DQN - INFO - episode 4 step 132 reward tensor([-1]) loss 1.3009291887283325 epsilon 0.7426202259375
26-Feb-25 09:39:28 - agent.DQN.DQN - INFO - episode 4 step 133 reward tensor([-1]) loss 0.8781806230545044 epsilon 0.7426202259375
26-Feb-25 09:39:28 - agent.DQN.DQN - INFO - episode 4 step 134 reward tensor([-1]) loss 0.5648007988929749 epsilon 0.7426202259375
26-Feb-25 09:39:28 - agent.DQN.DQN - INFO - episode 4 step 135 reward tensor([-1]) loss 1.7709527015686035 epsilon 0.7426202259375
26-Feb-25 09:39:28 - agent.DQN.DQN - INFO - episode 4 step 136 reward tensor([-1]) loss 0.7848196625709534 epsilon 0.7426202259375
26-Feb-25 09:39:28 - agent.DQN.DQN - INFO - episode 4 step 137 reward tensor([-1]) loss 0.5050124526023865 epsilon 0.7426202259375
26-Feb-25 09:39:28 - agent.DQN.DQN - INFO - episode 4 step 138 reward tensor([-1]) loss 0.6448118090629578 epsilon 0.7426202259375
26-Feb-25 09:39:28 - agent.DQN.DQN - INFO - episode 4 step 139 reward tensor([-1]) loss 0.5442774891853333 epsilon 0.7426202259375
26-Feb-25 09:39:28 - agent.DQN.DQN - INFO - episode 4 step 140 reward tensor([-1]) loss 1.2605897188186646 epsilon 0.7426202259375
26-Feb-25 09:39:28 - agent.DQN.DQN - INFO - episode 4 step 141 reward tensor([-1]) loss 0.6756038069725037 epsilon 0.7426202259375
26-Feb-25 09:39:28 - agent.DQN.DQN - INFO - episode 4 step 142 reward tensor([-1]) loss 0.7206748723983765 epsilon 0.7426202259375
26-Feb-25 09:39:28 - agent.DQN.DQN - INFO - episode 4 step 143 reward tensor([-1]) loss 0.597328245639801 epsilon 0.7426202259375
26-Feb-25 09:39:28 - agent.DQN.DQN - INFO - episode 4 step 144 reward tensor([-1]) loss 0.4549974799156189 epsilon 0.7426202259375
26-Feb-25 09:39:28 - agent.DQN.DQN - INFO - episode 4 step 145 reward tensor([-1]) loss 1.0441031455993652 epsilon 0.7426202259375
26-Feb-25 09:39:28 - agent.DQN.DQN - INFO - episode 4 step 146 reward tensor([-1]) loss 1.2970499992370605 epsilon 0.7426202259375
26-Feb-25 09:39:28 - agent.DQN.DQN - INFO - episode 4 step 147 reward tensor([-1]) loss 0.780918538570404 epsilon 0.7426202259375
26-Feb-25 09:39:28 - agent.DQN.DQN - INFO - episode 4 step 148 reward tensor([-1]) loss 0.7758862972259521 epsilon 0.7426202259375
26-Feb-25 09:39:28 - agent.DQN.DQN - INFO - episode 4 step 149 reward tensor([-1]) loss 0.935031533241272 epsilon 0.7426202259375
26-Feb-25 09:39:28 - agent.DQN.DQN - INFO - episode 4 step 150 reward tensor([-1]) loss 0.5714569091796875 epsilon 0.7426202259375
26-Feb-25 09:39:28 - agent.DQN.DQN - INFO - episode 4 step 151 reward tensor([-1]) loss 0.6957817077636719 epsilon 0.7426202259375
26-Feb-25 09:39:28 - agent.DQN.DQN - INFO - episode 4 step 152 reward tensor([-1]) loss 0.9811215400695801 epsilon 0.7426202259375
26-Feb-25 09:39:28 - agent.DQN.DQN - INFO - episode 4 step 153 reward tensor([-1]) loss 0.9451800584793091 epsilon 0.7426202259375
26-Feb-25 09:39:28 - agent.DQN.DQN - INFO - episode 4 step 154 reward tensor([-1]) loss 1.2485778331756592 epsilon 0.7426202259375
26-Feb-25 09:39:28 - agent.DQN.DQN - INFO - episode 4 step 155 reward tensor([-1]) loss 0.7919071912765503 epsilon 0.7426202259375
26-Feb-25 09:39:28 - agent.DQN.DQN - INFO - episode 4 step 156 reward tensor([-1]) loss 0.7199354767799377 epsilon 0.7426202259375
26-Feb-25 09:39:28 - agent.DQN.DQN - INFO - episode 4 step 157 reward tensor([-1]) loss 0.6628144383430481 epsilon 0.7426202259375
26-Feb-25 09:39:28 - agent.DQN.DQN - INFO - episode 4 step 158 reward tensor([-1]) loss 0.9074031114578247 epsilon 0.7426202259375
26-Feb-25 09:39:28 - agent.DQN.DQN - INFO - episode 4 step 159 reward tensor([-1]) loss 1.2103573083877563 epsilon 0.7426202259375
26-Feb-25 09:39:28 - agent.DQN.DQN - INFO - episode 4 step 160 reward tensor([-1]) loss 0.4868201017379761 epsilon 0.7426202259375
26-Feb-25 09:39:28 - agent.DQN.DQN - INFO - episode 4 step 161 reward tensor([-1]) loss 1.0081409215927124 epsilon 0.7426202259375
26-Feb-25 09:39:28 - agent.DQN.DQN - INFO - episode 4 step 162 reward tensor([-1]) loss 0.5495687127113342 epsilon 0.7426202259375
26-Feb-25 09:39:28 - agent.DQN.DQN - INFO - episode 4 step 163 reward tensor([-1]) loss 0.44228944182395935 epsilon 0.7426202259375
26-Feb-25 09:39:28 - agent.DQN.DQN - INFO - episode 4 step 164 reward tensor([-1]) loss 1.1113909482955933 epsilon 0.7426202259375
26-Feb-25 09:39:28 - agent.DQN.DQN - INFO - episode 4 step 165 reward tensor([-1]) loss 0.6938520073890686 epsilon 0.7426202259375
26-Feb-25 09:39:28 - agent.DQN.DQN - INFO - episode 4 step 166 reward tensor([-1]) loss 1.056060552597046 epsilon 0.7426202259375
26-Feb-25 09:39:28 - agent.DQN.DQN - INFO - episode 4 step 167 reward tensor([-1]) loss 0.522239625453949 epsilon 0.7426202259375
26-Feb-25 09:39:28 - agent.DQN.DQN - INFO - episode 4 step 168 reward tensor([-1]) loss 0.6905689835548401 epsilon 0.7426202259375
26-Feb-25 09:39:28 - agent.DQN.DQN - INFO - episode 4 step 169 reward tensor([-1]) loss 0.5728520154953003 epsilon 0.7426202259375
26-Feb-25 09:39:28 - agent.DQN.DQN - INFO - episode 4 step 170 reward tensor([-1]) loss 1.104283094406128 epsilon 0.7426202259375
26-Feb-25 09:39:28 - agent.DQN.DQN - INFO - episode 4 step 171 reward tensor([-1]) loss 0.45173460245132446 epsilon 0.7426202259375
26-Feb-25 09:39:28 - agent.DQN.DQN - INFO - episode 4 step 172 reward tensor([-1]) loss 0.776077926158905 epsilon 0.7426202259375
26-Feb-25 09:39:28 - agent.DQN.DQN - INFO - episode 4 step 173 reward tensor([-1]) loss 0.9313077926635742 epsilon 0.7426202259375
26-Feb-25 09:39:28 - agent.DQN.DQN - INFO - episode 4 step 174 reward tensor([-1]) loss 0.5746996998786926 epsilon 0.7426202259375
26-Feb-25 09:39:28 - agent.DQN.DQN - INFO - episode 4 step 175 reward tensor([-1]) loss 0.9837594032287598 epsilon 0.7426202259375
26-Feb-25 09:39:28 - agent.DQN.DQN - INFO - episode 4 step 176 reward tensor([-1]) loss 1.1976101398468018 epsilon 0.7426202259375
26-Feb-25 09:39:28 - agent.DQN.DQN - INFO - episode 4 step 177 reward tensor([-1]) loss 0.7863300442695618 epsilon 0.7426202259375
26-Feb-25 09:39:28 - agent.DQN.DQN - INFO - episode 4 step 178 reward tensor([-1]) loss 1.2065858840942383 epsilon 0.7426202259375
26-Feb-25 09:39:28 - agent.DQN.DQN - INFO - episode 4 step 179 reward tensor([-1]) loss 0.7582940459251404 epsilon 0.7426202259375
26-Feb-25 09:39:28 - agent.DQN.DQN - INFO - episode 4 step 180 reward tensor([-1]) loss 1.01889169216156 epsilon 0.7426202259375
26-Feb-25 09:39:28 - agent.DQN.DQN - INFO - episode 4 step 181 reward tensor([-1]) loss 1.0576092004776 epsilon 0.7426202259375
26-Feb-25 09:39:28 - agent.DQN.DQN - INFO - episode 4 step 182 reward tensor([-1]) loss 1.1272999048233032 epsilon 0.7426202259375
26-Feb-25 09:39:28 - agent.DQN.DQN - INFO - episode 4 step 183 reward tensor([-1]) loss 0.8737506866455078 epsilon 0.7426202259375
26-Feb-25 09:39:28 - agent.DQN.DQN - INFO - episode 4 step 184 reward tensor([-1]) loss 1.0747723579406738 epsilon 0.7426202259375
26-Feb-25 09:39:28 - agent.DQN.DQN - INFO - episode 4 step 185 reward tensor([-1]) loss 0.9457544088363647 epsilon 0.7426202259375
26-Feb-25 09:39:28 - agent.DQN.DQN - INFO - episode 4 step 186 reward tensor([-1]) loss 0.6082710027694702 epsilon 0.7426202259375
26-Feb-25 09:39:28 - agent.DQN.DQN - INFO - episode 4 step 187 reward tensor([-1]) loss 0.9857287406921387 epsilon 0.7426202259375
26-Feb-25 09:39:28 - agent.DQN.DQN - INFO - episode 4 step 188 reward tensor([-1]) loss 1.2246534824371338 epsilon 0.7426202259375
26-Feb-25 09:39:28 - agent.DQN.DQN - INFO - episode 4 step 189 reward tensor([-1]) loss 0.9439586400985718 epsilon 0.7426202259375
26-Feb-25 09:39:28 - agent.DQN.DQN - INFO - episode 4 step 190 reward tensor([-1]) loss 0.6976933479309082 epsilon 0.7426202259375
26-Feb-25 09:39:28 - agent.DQN.DQN - INFO - episode 4 step 191 reward tensor([-1]) loss 0.6007208824157715 epsilon 0.7426202259375
26-Feb-25 09:39:28 - agent.DQN.DQN - INFO - episode 4 step 192 reward tensor([-1]) loss 1.2383229732513428 epsilon 0.7426202259375
26-Feb-25 09:39:28 - agent.DQN.DQN - INFO - episode 4 step 193 reward tensor([-1]) loss 0.6994075775146484 epsilon 0.7426202259375
26-Feb-25 09:39:28 - agent.DQN.DQN - INFO - episode 4 step 194 reward tensor([-1]) loss 0.6450142860412598 epsilon 0.7426202259375
26-Feb-25 09:39:28 - agent.DQN.DQN - INFO - episode 4 step 195 reward tensor([-1]) loss 0.5157923698425293 epsilon 0.7426202259375
26-Feb-25 09:39:28 - agent.DQN.DQN - INFO - episode 4 step 196 reward tensor([-1]) loss 0.9147123098373413 epsilon 0.7426202259375
26-Feb-25 09:39:28 - agent.DQN.DQN - INFO - episode 4 step 197 reward tensor([-1]) loss 0.6264109015464783 epsilon 0.7426202259375
26-Feb-25 09:39:28 - agent.DQN.DQN - INFO - episode 4 step 198 reward tensor([-1]) loss 1.0357697010040283 epsilon 0.7426202259375
26-Feb-25 09:39:28 - agent.DQN.DQN - INFO - episode 4 step 199 reward tensor([-1]) loss 0.6418519020080566 epsilon 0.7426202259375
26-Feb-25 09:39:28 - agent.DQN.DQN - INFO - episode 4 step 200 reward tensor([-1]) loss 0.5537960529327393 epsilon 0.7426202259375
26-Feb-25 09:39:28 - agent.DQN.DQN - INFO - episode 4 step 201 reward tensor([-1]) loss 0.42999380826950073 epsilon 0.7426202259375
26-Feb-25 09:39:28 - agent.DQN.DQN - INFO - episode 4 step 202 reward tensor([-1]) loss 0.5477814078330994 epsilon 0.7426202259375
26-Feb-25 09:39:28 - agent.DQN.DQN - INFO - episode 4 step 203 reward tensor([-1]) loss 0.996684193611145 epsilon 0.7426202259375
26-Feb-25 09:39:28 - agent.DQN.DQN - INFO - episode 4 step 204 reward tensor([-1]) loss 0.4349396228790283 epsilon 0.7426202259375
26-Feb-25 09:39:28 - agent.DQN.DQN - INFO - episode 4 step 205 reward tensor([-1]) loss 0.9813176393508911 epsilon 0.7426202259375
26-Feb-25 09:39:28 - agent.DQN.DQN - INFO - episode 4 step 206 reward tensor([-1]) loss 0.9568085670471191 epsilon 0.7426202259375
26-Feb-25 09:39:29 - agent.DQN.DQN - INFO - episode 4 step 207 reward tensor([-1]) loss 0.7836767435073853 epsilon 0.7426202259375
26-Feb-25 09:39:29 - agent.DQN.DQN - INFO - episode 4 step 208 reward tensor([-1]) loss 0.7989050149917603 epsilon 0.7426202259375
26-Feb-25 09:39:29 - agent.DQN.DQN - INFO - episode 4 step 209 reward tensor([-1]) loss 0.8156816959381104 epsilon 0.7426202259375
26-Feb-25 09:39:29 - agent.DQN.DQN - INFO - episode 4 step 210 reward tensor([-1]) loss 0.512650728225708 epsilon 0.7426202259375
26-Feb-25 09:39:29 - agent.DQN.DQN - INFO - episode 4 step 211 reward tensor([-1]) loss 1.1265172958374023 epsilon 0.7426202259375
26-Feb-25 09:39:29 - agent.DQN.DQN - INFO - episode 4 step 212 reward tensor([-1]) loss 0.7051349878311157 epsilon 0.7426202259375
26-Feb-25 09:39:29 - agent.DQN.DQN - INFO - episode 4 step 213 reward tensor([-1]) loss 0.8976300954818726 epsilon 0.7426202259375
26-Feb-25 09:39:29 - agent.DQN.DQN - INFO - episode 4 step 214 reward tensor([-1]) loss 0.6335505247116089 epsilon 0.7426202259375
26-Feb-25 09:39:29 - agent.DQN.DQN - INFO - episode 4 step 215 reward tensor([-1]) loss 0.6140294075012207 epsilon 0.7426202259375
26-Feb-25 09:39:29 - agent.DQN.DQN - INFO - episode 4 step 216 reward tensor([-1]) loss 0.8485681414604187 epsilon 0.7426202259375
26-Feb-25 09:39:29 - agent.DQN.DQN - INFO - episode 4 step 217 reward tensor([-1]) loss 0.7653167247772217 epsilon 0.7426202259375
26-Feb-25 09:39:29 - agent.DQN.DQN - INFO - episode 4 step 218 reward tensor([-1]) loss 0.8771527409553528 epsilon 0.7426202259375
26-Feb-25 09:39:29 - agent.DQN.DQN - INFO - episode 4 step 219 reward tensor([-1]) loss 0.7499735951423645 epsilon 0.7426202259375
26-Feb-25 09:39:29 - agent.DQN.DQN - INFO - episode 4 step 220 reward tensor([-1]) loss 0.5857962369918823 epsilon 0.7426202259375
26-Feb-25 09:39:29 - agent.DQN.DQN - INFO - episode 4 step 221 reward tensor([-1]) loss 0.5259802341461182 epsilon 0.7426202259375
26-Feb-25 09:39:29 - agent.DQN.DQN - INFO - episode 4 step 222 reward tensor([-1]) loss 0.6424857974052429 epsilon 0.7426202259375
26-Feb-25 09:39:29 - agent.DQN.DQN - INFO - episode 4 step 223 reward tensor([-1]) loss 0.6815470457077026 epsilon 0.7426202259375
26-Feb-25 09:39:29 - agent.DQN.DQN - INFO - episode 4 step 224 reward tensor([-1]) loss 0.896061897277832 epsilon 0.7426202259375
26-Feb-25 09:39:29 - agent.DQN.DQN - INFO - episode 4 step 225 reward tensor([-1]) loss 1.1814799308776855 epsilon 0.7426202259375
26-Feb-25 09:39:29 - agent.DQN.DQN - INFO - episode 4 step 226 reward tensor([-1]) loss 1.0403327941894531 epsilon 0.7426202259375
26-Feb-25 09:39:29 - agent.DQN.DQN - INFO - episode 4 step 227 reward tensor([-1]) loss 0.5578538775444031 epsilon 0.7426202259375
26-Feb-25 09:39:29 - agent.DQN.DQN - INFO - episode 4 step 228 reward tensor([-1]) loss 0.46394938230514526 epsilon 0.7426202259375
26-Feb-25 09:39:29 - agent.DQN.DQN - INFO - episode 4 step 229 reward tensor([-1]) loss 0.9959948062896729 epsilon 0.7426202259375
26-Feb-25 09:39:29 - agent.DQN.DQN - INFO - episode 4 step 230 reward tensor([-1]) loss 1.0730921030044556 epsilon 0.7426202259375
26-Feb-25 09:39:29 - agent.DQN.DQN - INFO - episode 4 step 231 reward tensor([-1]) loss 0.9119731187820435 epsilon 0.7426202259375
26-Feb-25 09:39:29 - agent.DQN.DQN - INFO - episode 4 step 232 reward tensor([-1]) loss 0.8414155840873718 epsilon 0.7426202259375
26-Feb-25 09:39:29 - agent.DQN.DQN - INFO - episode 4 step 233 reward tensor([-1]) loss 0.6203636527061462 epsilon 0.7426202259375
26-Feb-25 09:39:29 - agent.DQN.DQN - INFO - episode 4 step 234 reward tensor([-1]) loss 0.5330210328102112 epsilon 0.7426202259375
26-Feb-25 09:39:29 - agent.DQN.DQN - INFO - episode 4 step 235 reward tensor([-1]) loss 0.9694335460662842 epsilon 0.7426202259375
26-Feb-25 09:39:29 - agent.DQN.DQN - INFO - episode 4 step 236 reward tensor([-1]) loss 0.6660778522491455 epsilon 0.7426202259375
26-Feb-25 09:39:29 - agent.DQN.DQN - INFO - episode 4 step 237 reward tensor([-1]) loss 0.6204318404197693 epsilon 0.7426202259375
26-Feb-25 09:39:29 - agent.DQN.DQN - INFO - episode 4 step 238 reward tensor([-1]) loss 0.737608015537262 epsilon 0.7426202259375
26-Feb-25 09:39:29 - agent.DQN.DQN - INFO - episode 4 step 239 reward tensor([-1]) loss 0.9296557903289795 epsilon 0.7426202259375
26-Feb-25 09:39:29 - agent.DQN.DQN - INFO - episode 4 step 240 reward tensor([-1]) loss 0.7069864869117737 epsilon 0.7426202259375
26-Feb-25 09:39:29 - agent.DQN.DQN - INFO - episode 4 step 241 reward tensor([-1]) loss 0.5239747762680054 epsilon 0.7426202259375
26-Feb-25 09:39:29 - agent.DQN.DQN - INFO - episode 4 step 242 reward tensor([-1]) loss 0.7113345861434937 epsilon 0.7426202259375
26-Feb-25 09:39:29 - agent.DQN.DQN - INFO - episode 4 step 243 reward tensor([-1]) loss 0.8433260917663574 epsilon 0.7426202259375
26-Feb-25 09:39:29 - agent.DQN.DQN - INFO - episode 4 step 244 reward tensor([-1]) loss 0.5941783785820007 epsilon 0.7426202259375
26-Feb-25 09:39:29 - agent.DQN.DQN - INFO - episode 4 step 245 reward tensor([-1]) loss 0.9492273926734924 epsilon 0.7426202259375
26-Feb-25 09:39:29 - agent.DQN.DQN - INFO - episode 4 step 246 reward tensor([-1]) loss 0.6482551097869873 epsilon 0.7426202259375
26-Feb-25 09:39:29 - agent.DQN.DQN - INFO - episode 4 step 247 reward tensor([-1]) loss 0.6148055195808411 epsilon 0.7426202259375
26-Feb-25 09:39:29 - agent.DQN.DQN - INFO - episode 4 step 248 reward tensor([-1]) loss 0.5766215920448303 epsilon 0.7426202259375
26-Feb-25 09:39:29 - agent.DQN.DQN - INFO - episode 4 step 249 reward tensor([-1]) loss 0.7511457204818726 epsilon 0.7426202259375
26-Feb-25 09:39:29 - agent.DQN.DQN - INFO - episode 4 step 250 reward tensor([-1]) loss 0.8563013076782227 epsilon 0.7426202259375
26-Feb-25 09:39:29 - agent.DQN.DQN - INFO - episode 4 step 251 reward tensor([-1]) loss 0.7868297696113586 epsilon 0.7426202259375
26-Feb-25 09:39:29 - agent.DQN.DQN - INFO - episode 4 step 252 reward tensor([-1]) loss 0.6038796901702881 epsilon 0.7426202259375
26-Feb-25 09:39:29 - agent.DQN.DQN - INFO - episode 4 step 253 reward tensor([-1]) loss 0.7908439040184021 epsilon 0.7426202259375
26-Feb-25 09:39:29 - agent.DQN.DQN - INFO - episode 4 step 254 reward tensor([-1]) loss 0.7737507224082947 epsilon 0.7426202259375
26-Feb-25 09:39:29 - agent.DQN.DQN - INFO - episode 4 step 255 reward tensor([-1]) loss 0.5538660287857056 epsilon 0.7426202259375
26-Feb-25 09:39:29 - agent.DQN.DQN - INFO - episode 4 step 256 reward tensor([-1]) loss 0.8272425532341003 epsilon 0.7426202259375
26-Feb-25 09:39:29 - agent.DQN.DQN - INFO - episode 4 step 257 reward tensor([-1]) loss 0.6904044151306152 epsilon 0.7426202259375
26-Feb-25 09:39:29 - agent.DQN.DQN - INFO - episode 4 step 258 reward tensor([-1]) loss 0.5155506134033203 epsilon 0.7426202259375
26-Feb-25 09:39:29 - agent.DQN.DQN - INFO - episode 4 step 259 reward tensor([-1]) loss 0.5926430225372314 epsilon 0.7426202259375
26-Feb-25 09:39:29 - agent.DQN.DQN - INFO - episode 4 step 260 reward tensor([-1]) loss 1.2489755153656006 epsilon 0.7426202259375
26-Feb-25 09:39:29 - agent.DQN.DQN - INFO - episode 4 step 261 reward tensor([-1]) loss 0.7676241397857666 epsilon 0.7426202259375
26-Feb-25 09:39:29 - agent.DQN.DQN - INFO - episode 4 step 262 reward tensor([-1]) loss 0.49531278014183044 epsilon 0.7426202259375
26-Feb-25 09:39:29 - agent.DQN.DQN - INFO - episode 4 step 263 reward tensor([-1]) loss 0.5921686887741089 epsilon 0.7426202259375
26-Feb-25 09:39:29 - agent.DQN.DQN - INFO - episode 4 step 264 reward tensor([-1]) loss 0.8936281204223633 epsilon 0.7426202259375
26-Feb-25 09:39:29 - agent.DQN.DQN - INFO - episode 4 step 265 reward tensor([-1]) loss 0.6987667083740234 epsilon 0.7426202259375
26-Feb-25 09:39:29 - agent.DQN.DQN - INFO - episode 4 step 266 reward tensor([-1]) loss 0.9496897459030151 epsilon 0.7426202259375
26-Feb-25 09:39:29 - agent.DQN.DQN - INFO - episode 4 step 267 reward tensor([-1]) loss 0.635807991027832 epsilon 0.7426202259375
26-Feb-25 09:39:29 - agent.DQN.DQN - INFO - episode 4 step 268 reward tensor([-1]) loss 0.5713692307472229 epsilon 0.7426202259375
26-Feb-25 09:39:29 - agent.DQN.DQN - INFO - episode 4 step 269 reward tensor([-1]) loss 0.558093786239624 epsilon 0.7426202259375
26-Feb-25 09:39:29 - agent.DQN.DQN - INFO - episode 4 step 270 reward tensor([-1]) loss 0.6776547431945801 epsilon 0.7426202259375
26-Feb-25 09:39:29 - agent.DQN.DQN - INFO - episode 4 step 271 reward tensor([-1]) loss 0.7175577878952026 epsilon 0.7426202259375
26-Feb-25 09:39:29 - agent.DQN.DQN - INFO - episode 4 step 272 reward tensor([-1]) loss 0.5898815393447876 epsilon 0.7426202259375
26-Feb-25 09:39:29 - agent.DQN.DQN - INFO - episode 4 step 273 reward tensor([-1]) loss 0.535377025604248 epsilon 0.7426202259375
26-Feb-25 09:39:29 - agent.DQN.DQN - INFO - episode 4 step 274 reward tensor([-1]) loss 0.9223958253860474 epsilon 0.7426202259375
26-Feb-25 09:39:29 - agent.DQN.DQN - INFO - episode 4 step 275 reward tensor([-1]) loss 0.6575464010238647 epsilon 0.7426202259375
26-Feb-25 09:39:29 - agent.DQN.DQN - INFO - episode 4 step 276 reward tensor([-1]) loss 0.5651236772537231 epsilon 0.7426202259375
26-Feb-25 09:39:29 - agent.DQN.DQN - INFO - episode 4 step 277 reward tensor([-1]) loss 0.6167390942573547 epsilon 0.7426202259375
26-Feb-25 09:39:29 - agent.DQN.DQN - INFO - episode 4 step 278 reward tensor([-1]) loss 0.5372269153594971 epsilon 0.7426202259375
26-Feb-25 09:39:29 - agent.DQN.DQN - INFO - episode 4 step 279 reward tensor([-1]) loss 0.6976972818374634 epsilon 0.7426202259375
26-Feb-25 09:39:29 - agent.DQN.DQN - INFO - episode 4 step 280 reward tensor([-1]) loss 0.5906010270118713 epsilon 0.7426202259375
26-Feb-25 09:39:29 - agent.DQN.DQN - INFO - episode 4 step 281 reward tensor([-1]) loss 0.5424547791481018 epsilon 0.7426202259375
26-Feb-25 09:39:29 - agent.DQN.DQN - INFO - episode 4 step 282 reward tensor([-1]) loss 0.5065173506736755 epsilon 0.7426202259375
26-Feb-25 09:39:29 - agent.DQN.DQN - INFO - episode 4 step 283 reward tensor([-1]) loss 0.7143065333366394 epsilon 0.7426202259375
26-Feb-25 09:39:29 - agent.DQN.DQN - INFO - episode 4 step 284 reward tensor([-1]) loss 0.634710431098938 epsilon 0.7426202259375
26-Feb-25 09:39:29 - agent.DQN.DQN - INFO - episode 4 step 285 reward tensor([-1]) loss 0.9586337208747864 epsilon 0.7426202259375
26-Feb-25 09:39:29 - agent.DQN.DQN - INFO - episode 4 step 286 reward tensor([-1]) loss 0.582574725151062 epsilon 0.7426202259375
26-Feb-25 09:39:30 - agent.DQN.DQN - INFO - episode 4 step 287 reward tensor([-1]) loss 0.5286186337471008 epsilon 0.7426202259375
26-Feb-25 09:39:30 - agent.DQN.DQN - INFO - episode 4 step 288 reward tensor([-1]) loss 0.5247470140457153 epsilon 0.7426202259375
26-Feb-25 09:39:30 - agent.DQN.DQN - INFO - episode 4 step 289 reward tensor([-1]) loss 0.8213574886322021 epsilon 0.7426202259375
26-Feb-25 09:39:30 - agent.DQN.DQN - INFO - episode 4 step 290 reward tensor([-1]) loss 0.7424263954162598 epsilon 0.7426202259375
26-Feb-25 09:39:30 - agent.DQN.DQN - INFO - episode 4 step 291 reward tensor([-1]) loss 0.9063557386398315 epsilon 0.7426202259375
26-Feb-25 09:39:30 - agent.DQN.DQN - INFO - episode 4 step 292 reward tensor([-1]) loss 0.4161134660243988 epsilon 0.7426202259375
26-Feb-25 09:39:30 - agent.DQN.DQN - INFO - episode 4 step 293 reward tensor([-1]) loss 0.6118026971817017 epsilon 0.7426202259375
26-Feb-25 09:39:30 - agent.DQN.DQN - INFO - episode 4 step 294 reward tensor([-1]) loss 0.7383121848106384 epsilon 0.7426202259375
26-Feb-25 09:39:30 - agent.DQN.DQN - INFO - episode 4 step 295 reward tensor([-1]) loss 0.6289197206497192 epsilon 0.7426202259375
26-Feb-25 09:39:30 - agent.DQN.DQN - INFO - episode 4 step 296 reward tensor([-1]) loss 0.6553969979286194 epsilon 0.7426202259375
26-Feb-25 09:39:30 - agent.DQN.DQN - INFO - episode 4 step 297 reward tensor([-1]) loss 0.6272337436676025 epsilon 0.7426202259375
26-Feb-25 09:39:30 - agent.DQN.DQN - INFO - episode 4 step 298 reward tensor([-1]) loss 0.6159090399742126 epsilon 0.7426202259375
26-Feb-25 09:39:30 - agent.DQN.DQN - INFO - episode 4 step 299 reward tensor([-1]) loss 0.5417236089706421 epsilon 0.7426202259375
26-Feb-25 09:39:30 - agent.DQN.DQN - INFO - episode 4 step 300 reward tensor([-1]) loss 1.019075632095337 epsilon 0.7426202259375
26-Feb-25 09:39:30 - agent.DQN.DQN - INFO - episode 4 step 301 reward tensor([-1]) loss 0.442907452583313 epsilon 0.7426202259375
26-Feb-25 09:39:30 - agent.DQN.DQN - INFO - episode 5 step 0 reward tensor([-1]) loss 0.7358229160308838 epsilon 0.7184850685945312
26-Feb-25 09:39:30 - agent.DQN.DQN - INFO - episode 5 step 1 reward tensor([-1]) loss 0.6662978529930115 epsilon 0.7184850685945312
26-Feb-25 09:39:30 - agent.DQN.DQN - INFO - episode 5 step 2 reward tensor([-1]) loss 0.5304120182991028 epsilon 0.7184850685945312
26-Feb-25 09:39:30 - agent.DQN.DQN - INFO - episode 5 step 3 reward tensor([-1]) loss 0.5980573892593384 epsilon 0.7184850685945312
26-Feb-25 09:39:30 - agent.DQN.DQN - INFO - episode 5 step 4 reward tensor([-1]) loss 0.48544949293136597 epsilon 0.7184850685945312
26-Feb-25 09:39:30 - agent.DQN.DQN - INFO - episode 5 step 5 reward tensor([-1]) loss 0.49879488348960876 epsilon 0.7184850685945312
26-Feb-25 09:39:30 - agent.DQN.DQN - INFO - episode 5 step 6 reward tensor([-1]) loss 0.5823515057563782 epsilon 0.7184850685945312
26-Feb-25 09:39:30 - agent.DQN.DQN - INFO - episode 5 step 7 reward tensor([-1]) loss 0.6423056125640869 epsilon 0.7184850685945312
26-Feb-25 09:39:30 - agent.DQN.DQN - INFO - episode 5 step 8 reward tensor([-1]) loss 0.4849947392940521 epsilon 0.7184850685945312
26-Feb-25 09:39:30 - agent.DQN.DQN - INFO - episode 5 step 9 reward tensor([-1]) loss 0.505925178527832 epsilon 0.7184850685945312
26-Feb-25 09:39:30 - agent.DQN.DQN - INFO - episode 5 step 10 reward tensor([-1]) loss 0.43896913528442383 epsilon 0.7184850685945312
26-Feb-25 09:39:30 - agent.DQN.DQN - INFO - episode 5 step 11 reward tensor([-1]) loss 0.6125180721282959 epsilon 0.7184850685945312
26-Feb-25 09:39:30 - agent.DQN.DQN - INFO - episode 5 step 12 reward tensor([-1]) loss 0.5047682523727417 epsilon 0.7184850685945312
26-Feb-25 09:39:30 - agent.DQN.DQN - INFO - episode 5 step 13 reward tensor([-1]) loss 0.6300775408744812 epsilon 0.7184850685945312
26-Feb-25 09:39:30 - agent.DQN.DQN - INFO - episode 5 step 14 reward tensor([-1]) loss 0.5999322533607483 epsilon 0.7184850685945312
26-Feb-25 09:39:30 - agent.DQN.DQN - INFO - episode 5 step 15 reward tensor([-1]) loss 0.9193105697631836 epsilon 0.7184850685945312
26-Feb-25 09:39:30 - agent.DQN.DQN - INFO - episode 5 step 16 reward tensor([-1]) loss 0.5568055510520935 epsilon 0.7184850685945312
26-Feb-25 09:39:30 - agent.DQN.DQN - INFO - episode 5 step 17 reward tensor([-1]) loss 0.5686371326446533 epsilon 0.7184850685945312
26-Feb-25 09:39:30 - agent.DQN.DQN - INFO - episode 5 step 18 reward tensor([-1]) loss 0.4569855332374573 epsilon 0.7184850685945312
26-Feb-25 09:39:30 - agent.DQN.DQN - INFO - episode 5 step 19 reward tensor([-1]) loss 0.6461575627326965 epsilon 0.7184850685945312
26-Feb-25 09:39:30 - agent.DQN.DQN - INFO - episode 5 step 20 reward tensor([-1]) loss 0.573444128036499 epsilon 0.7184850685945312
26-Feb-25 09:39:30 - agent.DQN.DQN - INFO - episode 5 step 21 reward tensor([-1]) loss 0.5402563810348511 epsilon 0.7184850685945312
26-Feb-25 09:39:30 - agent.DQN.DQN - INFO - episode 5 step 22 reward tensor([-1]) loss 0.8880264759063721 epsilon 0.7184850685945312
26-Feb-25 09:39:30 - agent.DQN.DQN - INFO - episode 5 step 23 reward tensor([-1]) loss 0.7902531623840332 epsilon 0.7184850685945312
26-Feb-25 09:39:30 - agent.DQN.DQN - INFO - episode 5 step 24 reward tensor([-1]) loss 0.6636125445365906 epsilon 0.7184850685945312
26-Feb-25 09:39:30 - agent.DQN.DQN - INFO - episode 5 step 25 reward tensor([-1]) loss 0.5860883593559265 epsilon 0.7184850685945312
26-Feb-25 09:39:30 - agent.DQN.DQN - INFO - episode 5 step 26 reward tensor([-1]) loss 0.52431321144104 epsilon 0.7184850685945312
26-Feb-25 09:39:30 - agent.DQN.DQN - INFO - episode 5 step 27 reward tensor([-1]) loss 0.737084686756134 epsilon 0.7184850685945312
26-Feb-25 09:39:30 - agent.DQN.DQN - INFO - episode 5 step 28 reward tensor([-1]) loss 0.725784420967102 epsilon 0.7184850685945312
26-Feb-25 09:39:30 - agent.DQN.DQN - INFO - episode 5 step 29 reward tensor([-1]) loss 0.7657951712608337 epsilon 0.7184850685945312
26-Feb-25 09:39:30 - agent.DQN.DQN - INFO - episode 5 step 30 reward tensor([-1]) loss 0.48574280738830566 epsilon 0.7184850685945312
26-Feb-25 09:39:30 - agent.DQN.DQN - INFO - episode 5 step 31 reward tensor([-1]) loss 0.5101165771484375 epsilon 0.7184850685945312
26-Feb-25 09:39:30 - agent.DQN.DQN - INFO - episode 5 step 32 reward tensor([-1]) loss 0.6440650224685669 epsilon 0.7184850685945312
26-Feb-25 09:39:30 - agent.DQN.DQN - INFO - episode 5 step 33 reward tensor([-1]) loss 0.6095833778381348 epsilon 0.7184850685945312
26-Feb-25 09:39:30 - agent.DQN.DQN - INFO - episode 5 step 34 reward tensor([-1]) loss 0.8179583549499512 epsilon 0.7184850685945312
26-Feb-25 09:39:30 - agent.DQN.DQN - INFO - episode 5 step 35 reward tensor([-1]) loss 0.47554492950439453 epsilon 0.7184850685945312
26-Feb-25 09:39:30 - agent.DQN.DQN - INFO - episode 5 step 36 reward tensor([-1]) loss 0.5481781959533691 epsilon 0.7184850685945312
26-Feb-25 09:39:30 - agent.DQN.DQN - INFO - episode 5 step 37 reward tensor([-1]) loss 0.5245112776756287 epsilon 0.7184850685945312
26-Feb-25 09:39:30 - agent.DQN.DQN - INFO - episode 5 step 38 reward tensor([-1]) loss 0.5651395320892334 epsilon 0.7184850685945312
26-Feb-25 09:39:30 - agent.DQN.DQN - INFO - episode 5 step 39 reward tensor([-1]) loss 0.4996790289878845 epsilon 0.7184850685945312
26-Feb-25 09:39:30 - agent.DQN.DQN - INFO - episode 5 step 40 reward tensor([-1]) loss 0.5762003660202026 epsilon 0.7184850685945312
26-Feb-25 09:39:30 - agent.DQN.DQN - INFO - episode 5 step 41 reward tensor([-1]) loss 0.6362361311912537 epsilon 0.7184850685945312
26-Feb-25 09:39:30 - agent.DQN.DQN - INFO - episode 5 step 42 reward tensor([-1]) loss 0.5989513397216797 epsilon 0.7184850685945312
26-Feb-25 09:39:30 - agent.DQN.DQN - INFO - episode 5 step 43 reward tensor([-1]) loss 0.4419739544391632 epsilon 0.7184850685945312
26-Feb-25 09:39:30 - agent.DQN.DQN - INFO - episode 5 step 44 reward tensor([-1]) loss 0.8574050664901733 epsilon 0.7184850685945312
26-Feb-25 09:39:30 - agent.DQN.DQN - INFO - episode 5 step 45 reward tensor([-1]) loss 0.5136338472366333 epsilon 0.7184850685945312
26-Feb-25 09:39:30 - agent.DQN.DQN - INFO - episode 5 step 46 reward tensor([-1]) loss 0.5771133899688721 epsilon 0.7184850685945312
26-Feb-25 09:39:30 - agent.DQN.DQN - INFO - episode 5 step 47 reward tensor([-1]) loss 0.432309627532959 epsilon 0.7184850685945312
26-Feb-25 09:39:30 - agent.DQN.DQN - INFO - episode 5 step 48 reward tensor([-1]) loss 0.4315131902694702 epsilon 0.7184850685945312
26-Feb-25 09:39:30 - agent.DQN.DQN - INFO - episode 5 step 49 reward tensor([-1]) loss 0.5564129948616028 epsilon 0.7184850685945312
26-Feb-25 09:39:30 - agent.DQN.DQN - INFO - episode 5 step 50 reward tensor([-1]) loss 0.5300506949424744 epsilon 0.7184850685945312
26-Feb-25 09:39:31 - agent.DQN.DQN - INFO - episode 5 step 51 reward tensor([-1]) loss 0.8009055256843567 epsilon 0.7184850685945312
26-Feb-25 09:39:31 - agent.DQN.DQN - INFO - episode 5 step 52 reward tensor([-1]) loss 0.5256491899490356 epsilon 0.7184850685945312
26-Feb-25 09:39:31 - agent.DQN.DQN - INFO - episode 5 step 53 reward tensor([-1]) loss 0.8182660341262817 epsilon 0.7184850685945312
26-Feb-25 09:39:31 - agent.DQN.DQN - INFO - episode 5 step 54 reward tensor([-1]) loss 0.6932353377342224 epsilon 0.7184850685945312
26-Feb-25 09:39:31 - agent.DQN.DQN - INFO - episode 5 step 55 reward tensor([-1]) loss 0.6049983501434326 epsilon 0.7184850685945312
26-Feb-25 09:39:31 - agent.DQN.DQN - INFO - episode 5 step 56 reward tensor([-1]) loss 0.46685802936553955 epsilon 0.7184850685945312
26-Feb-25 09:39:31 - agent.DQN.DQN - INFO - episode 5 step 57 reward tensor([-1]) loss 0.5326027870178223 epsilon 0.7184850685945312
26-Feb-25 09:39:31 - agent.DQN.DQN - INFO - episode 5 step 58 reward tensor([-1]) loss 0.5177178978919983 epsilon 0.7184850685945312
26-Feb-25 09:39:31 - agent.DQN.DQN - INFO - episode 5 step 59 reward tensor([-1]) loss 0.5688310861587524 epsilon 0.7184850685945312
26-Feb-25 09:39:31 - agent.DQN.DQN - INFO - episode 5 step 60 reward tensor([-1]) loss 0.49527060985565186 epsilon 0.7184850685945312
26-Feb-25 09:39:31 - agent.DQN.DQN - INFO - episode 5 step 61 reward tensor([-1]) loss 0.5774232745170593 epsilon 0.7184850685945312
26-Feb-25 09:39:31 - agent.DQN.DQN - INFO - episode 5 step 62 reward tensor([-1]) loss 0.7216828465461731 epsilon 0.7184850685945312
26-Feb-25 09:39:31 - agent.DQN.DQN - INFO - episode 5 step 63 reward tensor([-1]) loss 0.6601312756538391 epsilon 0.7184850685945312
26-Feb-25 09:39:31 - agent.DQN.DQN - INFO - episode 5 step 64 reward tensor([-1]) loss 0.9745236039161682 epsilon 0.7184850685945312
26-Feb-25 09:39:31 - agent.DQN.DQN - INFO - episode 5 step 65 reward tensor([-1]) loss 0.8134121894836426 epsilon 0.7184850685945312
26-Feb-25 09:39:31 - agent.DQN.DQN - INFO - episode 5 step 66 reward tensor([-1]) loss 0.7245645523071289 epsilon 0.7184850685945312
26-Feb-25 09:39:31 - agent.DQN.DQN - INFO - episode 5 step 67 reward tensor([-1]) loss 0.5670077800750732 epsilon 0.7184850685945312
26-Feb-25 09:39:31 - agent.DQN.DQN - INFO - episode 5 step 68 reward tensor([-1]) loss 0.8469645380973816 epsilon 0.7184850685945312
26-Feb-25 09:39:31 - agent.DQN.DQN - INFO - episode 5 step 69 reward tensor([-1]) loss 0.8607606887817383 epsilon 0.7184850685945312
26-Feb-25 09:39:31 - agent.DQN.DQN - INFO - episode 5 step 70 reward tensor([-1]) loss 0.6167699098587036 epsilon 0.7184850685945312
26-Feb-25 09:39:31 - agent.DQN.DQN - INFO - episode 5 step 71 reward tensor([-1]) loss 0.6916214823722839 epsilon 0.7184850685945312
26-Feb-25 09:39:31 - agent.DQN.DQN - INFO - episode 5 step 72 reward tensor([-1]) loss 0.8548016548156738 epsilon 0.7184850685945312
26-Feb-25 09:39:31 - agent.DQN.DQN - INFO - episode 5 step 73 reward tensor([-1]) loss 0.4220915734767914 epsilon 0.7184850685945312
26-Feb-25 09:39:31 - agent.DQN.DQN - INFO - episode 5 step 74 reward tensor([-1]) loss 0.4325275421142578 epsilon 0.7184850685945312
26-Feb-25 09:39:31 - agent.DQN.DQN - INFO - episode 5 step 75 reward tensor([-1]) loss 0.6702554225921631 epsilon 0.7184850685945312
26-Feb-25 09:39:31 - agent.DQN.DQN - INFO - episode 5 step 76 reward tensor([-1]) loss 0.6048858165740967 epsilon 0.7184850685945312
26-Feb-25 09:39:31 - agent.DQN.DQN - INFO - episode 5 step 77 reward tensor([-1]) loss 0.5993559956550598 epsilon 0.7184850685945312
26-Feb-25 09:39:31 - agent.DQN.DQN - INFO - episode 5 step 78 reward tensor([-1]) loss 0.45642125606536865 epsilon 0.7184850685945312
26-Feb-25 09:39:31 - agent.DQN.DQN - INFO - episode 5 step 79 reward tensor([-1]) loss 0.5923904776573181 epsilon 0.7184850685945312
26-Feb-25 09:39:31 - agent.DQN.DQN - INFO - episode 5 step 80 reward tensor([-1]) loss 0.7107812166213989 epsilon 0.7184850685945312
26-Feb-25 09:39:31 - agent.DQN.DQN - INFO - episode 5 step 81 reward tensor([-1]) loss 0.5951552391052246 epsilon 0.7184850685945312
26-Feb-25 09:39:31 - agent.DQN.DQN - INFO - episode 5 step 82 reward tensor([-1]) loss 0.8655143976211548 epsilon 0.7184850685945312
26-Feb-25 09:39:31 - agent.DQN.DQN - INFO - episode 5 step 83 reward tensor([-1]) loss 0.7152442932128906 epsilon 0.7184850685945312
26-Feb-25 09:39:31 - agent.DQN.DQN - INFO - episode 5 step 84 reward tensor([-1]) loss 0.8803092241287231 epsilon 0.7184850685945312
26-Feb-25 09:39:31 - agent.DQN.DQN - INFO - episode 5 step 85 reward tensor([-1]) loss 0.8733519315719604 epsilon 0.7184850685945312
26-Feb-25 09:39:31 - agent.DQN.DQN - INFO - episode 5 step 86 reward tensor([-1]) loss 0.47565925121307373 epsilon 0.7184850685945312
26-Feb-25 09:39:31 - agent.DQN.DQN - INFO - episode 5 step 87 reward tensor([-1]) loss 0.5480358600616455 epsilon 0.7184850685945312
26-Feb-25 09:39:31 - agent.DQN.DQN - INFO - episode 5 step 88 reward tensor([-1]) loss 0.7202767133712769 epsilon 0.7184850685945312
26-Feb-25 09:39:31 - agent.DQN.DQN - INFO - episode 5 step 89 reward tensor([-1]) loss 0.7571990489959717 epsilon 0.7184850685945312
26-Feb-25 09:39:31 - agent.DQN.DQN - INFO - episode 5 step 90 reward tensor([-1]) loss 0.7446475625038147 epsilon 0.7184850685945312
26-Feb-25 09:39:31 - agent.DQN.DQN - INFO - episode 5 step 91 reward tensor([-1]) loss 0.5794119238853455 epsilon 0.7184850685945312
26-Feb-25 09:39:31 - agent.DQN.DQN - INFO - episode 5 step 92 reward tensor([-1]) loss 0.8399611115455627 epsilon 0.7184850685945312
26-Feb-25 09:39:31 - agent.DQN.DQN - INFO - episode 5 step 93 reward tensor([-1]) loss 0.7318505644798279 epsilon 0.7184850685945312
26-Feb-25 09:39:31 - agent.DQN.DQN - INFO - episode 5 step 94 reward tensor([-1]) loss 0.9330102801322937 epsilon 0.7184850685945312
26-Feb-25 09:39:31 - agent.DQN.DQN - INFO - episode 5 step 95 reward tensor([-1]) loss 0.8248807787895203 epsilon 0.7184850685945312
26-Feb-25 09:39:31 - agent.DQN.DQN - INFO - episode 5 step 96 reward tensor([-1]) loss 0.7564582824707031 epsilon 0.7184850685945312
26-Feb-25 09:39:31 - agent.DQN.DQN - INFO - episode 5 step 97 reward tensor([-1]) loss 0.581363320350647 epsilon 0.7184850685945312
26-Feb-25 09:39:31 - agent.DQN.DQN - INFO - episode 5 step 98 reward tensor([-1]) loss 0.7858189344406128 epsilon 0.7184850685945312
26-Feb-25 09:39:31 - agent.DQN.DQN - INFO - episode 5 step 99 reward tensor([-1]) loss 0.9867370128631592 epsilon 0.7184850685945312
26-Feb-25 09:39:31 - agent.DQN.DQN - INFO - episode 5 step 100 reward tensor([-1]) loss 0.5973377823829651 epsilon 0.7184850685945312
26-Feb-25 09:39:31 - agent.DQN.DQN - INFO - episode 5 step 101 reward tensor([-1]) loss 0.6203982830047607 epsilon 0.7184850685945312
26-Feb-25 09:39:31 - agent.DQN.DQN - INFO - episode 5 step 102 reward tensor([-1]) loss 0.9974735379219055 epsilon 0.7184850685945312
26-Feb-25 09:39:31 - agent.DQN.DQN - INFO - episode 5 step 103 reward tensor([-1]) loss 0.5893954038619995 epsilon 0.7184850685945312
26-Feb-25 09:39:31 - agent.DQN.DQN - INFO - episode 5 step 104 reward tensor([-1]) loss 0.8422123789787292 epsilon 0.7184850685945312
26-Feb-25 09:39:31 - agent.DQN.DQN - INFO - episode 5 step 105 reward tensor([-1]) loss 0.7317672371864319 epsilon 0.7184850685945312
26-Feb-25 09:39:31 - agent.DQN.DQN - INFO - episode 5 step 106 reward tensor([-1]) loss 0.5691831111907959 epsilon 0.7184850685945312
26-Feb-25 09:39:31 - agent.DQN.DQN - INFO - episode 5 step 107 reward tensor([-1]) loss 0.802291214466095 epsilon 0.7184850685945312
26-Feb-25 09:39:31 - agent.DQN.DQN - INFO - episode 5 step 108 reward tensor([-1]) loss 0.8405970931053162 epsilon 0.7184850685945312
26-Feb-25 09:39:31 - agent.DQN.DQN - INFO - episode 5 step 109 reward tensor([-1]) loss 0.40121179819107056 epsilon 0.7184850685945312
26-Feb-25 09:39:31 - agent.DQN.DQN - INFO - episode 5 step 110 reward tensor([-1]) loss 0.6478896141052246 epsilon 0.7184850685945312
26-Feb-25 09:39:31 - agent.DQN.DQN - INFO - episode 5 step 111 reward tensor([-1]) loss 0.866454005241394 epsilon 0.7184850685945312
26-Feb-25 09:39:31 - agent.DQN.DQN - INFO - episode 5 step 112 reward tensor([-1]) loss 0.5303786993026733 epsilon 0.7184850685945312
26-Feb-25 09:39:31 - agent.DQN.DQN - INFO - episode 5 step 113 reward tensor([-1]) loss 0.7207103371620178 epsilon 0.7184850685945312
26-Feb-25 09:39:31 - agent.DQN.DQN - INFO - episode 5 step 114 reward tensor([-1]) loss 0.858392059803009 epsilon 0.7184850685945312
26-Feb-25 09:39:31 - agent.DQN.DQN - INFO - episode 5 step 115 reward tensor([-1]) loss 0.7669132947921753 epsilon 0.7184850685945312
26-Feb-25 09:39:31 - agent.DQN.DQN - INFO - episode 5 step 116 reward tensor([-1]) loss 1.1082890033721924 epsilon 0.7184850685945312
26-Feb-25 09:39:31 - agent.DQN.DQN - INFO - episode 5 step 117 reward tensor([-1]) loss 0.6167480945587158 epsilon 0.7184850685945312
26-Feb-25 09:39:31 - agent.DQN.DQN - INFO - episode 5 step 118 reward tensor([-1]) loss 0.8695150017738342 epsilon 0.7184850685945312
26-Feb-25 09:39:31 - agent.DQN.DQN - INFO - episode 5 step 119 reward tensor([-1]) loss 0.4964425563812256 epsilon 0.7184850685945312
26-Feb-25 09:39:31 - agent.DQN.DQN - INFO - episode 5 step 120 reward tensor([-1]) loss 0.5797282457351685 epsilon 0.7184850685945312
26-Feb-25 09:39:31 - agent.DQN.DQN - INFO - episode 5 step 121 reward tensor([-1]) loss 0.6633683443069458 epsilon 0.7184850685945312
26-Feb-25 09:39:31 - agent.DQN.DQN - INFO - episode 5 step 122 reward tensor([-1]) loss 0.5238749384880066 epsilon 0.7184850685945312
26-Feb-25 09:39:31 - agent.DQN.DQN - INFO - episode 5 step 123 reward tensor([-1]) loss 1.2824020385742188 epsilon 0.7184850685945312
26-Feb-25 09:39:31 - agent.DQN.DQN - INFO - episode 5 step 124 reward tensor([-1]) loss 0.43789684772491455 epsilon 0.7184850685945312
26-Feb-25 09:39:31 - agent.DQN.DQN - INFO - episode 5 step 125 reward tensor([-1]) loss 0.8116121888160706 epsilon 0.7184850685945312
26-Feb-25 09:39:31 - agent.DQN.DQN - INFO - episode 5 step 126 reward tensor([-1]) loss 0.4867680072784424 epsilon 0.7184850685945312
26-Feb-25 09:39:31 - agent.DQN.DQN - INFO - episode 5 step 127 reward tensor([-1]) loss 0.7618210315704346 epsilon 0.7184850685945312
26-Feb-25 09:39:31 - agent.DQN.DQN - INFO - episode 5 step 128 reward tensor([-1]) loss 0.9700322151184082 epsilon 0.7184850685945312
26-Feb-25 09:39:31 - agent.DQN.DQN - INFO - episode 5 step 129 reward tensor([-1]) loss 0.9789239168167114 epsilon 0.7184850685945312
26-Feb-25 09:39:31 - agent.DQN.DQN - INFO - episode 5 step 130 reward tensor([-1]) loss 0.7950118780136108 epsilon 0.7184850685945312
26-Feb-25 09:39:31 - agent.DQN.DQN - INFO - episode 5 step 131 reward tensor([-1]) loss 1.0632230043411255 epsilon 0.7184850685945312
26-Feb-25 09:39:31 - agent.DQN.DQN - INFO - episode 5 step 132 reward tensor([-1]) loss 0.5451282262802124 epsilon 0.7184850685945312
26-Feb-25 09:39:31 - agent.DQN.DQN - INFO - episode 5 step 133 reward tensor([-1]) loss 0.7723236680030823 epsilon 0.7184850685945312
26-Feb-25 09:39:31 - agent.DQN.DQN - INFO - episode 5 step 134 reward tensor([-1]) loss 0.7953768968582153 epsilon 0.7184850685945312
26-Feb-25 09:39:31 - agent.DQN.DQN - INFO - episode 5 step 135 reward tensor([-1]) loss 0.6688014268875122 epsilon 0.7184850685945312
26-Feb-25 09:39:31 - agent.DQN.DQN - INFO - episode 5 step 136 reward tensor([-1]) loss 1.2154875993728638 epsilon 0.7184850685945312
26-Feb-25 09:39:31 - agent.DQN.DQN - INFO - episode 5 step 137 reward tensor([-1]) loss 0.8640000224113464 epsilon 0.7184850685945312
26-Feb-25 09:39:32 - agent.DQN.DQN - INFO - episode 5 step 138 reward tensor([-1]) loss 0.7138089537620544 epsilon 0.7184850685945312
26-Feb-25 09:39:32 - agent.DQN.DQN - INFO - episode 5 step 139 reward tensor([-1]) loss 0.8407565951347351 epsilon 0.7184850685945312
26-Feb-25 09:39:32 - agent.DQN.DQN - INFO - episode 5 step 140 reward tensor([-1]) loss 0.7548645734786987 epsilon 0.7184850685945312
26-Feb-25 09:39:32 - agent.DQN.DQN - INFO - episode 5 step 141 reward tensor([-1]) loss 0.3978806138038635 epsilon 0.7184850685945312
26-Feb-25 09:39:32 - agent.DQN.DQN - INFO - episode 5 step 142 reward tensor([-1]) loss 0.9794527292251587 epsilon 0.7184850685945312
26-Feb-25 09:39:32 - agent.DQN.DQN - INFO - episode 5 step 143 reward tensor([-1]) loss 0.6063746809959412 epsilon 0.7184850685945312
26-Feb-25 09:39:32 - agent.DQN.DQN - INFO - episode 5 step 144 reward tensor([-1]) loss 0.9402546286582947 epsilon 0.7184850685945312
26-Feb-25 09:39:32 - agent.DQN.DQN - INFO - episode 5 step 145 reward tensor([-1]) loss 0.9220376014709473 epsilon 0.7184850685945312
26-Feb-25 09:39:32 - agent.DQN.DQN - INFO - episode 5 step 146 reward tensor([-1]) loss 0.70691978931427 epsilon 0.7184850685945312
26-Feb-25 09:39:32 - agent.DQN.DQN - INFO - episode 5 step 147 reward tensor([-1]) loss 0.6331952214241028 epsilon 0.7184850685945312
26-Feb-25 09:39:32 - agent.DQN.DQN - INFO - episode 5 step 148 reward tensor([-1]) loss 0.7352396845817566 epsilon 0.7184850685945312
26-Feb-25 09:39:32 - agent.DQN.DQN - INFO - episode 5 step 149 reward tensor([-1]) loss 0.5691721439361572 epsilon 0.7184850685945312
26-Feb-25 09:39:32 - agent.DQN.DQN - INFO - episode 5 step 150 reward tensor([-1]) loss 0.5017514228820801 epsilon 0.7184850685945312
26-Feb-25 09:39:32 - agent.DQN.DQN - INFO - episode 5 step 151 reward tensor([-1]) loss 0.7347064018249512 epsilon 0.7184850685945312
26-Feb-25 09:39:32 - agent.DQN.DQN - INFO - episode 5 step 152 reward tensor([-1]) loss 0.6348557472229004 epsilon 0.7184850685945312
26-Feb-25 09:39:32 - agent.DQN.DQN - INFO - episode 5 step 153 reward tensor([-1]) loss 0.8994497656822205 epsilon 0.7184850685945312
26-Feb-25 09:39:32 - agent.DQN.DQN - INFO - episode 5 step 154 reward tensor([-1]) loss 0.65461665391922 epsilon 0.7184850685945312
26-Feb-25 09:39:32 - agent.DQN.DQN - INFO - episode 5 step 155 reward tensor([-1]) loss 0.6375104784965515 epsilon 0.7184850685945312
26-Feb-25 09:39:32 - agent.DQN.DQN - INFO - episode 5 step 156 reward tensor([-1]) loss 0.7272968292236328 epsilon 0.7184850685945312
26-Feb-25 09:39:32 - agent.DQN.DQN - INFO - episode 5 step 157 reward tensor([-1]) loss 0.7247951030731201 epsilon 0.7184850685945312
26-Feb-25 09:39:32 - agent.DQN.DQN - INFO - episode 5 step 158 reward tensor([-1]) loss 0.9234142303466797 epsilon 0.7184850685945312
26-Feb-25 09:39:32 - agent.DQN.DQN - INFO - episode 5 step 159 reward tensor([-1]) loss 0.7728970050811768 epsilon 0.7184850685945312
26-Feb-25 09:39:32 - agent.DQN.DQN - INFO - episode 5 step 160 reward tensor([-1]) loss 0.6276824474334717 epsilon 0.7184850685945312
26-Feb-25 09:39:32 - agent.DQN.DQN - INFO - episode 5 step 161 reward tensor([-1]) loss 0.6158969402313232 epsilon 0.7184850685945312
26-Feb-25 09:39:32 - agent.DQN.DQN - INFO - episode 5 step 162 reward tensor([-1]) loss 0.633182168006897 epsilon 0.7184850685945312
26-Feb-25 09:39:32 - agent.DQN.DQN - INFO - episode 5 step 163 reward tensor([-1]) loss 0.8811012506484985 epsilon 0.7184850685945312
26-Feb-25 09:39:32 - agent.DQN.DQN - INFO - episode 5 step 164 reward tensor([-1]) loss 0.6338138580322266 epsilon 0.7184850685945312
26-Feb-25 09:39:32 - agent.DQN.DQN - INFO - episode 5 step 165 reward tensor([-1]) loss 0.8369243741035461 epsilon 0.7184850685945312
26-Feb-25 09:39:32 - agent.DQN.DQN - INFO - episode 5 step 166 reward tensor([-1]) loss 0.7940478324890137 epsilon 0.7184850685945312
26-Feb-25 09:39:32 - agent.DQN.DQN - INFO - episode 5 step 167 reward tensor([-1]) loss 0.8449232578277588 epsilon 0.7184850685945312
26-Feb-25 09:39:32 - agent.DQN.DQN - INFO - episode 5 step 168 reward tensor([-1]) loss 0.49553489685058594 epsilon 0.7184850685945312
26-Feb-25 09:39:32 - agent.DQN.DQN - INFO - episode 5 step 169 reward tensor([-1]) loss 0.5291762351989746 epsilon 0.7184850685945312
26-Feb-25 09:39:32 - agent.DQN.DQN - INFO - episode 5 step 170 reward tensor([-1]) loss 0.8033210039138794 epsilon 0.7184850685945312
26-Feb-25 09:39:32 - agent.DQN.DQN - INFO - episode 5 step 171 reward tensor([-1]) loss 0.9535869359970093 epsilon 0.7184850685945312
26-Feb-25 09:39:32 - agent.DQN.DQN - INFO - episode 5 step 172 reward tensor([-1]) loss 0.6149960160255432 epsilon 0.7184850685945312
26-Feb-25 09:39:32 - agent.DQN.DQN - INFO - episode 5 step 173 reward tensor([-1]) loss 0.7691751718521118 epsilon 0.7184850685945312
26-Feb-25 09:39:32 - agent.DQN.DQN - INFO - episode 5 step 174 reward tensor([-1]) loss 0.6672666072845459 epsilon 0.7184850685945312
26-Feb-25 09:39:32 - agent.DQN.DQN - INFO - episode 5 step 175 reward tensor([-1]) loss 0.7395715713500977 epsilon 0.7184850685945312
26-Feb-25 09:39:32 - agent.DQN.DQN - INFO - episode 5 step 176 reward tensor([-1]) loss 0.5997455716133118 epsilon 0.7184850685945312
26-Feb-25 09:39:32 - agent.DQN.DQN - INFO - episode 5 step 177 reward tensor([-1]) loss 0.6531338095664978 epsilon 0.7184850685945312
26-Feb-25 09:39:32 - agent.DQN.DQN - INFO - episode 5 step 178 reward tensor([-1]) loss 1.0124499797821045 epsilon 0.7184850685945312
26-Feb-25 09:39:32 - agent.DQN.DQN - INFO - episode 5 step 179 reward tensor([-1]) loss 0.7010537385940552 epsilon 0.7184850685945312
26-Feb-25 09:39:32 - agent.DQN.DQN - INFO - episode 5 step 180 reward tensor([-1]) loss 0.7328935265541077 epsilon 0.7184850685945312
26-Feb-25 09:39:32 - agent.DQN.DQN - INFO - episode 5 step 181 reward tensor([-1]) loss 0.8255745768547058 epsilon 0.7184850685945312
26-Feb-25 09:39:32 - agent.DQN.DQN - INFO - episode 5 step 182 reward tensor([-1]) loss 0.9059298634529114 epsilon 0.7184850685945312
26-Feb-25 09:39:32 - agent.DQN.DQN - INFO - episode 5 step 183 reward tensor([-1]) loss 0.6019418835639954 epsilon 0.7184850685945312
26-Feb-25 09:39:32 - agent.DQN.DQN - INFO - episode 5 step 184 reward tensor([-1]) loss 1.8665578365325928 epsilon 0.7184850685945312
26-Feb-25 09:39:32 - agent.DQN.DQN - INFO - episode 5 step 185 reward tensor([-1]) loss 1.6982309818267822 epsilon 0.7184850685945312
26-Feb-25 09:39:32 - agent.DQN.DQN - INFO - episode 5 step 186 reward tensor([-1]) loss 0.5861941576004028 epsilon 0.7184850685945312
26-Feb-25 09:39:32 - agent.DQN.DQN - INFO - episode 5 step 187 reward tensor([-1]) loss 1.4273433685302734 epsilon 0.7184850685945312
26-Feb-25 09:39:32 - agent.DQN.DQN - INFO - episode 5 step 188 reward tensor([-1]) loss 2.519558906555176 epsilon 0.7184850685945312
26-Feb-25 09:39:32 - agent.DQN.DQN - INFO - episode 5 step 189 reward tensor([-1]) loss 0.8341541290283203 epsilon 0.7184850685945312
26-Feb-25 09:39:32 - agent.DQN.DQN - INFO - episode 5 step 190 reward tensor([-1]) loss 1.99876868724823 epsilon 0.7184850685945312
26-Feb-25 09:39:32 - agent.DQN.DQN - INFO - episode 5 step 191 reward tensor([-1]) loss 1.7410364151000977 epsilon 0.7184850685945312
26-Feb-25 09:39:32 - agent.DQN.DQN - INFO - episode 5 step 192 reward tensor([-1]) loss 1.9801002740859985 epsilon 0.7184850685945312
26-Feb-25 09:39:32 - agent.DQN.DQN - INFO - episode 5 step 193 reward tensor([-1]) loss 1.3900970220565796 epsilon 0.7184850685945312
26-Feb-25 09:39:32 - agent.DQN.DQN - INFO - episode 5 step 194 reward tensor([-1]) loss 1.6292948722839355 epsilon 0.7184850685945312
26-Feb-25 09:39:32 - agent.DQN.DQN - INFO - episode 5 step 195 reward tensor([-1]) loss 0.7569767236709595 epsilon 0.7184850685945312
26-Feb-25 09:39:32 - agent.DQN.DQN - INFO - episode 5 step 196 reward tensor([-1]) loss 0.6282050013542175 epsilon 0.7184850685945312
26-Feb-25 09:39:32 - agent.DQN.DQN - INFO - episode 5 step 197 reward tensor([-1]) loss 1.431546926498413 epsilon 0.7184850685945312
26-Feb-25 09:39:32 - agent.DQN.DQN - INFO - episode 5 step 198 reward tensor([-1]) loss 0.5688855648040771 epsilon 0.7184850685945312
26-Feb-25 09:39:32 - agent.DQN.DQN - INFO - episode 5 step 199 reward tensor([-1]) loss 0.7161505818367004 epsilon 0.7184850685945312
26-Feb-25 09:39:32 - agent.DQN.DQN - INFO - episode 5 step 200 reward tensor([-1]) loss 0.8062936067581177 epsilon 0.7184850685945312
26-Feb-25 09:39:32 - agent.DQN.DQN - INFO - episode 5 step 201 reward tensor([-1]) loss 0.5662276744842529 epsilon 0.7184850685945312
26-Feb-25 09:39:32 - agent.DQN.DQN - INFO - episode 5 step 202 reward tensor([-1]) loss 1.707606315612793 epsilon 0.7184850685945312
26-Feb-25 09:39:32 - agent.DQN.DQN - INFO - episode 5 step 203 reward tensor([-1]) loss 0.7836409211158752 epsilon 0.7184850685945312
26-Feb-25 09:39:32 - agent.DQN.DQN - INFO - episode 5 step 204 reward tensor([-1]) loss 1.2914830446243286 epsilon 0.7184850685945312
26-Feb-25 09:39:32 - agent.DQN.DQN - INFO - episode 5 step 205 reward tensor([-1]) loss 1.0413964986801147 epsilon 0.7184850685945312
26-Feb-25 09:39:32 - agent.DQN.DQN - INFO - episode 5 step 206 reward tensor([-1]) loss 1.0480473041534424 epsilon 0.7184850685945312
26-Feb-25 09:39:32 - agent.DQN.DQN - INFO - episode 5 step 207 reward tensor([-1]) loss 0.9675195217132568 epsilon 0.7184850685945312
26-Feb-25 09:39:32 - agent.DQN.DQN - INFO - episode 5 step 208 reward tensor([-1]) loss 0.7112492322921753 epsilon 0.7184850685945312
26-Feb-25 09:39:32 - agent.DQN.DQN - INFO - episode 5 step 209 reward tensor([-1]) loss 0.7820113301277161 epsilon 0.7184850685945312
26-Feb-25 09:39:32 - agent.DQN.DQN - INFO - episode 5 step 210 reward tensor([-1]) loss 0.9684608578681946 epsilon 0.7184850685945312
26-Feb-25 09:39:32 - agent.DQN.DQN - INFO - episode 5 step 211 reward tensor([-1]) loss 0.9713815450668335 epsilon 0.7184850685945312
26-Feb-25 09:39:32 - agent.DQN.DQN - INFO - episode 5 step 212 reward tensor([-1]) loss 1.4314241409301758 epsilon 0.7184850685945312
26-Feb-25 09:39:32 - agent.DQN.DQN - INFO - episode 5 step 213 reward tensor([-1]) loss 1.6535505056381226 epsilon 0.7184850685945312
26-Feb-25 09:39:32 - agent.DQN.DQN - INFO - episode 5 step 214 reward tensor([-1]) loss 0.6659794449806213 epsilon 0.7184850685945312
26-Feb-25 09:39:33 - agent.DQN.DQN - INFO - episode 5 step 215 reward tensor([-1]) loss 0.6036491394042969 epsilon 0.7184850685945312
26-Feb-25 09:39:33 - agent.DQN.DQN - INFO - episode 5 step 216 reward tensor([-1]) loss 0.8768323659896851 epsilon 0.7184850685945312
26-Feb-25 09:39:33 - agent.DQN.DQN - INFO - episode 5 step 217 reward tensor([-1]) loss 0.6133586764335632 epsilon 0.7184850685945312
26-Feb-25 09:39:33 - agent.DQN.DQN - INFO - episode 5 step 218 reward tensor([-1]) loss 0.7102372050285339 epsilon 0.7184850685945312
26-Feb-25 09:39:33 - agent.DQN.DQN - INFO - episode 5 step 219 reward tensor([-1]) loss 0.8149033188819885 epsilon 0.7184850685945312
26-Feb-25 09:39:33 - agent.DQN.DQN - INFO - episode 5 step 220 reward tensor([-1]) loss 0.9514237642288208 epsilon 0.7184850685945312
26-Feb-25 09:39:33 - agent.DQN.DQN - INFO - episode 5 step 221 reward tensor([-1]) loss 0.8555319309234619 epsilon 0.7184850685945312
26-Feb-25 09:39:33 - agent.DQN.DQN - INFO - episode 5 step 222 reward tensor([-1]) loss 0.8337071537971497 epsilon 0.7184850685945312
26-Feb-25 09:39:33 - agent.DQN.DQN - INFO - episode 5 step 223 reward tensor([-1]) loss 1.0219990015029907 epsilon 0.7184850685945312
26-Feb-25 09:39:33 - agent.DQN.DQN - INFO - episode 5 step 224 reward tensor([-1]) loss 0.6391269564628601 epsilon 0.7184850685945312
26-Feb-25 09:39:33 - agent.DQN.DQN - INFO - episode 5 step 225 reward tensor([-1]) loss 0.6524879932403564 epsilon 0.7184850685945312
26-Feb-25 09:39:33 - agent.DQN.DQN - INFO - episode 5 step 226 reward tensor([-1]) loss 0.8970282077789307 epsilon 0.7184850685945312
26-Feb-25 09:39:33 - agent.DQN.DQN - INFO - episode 5 step 227 reward tensor([-1]) loss 0.6175641417503357 epsilon 0.7184850685945312
26-Feb-25 09:39:33 - agent.DQN.DQN - INFO - episode 5 step 228 reward tensor([-1]) loss 0.8012675642967224 epsilon 0.7184850685945312
26-Feb-25 09:39:33 - agent.DQN.DQN - INFO - episode 5 step 229 reward tensor([-1]) loss 0.8373172283172607 epsilon 0.7184850685945312
26-Feb-25 09:39:33 - agent.DQN.DQN - INFO - episode 5 step 230 reward tensor([-1]) loss 0.7159431576728821 epsilon 0.7184850685945312
26-Feb-25 09:39:33 - agent.DQN.DQN - INFO - episode 5 step 231 reward tensor([-1]) loss 0.9697337746620178 epsilon 0.7184850685945312
26-Feb-25 09:39:33 - agent.DQN.DQN - INFO - episode 5 step 232 reward tensor([-1]) loss 0.6726473569869995 epsilon 0.7184850685945312
26-Feb-25 09:39:33 - agent.DQN.DQN - INFO - episode 5 step 233 reward tensor([-1]) loss 1.036432147026062 epsilon 0.7184850685945312
26-Feb-25 09:39:33 - agent.DQN.DQN - INFO - episode 5 step 234 reward tensor([-1]) loss 0.9400156736373901 epsilon 0.7184850685945312
26-Feb-25 09:39:33 - agent.DQN.DQN - INFO - episode 5 step 235 reward tensor([-1]) loss 1.204038143157959 epsilon 0.7184850685945312
26-Feb-25 09:39:33 - agent.DQN.DQN - INFO - episode 5 step 236 reward tensor([-1]) loss 0.7379053235054016 epsilon 0.7184850685945312
26-Feb-25 09:39:33 - agent.DQN.DQN - INFO - episode 5 step 237 reward tensor([-1]) loss 0.8017687797546387 epsilon 0.7184850685945312
26-Feb-25 09:39:33 - agent.DQN.DQN - INFO - episode 5 step 238 reward tensor([-1]) loss 0.8094667792320251 epsilon 0.7184850685945312
26-Feb-25 09:39:33 - agent.DQN.DQN - INFO - episode 5 step 239 reward tensor([-1]) loss 0.9734349846839905 epsilon 0.7184850685945312
26-Feb-25 09:39:33 - agent.DQN.DQN - INFO - episode 5 step 240 reward tensor([-1]) loss 0.8022095561027527 epsilon 0.7184850685945312
26-Feb-25 09:39:33 - agent.DQN.DQN - INFO - episode 5 step 241 reward tensor([-1]) loss 0.7157202363014221 epsilon 0.7184850685945312
26-Feb-25 09:39:33 - agent.DQN.DQN - INFO - episode 5 step 242 reward tensor([-1]) loss 0.801638126373291 epsilon 0.7184850685945312
26-Feb-25 09:39:33 - agent.DQN.DQN - INFO - episode 5 step 243 reward tensor([-1]) loss 0.8810406923294067 epsilon 0.7184850685945312
26-Feb-25 09:39:33 - agent.DQN.DQN - INFO - episode 5 step 244 reward tensor([-1]) loss 0.9488977789878845 epsilon 0.7184850685945312
26-Feb-25 09:39:33 - agent.DQN.DQN - INFO - episode 5 step 245 reward tensor([-1]) loss 0.6386274695396423 epsilon 0.7184850685945312
26-Feb-25 09:39:33 - agent.DQN.DQN - INFO - episode 5 step 246 reward tensor([-1]) loss 0.7589829564094543 epsilon 0.7184850685945312
26-Feb-25 09:39:33 - agent.DQN.DQN - INFO - episode 5 step 247 reward tensor([-1]) loss 0.8263285160064697 epsilon 0.7184850685945312
26-Feb-25 09:39:33 - agent.DQN.DQN - INFO - episode 5 step 248 reward tensor([-1]) loss 0.6986289024353027 epsilon 0.7184850685945312
26-Feb-25 09:39:33 - agent.DQN.DQN - INFO - episode 5 step 249 reward tensor([-1]) loss 0.8619130253791809 epsilon 0.7184850685945312
26-Feb-25 09:39:33 - agent.DQN.DQN - INFO - episode 5 step 250 reward tensor([-1]) loss 0.7059557437896729 epsilon 0.7184850685945312
26-Feb-25 09:39:33 - agent.DQN.DQN - INFO - episode 5 step 251 reward tensor([-1]) loss 0.7909632921218872 epsilon 0.7184850685945312
26-Feb-25 09:39:33 - agent.DQN.DQN - INFO - episode 5 step 252 reward tensor([-1]) loss 0.7701597809791565 epsilon 0.7184850685945312
26-Feb-25 09:39:33 - agent.DQN.DQN - INFO - episode 5 step 253 reward tensor([-1]) loss 0.7181668877601624 epsilon 0.7184850685945312
26-Feb-25 09:39:33 - agent.DQN.DQN - INFO - episode 5 step 254 reward tensor([-1]) loss 0.5993820428848267 epsilon 0.7184850685945312
26-Feb-25 09:39:33 - agent.DQN.DQN - INFO - episode 5 step 255 reward tensor([-1]) loss 0.8117966651916504 epsilon 0.7184850685945312
26-Feb-25 09:39:33 - agent.DQN.DQN - INFO - episode 5 step 256 reward tensor([-1]) loss 0.7806025147438049 epsilon 0.7184850685945312
26-Feb-25 09:39:33 - agent.DQN.DQN - INFO - episode 5 step 257 reward tensor([-1]) loss 0.5485227704048157 epsilon 0.7184850685945312
26-Feb-25 09:39:33 - agent.DQN.DQN - INFO - episode 5 step 258 reward tensor([-1]) loss 0.7836213707923889 epsilon 0.7184850685945312
26-Feb-25 09:39:33 - agent.DQN.DQN - INFO - episode 5 step 259 reward tensor([-1]) loss 0.7385185956954956 epsilon 0.7184850685945312
26-Feb-25 09:39:33 - agent.DQN.DQN - INFO - episode 5 step 260 reward tensor([-1]) loss 0.5623740553855896 epsilon 0.7184850685945312
26-Feb-25 09:39:33 - agent.DQN.DQN - INFO - episode 5 step 261 reward tensor([-1]) loss 0.8328166007995605 epsilon 0.7184850685945312
26-Feb-25 09:39:33 - agent.DQN.DQN - INFO - episode 5 step 262 reward tensor([-1]) loss 0.9230700135231018 epsilon 0.7184850685945312
26-Feb-25 09:39:33 - agent.DQN.DQN - INFO - episode 5 step 263 reward tensor([-1]) loss 0.9676193594932556 epsilon 0.7184850685945312
26-Feb-25 09:39:33 - agent.DQN.DQN - INFO - episode 5 step 264 reward tensor([-1]) loss 0.7726055383682251 epsilon 0.7184850685945312
26-Feb-25 09:39:33 - agent.DQN.DQN - INFO - episode 5 step 265 reward tensor([-1]) loss 1.0218088626861572 epsilon 0.7184850685945312
26-Feb-25 09:39:33 - agent.DQN.DQN - INFO - episode 5 step 266 reward tensor([-1]) loss 0.5115777254104614 epsilon 0.7184850685945312
26-Feb-25 09:39:33 - agent.DQN.DQN - INFO - episode 5 step 267 reward tensor([-1]) loss 0.6410973072052002 epsilon 0.7184850685945312
26-Feb-25 09:39:33 - agent.DQN.DQN - INFO - episode 5 step 268 reward tensor([-1]) loss 0.7815034985542297 epsilon 0.7184850685945312
26-Feb-25 09:39:33 - agent.DQN.DQN - INFO - episode 5 step 269 reward tensor([-1]) loss 0.6172940731048584 epsilon 0.7184850685945312
26-Feb-25 09:39:33 - agent.DQN.DQN - INFO - episode 5 step 270 reward tensor([-1]) loss 0.5917478799819946 epsilon 0.7184850685945312
26-Feb-25 09:39:33 - agent.DQN.DQN - INFO - episode 5 step 271 reward tensor([-1]) loss 0.7252156734466553 epsilon 0.7184850685945312
26-Feb-25 09:39:33 - agent.DQN.DQN - INFO - episode 5 step 272 reward tensor([-1]) loss 0.4737270474433899 epsilon 0.7184850685945312
26-Feb-25 09:39:33 - agent.DQN.DQN - INFO - episode 5 step 273 reward tensor([-1]) loss 0.8114279508590698 epsilon 0.7184850685945312
26-Feb-25 09:39:33 - agent.DQN.DQN - INFO - episode 5 step 274 reward tensor([-1]) loss 0.468863844871521 epsilon 0.7184850685945312
26-Feb-25 09:39:33 - agent.DQN.DQN - INFO - episode 5 step 275 reward tensor([-1]) loss 0.5947526693344116 epsilon 0.7184850685945312
26-Feb-25 09:39:33 - agent.DQN.DQN - INFO - episode 5 step 276 reward tensor([-1]) loss 0.6861320734024048 epsilon 0.7184850685945312
26-Feb-25 09:39:33 - agent.DQN.DQN - INFO - episode 5 step 277 reward tensor([-1]) loss 0.45466697216033936 epsilon 0.7184850685945312
26-Feb-25 09:39:33 - agent.DQN.DQN - INFO - episode 5 step 278 reward tensor([-1]) loss 0.756942629814148 epsilon 0.7184850685945312
26-Feb-25 09:39:33 - agent.DQN.DQN - INFO - episode 5 step 279 reward tensor([-1]) loss 0.7220379114151001 epsilon 0.7184850685945312
26-Feb-25 09:39:33 - agent.DQN.DQN - INFO - episode 5 step 280 reward tensor([-1]) loss 0.611545979976654 epsilon 0.7184850685945312
26-Feb-25 09:39:33 - agent.DQN.DQN - INFO - episode 5 step 281 reward tensor([-1]) loss 0.760215699672699 epsilon 0.7184850685945312
26-Feb-25 09:39:33 - agent.DQN.DQN - INFO - episode 5 step 282 reward tensor([-1]) loss 0.6845676898956299 epsilon 0.7184850685945312
26-Feb-25 09:39:33 - agent.DQN.DQN - INFO - episode 5 step 283 reward tensor([-1]) loss 0.8137688636779785 epsilon 0.7184850685945312
26-Feb-25 09:39:33 - agent.DQN.DQN - INFO - episode 5 step 284 reward tensor([-1]) loss 0.7487522959709167 epsilon 0.7184850685945312
26-Feb-25 09:39:33 - agent.DQN.DQN - INFO - episode 5 step 285 reward tensor([-1]) loss 0.632523775100708 epsilon 0.7184850685945312
26-Feb-25 09:39:33 - agent.DQN.DQN - INFO - episode 5 step 286 reward tensor([-1]) loss 0.6162081360816956 epsilon 0.7184850685945312
26-Feb-25 09:39:33 - agent.DQN.DQN - INFO - episode 5 step 287 reward tensor([-1]) loss 0.9630693793296814 epsilon 0.7184850685945312
26-Feb-25 09:39:33 - agent.DQN.DQN - INFO - episode 5 step 288 reward tensor([-1]) loss 0.6749960780143738 epsilon 0.7184850685945312
26-Feb-25 09:39:33 - agent.DQN.DQN - INFO - episode 5 step 289 reward tensor([-1]) loss 0.48324501514434814 epsilon 0.7184850685945312
26-Feb-25 09:39:33 - agent.DQN.DQN - INFO - episode 5 step 290 reward tensor([-1]) loss 0.42576462030410767 epsilon 0.7184850685945312
26-Feb-25 09:39:33 - agent.DQN.DQN - INFO - episode 5 step 291 reward tensor([-1]) loss 0.4811590313911438 epsilon 0.7184850685945312
26-Feb-25 09:39:33 - agent.DQN.DQN - INFO - episode 5 step 292 reward tensor([-1]) loss 0.48732683062553406 epsilon 0.7184850685945312
26-Feb-25 09:39:33 - agent.DQN.DQN - INFO - episode 5 step 293 reward tensor([-1]) loss 0.6446949243545532 epsilon 0.7184850685945312
26-Feb-25 09:39:33 - agent.DQN.DQN - INFO - episode 5 step 294 reward tensor([-1]) loss 0.6236193180084229 epsilon 0.7184850685945312
26-Feb-25 09:39:33 - agent.DQN.DQN - INFO - episode 5 step 295 reward tensor([-1]) loss 0.8112649917602539 epsilon 0.7184850685945312
26-Feb-25 09:39:33 - agent.DQN.DQN - INFO - episode 5 step 296 reward tensor([-1]) loss 0.5548836588859558 epsilon 0.7184850685945312
26-Feb-25 09:39:33 - agent.DQN.DQN - INFO - episode 5 step 297 reward tensor([-1]) loss 0.7070665955543518 epsilon 0.7184850685945312
26-Feb-25 09:39:33 - agent.DQN.DQN - INFO - episode 5 step 298 reward tensor([-1]) loss 0.5956154465675354 epsilon 0.7184850685945312
26-Feb-25 09:39:33 - agent.DQN.DQN - INFO - episode 5 step 299 reward tensor([-1]) loss 0.6894967555999756 epsilon 0.7184850685945312
26-Feb-25 09:39:33 - agent.DQN.DQN - INFO - episode 5 step 300 reward tensor([-1]) loss 0.5535603165626526 epsilon 0.7184850685945312
26-Feb-25 09:39:33 - agent.DQN.DQN - INFO - episode 5 step 301 reward tensor([-1]) loss 0.5034372210502625 epsilon 0.7184850685945312
26-Feb-25 09:39:33 - agent.DQN.DQN - INFO - episode 6 step 0 reward tensor([-1]) loss 0.5531038641929626 epsilon 0.6951343038652089
26-Feb-25 09:39:33 - agent.DQN.DQN - INFO - episode 6 step 1 reward tensor([-1]) loss 0.5492232441902161 epsilon 0.6951343038652089
26-Feb-25 09:39:33 - agent.DQN.DQN - INFO - episode 6 step 2 reward tensor([-1]) loss 0.4547027051448822 epsilon 0.6951343038652089
26-Feb-25 09:39:34 - agent.DQN.DQN - INFO - episode 6 step 3 reward tensor([-1]) loss 0.4625891447067261 epsilon 0.6951343038652089
26-Feb-25 09:39:34 - agent.DQN.DQN - INFO - episode 6 step 4 reward tensor([-1]) loss 0.5588730573654175 epsilon 0.6951343038652089
26-Feb-25 09:39:34 - agent.DQN.DQN - INFO - episode 6 step 5 reward tensor([-1]) loss 0.47648754715919495 epsilon 0.6951343038652089
26-Feb-25 09:39:34 - agent.DQN.DQN - INFO - episode 6 step 6 reward tensor([-1]) loss 0.5857385396957397 epsilon 0.6951343038652089
26-Feb-25 09:39:34 - agent.DQN.DQN - INFO - episode 6 step 7 reward tensor([-1]) loss 0.4588831961154938 epsilon 0.6951343038652089
26-Feb-25 09:39:34 - agent.DQN.DQN - INFO - episode 6 step 8 reward tensor([-1]) loss 0.6508905291557312 epsilon 0.6951343038652089
26-Feb-25 09:39:34 - agent.DQN.DQN - INFO - episode 6 step 9 reward tensor([-1]) loss 0.5091274380683899 epsilon 0.6951343038652089
26-Feb-25 09:39:34 - agent.DQN.DQN - INFO - episode 6 step 10 reward tensor([-1]) loss 0.5782081484794617 epsilon 0.6951343038652089
26-Feb-25 09:39:34 - agent.DQN.DQN - INFO - episode 6 step 11 reward tensor([-1]) loss 0.5189805030822754 epsilon 0.6951343038652089
26-Feb-25 09:39:34 - agent.DQN.DQN - INFO - episode 6 step 12 reward tensor([-1]) loss 0.6968929767608643 epsilon 0.6951343038652089
26-Feb-25 09:39:34 - agent.DQN.DQN - INFO - episode 6 step 13 reward tensor([-1]) loss 0.49249497056007385 epsilon 0.6951343038652089
26-Feb-25 09:39:34 - agent.DQN.DQN - INFO - episode 6 step 14 reward tensor([-1]) loss 0.4699851870536804 epsilon 0.6951343038652089
26-Feb-25 09:39:34 - agent.DQN.DQN - INFO - episode 6 step 15 reward tensor([-1]) loss 0.48252904415130615 epsilon 0.6951343038652089
26-Feb-25 09:39:34 - agent.DQN.DQN - INFO - episode 6 step 16 reward tensor([-1]) loss 0.4764317572116852 epsilon 0.6951343038652089
26-Feb-25 09:39:34 - agent.DQN.DQN - INFO - episode 6 step 17 reward tensor([-1]) loss 0.5507665276527405 epsilon 0.6951343038652089
26-Feb-25 09:39:34 - agent.DQN.DQN - INFO - episode 6 step 18 reward tensor([-1]) loss 0.5140784382820129 epsilon 0.6951343038652089
26-Feb-25 09:39:34 - agent.DQN.DQN - INFO - episode 6 step 19 reward tensor([-1]) loss 0.6309902667999268 epsilon 0.6951343038652089
26-Feb-25 09:39:34 - agent.DQN.DQN - INFO - episode 6 step 20 reward tensor([-1]) loss 0.5965867042541504 epsilon 0.6951343038652089
26-Feb-25 09:39:34 - agent.DQN.DQN - INFO - episode 6 step 21 reward tensor([-1]) loss 0.5141205787658691 epsilon 0.6951343038652089
26-Feb-25 09:39:34 - agent.DQN.DQN - INFO - episode 6 step 22 reward tensor([-1]) loss 0.5788175463676453 epsilon 0.6951343038652089
26-Feb-25 09:39:34 - agent.DQN.DQN - INFO - episode 6 step 23 reward tensor([-1]) loss 0.5992929339408875 epsilon 0.6951343038652089
26-Feb-25 09:39:34 - agent.DQN.DQN - INFO - episode 6 step 24 reward tensor([-1]) loss 0.5266687273979187 epsilon 0.6951343038652089
26-Feb-25 09:39:34 - agent.DQN.DQN - INFO - episode 6 step 25 reward tensor([-1]) loss 0.6947085857391357 epsilon 0.6951343038652089
26-Feb-25 09:39:34 - agent.DQN.DQN - INFO - episode 6 step 26 reward tensor([-1]) loss 0.42951440811157227 epsilon 0.6951343038652089
26-Feb-25 09:39:34 - agent.DQN.DQN - INFO - episode 6 step 27 reward tensor([-1]) loss 0.8132452368736267 epsilon 0.6951343038652089
26-Feb-25 09:39:34 - agent.DQN.DQN - INFO - episode 6 step 28 reward tensor([-1]) loss 0.5894516706466675 epsilon 0.6951343038652089
26-Feb-25 09:39:34 - agent.DQN.DQN - INFO - episode 6 step 29 reward tensor([-1]) loss 0.4207448959350586 epsilon 0.6951343038652089
26-Feb-25 09:39:34 - agent.DQN.DQN - INFO - episode 6 step 30 reward tensor([-1]) loss 0.5638414621353149 epsilon 0.6951343038652089
26-Feb-25 09:39:34 - agent.DQN.DQN - INFO - episode 6 step 31 reward tensor([-1]) loss 0.5808319449424744 epsilon 0.6951343038652089
26-Feb-25 09:39:34 - agent.DQN.DQN - INFO - episode 6 step 32 reward tensor([-1]) loss 0.4413273334503174 epsilon 0.6951343038652089
26-Feb-25 09:39:34 - agent.DQN.DQN - INFO - episode 6 step 33 reward tensor([-1]) loss 0.7491768002510071 epsilon 0.6951343038652089
26-Feb-25 09:39:34 - agent.DQN.DQN - INFO - episode 6 step 34 reward tensor([-1]) loss 0.5166602730751038 epsilon 0.6951343038652089
26-Feb-25 09:39:34 - agent.DQN.DQN - INFO - episode 6 step 35 reward tensor([-1]) loss 0.4929187595844269 epsilon 0.6951343038652089
26-Feb-25 09:39:34 - agent.DQN.DQN - INFO - episode 6 step 36 reward tensor([-1]) loss 0.4553092122077942 epsilon 0.6951343038652089
26-Feb-25 09:39:34 - agent.DQN.DQN - INFO - episode 6 step 37 reward tensor([-1]) loss 0.6194148063659668 epsilon 0.6951343038652089
26-Feb-25 09:39:34 - agent.DQN.DQN - INFO - episode 6 step 38 reward tensor([-1]) loss 0.6082299947738647 epsilon 0.6951343038652089
26-Feb-25 09:39:34 - agent.DQN.DQN - INFO - episode 6 step 39 reward tensor([-1]) loss 0.4460117220878601 epsilon 0.6951343038652089
26-Feb-25 09:39:34 - agent.DQN.DQN - INFO - episode 6 step 40 reward tensor([-1]) loss 0.4475896954536438 epsilon 0.6951343038652089
26-Feb-25 09:39:34 - agent.DQN.DQN - INFO - episode 6 step 41 reward tensor([-1]) loss 0.4005650281906128 epsilon 0.6951343038652089
26-Feb-25 09:39:34 - agent.DQN.DQN - INFO - episode 6 step 42 reward tensor([-1]) loss 0.5545771718025208 epsilon 0.6951343038652089
26-Feb-25 09:39:34 - agent.DQN.DQN - INFO - episode 6 step 43 reward tensor([-1]) loss 0.7316575646400452 epsilon 0.6951343038652089
26-Feb-25 09:39:34 - agent.DQN.DQN - INFO - episode 6 step 44 reward tensor([-1]) loss 0.39038971066474915 epsilon 0.6951343038652089
26-Feb-25 09:39:34 - agent.DQN.DQN - INFO - episode 6 step 45 reward tensor([-1]) loss 0.31684839725494385 epsilon 0.6951343038652089
26-Feb-25 09:39:34 - agent.DQN.DQN - INFO - episode 6 step 46 reward tensor([-1]) loss 0.42201799154281616 epsilon 0.6951343038652089
26-Feb-25 09:39:34 - agent.DQN.DQN - INFO - episode 6 step 47 reward tensor([-1]) loss 0.4262179434299469 epsilon 0.6951343038652089
26-Feb-25 09:39:34 - agent.DQN.DQN - INFO - episode 6 step 48 reward tensor([-1]) loss 0.4757307171821594 epsilon 0.6951343038652089
26-Feb-25 09:39:34 - agent.DQN.DQN - INFO - episode 6 step 49 reward tensor([-1]) loss 0.5496557950973511 epsilon 0.6951343038652089
26-Feb-25 09:39:34 - agent.DQN.DQN - INFO - episode 6 step 50 reward tensor([-1]) loss 0.8560947179794312 epsilon 0.6951343038652089
26-Feb-25 09:39:34 - agent.DQN.DQN - INFO - episode 6 step 51 reward tensor([-1]) loss 0.6558516025543213 epsilon 0.6951343038652089
26-Feb-25 09:39:34 - agent.DQN.DQN - INFO - episode 6 step 52 reward tensor([-1]) loss 0.4928499460220337 epsilon 0.6951343038652089
26-Feb-25 09:39:34 - agent.DQN.DQN - INFO - episode 6 step 53 reward tensor([-1]) loss 0.3625750243663788 epsilon 0.6951343038652089
26-Feb-25 09:39:34 - agent.DQN.DQN - INFO - episode 6 step 54 reward tensor([-1]) loss 0.4011304974555969 epsilon 0.6951343038652089
26-Feb-25 09:39:34 - agent.DQN.DQN - INFO - episode 6 step 55 reward tensor([-1]) loss 0.57140052318573 epsilon 0.6951343038652089
26-Feb-25 09:39:34 - agent.DQN.DQN - INFO - episode 6 step 56 reward tensor([-1]) loss 0.4372667372226715 epsilon 0.6951343038652089
26-Feb-25 09:39:34 - agent.DQN.DQN - INFO - episode 6 step 57 reward tensor([-1]) loss 1.097062110900879 epsilon 0.6951343038652089
26-Feb-25 09:39:34 - agent.DQN.DQN - INFO - episode 6 step 58 reward tensor([-1]) loss 0.7158949971199036 epsilon 0.6951343038652089
26-Feb-25 09:39:34 - agent.DQN.DQN - INFO - episode 6 step 59 reward tensor([-1]) loss 0.44537705183029175 epsilon 0.6951343038652089
26-Feb-25 09:39:34 - agent.DQN.DQN - INFO - episode 6 step 60 reward tensor([-1]) loss 0.6288519501686096 epsilon 0.6951343038652089
26-Feb-25 09:39:34 - agent.DQN.DQN - INFO - episode 6 step 61 reward tensor([-1]) loss 0.4944709837436676 epsilon 0.6951343038652089
26-Feb-25 09:39:34 - agent.DQN.DQN - INFO - episode 6 step 62 reward tensor([-1]) loss 0.4526725709438324 epsilon 0.6951343038652089
